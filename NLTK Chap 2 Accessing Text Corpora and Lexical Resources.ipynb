{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 2. Accessing Text Corpora and Lexical Resources\n",
    "\n",
    "Natural Language Processing with Python, by Steven Bird, Ewan Klein, and Edward Loper. \n",
    "\n",
    "O'Reilly Media, 978-0-596-51649-9.\n",
    "\n",
    "## 1   Accessing Text Corpora\n",
    "\n",
    "### 1.1   Gutenberg Corpus"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['austen-emma.txt',\n",
       " 'austen-persuasion.txt',\n",
       " 'austen-sense.txt',\n",
       " 'bible-kjv.txt',\n",
       " 'blake-poems.txt',\n",
       " 'bryant-stories.txt',\n",
       " 'burgess-busterbrown.txt',\n",
       " 'carroll-alice.txt',\n",
       " 'chesterton-ball.txt',\n",
       " 'chesterton-brown.txt',\n",
       " 'chesterton-thursday.txt',\n",
       " 'edgeworth-parents.txt',\n",
       " 'melville-moby_dick.txt',\n",
       " 'milton-paradise.txt',\n",
       " 'shakespeare-caesar.txt',\n",
       " 'shakespeare-hamlet.txt',\n",
       " 'shakespeare-macbeth.txt',\n",
       " 'whitman-leaves.txt']"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import nltk\n",
    "nltk.corpus.gutenberg.fileids()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "192427"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "emma = nltk.corpus.gutenberg.words('austen-emma.txt')\n",
    "len(emma)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Displaying 25 of 37 matches:\n",
      "er father , was sometimes taken by surprize at his being still able to pity ` \n",
      "hem do the other any good .\" \" You surprize me ! Emma must do Harriet good : a\n",
      "Knightley actually looked red with surprize and displeasure , as he stood up ,\n",
      "r . Elton , and found to his great surprize , that Mr . Elton was actually on \n",
      "d aid .\" Emma saw Mrs . Weston ' s surprize , and felt that it must be great ,\n",
      "father was quite taken up with the surprize of so sudden a journey , and his f\n",
      "y , in all the favouring warmth of surprize and conjecture . She was , moreove\n",
      "he appeared , to have her share of surprize , introduction , and pleasure . Th\n",
      "ir plans ; and it was an agreeable surprize to her , therefore , to perceive t\n",
      "talking aunt had taken me quite by surprize , it must have been the death of m\n",
      "f all the dialogue which ensued of surprize , and inquiry , and congratulation\n",
      " the present . They might chuse to surprize her .\" Mrs . Cole had many to agre\n",
      "the mode of it , the mystery , the surprize , is more like a young woman ' s s\n",
      " to her song took her agreeably by surprize -- a second , slightly but correct\n",
      "\" \" Oh ! no -- there is nothing to surprize one at all .-- A pretty fortune ; \n",
      "t to be considered . Emma ' s only surprize was that Jane Fairfax should accep\n",
      "of your admiration may take you by surprize some day or other .\" Mr . Knightle\n",
      "ation for her will ever take me by surprize .-- I never had a thought of her i\n",
      " expected by the best judges , for surprize -- but there was great joy . Mr . \n",
      " sound of at first , without great surprize . \" So unreasonably early !\" she w\n",
      "d Frank Churchill , with a look of surprize and displeasure .-- \" That is easy\n",
      "; and Emma could imagine with what surprize and mortification she must be retu\n",
      "tled that Jane should go . Quite a surprize to me ! I had not the least idea !\n",
      " . It is impossible to express our surprize . He came to speak to his father o\n",
      "g engaged !\" Emma even jumped with surprize ;-- and , horror - struck , exclai\n"
     ]
    }
   ],
   "source": [
    "emma = nltk.Text(nltk.corpus.gutenberg.words('austen-emma.txt'))\n",
    "emma.concordance(\"surprize\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "moby = nltk.corpus.gutenberg.words('whitman-leaves.txt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "'StreamBackedCorpusView' object has no attribute 'concordance'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-5-296ebd35b9a7>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mmoby\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mconcordance\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"whale\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;31mAttributeError\u001b[0m: 'StreamBackedCorpusView' object has no attribute 'concordance'"
     ]
    }
   ],
   "source": [
    "moby.concordance(\"whale\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Displaying 5 of 5 matches:\n",
      " arm , The mate stands braced in the whale - boat , lance and harpoon are ready\n",
      "in the dented sand , Where the she - whale swims with her calf and never forsak\n",
      "e the porpoise - hunters , I see the whale - crews of the south Pacific and the\n",
      "ain far out in the ocean the wounded whale , settling , running to windward , t\n",
      "ng close to the bottom , The sperm - whale at the surface blowing air and spray\n"
     ]
    }
   ],
   "source": [
    "moby = nltk.Text(nltk.corpus.gutenberg.words('whitman-leaves.txt'))\n",
    "moby.concordance(\"whale\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['austen-emma.txt',\n",
       " 'austen-persuasion.txt',\n",
       " 'austen-sense.txt',\n",
       " 'bible-kjv.txt',\n",
       " 'blake-poems.txt',\n",
       " 'bryant-stories.txt',\n",
       " 'burgess-busterbrown.txt',\n",
       " 'carroll-alice.txt',\n",
       " 'chesterton-ball.txt',\n",
       " 'chesterton-brown.txt',\n",
       " 'chesterton-thursday.txt',\n",
       " 'edgeworth-parents.txt',\n",
       " 'melville-moby_dick.txt',\n",
       " 'milton-paradise.txt',\n",
       " 'shakespeare-caesar.txt',\n",
       " 'shakespeare-hamlet.txt',\n",
       " 'shakespeare-macbeth.txt',\n",
       " 'whitman-leaves.txt']"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from nltk.corpus import gutenberg\n",
    "gutenberg.fileids()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "emma = gutenberg.words('austen-emma.txt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['AlignedCorpusReader',\n",
       " 'AlpinoCorpusReader',\n",
       " 'BNCCorpusReader',\n",
       " 'BracketParseCorpusReader',\n",
       " 'CHILDESCorpusReader',\n",
       " 'CMUDictCorpusReader',\n",
       " 'CategorizedBracketParseCorpusReader',\n",
       " 'CategorizedCorpusReader',\n",
       " 'CategorizedPlaintextCorpusReader',\n",
       " 'CategorizedSentencesCorpusReader',\n",
       " 'CategorizedTaggedCorpusReader',\n",
       " 'ChasenCorpusReader',\n",
       " 'ChunkedCorpusReader',\n",
       " 'ComparativeSentencesCorpusReader',\n",
       " 'ConllChunkCorpusReader',\n",
       " 'ConllCorpusReader',\n",
       " 'CorpusReader',\n",
       " 'CrubadanCorpusReader',\n",
       " 'DependencyCorpusReader',\n",
       " 'EuroparlCorpusReader',\n",
       " 'FramenetCorpusReader',\n",
       " 'IEERCorpusReader',\n",
       " 'IPIPANCorpusReader',\n",
       " 'IndianCorpusReader',\n",
       " 'KNBCorpusReader',\n",
       " 'LazyCorpusLoader',\n",
       " 'LinThesaurusCorpusReader',\n",
       " 'MTECorpusReader',\n",
       " 'MWAPPDBCorpusReader',\n",
       " 'MacMorphoCorpusReader',\n",
       " 'NKJPCorpusReader',\n",
       " 'NPSChatCorpusReader',\n",
       " 'NombankCorpusReader',\n",
       " 'NonbreakingPrefixesCorpusReader',\n",
       " 'OpinionLexiconCorpusReader',\n",
       " 'PPAttachmentCorpusReader',\n",
       " 'PanLexLiteCorpusReader',\n",
       " 'PanlexSwadeshCorpusReader',\n",
       " 'Pl196xCorpusReader',\n",
       " 'PlaintextCorpusReader',\n",
       " 'PortugueseCategorizedPlaintextCorpusReader',\n",
       " 'PropbankCorpusReader',\n",
       " 'ProsConsCorpusReader',\n",
       " 'RTECorpusReader',\n",
       " 'RegexpTokenizer',\n",
       " 'ReviewsCorpusReader',\n",
       " 'SemcorCorpusReader',\n",
       " 'SensevalCorpusReader',\n",
       " 'SentiSynset',\n",
       " 'SentiWordNetCorpusReader',\n",
       " 'SinicaTreebankCorpusReader',\n",
       " 'StringCategoryCorpusReader',\n",
       " 'SwadeshCorpusReader',\n",
       " 'SwitchboardCorpusReader',\n",
       " 'SyntaxCorpusReader',\n",
       " 'TEICorpusView',\n",
       " 'TaggedCorpusReader',\n",
       " 'TimitCorpusReader',\n",
       " 'TimitTaggedCorpusReader',\n",
       " 'ToolboxCorpusReader',\n",
       " 'TwitterCorpusReader',\n",
       " 'UdhrCorpusReader',\n",
       " 'UnicharsCorpusReader',\n",
       " 'VerbnetCorpusReader',\n",
       " 'WordListCorpusReader',\n",
       " 'WordNetCorpusReader',\n",
       " 'WordNetICCorpusReader',\n",
       " 'XMLCorpusReader',\n",
       " 'YCOECorpusReader',\n",
       " '_LazyModule__lazymodule_globals',\n",
       " '_LazyModule__lazymodule_import',\n",
       " '_LazyModule__lazymodule_init',\n",
       " '_LazyModule__lazymodule_loaded',\n",
       " '_LazyModule__lazymodule_locals',\n",
       " '_LazyModule__lazymodule_name',\n",
       " '__builtins__',\n",
       " '__cached__',\n",
       " '__class__',\n",
       " '__delattr__',\n",
       " '__dict__',\n",
       " '__dir__',\n",
       " '__doc__',\n",
       " '__eq__',\n",
       " '__file__',\n",
       " '__format__',\n",
       " '__ge__',\n",
       " '__getattr__',\n",
       " '__getattribute__',\n",
       " '__gt__',\n",
       " '__hash__',\n",
       " '__init__',\n",
       " '__init_subclass__',\n",
       " '__lazymodule_loaded',\n",
       " '__le__',\n",
       " '__loader__',\n",
       " '__lt__',\n",
       " '__module__',\n",
       " '__name__',\n",
       " '__ne__',\n",
       " '__new__',\n",
       " '__package__',\n",
       " '__path__',\n",
       " '__reduce__',\n",
       " '__reduce_ex__',\n",
       " '__repr__',\n",
       " '__setattr__',\n",
       " '__sizeof__',\n",
       " '__spec__',\n",
       " '__str__',\n",
       " '__subclasshook__',\n",
       " '__weakref__',\n",
       " 'abc',\n",
       " 'alpino',\n",
       " 'brown',\n",
       " 'cess_cat',\n",
       " 'cess_esp',\n",
       " 'cmudict',\n",
       " 'comparative_sentences',\n",
       " 'comtrans',\n",
       " 'conll2000',\n",
       " 'conll2002',\n",
       " 'conll2007',\n",
       " 'crubadan',\n",
       " 'demo',\n",
       " 'dependency_treebank',\n",
       " 'find_corpus_fileids',\n",
       " 'floresta',\n",
       " 'framenet',\n",
       " 'framenet15',\n",
       " 'gazetteers',\n",
       " 'genesis',\n",
       " 'gutenberg',\n",
       " 'ieer',\n",
       " 'inaugural',\n",
       " 'indian',\n",
       " 'jeita',\n",
       " 'knbc',\n",
       " 'lin_thesaurus',\n",
       " 'mac_morpho',\n",
       " 'machado',\n",
       " 'masc_tagged',\n",
       " 'movie_reviews',\n",
       " 'multext_east',\n",
       " 'names',\n",
       " 'nombank',\n",
       " 'nombank_ptb',\n",
       " 'nonbreaking_prefixes',\n",
       " 'nps_chat',\n",
       " 'opinion_lexicon',\n",
       " 'perluniprops',\n",
       " 'ppattach',\n",
       " 'product_reviews_1',\n",
       " 'product_reviews_2',\n",
       " 'propbank',\n",
       " 'propbank_ptb',\n",
       " 'pros_cons',\n",
       " 'ptb',\n",
       " 'qc',\n",
       " 're',\n",
       " 'reader',\n",
       " 'reuters',\n",
       " 'rte',\n",
       " 'semcor',\n",
       " 'senseval',\n",
       " 'sentence_polarity',\n",
       " 'sentiwordnet',\n",
       " 'shakespeare',\n",
       " 'sinica_treebank',\n",
       " 'state_union',\n",
       " 'stopwords',\n",
       " 'subjectivity',\n",
       " 'swadesh',\n",
       " 'swadesh110',\n",
       " 'swadesh207',\n",
       " 'switchboard',\n",
       " 'tagged_treebank_para_block_reader',\n",
       " 'teardown_module',\n",
       " 'timit',\n",
       " 'timit_tagged',\n",
       " 'toolbox',\n",
       " 'treebank',\n",
       " 'treebank_chunk',\n",
       " 'treebank_raw',\n",
       " 'twitter_samples',\n",
       " 'udhr',\n",
       " 'udhr2',\n",
       " 'universal_treebanks',\n",
       " 'util',\n",
       " 'verbnet',\n",
       " 'webtext',\n",
       " 'wordnet',\n",
       " 'wordnet_ic',\n",
       " 'words']"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dir(nltk.corpus)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5 25 26 austen-emma.txt\n",
      "5 26 17 austen-persuasion.txt\n",
      "5 28 22 austen-sense.txt\n",
      "4 34 79 bible-kjv.txt\n",
      "5 19 5 blake-poems.txt\n",
      "4 19 14 bryant-stories.txt\n",
      "4 18 12 burgess-busterbrown.txt\n",
      "4 20 13 carroll-alice.txt\n",
      "5 20 12 chesterton-ball.txt\n",
      "5 23 11 chesterton-brown.txt\n",
      "5 18 11 chesterton-thursday.txt\n",
      "4 21 25 edgeworth-parents.txt\n",
      "5 26 15 melville-moby_dick.txt\n",
      "5 52 11 milton-paradise.txt\n",
      "4 12 9 shakespeare-caesar.txt\n",
      "4 12 8 shakespeare-hamlet.txt\n",
      "4 12 7 shakespeare-macbeth.txt\n",
      "5 36 12 whitman-leaves.txt\n"
     ]
    }
   ],
   "source": [
    "for fileid in gutenberg.fileids():\n",
    "    num_chars = len(gutenberg.raw(fileid)) #how many letters occur in the text, including the spaces between words\n",
    "    num_words = len(gutenberg.words(fileid))\n",
    "    num_sents = len(gutenberg.sents(fileid)) # divides the text up into its sentences, where each sentence is a list of words\n",
    "    num_vocab = len(set(w.lower() for w in gutenberg.words(fileid)))\n",
    "    print(round(num_chars/num_words), round(num_words/num_sents), round(num_words/num_vocab), fileid)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[['[', 'The', 'Tragedie', 'of', 'Macbeth', 'by', 'William', 'Shakespeare', '1603', ']'], ['Actus', 'Primus', '.'], ...]"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "macbeth_sentences = gutenberg.sents('shakespeare-macbeth.txt')\n",
    "macbeth_sentences"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Double',\n",
       " ',',\n",
       " 'double',\n",
       " ',',\n",
       " 'toile',\n",
       " 'and',\n",
       " 'trouble',\n",
       " ';',\n",
       " 'Fire',\n",
       " 'burne',\n",
       " ',',\n",
       " 'and',\n",
       " 'Cauldron',\n",
       " 'bubble']"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "macbeth_sentences[1116]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "longest_len = max(len(s) for s in macbeth_sentences)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "158"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "longest_len"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[['Doubtfull',\n",
       "  'it',\n",
       "  'stood',\n",
       "  ',',\n",
       "  'As',\n",
       "  'two',\n",
       "  'spent',\n",
       "  'Swimmers',\n",
       "  ',',\n",
       "  'that',\n",
       "  'doe',\n",
       "  'cling',\n",
       "  'together',\n",
       "  ',',\n",
       "  'And',\n",
       "  'choake',\n",
       "  'their',\n",
       "  'Art',\n",
       "  ':',\n",
       "  'The',\n",
       "  'mercilesse',\n",
       "  'Macdonwald',\n",
       "  '(',\n",
       "  'Worthie',\n",
       "  'to',\n",
       "  'be',\n",
       "  'a',\n",
       "  'Rebell',\n",
       "  ',',\n",
       "  'for',\n",
       "  'to',\n",
       "  'that',\n",
       "  'The',\n",
       "  'multiplying',\n",
       "  'Villanies',\n",
       "  'of',\n",
       "  'Nature',\n",
       "  'Doe',\n",
       "  'swarme',\n",
       "  'vpon',\n",
       "  'him',\n",
       "  ')',\n",
       "  'from',\n",
       "  'the',\n",
       "  'Westerne',\n",
       "  'Isles',\n",
       "  'Of',\n",
       "  'Kernes',\n",
       "  'and',\n",
       "  'Gallowgrosses',\n",
       "  'is',\n",
       "  'supply',\n",
       "  \"'\",\n",
       "  'd',\n",
       "  ',',\n",
       "  'And',\n",
       "  'Fortune',\n",
       "  'on',\n",
       "  'his',\n",
       "  'damned',\n",
       "  'Quarry',\n",
       "  'smiling',\n",
       "  ',',\n",
       "  'Shew',\n",
       "  \"'\",\n",
       "  'd',\n",
       "  'like',\n",
       "  'a',\n",
       "  'Rebells',\n",
       "  'Whore',\n",
       "  ':',\n",
       "  'but',\n",
       "  'all',\n",
       "  \"'\",\n",
       "  's',\n",
       "  'too',\n",
       "  'weake',\n",
       "  ':',\n",
       "  'For',\n",
       "  'braue',\n",
       "  'Macbeth',\n",
       "  '(',\n",
       "  'well',\n",
       "  'hee',\n",
       "  'deserues',\n",
       "  'that',\n",
       "  'Name',\n",
       "  ')',\n",
       "  'Disdayning',\n",
       "  'Fortune',\n",
       "  ',',\n",
       "  'with',\n",
       "  'his',\n",
       "  'brandisht',\n",
       "  'Steele',\n",
       "  ',',\n",
       "  'Which',\n",
       "  'smoak',\n",
       "  \"'\",\n",
       "  'd',\n",
       "  'with',\n",
       "  'bloody',\n",
       "  'execution',\n",
       "  '(',\n",
       "  'Like',\n",
       "  'Valours',\n",
       "  'Minion',\n",
       "  ')',\n",
       "  'caru',\n",
       "  \"'\",\n",
       "  'd',\n",
       "  'out',\n",
       "  'his',\n",
       "  'passage',\n",
       "  ',',\n",
       "  'Till',\n",
       "  'hee',\n",
       "  'fac',\n",
       "  \"'\",\n",
       "  'd',\n",
       "  'the',\n",
       "  'Slaue',\n",
       "  ':',\n",
       "  'Which',\n",
       "  'neu',\n",
       "  \"'\",\n",
       "  'r',\n",
       "  'shooke',\n",
       "  'hands',\n",
       "  ',',\n",
       "  'nor',\n",
       "  'bad',\n",
       "  'farwell',\n",
       "  'to',\n",
       "  'him',\n",
       "  ',',\n",
       "  'Till',\n",
       "  'he',\n",
       "  'vnseam',\n",
       "  \"'\",\n",
       "  'd',\n",
       "  'him',\n",
       "  'from',\n",
       "  'the',\n",
       "  'Naue',\n",
       "  'toth',\n",
       "  \"'\",\n",
       "  'Chops',\n",
       "  ',',\n",
       "  'And',\n",
       "  'fix',\n",
       "  \"'\",\n",
       "  'd',\n",
       "  'his',\n",
       "  'Head',\n",
       "  'vpon',\n",
       "  'our',\n",
       "  'Battlements']]"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "[s for s in macbeth_sentences if len(s) == longest_len]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len([s for s in macbeth_sentences if len(s) == longest_len])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.2   Web and Chat Text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "firefox.txt Cookie Manager: \"Don't allow sites that set removed cookies to se ...\n",
      "grail.txt SCENE 1: [wind] [clop clop clop] \n",
      "KING ARTHUR: Whoa there!  [clop ...\n",
      "overheard.txt White guy: So, do you have any plans for this evening?\n",
      "Asian girl ...\n",
      "pirates.txt PIRATES OF THE CARRIBEAN: DEAD MAN'S CHEST, by Ted Elliott & Terr ...\n",
      "singles.txt 25 SEXY MALE, seeks attrac older single lady, for discreet encoun ...\n",
      "wine.txt Lovely delicate, fragrant Rhone wine. Polished leather and strawb ...\n"
     ]
    }
   ],
   "source": [
    "from nltk.corpus import webtext\n",
    "for fileid in webtext.fileids():\n",
    "    print(fileid, webtext.raw(fileid)[:65], '...')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['i',\n",
       " 'do',\n",
       " \"n't\",\n",
       " 'want',\n",
       " 'hot',\n",
       " 'pics',\n",
       " 'of',\n",
       " 'a',\n",
       " 'female',\n",
       " ',',\n",
       " 'I',\n",
       " 'can',\n",
       " 'look',\n",
       " 'in',\n",
       " 'a',\n",
       " 'mirror',\n",
       " '.']"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from nltk.corpus import nps_chat\n",
    "chatroom = nps_chat.posts('10-19-20s_706posts.xml')\n",
    "chatroom[123]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.3   Brown Corpus"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['adventure',\n",
       " 'belles_lettres',\n",
       " 'editorial',\n",
       " 'fiction',\n",
       " 'government',\n",
       " 'hobbies',\n",
       " 'humor',\n",
       " 'learned',\n",
       " 'lore',\n",
       " 'mystery',\n",
       " 'news',\n",
       " 'religion',\n",
       " 'reviews',\n",
       " 'romance',\n",
       " 'science_fiction']"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from nltk.corpus import brown\n",
    "brown.categories()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['The', 'Fulton', 'County', 'Grand', 'Jury', 'said', ...]"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "brown.words(categories='news')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Does', 'our', 'society', 'have', 'a', 'runaway', ',', ...]"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "brown.words(fileids=['cg22'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[['The', 'Fulton', 'County', 'Grand', 'Jury', 'said', 'Friday', 'an', 'investigation', 'of', \"Atlanta's\", 'recent', 'primary', 'election', 'produced', '``', 'no', 'evidence', \"''\", 'that', 'any', 'irregularities', 'took', 'place', '.'], ['The', 'jury', 'further', 'said', 'in', 'term-end', 'presentments', 'that', 'the', 'City', 'Executive', 'Committee', ',', 'which', 'had', 'over-all', 'charge', 'of', 'the', 'election', ',', '``', 'deserves', 'the', 'praise', 'and', 'thanks', 'of', 'the', 'City', 'of', 'Atlanta', \"''\", 'for', 'the', 'manner', 'in', 'which', 'the', 'election', 'was', 'conducted', '.'], ...]"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "brown.sents(categories=['news', 'editorial', 'reviews'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "can: 94 could: 87 may: 93 might: 38 must: 53 will: 389 "
     ]
    }
   ],
   "source": [
    "from nltk.corpus import brown\n",
    "news_text = brown.words(categories='news')\n",
    "fdist = nltk.FreqDist(w.lower() for w in news_text)\n",
    "modals = ['can', 'could', 'may', 'might', 'must', 'will']\n",
    "for m in modals:\n",
    "    print(m + ':', fdist[m], end=' ')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "can: 94\n",
      "could: 87\n",
      "may: 93\n",
      "might: 38\n",
      "must: 53\n",
      "will: 389\n"
     ]
    }
   ],
   "source": [
    "for m in modals:\n",
    "    print(m + ':', fdist[m], end='\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                  can could   may might  must  will \n",
      "           news    93    86    66    38    50   389 \n",
      "       religion    82    59    78    12    54    71 \n",
      "        hobbies   268    58   131    22    83   264 \n",
      "science_fiction    16    49     4    12     8    16 \n",
      "        romance    74   193    11    51    45    43 \n",
      "          humor    16    30     8     8     9    13 \n"
     ]
    }
   ],
   "source": [
    "cfd = nltk.ConditionalFreqDist(\n",
    "    (genre, word)\n",
    "    for genre in brown.categories()\n",
    "    for word in brown.words(categories=genre))\n",
    "genres = ['news', 'religion', 'hobbies', 'science_fiction', 'romance', 'humor']\n",
    "modals = ['can', 'could', 'may', 'might', 'must', 'will']\n",
    "cfd.tabulate(conditions=genres, samples=modals)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.4   Reuters Corpus"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['test/14826',\n",
       " 'test/14828',\n",
       " 'test/14829',\n",
       " 'test/14832',\n",
       " 'test/14833',\n",
       " 'test/14839',\n",
       " 'test/14840',\n",
       " 'test/14841',\n",
       " 'test/14842',\n",
       " 'test/14843',\n",
       " 'test/14844',\n",
       " 'test/14849',\n",
       " 'test/14852',\n",
       " 'test/14854',\n",
       " 'test/14858',\n",
       " 'test/14859',\n",
       " 'test/14860',\n",
       " 'test/14861',\n",
       " 'test/14862',\n",
       " 'test/14863',\n",
       " 'test/14865',\n",
       " 'test/14867',\n",
       " 'test/14872',\n",
       " 'test/14873',\n",
       " 'test/14875',\n",
       " 'test/14876',\n",
       " 'test/14877',\n",
       " 'test/14881',\n",
       " 'test/14882',\n",
       " 'test/14885',\n",
       " 'test/14886',\n",
       " 'test/14888',\n",
       " 'test/14890',\n",
       " 'test/14891',\n",
       " 'test/14892',\n",
       " 'test/14899',\n",
       " 'test/14900',\n",
       " 'test/14903',\n",
       " 'test/14904',\n",
       " 'test/14907',\n",
       " 'test/14909',\n",
       " 'test/14911',\n",
       " 'test/14912',\n",
       " 'test/14913',\n",
       " 'test/14918',\n",
       " 'test/14919',\n",
       " 'test/14921',\n",
       " 'test/14922',\n",
       " 'test/14923',\n",
       " 'test/14926',\n",
       " 'test/14928',\n",
       " 'test/14930',\n",
       " 'test/14931',\n",
       " 'test/14932',\n",
       " 'test/14933',\n",
       " 'test/14934',\n",
       " 'test/14941',\n",
       " 'test/14943',\n",
       " 'test/14949',\n",
       " 'test/14951',\n",
       " 'test/14954',\n",
       " 'test/14957',\n",
       " 'test/14958',\n",
       " 'test/14959',\n",
       " 'test/14960',\n",
       " 'test/14962',\n",
       " 'test/14963',\n",
       " 'test/14964',\n",
       " 'test/14965',\n",
       " 'test/14967',\n",
       " 'test/14968',\n",
       " 'test/14969',\n",
       " 'test/14970',\n",
       " 'test/14971',\n",
       " 'test/14974',\n",
       " 'test/14975',\n",
       " 'test/14978',\n",
       " 'test/14981',\n",
       " 'test/14982',\n",
       " 'test/14983',\n",
       " 'test/14984',\n",
       " 'test/14985',\n",
       " 'test/14986',\n",
       " 'test/14987',\n",
       " 'test/14988',\n",
       " 'test/14993',\n",
       " 'test/14995',\n",
       " 'test/14998',\n",
       " 'test/15000',\n",
       " 'test/15001',\n",
       " 'test/15002',\n",
       " 'test/15004',\n",
       " 'test/15005',\n",
       " 'test/15006',\n",
       " 'test/15011',\n",
       " 'test/15012',\n",
       " 'test/15013',\n",
       " 'test/15016',\n",
       " 'test/15017',\n",
       " 'test/15020',\n",
       " 'test/15023',\n",
       " 'test/15024',\n",
       " 'test/15026',\n",
       " 'test/15027',\n",
       " 'test/15028',\n",
       " 'test/15029',\n",
       " 'test/15031',\n",
       " 'test/15032',\n",
       " 'test/15033',\n",
       " 'test/15037',\n",
       " 'test/15038',\n",
       " 'test/15043',\n",
       " 'test/15045',\n",
       " 'test/15046',\n",
       " 'test/15048',\n",
       " 'test/15049',\n",
       " 'test/15052',\n",
       " 'test/15053',\n",
       " 'test/15055',\n",
       " 'test/15056',\n",
       " 'test/15060',\n",
       " 'test/15061',\n",
       " 'test/15062',\n",
       " 'test/15063',\n",
       " 'test/15065',\n",
       " 'test/15067',\n",
       " 'test/15069',\n",
       " 'test/15070',\n",
       " 'test/15074',\n",
       " 'test/15077',\n",
       " 'test/15078',\n",
       " 'test/15079',\n",
       " 'test/15082',\n",
       " 'test/15090',\n",
       " 'test/15091',\n",
       " 'test/15092',\n",
       " 'test/15093',\n",
       " 'test/15094',\n",
       " 'test/15095',\n",
       " 'test/15096',\n",
       " 'test/15097',\n",
       " 'test/15103',\n",
       " 'test/15104',\n",
       " 'test/15106',\n",
       " 'test/15107',\n",
       " 'test/15109',\n",
       " 'test/15110',\n",
       " 'test/15111',\n",
       " 'test/15112',\n",
       " 'test/15118',\n",
       " 'test/15119',\n",
       " 'test/15120',\n",
       " 'test/15121',\n",
       " 'test/15122',\n",
       " 'test/15124',\n",
       " 'test/15126',\n",
       " 'test/15128',\n",
       " 'test/15129',\n",
       " 'test/15130',\n",
       " 'test/15132',\n",
       " 'test/15136',\n",
       " 'test/15138',\n",
       " 'test/15141',\n",
       " 'test/15144',\n",
       " 'test/15145',\n",
       " 'test/15146',\n",
       " 'test/15149',\n",
       " 'test/15152',\n",
       " 'test/15153',\n",
       " 'test/15154',\n",
       " 'test/15156',\n",
       " 'test/15157',\n",
       " 'test/15161',\n",
       " 'test/15162',\n",
       " 'test/15171',\n",
       " 'test/15172',\n",
       " 'test/15175',\n",
       " 'test/15179',\n",
       " 'test/15180',\n",
       " 'test/15185',\n",
       " 'test/15188',\n",
       " 'test/15189',\n",
       " 'test/15190',\n",
       " 'test/15193',\n",
       " 'test/15194',\n",
       " 'test/15197',\n",
       " 'test/15198',\n",
       " 'test/15200',\n",
       " 'test/15204',\n",
       " 'test/15205',\n",
       " 'test/15206',\n",
       " 'test/15207',\n",
       " 'test/15208',\n",
       " 'test/15210',\n",
       " 'test/15211',\n",
       " 'test/15212',\n",
       " 'test/15213',\n",
       " 'test/15217',\n",
       " 'test/15219',\n",
       " 'test/15220',\n",
       " 'test/15221',\n",
       " 'test/15222',\n",
       " 'test/15223',\n",
       " 'test/15226',\n",
       " 'test/15227',\n",
       " 'test/15230',\n",
       " 'test/15233',\n",
       " 'test/15234',\n",
       " 'test/15237',\n",
       " 'test/15238',\n",
       " 'test/15239',\n",
       " 'test/15240',\n",
       " 'test/15242',\n",
       " 'test/15243',\n",
       " 'test/15244',\n",
       " 'test/15246',\n",
       " 'test/15247',\n",
       " 'test/15250',\n",
       " 'test/15253',\n",
       " 'test/15254',\n",
       " 'test/15255',\n",
       " 'test/15258',\n",
       " 'test/15259',\n",
       " 'test/15262',\n",
       " 'test/15263',\n",
       " 'test/15264',\n",
       " 'test/15265',\n",
       " 'test/15270',\n",
       " 'test/15271',\n",
       " 'test/15273',\n",
       " 'test/15274',\n",
       " 'test/15276',\n",
       " 'test/15278',\n",
       " 'test/15280',\n",
       " 'test/15281',\n",
       " 'test/15283',\n",
       " 'test/15287',\n",
       " 'test/15290',\n",
       " 'test/15292',\n",
       " 'test/15294',\n",
       " 'test/15295',\n",
       " 'test/15296',\n",
       " 'test/15299',\n",
       " 'test/15300',\n",
       " 'test/15302',\n",
       " 'test/15303',\n",
       " 'test/15306',\n",
       " 'test/15307',\n",
       " 'test/15308',\n",
       " 'test/15309',\n",
       " 'test/15310',\n",
       " 'test/15311',\n",
       " 'test/15312',\n",
       " 'test/15313',\n",
       " 'test/15314',\n",
       " 'test/15315',\n",
       " 'test/15321',\n",
       " 'test/15322',\n",
       " 'test/15324',\n",
       " 'test/15325',\n",
       " 'test/15326',\n",
       " 'test/15327',\n",
       " 'test/15329',\n",
       " 'test/15335',\n",
       " 'test/15336',\n",
       " 'test/15337',\n",
       " 'test/15339',\n",
       " 'test/15341',\n",
       " 'test/15344',\n",
       " 'test/15345',\n",
       " 'test/15348',\n",
       " 'test/15349',\n",
       " 'test/15351',\n",
       " 'test/15352',\n",
       " 'test/15354',\n",
       " 'test/15356',\n",
       " 'test/15357',\n",
       " 'test/15359',\n",
       " 'test/15363',\n",
       " 'test/15364',\n",
       " 'test/15365',\n",
       " 'test/15366',\n",
       " 'test/15367',\n",
       " 'test/15368',\n",
       " 'test/15372',\n",
       " 'test/15375',\n",
       " 'test/15378',\n",
       " 'test/15379',\n",
       " 'test/15380',\n",
       " 'test/15383',\n",
       " 'test/15384',\n",
       " 'test/15386',\n",
       " 'test/15387',\n",
       " 'test/15388',\n",
       " 'test/15389',\n",
       " 'test/15391',\n",
       " 'test/15394',\n",
       " 'test/15396',\n",
       " 'test/15397',\n",
       " 'test/15400',\n",
       " 'test/15404',\n",
       " 'test/15406',\n",
       " 'test/15409',\n",
       " 'test/15410',\n",
       " 'test/15411',\n",
       " 'test/15413',\n",
       " 'test/15415',\n",
       " 'test/15416',\n",
       " 'test/15417',\n",
       " 'test/15420',\n",
       " 'test/15421',\n",
       " 'test/15424',\n",
       " 'test/15425',\n",
       " 'test/15427',\n",
       " 'test/15428',\n",
       " 'test/15429',\n",
       " 'test/15430',\n",
       " 'test/15431',\n",
       " 'test/15432',\n",
       " 'test/15436',\n",
       " 'test/15438',\n",
       " 'test/15441',\n",
       " 'test/15442',\n",
       " 'test/15444',\n",
       " 'test/15446',\n",
       " 'test/15447',\n",
       " 'test/15448',\n",
       " 'test/15449',\n",
       " 'test/15450',\n",
       " 'test/15451',\n",
       " 'test/15452',\n",
       " 'test/15453',\n",
       " 'test/15454',\n",
       " 'test/15455',\n",
       " 'test/15457',\n",
       " 'test/15459',\n",
       " 'test/15460',\n",
       " 'test/15462',\n",
       " 'test/15464',\n",
       " 'test/15467',\n",
       " 'test/15468',\n",
       " 'test/15471',\n",
       " 'test/15472',\n",
       " 'test/15476',\n",
       " 'test/15477',\n",
       " 'test/15478',\n",
       " 'test/15479',\n",
       " 'test/15481',\n",
       " 'test/15482',\n",
       " 'test/15483',\n",
       " 'test/15484',\n",
       " 'test/15485',\n",
       " 'test/15487',\n",
       " 'test/15489',\n",
       " 'test/15494',\n",
       " 'test/15495',\n",
       " 'test/15496',\n",
       " 'test/15500',\n",
       " 'test/15501',\n",
       " 'test/15503',\n",
       " 'test/15504',\n",
       " 'test/15510',\n",
       " 'test/15511',\n",
       " 'test/15515',\n",
       " 'test/15520',\n",
       " 'test/15521',\n",
       " 'test/15522',\n",
       " 'test/15523',\n",
       " 'test/15527',\n",
       " 'test/15528',\n",
       " 'test/15531',\n",
       " 'test/15532',\n",
       " 'test/15535',\n",
       " 'test/15536',\n",
       " 'test/15539',\n",
       " 'test/15540',\n",
       " 'test/15542',\n",
       " 'test/15543',\n",
       " 'test/15544',\n",
       " 'test/15545',\n",
       " 'test/15547',\n",
       " 'test/15548',\n",
       " 'test/15549',\n",
       " 'test/15550',\n",
       " 'test/15551',\n",
       " 'test/15552',\n",
       " 'test/15553',\n",
       " 'test/15556',\n",
       " 'test/15558',\n",
       " 'test/15559',\n",
       " 'test/15560',\n",
       " 'test/15561',\n",
       " 'test/15562',\n",
       " 'test/15563',\n",
       " 'test/15565',\n",
       " 'test/15566',\n",
       " 'test/15567',\n",
       " 'test/15568',\n",
       " 'test/15569',\n",
       " 'test/15570',\n",
       " 'test/15571',\n",
       " 'test/15572',\n",
       " 'test/15573',\n",
       " 'test/15574',\n",
       " 'test/15575',\n",
       " 'test/15578',\n",
       " 'test/15579',\n",
       " 'test/15580',\n",
       " 'test/15581',\n",
       " 'test/15582',\n",
       " 'test/15583',\n",
       " 'test/15584',\n",
       " 'test/15585',\n",
       " 'test/15590',\n",
       " 'test/15591',\n",
       " 'test/15593',\n",
       " 'test/15594',\n",
       " 'test/15595',\n",
       " 'test/15596',\n",
       " 'test/15597',\n",
       " 'test/15598',\n",
       " 'test/15600',\n",
       " 'test/15601',\n",
       " 'test/15602',\n",
       " 'test/15603',\n",
       " 'test/15605',\n",
       " 'test/15607',\n",
       " 'test/15610',\n",
       " 'test/15613',\n",
       " 'test/15615',\n",
       " 'test/15616',\n",
       " 'test/15617',\n",
       " 'test/15618',\n",
       " 'test/15620',\n",
       " 'test/15621',\n",
       " 'test/15623',\n",
       " 'test/15624',\n",
       " 'test/15625',\n",
       " 'test/15626',\n",
       " 'test/15629',\n",
       " 'test/15632',\n",
       " 'test/15634',\n",
       " 'test/15636',\n",
       " 'test/15637',\n",
       " 'test/15639',\n",
       " 'test/15640',\n",
       " 'test/15641',\n",
       " 'test/15642',\n",
       " 'test/15643',\n",
       " 'test/15646',\n",
       " 'test/15648',\n",
       " 'test/15649',\n",
       " 'test/15651',\n",
       " 'test/15653',\n",
       " 'test/15655',\n",
       " 'test/15656',\n",
       " 'test/15664',\n",
       " 'test/15666',\n",
       " 'test/15667',\n",
       " 'test/15668',\n",
       " 'test/15669',\n",
       " 'test/15672',\n",
       " 'test/15674',\n",
       " 'test/15675',\n",
       " 'test/15676',\n",
       " 'test/15677',\n",
       " 'test/15679',\n",
       " 'test/15680',\n",
       " 'test/15682',\n",
       " 'test/15686',\n",
       " 'test/15688',\n",
       " 'test/15689',\n",
       " 'test/15691',\n",
       " 'test/15692',\n",
       " 'test/15694',\n",
       " 'test/15695',\n",
       " 'test/15696',\n",
       " 'test/15698',\n",
       " 'test/15702',\n",
       " 'test/15703',\n",
       " 'test/15704',\n",
       " 'test/15707',\n",
       " 'test/15708',\n",
       " 'test/15709',\n",
       " 'test/15710',\n",
       " 'test/15713',\n",
       " 'test/15715',\n",
       " 'test/15717',\n",
       " 'test/15719',\n",
       " 'test/15720',\n",
       " 'test/15721',\n",
       " 'test/15723',\n",
       " 'test/15725',\n",
       " 'test/15726',\n",
       " 'test/15727',\n",
       " 'test/15728',\n",
       " 'test/15729',\n",
       " 'test/15732',\n",
       " 'test/15733',\n",
       " 'test/15736',\n",
       " 'test/15737',\n",
       " 'test/15739',\n",
       " 'test/15742',\n",
       " 'test/15749',\n",
       " 'test/15751',\n",
       " 'test/15753',\n",
       " 'test/15757',\n",
       " 'test/15759',\n",
       " 'test/15762',\n",
       " 'test/15767',\n",
       " 'test/15768',\n",
       " 'test/15769',\n",
       " 'test/15772',\n",
       " 'test/15777',\n",
       " 'test/15778',\n",
       " 'test/15780',\n",
       " 'test/15782',\n",
       " 'test/15785',\n",
       " 'test/15790',\n",
       " 'test/15793',\n",
       " 'test/15797',\n",
       " 'test/15798',\n",
       " 'test/15800',\n",
       " 'test/15801',\n",
       " 'test/15803',\n",
       " 'test/15804',\n",
       " 'test/15805',\n",
       " 'test/15807',\n",
       " 'test/15808',\n",
       " 'test/15810',\n",
       " 'test/15811',\n",
       " 'test/15816',\n",
       " 'test/15817',\n",
       " 'test/15819',\n",
       " 'test/15821',\n",
       " 'test/15822',\n",
       " 'test/15823',\n",
       " 'test/15829',\n",
       " 'test/15831',\n",
       " 'test/15832',\n",
       " 'test/15833',\n",
       " 'test/15834',\n",
       " 'test/15836',\n",
       " 'test/15838',\n",
       " 'test/15840',\n",
       " 'test/15841',\n",
       " 'test/15842',\n",
       " 'test/15844',\n",
       " 'test/15845',\n",
       " 'test/15846',\n",
       " 'test/15847',\n",
       " 'test/15851',\n",
       " 'test/15852',\n",
       " 'test/15853',\n",
       " 'test/15854',\n",
       " 'test/15855',\n",
       " 'test/15856',\n",
       " 'test/15858',\n",
       " 'test/15859',\n",
       " 'test/15860',\n",
       " 'test/15861',\n",
       " 'test/15863',\n",
       " 'test/15864',\n",
       " 'test/15865',\n",
       " 'test/15866',\n",
       " 'test/15867',\n",
       " 'test/15868',\n",
       " 'test/15869',\n",
       " 'test/15870',\n",
       " 'test/15871',\n",
       " 'test/15872',\n",
       " 'test/15874',\n",
       " 'test/15875',\n",
       " 'test/15876',\n",
       " 'test/15877',\n",
       " 'test/15878',\n",
       " 'test/15879',\n",
       " 'test/15881',\n",
       " 'test/15885',\n",
       " 'test/15886',\n",
       " 'test/15888',\n",
       " 'test/15889',\n",
       " 'test/15890',\n",
       " 'test/15892',\n",
       " 'test/15893',\n",
       " 'test/15894',\n",
       " 'test/15895',\n",
       " 'test/15896',\n",
       " 'test/15897',\n",
       " 'test/15898',\n",
       " 'test/15899',\n",
       " 'test/15900',\n",
       " 'test/15901',\n",
       " 'test/15902',\n",
       " 'test/15903',\n",
       " 'test/15904',\n",
       " 'test/15906',\n",
       " 'test/15908',\n",
       " 'test/15909',\n",
       " 'test/15910',\n",
       " 'test/15911',\n",
       " 'test/15912',\n",
       " 'test/15913',\n",
       " 'test/15914',\n",
       " 'test/15916',\n",
       " 'test/15917',\n",
       " 'test/15918',\n",
       " 'test/15920',\n",
       " 'test/15921',\n",
       " 'test/15922',\n",
       " 'test/15923',\n",
       " 'test/15924',\n",
       " 'test/15925',\n",
       " 'test/15927',\n",
       " 'test/15928',\n",
       " 'test/15929',\n",
       " 'test/15930',\n",
       " 'test/15932',\n",
       " 'test/15933',\n",
       " 'test/15934',\n",
       " 'test/15937',\n",
       " 'test/15939',\n",
       " 'test/15942',\n",
       " 'test/15944',\n",
       " 'test/15949',\n",
       " 'test/15950',\n",
       " 'test/15951',\n",
       " 'test/15952',\n",
       " 'test/15953',\n",
       " 'test/15956',\n",
       " 'test/15959',\n",
       " 'test/15960',\n",
       " 'test/15961',\n",
       " 'test/15963',\n",
       " 'test/15964',\n",
       " 'test/15967',\n",
       " 'test/15968',\n",
       " 'test/15969',\n",
       " 'test/15970',\n",
       " 'test/15973',\n",
       " 'test/15975',\n",
       " 'test/15976',\n",
       " 'test/15977',\n",
       " 'test/15978',\n",
       " 'test/15979',\n",
       " 'test/15980',\n",
       " 'test/15981',\n",
       " 'test/15984',\n",
       " 'test/15985',\n",
       " 'test/15987',\n",
       " 'test/15988',\n",
       " 'test/15989',\n",
       " 'test/15993',\n",
       " 'test/15995',\n",
       " 'test/15996',\n",
       " 'test/15997',\n",
       " 'test/15999',\n",
       " 'test/16002',\n",
       " 'test/16003',\n",
       " 'test/16004',\n",
       " 'test/16005',\n",
       " 'test/16006',\n",
       " 'test/16007',\n",
       " 'test/16009',\n",
       " 'test/16012',\n",
       " 'test/16013',\n",
       " 'test/16014',\n",
       " 'test/16015',\n",
       " 'test/16016',\n",
       " 'test/16021',\n",
       " 'test/16022',\n",
       " 'test/16023',\n",
       " 'test/16026',\n",
       " 'test/16029',\n",
       " 'test/16030',\n",
       " 'test/16033',\n",
       " 'test/16037',\n",
       " 'test/16040',\n",
       " 'test/16041',\n",
       " 'test/16045',\n",
       " 'test/16052',\n",
       " 'test/16053',\n",
       " 'test/16055',\n",
       " 'test/16063',\n",
       " 'test/16066',\n",
       " 'test/16067',\n",
       " 'test/16068',\n",
       " 'test/16069',\n",
       " 'test/16071',\n",
       " 'test/16072',\n",
       " 'test/16074',\n",
       " 'test/16075',\n",
       " 'test/16076',\n",
       " 'test/16077',\n",
       " 'test/16079',\n",
       " 'test/16080',\n",
       " 'test/16083',\n",
       " 'test/16086',\n",
       " 'test/16088',\n",
       " 'test/16091',\n",
       " 'test/16093',\n",
       " 'test/16094',\n",
       " 'test/16095',\n",
       " 'test/16096',\n",
       " 'test/16097',\n",
       " 'test/16098',\n",
       " 'test/16099',\n",
       " 'test/16100',\n",
       " 'test/16103',\n",
       " 'test/16106',\n",
       " 'test/16107',\n",
       " 'test/16108',\n",
       " 'test/16110',\n",
       " 'test/16111',\n",
       " 'test/16112',\n",
       " 'test/16115',\n",
       " 'test/16117',\n",
       " 'test/16118',\n",
       " 'test/16119',\n",
       " 'test/16120',\n",
       " 'test/16122',\n",
       " 'test/16123',\n",
       " 'test/16125',\n",
       " 'test/16126',\n",
       " 'test/16130',\n",
       " 'test/16133',\n",
       " 'test/16134',\n",
       " 'test/16136',\n",
       " 'test/16139',\n",
       " 'test/16140',\n",
       " 'test/16141',\n",
       " 'test/16142',\n",
       " 'test/16143',\n",
       " 'test/16144',\n",
       " 'test/16145',\n",
       " 'test/16146',\n",
       " 'test/16147',\n",
       " 'test/16148',\n",
       " 'test/16149',\n",
       " 'test/16150',\n",
       " 'test/16152',\n",
       " 'test/16155',\n",
       " 'test/16158',\n",
       " 'test/16159',\n",
       " 'test/16161',\n",
       " 'test/16162',\n",
       " 'test/16163',\n",
       " 'test/16164',\n",
       " 'test/16166',\n",
       " 'test/16170',\n",
       " 'test/16171',\n",
       " 'test/16172',\n",
       " 'test/16173',\n",
       " 'test/16175',\n",
       " 'test/16176',\n",
       " 'test/16177',\n",
       " 'test/16179',\n",
       " 'test/16180',\n",
       " 'test/16185',\n",
       " 'test/16188',\n",
       " 'test/16189',\n",
       " 'test/16190',\n",
       " 'test/16193',\n",
       " 'test/16194',\n",
       " 'test/16195',\n",
       " 'test/16196',\n",
       " 'test/16197',\n",
       " 'test/16200',\n",
       " 'test/16201',\n",
       " 'test/16202',\n",
       " 'test/16203',\n",
       " 'test/16206',\n",
       " 'test/16207',\n",
       " 'test/16210',\n",
       " 'test/16211',\n",
       " 'test/16212',\n",
       " 'test/16213',\n",
       " 'test/16214',\n",
       " 'test/16215',\n",
       " 'test/16216',\n",
       " 'test/16219',\n",
       " 'test/16221',\n",
       " 'test/16223',\n",
       " 'test/16225',\n",
       " 'test/16226',\n",
       " 'test/16228',\n",
       " 'test/16230',\n",
       " 'test/16232',\n",
       " 'test/16233',\n",
       " 'test/16234',\n",
       " 'test/16236',\n",
       " 'test/16238',\n",
       " 'test/16241',\n",
       " 'test/16243',\n",
       " 'test/16244',\n",
       " 'test/16246',\n",
       " 'test/16247',\n",
       " 'test/16248',\n",
       " 'test/16250',\n",
       " 'test/16251',\n",
       " 'test/16252',\n",
       " 'test/16255',\n",
       " 'test/16256',\n",
       " 'test/16257',\n",
       " 'test/16258',\n",
       " 'test/16260',\n",
       " 'test/16262',\n",
       " 'test/16263',\n",
       " 'test/16264',\n",
       " 'test/16265',\n",
       " 'test/16266',\n",
       " 'test/16268',\n",
       " 'test/16269',\n",
       " 'test/16270',\n",
       " 'test/16271',\n",
       " 'test/16274',\n",
       " 'test/16275',\n",
       " 'test/16277',\n",
       " 'test/16278',\n",
       " 'test/16279',\n",
       " 'test/16281',\n",
       " 'test/16282',\n",
       " 'test/16283',\n",
       " 'test/16284',\n",
       " 'test/16285',\n",
       " 'test/16286',\n",
       " 'test/16287',\n",
       " 'test/16288',\n",
       " 'test/16289',\n",
       " 'test/16291',\n",
       " 'test/16294',\n",
       " 'test/16297',\n",
       " 'test/16298',\n",
       " 'test/16299',\n",
       " 'test/16300',\n",
       " 'test/16301',\n",
       " 'test/16302',\n",
       " 'test/16303',\n",
       " 'test/16304',\n",
       " 'test/16307',\n",
       " 'test/16310',\n",
       " 'test/16311',\n",
       " 'test/16312',\n",
       " 'test/16314',\n",
       " 'test/16315',\n",
       " 'test/16316',\n",
       " 'test/16317',\n",
       " 'test/16318',\n",
       " 'test/16319',\n",
       " 'test/16320',\n",
       " 'test/16324',\n",
       " 'test/16327',\n",
       " 'test/16331',\n",
       " 'test/16332',\n",
       " 'test/16336',\n",
       " 'test/16337',\n",
       " 'test/16339',\n",
       " 'test/16342',\n",
       " 'test/16343',\n",
       " 'test/16346',\n",
       " 'test/16347',\n",
       " 'test/16348',\n",
       " 'test/16350',\n",
       " 'test/16354',\n",
       " 'test/16357',\n",
       " 'test/16359',\n",
       " 'test/16360',\n",
       " 'test/16362',\n",
       " 'test/16363',\n",
       " 'test/16365',\n",
       " 'test/16366',\n",
       " 'test/16367',\n",
       " 'test/16369',\n",
       " 'test/16370',\n",
       " 'test/16371',\n",
       " 'test/16372',\n",
       " 'test/16374',\n",
       " 'test/16376',\n",
       " 'test/16377',\n",
       " 'test/16379',\n",
       " 'test/16380',\n",
       " 'test/16383',\n",
       " 'test/16385',\n",
       " 'test/16386',\n",
       " 'test/16388',\n",
       " 'test/16390',\n",
       " 'test/16392',\n",
       " 'test/16393',\n",
       " 'test/16394',\n",
       " 'test/16395',\n",
       " 'test/16396',\n",
       " 'test/16398',\n",
       " 'test/16399',\n",
       " 'test/16400',\n",
       " 'test/16401',\n",
       " 'test/16402',\n",
       " 'test/16403',\n",
       " 'test/16404',\n",
       " 'test/16405',\n",
       " 'test/16406',\n",
       " 'test/16407',\n",
       " 'test/16409',\n",
       " 'test/16410',\n",
       " 'test/16415',\n",
       " 'test/16417',\n",
       " 'test/16418',\n",
       " 'test/16419',\n",
       " 'test/16420',\n",
       " 'test/16421',\n",
       " 'test/16422',\n",
       " 'test/16424',\n",
       " 'test/16426',\n",
       " 'test/16427',\n",
       " 'test/16428',\n",
       " 'test/16429',\n",
       " 'test/16430',\n",
       " 'test/16432',\n",
       " 'test/16433',\n",
       " 'test/16434',\n",
       " 'test/16437',\n",
       " 'test/16438',\n",
       " 'test/16440',\n",
       " 'test/16441',\n",
       " 'test/16442',\n",
       " 'test/16443',\n",
       " 'test/16444',\n",
       " 'test/16448',\n",
       " 'test/16449',\n",
       " 'test/16450',\n",
       " 'test/16454',\n",
       " 'test/16457',\n",
       " 'test/16458',\n",
       " 'test/16459',\n",
       " 'test/16460',\n",
       " 'test/16461',\n",
       " 'test/16463',\n",
       " 'test/16465',\n",
       " 'test/16468',\n",
       " 'test/16469',\n",
       " 'test/16470',\n",
       " 'test/16471',\n",
       " 'test/16472',\n",
       " 'test/16473',\n",
       " 'test/16475',\n",
       " 'test/16476',\n",
       " 'test/16478',\n",
       " 'test/16479',\n",
       " 'test/16480',\n",
       " 'test/16481',\n",
       " 'test/16483',\n",
       " 'test/16486',\n",
       " 'test/16487',\n",
       " 'test/16488',\n",
       " 'test/16490',\n",
       " 'test/16492',\n",
       " 'test/16493',\n",
       " 'test/16495',\n",
       " 'test/16496',\n",
       " 'test/16499',\n",
       " 'test/16502',\n",
       " 'test/16505',\n",
       " 'test/16510',\n",
       " 'test/16512',\n",
       " 'test/16513',\n",
       " 'test/16518',\n",
       " 'test/16519',\n",
       " 'test/16521',\n",
       " 'test/16522',\n",
       " 'test/16523',\n",
       " 'test/16525',\n",
       " 'test/16527',\n",
       " 'test/16530',\n",
       " 'test/16531',\n",
       " 'test/16533',\n",
       " 'test/16538',\n",
       " 'test/16539',\n",
       " 'test/16545',\n",
       " 'test/16546',\n",
       " 'test/16549',\n",
       " 'test/16551',\n",
       " 'test/16554',\n",
       " 'test/16555',\n",
       " 'test/16561',\n",
       " 'test/16563',\n",
       " 'test/16564',\n",
       " 'test/16565',\n",
       " 'test/16568',\n",
       " 'test/16569',\n",
       " 'test/16570',\n",
       " 'test/16574',\n",
       " 'test/16577',\n",
       " 'test/16581',\n",
       " 'test/16583',\n",
       " 'test/16584',\n",
       " 'test/16585',\n",
       " 'test/16587',\n",
       " 'test/16588',\n",
       " 'test/16589',\n",
       " 'test/16590',\n",
       " 'test/16591',\n",
       " ...]"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from nltk.corpus import reuters\n",
    "reuters.fileids()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['acq',\n",
       " 'alum',\n",
       " 'barley',\n",
       " 'bop',\n",
       " 'carcass',\n",
       " 'castor-oil',\n",
       " 'cocoa',\n",
       " 'coconut',\n",
       " 'coconut-oil',\n",
       " 'coffee',\n",
       " 'copper',\n",
       " 'copra-cake',\n",
       " 'corn',\n",
       " 'cotton',\n",
       " 'cotton-oil',\n",
       " 'cpi',\n",
       " 'cpu',\n",
       " 'crude',\n",
       " 'dfl',\n",
       " 'dlr',\n",
       " 'dmk',\n",
       " 'earn',\n",
       " 'fuel',\n",
       " 'gas',\n",
       " 'gnp',\n",
       " 'gold',\n",
       " 'grain',\n",
       " 'groundnut',\n",
       " 'groundnut-oil',\n",
       " 'heat',\n",
       " 'hog',\n",
       " 'housing',\n",
       " 'income',\n",
       " 'instal-debt',\n",
       " 'interest',\n",
       " 'ipi',\n",
       " 'iron-steel',\n",
       " 'jet',\n",
       " 'jobs',\n",
       " 'l-cattle',\n",
       " 'lead',\n",
       " 'lei',\n",
       " 'lin-oil',\n",
       " 'livestock',\n",
       " 'lumber',\n",
       " 'meal-feed',\n",
       " 'money-fx',\n",
       " 'money-supply',\n",
       " 'naphtha',\n",
       " 'nat-gas',\n",
       " 'nickel',\n",
       " 'nkr',\n",
       " 'nzdlr',\n",
       " 'oat',\n",
       " 'oilseed',\n",
       " 'orange',\n",
       " 'palladium',\n",
       " 'palm-oil',\n",
       " 'palmkernel',\n",
       " 'pet-chem',\n",
       " 'platinum',\n",
       " 'potato',\n",
       " 'propane',\n",
       " 'rand',\n",
       " 'rape-oil',\n",
       " 'rapeseed',\n",
       " 'reserves',\n",
       " 'retail',\n",
       " 'rice',\n",
       " 'rubber',\n",
       " 'rye',\n",
       " 'ship',\n",
       " 'silver',\n",
       " 'sorghum',\n",
       " 'soy-meal',\n",
       " 'soy-oil',\n",
       " 'soybean',\n",
       " 'strategic-metal',\n",
       " 'sugar',\n",
       " 'sun-meal',\n",
       " 'sun-oil',\n",
       " 'sunseed',\n",
       " 'tea',\n",
       " 'tin',\n",
       " 'trade',\n",
       " 'veg-oil',\n",
       " 'wheat',\n",
       " 'wpi',\n",
       " 'yen',\n",
       " 'zinc']"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "reuters.categories()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['barley', 'corn', 'grain', 'wheat']"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "reuters.categories('training/9865')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['barley', 'corn', 'grain', 'money-fx', 'wheat']"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "reuters.categories(['training/9865', 'training/9880'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['test/15618',\n",
       " 'test/15649',\n",
       " 'test/15676',\n",
       " 'test/15728',\n",
       " 'test/15871',\n",
       " 'test/15875',\n",
       " 'test/15952',\n",
       " 'test/17767',\n",
       " 'test/17769',\n",
       " 'test/18024',\n",
       " 'test/18263',\n",
       " 'test/18908',\n",
       " 'test/19275',\n",
       " 'test/19668',\n",
       " 'training/10175',\n",
       " 'training/1067',\n",
       " 'training/11208',\n",
       " 'training/11316',\n",
       " 'training/11885',\n",
       " 'training/12428',\n",
       " 'training/13099',\n",
       " 'training/13744',\n",
       " 'training/13795',\n",
       " 'training/13852',\n",
       " 'training/13856',\n",
       " 'training/1652',\n",
       " 'training/1970',\n",
       " 'training/2044',\n",
       " 'training/2171',\n",
       " 'training/2172',\n",
       " 'training/2191',\n",
       " 'training/2217',\n",
       " 'training/2232',\n",
       " 'training/3132',\n",
       " 'training/3324',\n",
       " 'training/395',\n",
       " 'training/4280',\n",
       " 'training/4296',\n",
       " 'training/5',\n",
       " 'training/501',\n",
       " 'training/5467',\n",
       " 'training/5610',\n",
       " 'training/5640',\n",
       " 'training/6626',\n",
       " 'training/7205',\n",
       " 'training/7579',\n",
       " 'training/8213',\n",
       " 'training/8257',\n",
       " 'training/8759',\n",
       " 'training/9865',\n",
       " 'training/9958']"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "reuters.fileids('barley')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['test/14832',\n",
       " 'test/14858',\n",
       " 'test/15033',\n",
       " 'test/15043',\n",
       " 'test/15106',\n",
       " 'test/15287',\n",
       " 'test/15341',\n",
       " 'test/15618',\n",
       " 'test/15648',\n",
       " 'test/15649',\n",
       " 'test/15676',\n",
       " 'test/15686',\n",
       " 'test/15720',\n",
       " 'test/15728',\n",
       " 'test/15845',\n",
       " 'test/15856',\n",
       " 'test/15860',\n",
       " 'test/15863',\n",
       " 'test/15871',\n",
       " 'test/15875',\n",
       " 'test/15877',\n",
       " 'test/15890',\n",
       " 'test/15904',\n",
       " 'test/15906',\n",
       " 'test/15910',\n",
       " 'test/15911',\n",
       " 'test/15917',\n",
       " 'test/15952',\n",
       " 'test/15999',\n",
       " 'test/16012',\n",
       " 'test/16071',\n",
       " 'test/16099',\n",
       " 'test/16147',\n",
       " 'test/16525',\n",
       " 'test/16624',\n",
       " 'test/16751',\n",
       " 'test/16765',\n",
       " 'test/17503',\n",
       " 'test/17509',\n",
       " 'test/17722',\n",
       " 'test/17767',\n",
       " 'test/17769',\n",
       " 'test/18024',\n",
       " 'test/18035',\n",
       " 'test/18263',\n",
       " 'test/18482',\n",
       " 'test/18614',\n",
       " 'test/18908',\n",
       " 'test/18954',\n",
       " 'test/18973',\n",
       " 'test/19165',\n",
       " 'test/19275',\n",
       " 'test/19668',\n",
       " 'test/19721',\n",
       " 'test/19821',\n",
       " 'test/20018',\n",
       " 'test/20366',\n",
       " 'test/20637',\n",
       " 'test/20645',\n",
       " 'test/20649',\n",
       " 'test/20723',\n",
       " 'test/20763',\n",
       " 'test/21091',\n",
       " 'test/21243',\n",
       " 'test/21493',\n",
       " 'training/10120',\n",
       " 'training/10139',\n",
       " 'training/10172',\n",
       " 'training/10175',\n",
       " 'training/10319',\n",
       " 'training/10339',\n",
       " 'training/10487',\n",
       " 'training/10489',\n",
       " 'training/10519',\n",
       " 'training/1067',\n",
       " 'training/10701',\n",
       " 'training/10882',\n",
       " 'training/10956',\n",
       " 'training/11012',\n",
       " 'training/11085',\n",
       " 'training/11091',\n",
       " 'training/11208',\n",
       " 'training/11269',\n",
       " 'training/1131',\n",
       " 'training/11316',\n",
       " 'training/11392',\n",
       " 'training/11436',\n",
       " 'training/11607',\n",
       " 'training/11612',\n",
       " 'training/11729',\n",
       " 'training/11739',\n",
       " 'training/11769',\n",
       " 'training/11885',\n",
       " 'training/11936',\n",
       " 'training/11939',\n",
       " 'training/11964',\n",
       " 'training/12002',\n",
       " 'training/12052',\n",
       " 'training/12055',\n",
       " 'training/1215',\n",
       " 'training/12160',\n",
       " 'training/12311',\n",
       " 'training/12323',\n",
       " 'training/12372',\n",
       " 'training/12417',\n",
       " 'training/12428',\n",
       " 'training/12436',\n",
       " 'training/12500',\n",
       " 'training/12583',\n",
       " 'training/12587',\n",
       " 'training/1268',\n",
       " 'training/1273',\n",
       " 'training/12872',\n",
       " 'training/13099',\n",
       " 'training/13173',\n",
       " 'training/13179',\n",
       " 'training/1369',\n",
       " 'training/13744',\n",
       " 'training/13795',\n",
       " 'training/1385',\n",
       " 'training/13852',\n",
       " 'training/13856',\n",
       " 'training/1395',\n",
       " 'training/1399',\n",
       " 'training/14483',\n",
       " 'training/1582',\n",
       " 'training/1652',\n",
       " 'training/1777',\n",
       " 'training/1843',\n",
       " 'training/193',\n",
       " 'training/1952',\n",
       " 'training/197',\n",
       " 'training/1970',\n",
       " 'training/2044',\n",
       " 'training/2171',\n",
       " 'training/2172',\n",
       " 'training/2183',\n",
       " 'training/2191',\n",
       " 'training/2217',\n",
       " 'training/2232',\n",
       " 'training/2264',\n",
       " 'training/235',\n",
       " 'training/2382',\n",
       " 'training/2436',\n",
       " 'training/2456',\n",
       " 'training/2595',\n",
       " 'training/2599',\n",
       " 'training/2617',\n",
       " 'training/2727',\n",
       " 'training/2741',\n",
       " 'training/2749',\n",
       " 'training/2777',\n",
       " 'training/2848',\n",
       " 'training/2913',\n",
       " 'training/2922',\n",
       " 'training/2947',\n",
       " 'training/3132',\n",
       " 'training/3138',\n",
       " 'training/3191',\n",
       " 'training/327',\n",
       " 'training/3282',\n",
       " 'training/3299',\n",
       " 'training/3306',\n",
       " 'training/3324',\n",
       " 'training/3330',\n",
       " 'training/3337',\n",
       " 'training/3358',\n",
       " 'training/3401',\n",
       " 'training/3429',\n",
       " 'training/3847',\n",
       " 'training/3855',\n",
       " 'training/3881',\n",
       " 'training/3949',\n",
       " 'training/395',\n",
       " 'training/3979',\n",
       " 'training/3981',\n",
       " 'training/4047',\n",
       " 'training/4133',\n",
       " 'training/4280',\n",
       " 'training/4289',\n",
       " 'training/4296',\n",
       " 'training/4382',\n",
       " 'training/4490',\n",
       " 'training/4599',\n",
       " 'training/4825',\n",
       " 'training/4905',\n",
       " 'training/4939',\n",
       " 'training/4988',\n",
       " 'training/5',\n",
       " 'training/5003',\n",
       " 'training/501',\n",
       " 'training/5017',\n",
       " 'training/5033',\n",
       " 'training/5109',\n",
       " 'training/516',\n",
       " 'training/5185',\n",
       " 'training/5338',\n",
       " 'training/5467',\n",
       " 'training/5518',\n",
       " 'training/5531',\n",
       " 'training/5606',\n",
       " 'training/5610',\n",
       " 'training/5636',\n",
       " 'training/5637',\n",
       " 'training/5640',\n",
       " 'training/57',\n",
       " 'training/5847',\n",
       " 'training/5933',\n",
       " 'training/6',\n",
       " 'training/6142',\n",
       " 'training/6221',\n",
       " 'training/6236',\n",
       " 'training/6239',\n",
       " 'training/6259',\n",
       " 'training/6269',\n",
       " 'training/6386',\n",
       " 'training/6585',\n",
       " 'training/6588',\n",
       " 'training/6626',\n",
       " 'training/6735',\n",
       " 'training/6890',\n",
       " 'training/6897',\n",
       " 'training/694',\n",
       " 'training/7062',\n",
       " 'training/7205',\n",
       " 'training/7215',\n",
       " 'training/7336',\n",
       " 'training/7387',\n",
       " 'training/7389',\n",
       " 'training/7390',\n",
       " 'training/7395',\n",
       " 'training/7579',\n",
       " 'training/7700',\n",
       " 'training/7792',\n",
       " 'training/7917',\n",
       " 'training/7934',\n",
       " 'training/7943',\n",
       " 'training/8004',\n",
       " 'training/8140',\n",
       " 'training/8161',\n",
       " 'training/8166',\n",
       " 'training/8213',\n",
       " 'training/8257',\n",
       " 'training/8273',\n",
       " 'training/8400',\n",
       " 'training/8443',\n",
       " 'training/8446',\n",
       " 'training/8535',\n",
       " 'training/855',\n",
       " 'training/8759',\n",
       " 'training/8941',\n",
       " 'training/8983',\n",
       " 'training/8993',\n",
       " 'training/9058',\n",
       " 'training/9093',\n",
       " 'training/9094',\n",
       " 'training/934',\n",
       " 'training/9470',\n",
       " 'training/9521',\n",
       " 'training/9667',\n",
       " 'training/97',\n",
       " 'training/9865',\n",
       " 'training/9958',\n",
       " 'training/9989']"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "reuters.fileids(['barley', 'corn'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['FRENCH',\n",
       " 'FREE',\n",
       " 'MARKET',\n",
       " 'CEREAL',\n",
       " 'EXPORT',\n",
       " 'BIDS',\n",
       " 'DETAILED',\n",
       " 'French',\n",
       " 'operators',\n",
       " 'have',\n",
       " 'requested',\n",
       " 'licences',\n",
       " 'to',\n",
       " 'export']"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "reuters.words('training/9865')[:14]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['FRENCH', 'FREE', 'MARKET', 'CEREAL', 'EXPORT', ...]"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "reuters.words(['training/9865', 'training/9880'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['FRENCH', 'FREE', 'MARKET', 'CEREAL', 'EXPORT', ...]"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "reuters.words(categories='barley')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['THAI', 'TRADE', 'DEFICIT', 'WIDENS', 'IN', 'FIRST', ...]"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "reuters.words(categories=['barley', 'corn'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.5   Inaugural Address Corpus"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['1789-Washington.txt',\n",
       " '1793-Washington.txt',\n",
       " '1797-Adams.txt',\n",
       " '1801-Jefferson.txt',\n",
       " '1805-Jefferson.txt',\n",
       " '1809-Madison.txt',\n",
       " '1813-Madison.txt',\n",
       " '1817-Monroe.txt',\n",
       " '1821-Monroe.txt',\n",
       " '1825-Adams.txt',\n",
       " '1829-Jackson.txt',\n",
       " '1833-Jackson.txt',\n",
       " '1837-VanBuren.txt',\n",
       " '1841-Harrison.txt',\n",
       " '1845-Polk.txt',\n",
       " '1849-Taylor.txt',\n",
       " '1853-Pierce.txt',\n",
       " '1857-Buchanan.txt',\n",
       " '1861-Lincoln.txt',\n",
       " '1865-Lincoln.txt',\n",
       " '1869-Grant.txt',\n",
       " '1873-Grant.txt',\n",
       " '1877-Hayes.txt',\n",
       " '1881-Garfield.txt',\n",
       " '1885-Cleveland.txt',\n",
       " '1889-Harrison.txt',\n",
       " '1893-Cleveland.txt',\n",
       " '1897-McKinley.txt',\n",
       " '1901-McKinley.txt',\n",
       " '1905-Roosevelt.txt',\n",
       " '1909-Taft.txt',\n",
       " '1913-Wilson.txt',\n",
       " '1917-Wilson.txt',\n",
       " '1921-Harding.txt',\n",
       " '1925-Coolidge.txt',\n",
       " '1929-Hoover.txt',\n",
       " '1933-Roosevelt.txt',\n",
       " '1937-Roosevelt.txt',\n",
       " '1941-Roosevelt.txt',\n",
       " '1945-Roosevelt.txt',\n",
       " '1949-Truman.txt',\n",
       " '1953-Eisenhower.txt',\n",
       " '1957-Eisenhower.txt',\n",
       " '1961-Kennedy.txt',\n",
       " '1965-Johnson.txt',\n",
       " '1969-Nixon.txt',\n",
       " '1973-Nixon.txt',\n",
       " '1977-Carter.txt',\n",
       " '1981-Reagan.txt',\n",
       " '1985-Reagan.txt',\n",
       " '1989-Bush.txt',\n",
       " '1993-Clinton.txt',\n",
       " '1997-Clinton.txt',\n",
       " '2001-Bush.txt',\n",
       " '2005-Bush.txt',\n",
       " '2009-Obama.txt',\n",
       " '2013-Obama.txt',\n",
       " '2017-Trump.txt']"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from nltk.corpus import inaugural\n",
    "inaugural.fileids()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['1789',\n",
       " '1793',\n",
       " '1797',\n",
       " '1801',\n",
       " '1805',\n",
       " '1809',\n",
       " '1813',\n",
       " '1817',\n",
       " '1821',\n",
       " '1825',\n",
       " '1829',\n",
       " '1833',\n",
       " '1837',\n",
       " '1841',\n",
       " '1845',\n",
       " '1849',\n",
       " '1853',\n",
       " '1857',\n",
       " '1861',\n",
       " '1865',\n",
       " '1869',\n",
       " '1873',\n",
       " '1877',\n",
       " '1881',\n",
       " '1885',\n",
       " '1889',\n",
       " '1893',\n",
       " '1897',\n",
       " '1901',\n",
       " '1905',\n",
       " '1909',\n",
       " '1913',\n",
       " '1917',\n",
       " '1921',\n",
       " '1925',\n",
       " '1929',\n",
       " '1933',\n",
       " '1937',\n",
       " '1941',\n",
       " '1945',\n",
       " '1949',\n",
       " '1953',\n",
       " '1957',\n",
       " '1961',\n",
       " '1965',\n",
       " '1969',\n",
       " '1973',\n",
       " '1977',\n",
       " '1981',\n",
       " '1985',\n",
       " '1989',\n",
       " '1993',\n",
       " '1997',\n",
       " '2001',\n",
       " '2005',\n",
       " '2009',\n",
       " '2013',\n",
       " '2017']"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "[fileid[:4] for fileid in inaugural.fileids()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<matplotlib.axes._subplots.AxesSubplot at 0x1f4d299ff88>"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Let's look at how the words America and citizen are used over time. \n",
    "cfd = nltk.ConditionalFreqDist(\n",
    "    (target, fileid[:4])\n",
    "    for fileid in inaugural.fileids()\n",
    "    for w in inaugural.words(fileid)\n",
    "    for target in ['america', 'citizen']\n",
    "    if w.lower().startswith(target))\n",
    "cfd.plot()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.6   Annotated Text Corpora\n",
    "\n",
    "http://nltk.org/data\n",
    "\n",
    "http://nltk.org/howto"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.7   Corpora in Other Languages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['El', 'grupo', 'estatal', 'Electricité_de_France', ...]"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nltk.corpus.cess_esp.words()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Um', 'revivalismo', 'refrescante', 'O', '7_e_Meio', ...]"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nltk.corpus.floresta.words()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['पूर्ण', 'प्रतिबंध', 'हटाओ', ':', 'इराक', 'संयुक्त', ...]"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nltk.corpus.indian.words('hindi.pos')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Abkhaz-Cyrillic+Abkh',\n",
       " 'Abkhaz-UTF8',\n",
       " 'Achehnese-Latin1',\n",
       " 'Achuar-Shiwiar-Latin1',\n",
       " 'Adja-UTF8',\n",
       " 'Afaan_Oromo_Oromiffa-Latin1',\n",
       " 'Afrikaans-Latin1',\n",
       " 'Aguaruna-Latin1',\n",
       " 'Akuapem_Twi-UTF8',\n",
       " 'Albanian_Shqip-Latin1',\n",
       " 'Amahuaca',\n",
       " 'Amahuaca-Latin1',\n",
       " 'Amarakaeri-Latin1',\n",
       " 'Amuesha-Yanesha-UTF8',\n",
       " 'Arabela-Latin1',\n",
       " 'Arabic_Alarabia-Arabic',\n",
       " 'Asante-UTF8',\n",
       " 'Ashaninca-Latin1',\n",
       " 'Asheninca-Latin1',\n",
       " 'Asturian_Bable-Latin1',\n",
       " 'Aymara-Latin1',\n",
       " 'Balinese-Latin1',\n",
       " 'Bambara-UTF8',\n",
       " 'Baoule-UTF8',\n",
       " 'Basque_Euskara-Latin1',\n",
       " 'Batonu_Bariba-UTF8',\n",
       " 'Belorus_Belaruski-Cyrillic',\n",
       " 'Belorus_Belaruski-UTF8',\n",
       " 'Bemba-Latin1',\n",
       " 'Bengali-UTF8',\n",
       " 'Beti-UTF8',\n",
       " 'Bichelamar-Latin1',\n",
       " 'Bikol_Bicolano-Latin1',\n",
       " 'Bora-Latin1',\n",
       " 'Bosnian_Bosanski-Cyrillic',\n",
       " 'Bosnian_Bosanski-Latin2',\n",
       " 'Bosnian_Bosanski-UTF8',\n",
       " 'Breton-Latin1',\n",
       " 'Bugisnese-Latin1',\n",
       " 'Bulgarian_Balgarski-Cyrillic',\n",
       " 'Bulgarian_Balgarski-UTF8',\n",
       " 'Cakchiquel-Latin1',\n",
       " 'Campa_Pajonalino-Latin1',\n",
       " 'Candoshi-Shapra-Latin1',\n",
       " 'Caquinte-Latin1',\n",
       " 'Cashibo-Cacataibo-Latin1',\n",
       " 'Cashinahua-Latin1',\n",
       " 'Catalan-Latin1',\n",
       " 'Catalan_Catala-Latin1',\n",
       " 'Cebuano-Latin1',\n",
       " 'Chamorro-Latin1',\n",
       " 'Chayahuita-Latin1',\n",
       " 'Chechewa_Nyanja-Latin1',\n",
       " 'Chickasaw-Latin1',\n",
       " 'Chinanteco-Ajitlan-Latin1',\n",
       " 'Chinanteco-UTF8',\n",
       " 'Chinese_Mandarin-GB2312',\n",
       " 'Chuuk_Trukese-Latin1',\n",
       " 'Cokwe-Latin1',\n",
       " 'Corsican-Latin1',\n",
       " 'Croatian_Hrvatski-Latin2',\n",
       " 'Czech-Latin2',\n",
       " 'Czech-UTF8',\n",
       " 'Czech_Cesky-Latin2',\n",
       " 'Czech_Cesky-UTF8',\n",
       " 'Dagaare-UTF8',\n",
       " 'Dagbani-UTF8',\n",
       " 'Dangme-UTF8',\n",
       " 'Danish_Dansk-Latin1',\n",
       " 'Dendi-UTF8',\n",
       " 'Ditammari-UTF8',\n",
       " 'Dutch_Nederlands-Latin1',\n",
       " 'Edo-Latin1',\n",
       " 'English-Latin1',\n",
       " 'Esperanto-UTF8',\n",
       " 'Estonian_Eesti-Latin1',\n",
       " 'Ewe_Eve-UTF8',\n",
       " 'Fante-UTF8',\n",
       " 'Faroese-Latin1',\n",
       " 'Farsi_Persian-UTF8',\n",
       " 'Farsi_Persian-v2-UTF8',\n",
       " 'Fijian-Latin1',\n",
       " 'Filipino_Tagalog-Latin1',\n",
       " 'Finnish_Suomi-Latin1',\n",
       " 'Fon-UTF8',\n",
       " 'French_Francais-Latin1',\n",
       " 'Frisian-Latin1',\n",
       " 'Friulian_Friulano-Latin1',\n",
       " 'Ga-UTF8',\n",
       " 'Gagauz_Gagauzi-UTF8',\n",
       " 'Galician_Galego-Latin1',\n",
       " 'Garifuna_Garifuna-Latin1',\n",
       " 'German_Deutsch-Latin1',\n",
       " 'Gonja-UTF8',\n",
       " 'Greek_Ellinika-Greek',\n",
       " 'Greek_Ellinika-UTF8',\n",
       " 'Greenlandic_Inuktikut-Latin1',\n",
       " 'Guarani-Latin1',\n",
       " 'Guen_Mina-UTF8',\n",
       " 'HaitianCreole_Kreyol-Latin1',\n",
       " 'HaitianCreole_Popular-Latin1',\n",
       " 'Hani-Latin1',\n",
       " 'Hausa_Haoussa-Latin1',\n",
       " 'Hawaiian-UTF8',\n",
       " 'Hebrew_Ivrit-Hebrew',\n",
       " 'Hebrew_Ivrit-UTF8',\n",
       " 'Hiligaynon-Latin1',\n",
       " 'Hindi-UTF8',\n",
       " 'Hindi_web-UTF8',\n",
       " 'Hmong_Miao-Sichuan-Guizhou-Yunnan-Latin1',\n",
       " 'Hmong_Miao-SouthernEast-Guizhou-Latin1',\n",
       " 'Hmong_Miao_Northern-East-Guizhou-Latin1',\n",
       " 'Hrvatski_Croatian-Latin2',\n",
       " 'Huasteco-Latin1',\n",
       " 'Huitoto_Murui-Latin1',\n",
       " 'Hungarian_Magyar-Latin1',\n",
       " 'Hungarian_Magyar-Latin2',\n",
       " 'Hungarian_Magyar-UTF8',\n",
       " 'Ibibio_Efik-Latin1',\n",
       " 'Icelandic_Yslenska-Latin1',\n",
       " 'Ido-Latin1',\n",
       " 'Igbo-UTF8',\n",
       " 'Iloko_Ilocano-Latin1',\n",
       " 'Indonesian-Latin1',\n",
       " 'Interlingua-Latin1',\n",
       " 'Inuktikut_Greenlandic-Latin1',\n",
       " 'IrishGaelic_Gaeilge-Latin1',\n",
       " 'Italian-Latin1',\n",
       " 'Italian_Italiano-Latin1',\n",
       " 'Japanese_Nihongo-EUC',\n",
       " 'Japanese_Nihongo-SJIS',\n",
       " 'Japanese_Nihongo-UTF8',\n",
       " 'Javanese-Latin1',\n",
       " 'Jola-Fogny_Diola-UTF8',\n",
       " 'Kabye-UTF8',\n",
       " 'Kannada-UTF8',\n",
       " 'Kaonde-Latin1',\n",
       " 'Kapampangan-Latin1',\n",
       " 'Kasem-UTF8',\n",
       " 'Kazakh-Cyrillic',\n",
       " 'Kazakh-UTF8',\n",
       " 'Kiche_Quiche-Latin1',\n",
       " 'Kicongo-Latin1',\n",
       " 'Kimbundu_Mbundu-Latin1',\n",
       " 'Kinyamwezi_Nyamwezi-Latin1',\n",
       " 'Kinyarwanda-Latin1',\n",
       " 'Kituba-Latin1',\n",
       " 'Korean_Hankuko-UTF8',\n",
       " 'Kpelewo-UTF8',\n",
       " 'Krio-UTF8',\n",
       " 'Kurdish-UTF8',\n",
       " 'Lamnso_Lam-nso-UTF8',\n",
       " 'Latin_Latina-Latin1',\n",
       " 'Latin_Latina-v2-Latin1',\n",
       " 'Latvian-Latin1',\n",
       " 'Limba-UTF8',\n",
       " 'Lingala-Latin1',\n",
       " 'Lithuanian_Lietuviskai-Baltic',\n",
       " 'Lozi-Latin1',\n",
       " 'Luba-Kasai_Tshiluba-Latin1',\n",
       " 'Luganda_Ganda-Latin1',\n",
       " 'Lunda_Chokwe-lunda-Latin1',\n",
       " 'Luvale-Latin1',\n",
       " 'Luxembourgish_Letzebuergeusch-Latin1',\n",
       " 'Macedonian-UTF8',\n",
       " 'Madurese-Latin1',\n",
       " 'Makonde-Latin1',\n",
       " 'Malagasy-Latin1',\n",
       " 'Malay_BahasaMelayu-Latin1',\n",
       " 'Maltese-UTF8',\n",
       " 'Mam-Latin1',\n",
       " 'Maninka-UTF8',\n",
       " 'Maori-Latin1',\n",
       " 'Mapudungun_Mapuzgun-Latin1',\n",
       " 'Mapudungun_Mapuzgun-UTF8',\n",
       " 'Marshallese-Latin1',\n",
       " 'Matses-Latin1',\n",
       " 'Mayan_Yucateco-Latin1',\n",
       " 'Mazahua_Jnatrjo-UTF8',\n",
       " 'Mazateco-Latin1',\n",
       " 'Mende-UTF8',\n",
       " 'Mikmaq_Micmac-Mikmaq-Latin1',\n",
       " 'Minangkabau-Latin1',\n",
       " 'Miskito_Miskito-Latin1',\n",
       " 'Mixteco-Latin1',\n",
       " 'Mongolian_Khalkha-Cyrillic',\n",
       " 'Mongolian_Khalkha-UTF8',\n",
       " 'Moore_More-UTF8',\n",
       " 'Nahuatl-Latin1',\n",
       " 'Ndebele-Latin1',\n",
       " 'Nepali-UTF8',\n",
       " 'Ngangela_Nyemba-Latin1',\n",
       " 'NigerianPidginEnglish-Latin1',\n",
       " 'Nomatsiguenga-Latin1',\n",
       " 'NorthernSotho_Pedi-Sepedi-Latin1',\n",
       " 'Norwegian-Latin1',\n",
       " 'Norwegian_Norsk-Bokmal-Latin1',\n",
       " 'Norwegian_Norsk-Nynorsk-Latin1',\n",
       " 'Nyanja_Chechewa-Latin1',\n",
       " 'Nyanja_Chinyanja-Latin1',\n",
       " 'Nzema-UTF8',\n",
       " 'OccitanAuvergnat-Latin1',\n",
       " 'OccitanLanguedocien-Latin1',\n",
       " 'Oromiffa_AfaanOromo-Latin1',\n",
       " 'Osetin_Ossetian-UTF8',\n",
       " 'Oshiwambo_Ndonga-Latin1',\n",
       " 'Otomi_Nahnu-Latin1',\n",
       " 'Paez-Latin1',\n",
       " 'Palauan-Latin1',\n",
       " 'Peuhl-UTF8',\n",
       " 'Picard-Latin1',\n",
       " 'Pipil-Latin1',\n",
       " 'Polish-Latin2',\n",
       " 'Polish_Polski-Latin2',\n",
       " 'Ponapean-Latin1',\n",
       " 'Portuguese_Portugues-Latin1',\n",
       " 'Pulaar-UTF8',\n",
       " 'Punjabi_Panjabi-UTF8',\n",
       " 'Purhepecha-UTF8',\n",
       " 'Qechi_Kekchi-Latin1',\n",
       " 'Quechua-Latin1',\n",
       " 'Quichua-Latin1',\n",
       " 'Rarotongan_MaoriCookIslands-Latin1',\n",
       " 'Rhaeto-Romance_Rumantsch-Latin1',\n",
       " 'Romani-Latin1',\n",
       " 'Romani-UTF8',\n",
       " 'Romanian-Latin2',\n",
       " 'Romanian_Romana-Latin2',\n",
       " 'Rukonzo_Konjo-Latin1',\n",
       " 'Rundi_Kirundi-Latin1',\n",
       " 'Runyankore-rukiga_Nkore-kiga-Latin1',\n",
       " 'Russian-Cyrillic',\n",
       " 'Russian-UTF8',\n",
       " 'Russian_Russky-Cyrillic',\n",
       " 'Russian_Russky-UTF8',\n",
       " 'Sami_Lappish-UTF8',\n",
       " 'Sammarinese-Latin1',\n",
       " 'Samoan-Latin1',\n",
       " 'Sango_Sangho-Latin1',\n",
       " 'Sanskrit-UTF8',\n",
       " 'Saraiki-UTF8',\n",
       " 'Sardinian-Latin1',\n",
       " 'ScottishGaelic_GaidhligAlbanach-Latin1',\n",
       " 'Seereer-UTF8',\n",
       " 'Serbian_Srpski-Cyrillic',\n",
       " 'Serbian_Srpski-Latin2',\n",
       " 'Serbian_Srpski-UTF8',\n",
       " 'Sharanahua-Latin1',\n",
       " 'Shipibo-Conibo-Latin1',\n",
       " 'Shona-Latin1',\n",
       " 'Sinhala-UTF8',\n",
       " 'Siswati-Latin1',\n",
       " 'Slovak-Latin2',\n",
       " 'Slovak_Slovencina-Latin2',\n",
       " 'Slovenian_Slovenscina-Latin2',\n",
       " 'SolomonsPidgin_Pijin-Latin1',\n",
       " 'Somali-Latin1',\n",
       " 'Soninke_Soninkanxaane-UTF8',\n",
       " 'Sorbian-Latin2',\n",
       " 'SouthernSotho_Sotho-Sesotho-Sutu-Sesutu-Latin1',\n",
       " 'Spanish-Latin1',\n",
       " 'Spanish_Espanol-Latin1',\n",
       " 'Sukuma-Latin1',\n",
       " 'Sundanese-Latin1',\n",
       " 'Sussu_Soussou-Sosso-Soso-Susu-UTF8',\n",
       " 'Swaheli-Latin1',\n",
       " 'Swahili_Kiswahili-Latin1',\n",
       " 'Swedish_Svenska-Latin1',\n",
       " 'Tahitian-UTF8',\n",
       " 'Tenek_Huasteco-Latin1',\n",
       " 'Tetum-Latin1',\n",
       " 'Themne_Temne-UTF8',\n",
       " 'Tiv-Latin1',\n",
       " 'Toba-UTF8',\n",
       " 'Tojol-abal-Latin1',\n",
       " 'TokPisin-Latin1',\n",
       " 'Tonga-Latin1',\n",
       " 'Tongan_Tonga-Latin1',\n",
       " 'Totonaco-Latin1',\n",
       " 'Trukese_Chuuk-Latin1',\n",
       " 'Turkish_Turkce-Turkish',\n",
       " 'Turkish_Turkce-UTF8',\n",
       " 'Tzeltal-Latin1',\n",
       " 'Tzotzil-Latin1',\n",
       " 'Uighur_Uyghur-Latin1',\n",
       " 'Uighur_Uyghur-UTF8',\n",
       " 'Ukrainian-Cyrillic',\n",
       " 'Ukrainian-UTF8',\n",
       " 'Umbundu-Latin1',\n",
       " 'Urarina-Latin1',\n",
       " 'Uzbek-Latin1',\n",
       " 'Vietnamese-ALRN-UTF8',\n",
       " 'Vietnamese-UTF8',\n",
       " 'Vlach-Latin1',\n",
       " 'Walloon_Wallon-Latin1',\n",
       " 'Wama-UTF8',\n",
       " 'Waray-Latin1',\n",
       " 'Wayuu-Latin1',\n",
       " 'Welsh_Cymraeg-Latin1',\n",
       " 'WesternSotho_Tswana-Setswana-Latin1',\n",
       " 'Wolof-Latin1',\n",
       " 'Xhosa-Latin1',\n",
       " 'Yagua-Latin1',\n",
       " 'Yao-Latin1',\n",
       " 'Yapese-Latin1',\n",
       " 'Yoruba-UTF8',\n",
       " 'Zapoteco-Latin1',\n",
       " 'Zapoteco-SanLucasQuiavini-Latin1',\n",
       " 'Zhuang-Latin1',\n",
       " 'Zulu-Latin1']"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nltk.corpus.udhr.fileids()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Saben', 'umat', 'manungsa', 'lair', 'kanthi', 'hak', ...]"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nltk.corpus.udhr.words('Javanese-Latin1')[11:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<matplotlib.axes._subplots.AxesSubplot at 0x1f4d242a248>"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from nltk.corpus import udhr\n",
    "languages = ['Spanish', 'English', 'German_Deutsch', 'Greenlandic_Inuktikut', 'Hungarian_Magyar', 'Ibibio_Efik']\n",
    "cfd = nltk.ConditionalFreqDist(\n",
    "    (lang, len(word))\n",
    "    for lang in languages\n",
    "    for word in udhr.words(lang + '-Latin1'))\n",
    "cfd.plot(cumulative=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.8   Text Corpus Structure"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Help on package nltk.corpus.reader in nltk.corpus:\n",
      "\n",
      "NAME\n",
      "    nltk.corpus.reader\n",
      "\n",
      "DESCRIPTION\n",
      "    NLTK corpus readers.  The modules in this package provide functions\n",
      "    that can be used to read corpus fileids in a variety of formats.  These\n",
      "    functions can be used to read both the corpus fileids that are\n",
      "    distributed in the NLTK corpus package, and corpus fileids that are part\n",
      "    of external corpora.\n",
      "    \n",
      "    Corpus Reader Functions\n",
      "    =======================\n",
      "    Each corpus module defines one or more \"corpus reader functions\",\n",
      "    which can be used to read documents from that corpus.  These functions\n",
      "    take an argument, ``item``, which is used to indicate which document\n",
      "    should be read from the corpus:\n",
      "    \n",
      "    - If ``item`` is one of the unique identifiers listed in the corpus\n",
      "      module's ``items`` variable, then the corresponding document will\n",
      "      be loaded from the NLTK corpus package.\n",
      "    - If ``item`` is a fileid, then that file will be read.\n",
      "    \n",
      "    Additionally, corpus reader functions can be given lists of item\n",
      "    names; in which case, they will return a concatenation of the\n",
      "    corresponding documents.\n",
      "    \n",
      "    Corpus reader functions are named based on the type of information\n",
      "    they return.  Some common examples, and their return types, are:\n",
      "    \n",
      "    - words(): list of str\n",
      "    - sents(): list of (list of str)\n",
      "    - paras(): list of (list of (list of str))\n",
      "    - tagged_words(): list of (str,str) tuple\n",
      "    - tagged_sents(): list of (list of (str,str))\n",
      "    - tagged_paras(): list of (list of (list of (str,str)))\n",
      "    - chunked_sents(): list of (Tree w/ (str,str) leaves)\n",
      "    - parsed_sents(): list of (Tree with str leaves)\n",
      "    - parsed_paras(): list of (list of (Tree with str leaves))\n",
      "    - xml(): A single xml ElementTree\n",
      "    - raw(): unprocessed corpus contents\n",
      "    \n",
      "    For example, to read a list of the words in the Brown Corpus, use\n",
      "    ``nltk.corpus.brown.words()``:\n",
      "    \n",
      "        >>> from nltk.corpus import brown\n",
      "        >>> print(\", \".join(brown.words()))\n",
      "        The, Fulton, County, Grand, Jury, said, ...\n",
      "\n",
      "PACKAGE CONTENTS\n",
      "    aligned\n",
      "    api\n",
      "    bnc\n",
      "    bracket_parse\n",
      "    categorized_sents\n",
      "    chasen\n",
      "    childes\n",
      "    chunked\n",
      "    cmudict\n",
      "    comparative_sents\n",
      "    conll\n",
      "    crubadan\n",
      "    dependency\n",
      "    framenet\n",
      "    ieer\n",
      "    indian\n",
      "    ipipan\n",
      "    knbc\n",
      "    lin\n",
      "    mte\n",
      "    nkjp\n",
      "    nombank\n",
      "    nps_chat\n",
      "    opinion_lexicon\n",
      "    panlex_lite\n",
      "    panlex_swadesh\n",
      "    pl196x\n",
      "    plaintext\n",
      "    ppattach\n",
      "    propbank\n",
      "    pros_cons\n",
      "    reviews\n",
      "    rte\n",
      "    semcor\n",
      "    senseval\n",
      "    sentiwordnet\n",
      "    sinica_treebank\n",
      "    string_category\n",
      "    switchboard\n",
      "    tagged\n",
      "    timit\n",
      "    toolbox\n",
      "    twitter\n",
      "    udhr\n",
      "    util\n",
      "    verbnet\n",
      "    wordlist\n",
      "    wordnet\n",
      "    xmldocs\n",
      "    ycoe\n",
      "\n",
      "CLASSES\n",
      "    builtins.object\n",
      "        nltk.corpus.reader.api.CategorizedCorpusReader\n",
      "            nltk.corpus.reader.bracket_parse.CategorizedBracketParseCorpusReader(nltk.corpus.reader.api.CategorizedCorpusReader, nltk.corpus.reader.bracket_parse.BracketParseCorpusReader)\n",
      "            nltk.corpus.reader.categorized_sents.CategorizedSentencesCorpusReader(nltk.corpus.reader.api.CategorizedCorpusReader, nltk.corpus.reader.api.CorpusReader)\n",
      "            nltk.corpus.reader.pl196x.Pl196xCorpusReader(nltk.corpus.reader.api.CategorizedCorpusReader, nltk.corpus.reader.xmldocs.XMLCorpusReader)\n",
      "            nltk.corpus.reader.plaintext.CategorizedPlaintextCorpusReader(nltk.corpus.reader.api.CategorizedCorpusReader, nltk.corpus.reader.plaintext.PlaintextCorpusReader)\n",
      "                nltk.corpus.reader.plaintext.PortugueseCategorizedPlaintextCorpusReader\n",
      "            nltk.corpus.reader.pros_cons.ProsConsCorpusReader(nltk.corpus.reader.api.CategorizedCorpusReader, nltk.corpus.reader.api.CorpusReader)\n",
      "            nltk.corpus.reader.tagged.CategorizedTaggedCorpusReader(nltk.corpus.reader.api.CategorizedCorpusReader, nltk.corpus.reader.tagged.TaggedCorpusReader)\n",
      "        nltk.corpus.reader.api.CorpusReader\n",
      "            nltk.corpus.reader.aligned.AlignedCorpusReader\n",
      "            nltk.corpus.reader.api.SyntaxCorpusReader\n",
      "                nltk.corpus.reader.bracket_parse.BracketParseCorpusReader\n",
      "                    nltk.corpus.reader.bracket_parse.AlpinoCorpusReader\n",
      "                nltk.corpus.reader.dependency.DependencyCorpusReader\n",
      "                nltk.corpus.reader.knbc.KNBCorpusReader\n",
      "                nltk.corpus.reader.sinica_treebank.SinicaTreebankCorpusReader\n",
      "            nltk.corpus.reader.chasen.ChasenCorpusReader\n",
      "            nltk.corpus.reader.chunked.ChunkedCorpusReader\n",
      "            nltk.corpus.reader.cmudict.CMUDictCorpusReader\n",
      "            nltk.corpus.reader.comparative_sents.ComparativeSentencesCorpusReader\n",
      "            nltk.corpus.reader.conll.ConllCorpusReader\n",
      "                nltk.corpus.reader.conll.ConllChunkCorpusReader\n",
      "            nltk.corpus.reader.crubadan.CrubadanCorpusReader\n",
      "            nltk.corpus.reader.ieer.IEERCorpusReader\n",
      "            nltk.corpus.reader.indian.IndianCorpusReader\n",
      "            nltk.corpus.reader.ipipan.IPIPANCorpusReader\n",
      "            nltk.corpus.reader.lin.LinThesaurusCorpusReader\n",
      "            nltk.corpus.reader.nombank.NombankCorpusReader\n",
      "            nltk.corpus.reader.panlex_lite.PanLexLiteCorpusReader\n",
      "            nltk.corpus.reader.plaintext.PlaintextCorpusReader\n",
      "                nltk.corpus.reader.plaintext.EuroparlCorpusReader\n",
      "                nltk.corpus.reader.udhr.UdhrCorpusReader\n",
      "            nltk.corpus.reader.ppattach.PPAttachmentCorpusReader\n",
      "            nltk.corpus.reader.propbank.PropbankCorpusReader\n",
      "            nltk.corpus.reader.reviews.ReviewsCorpusReader\n",
      "            nltk.corpus.reader.senseval.SensevalCorpusReader\n",
      "            nltk.corpus.reader.sentiwordnet.SentiWordNetCorpusReader\n",
      "            nltk.corpus.reader.string_category.StringCategoryCorpusReader\n",
      "            nltk.corpus.reader.switchboard.SwitchboardCorpusReader\n",
      "            nltk.corpus.reader.tagged.TaggedCorpusReader\n",
      "                nltk.corpus.reader.mte.MTECorpusReader\n",
      "                nltk.corpus.reader.tagged.MacMorphoCorpusReader\n",
      "                nltk.corpus.reader.tagged.TimitTaggedCorpusReader\n",
      "            nltk.corpus.reader.timit.TimitCorpusReader\n",
      "            nltk.corpus.reader.toolbox.ToolboxCorpusReader\n",
      "            nltk.corpus.reader.twitter.TwitterCorpusReader\n",
      "            nltk.corpus.reader.wordlist.WordListCorpusReader\n",
      "                nltk.corpus.reader.opinion_lexicon.OpinionLexiconCorpusReader\n",
      "                nltk.corpus.reader.panlex_swadesh.PanlexSwadeshCorpusReader\n",
      "                nltk.corpus.reader.wordlist.MWAPPDBCorpusReader\n",
      "                nltk.corpus.reader.wordlist.NonbreakingPrefixesCorpusReader\n",
      "                nltk.corpus.reader.wordlist.SwadeshCorpusReader\n",
      "                nltk.corpus.reader.wordlist.UnicharsCorpusReader\n",
      "            nltk.corpus.reader.wordnet.WordNetCorpusReader\n",
      "            nltk.corpus.reader.wordnet.WordNetICCorpusReader\n",
      "            nltk.corpus.reader.xmldocs.XMLCorpusReader\n",
      "                nltk.corpus.reader.bnc.BNCCorpusReader\n",
      "                nltk.corpus.reader.childes.CHILDESCorpusReader\n",
      "                nltk.corpus.reader.framenet.FramenetCorpusReader\n",
      "                nltk.corpus.reader.nkjp.NKJPCorpusReader\n",
      "                nltk.corpus.reader.nps_chat.NPSChatCorpusReader\n",
      "                nltk.corpus.reader.rte.RTECorpusReader\n",
      "                nltk.corpus.reader.semcor.SemcorCorpusReader\n",
      "                nltk.corpus.reader.verbnet.VerbnetCorpusReader\n",
      "            nltk.corpus.reader.ycoe.YCOECorpusReader\n",
      "        nltk.corpus.reader.sentiwordnet.SentiSynset\n",
      "    nltk.corpus.reader.util.StreamBackedCorpusView(nltk.collections.AbstractLazySequence)\n",
      "        nltk.corpus.reader.pl196x.TEICorpusView\n",
      "    \n",
      "    class AlignedCorpusReader(nltk.corpus.reader.api.CorpusReader)\n",
      "     |  AlignedCorpusReader(root, fileids, sep='/', word_tokenizer=WhitespaceTokenizer(pattern='\\\\s+', gaps=True, discard_empty=True, flags=<RegexFlag.UNICODE|DOTALL|MULTILINE: 56>), sent_tokenizer=RegexpTokenizer(pattern='\\n', gaps=True, discard_empty=True, flags=<RegexFlag.UNICODE|DOTALL|MULTILINE: 56>), alignedsent_block_reader=<function read_alignedsent_block at 0x000001F4CED35A68>, encoding='latin1')\n",
      "     |  \n",
      "     |  Reader for corpora of word-aligned sentences.  Tokens are assumed\n",
      "     |  to be separated by whitespace.  Sentences begin on separate lines.\n",
      "     |  \n",
      "     |  Method resolution order:\n",
      "     |      AlignedCorpusReader\n",
      "     |      nltk.corpus.reader.api.CorpusReader\n",
      "     |      builtins.object\n",
      "     |  \n",
      "     |  Methods defined here:\n",
      "     |  \n",
      "     |  __init__(self, root, fileids, sep='/', word_tokenizer=WhitespaceTokenizer(pattern='\\\\s+', gaps=True, discard_empty=True, flags=<RegexFlag.UNICODE|DOTALL|MULTILINE: 56>), sent_tokenizer=RegexpTokenizer(pattern='\\n', gaps=True, discard_empty=True, flags=<RegexFlag.UNICODE|DOTALL|MULTILINE: 56>), alignedsent_block_reader=<function read_alignedsent_block at 0x000001F4CED35A68>, encoding='latin1')\n",
      "     |      Construct a new Aligned Corpus reader for a set of documents\n",
      "     |      located at the given root directory.  Example usage:\n",
      "     |      \n",
      "     |          >>> root = '/...path to corpus.../'\n",
      "     |          >>> reader = AlignedCorpusReader(root, '.*', '.txt') # doctest: +SKIP\n",
      "     |      \n",
      "     |      :param root: The root directory for this corpus.\n",
      "     |      :param fileids: A list or regexp specifying the fileids in this corpus.\n",
      "     |  \n",
      "     |  aligned_sents(self, fileids=None)\n",
      "     |      :return: the given file(s) as a list of AlignedSent objects.\n",
      "     |      :rtype: list(AlignedSent)\n",
      "     |  \n",
      "     |  raw(self, fileids=None)\n",
      "     |      :return: the given file(s) as a single string.\n",
      "     |      :rtype: str\n",
      "     |  \n",
      "     |  sents(self, fileids=None)\n",
      "     |      :return: the given file(s) as a list of\n",
      "     |          sentences or utterances, each encoded as a list of word\n",
      "     |          strings.\n",
      "     |      :rtype: list(list(str))\n",
      "     |  \n",
      "     |  words(self, fileids=None)\n",
      "     |      :return: the given file(s) as a list of words\n",
      "     |          and punctuation symbols.\n",
      "     |      :rtype: list(str)\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Methods inherited from nltk.corpus.reader.api.CorpusReader:\n",
      "     |  \n",
      "     |  __repr__(self)\n",
      "     |      Return repr(self).\n",
      "     |  \n",
      "     |  __unicode__ = __str__(self, /)\n",
      "     |  \n",
      "     |  abspath(self, fileid)\n",
      "     |      Return the absolute path for the given file.\n",
      "     |      \n",
      "     |      :type fileid: str\n",
      "     |      :param fileid: The file identifier for the file whose path\n",
      "     |          should be returned.\n",
      "     |      :rtype: PathPointer\n",
      "     |  \n",
      "     |  abspaths(self, fileids=None, include_encoding=False, include_fileid=False)\n",
      "     |      Return a list of the absolute paths for all fileids in this corpus;\n",
      "     |      or for the given list of fileids, if specified.\n",
      "     |      \n",
      "     |      :type fileids: None or str or list\n",
      "     |      :param fileids: Specifies the set of fileids for which paths should\n",
      "     |          be returned.  Can be None, for all fileids; a list of\n",
      "     |          file identifiers, for a specified set of fileids; or a single\n",
      "     |          file identifier, for a single file.  Note that the return\n",
      "     |          value is always a list of paths, even if ``fileids`` is a\n",
      "     |          single file identifier.\n",
      "     |      \n",
      "     |      :param include_encoding: If true, then return a list of\n",
      "     |          ``(path_pointer, encoding)`` tuples.\n",
      "     |      \n",
      "     |      :rtype: list(PathPointer)\n",
      "     |  \n",
      "     |  citation(self)\n",
      "     |      Return the contents of the corpus citation.bib file, if it exists.\n",
      "     |  \n",
      "     |  encoding(self, file)\n",
      "     |      Return the unicode encoding for the given corpus file, if known.\n",
      "     |      If the encoding is unknown, or if the given file should be\n",
      "     |      processed using byte strings (str), then return None.\n",
      "     |  \n",
      "     |  ensure_loaded(self)\n",
      "     |      Load this corpus (if it has not already been loaded).  This is\n",
      "     |      used by LazyCorpusLoader as a simple method that can be used to\n",
      "     |      make sure a corpus is loaded -- e.g., in case a user wants to\n",
      "     |      do help(some_corpus).\n",
      "     |  \n",
      "     |  fileids(self)\n",
      "     |      Return a list of file identifiers for the fileids that make up\n",
      "     |      this corpus.\n",
      "     |  \n",
      "     |  license(self)\n",
      "     |      Return the contents of the corpus LICENSE file, if it exists.\n",
      "     |  \n",
      "     |  open(self, file)\n",
      "     |      Return an open stream that can be used to read the given file.\n",
      "     |      If the file's encoding is not None, then the stream will\n",
      "     |      automatically decode the file's contents into unicode.\n",
      "     |      \n",
      "     |      :param file: The file identifier of the file to read.\n",
      "     |  \n",
      "     |  readme(self)\n",
      "     |      Return the contents of the corpus README file, if it exists.\n",
      "     |  \n",
      "     |  unicode_repr = __repr__(self)\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Data descriptors inherited from nltk.corpus.reader.api.CorpusReader:\n",
      "     |  \n",
      "     |  __dict__\n",
      "     |      dictionary for instance variables (if defined)\n",
      "     |  \n",
      "     |  __weakref__\n",
      "     |      list of weak references to the object (if defined)\n",
      "     |  \n",
      "     |  root\n",
      "     |      The directory where this corpus is stored.\n",
      "     |      \n",
      "     |      :type: PathPointer\n",
      "    \n",
      "    class AlpinoCorpusReader(BracketParseCorpusReader)\n",
      "     |  AlpinoCorpusReader(root, encoding='ISO-8859-1', tagset=None)\n",
      "     |  \n",
      "     |  Reader for the Alpino Dutch Treebank.\n",
      "     |  This corpus has a lexical breakdown structure embedded, as read by _parse\n",
      "     |  Unfortunately this puts punctuation and some other words out of the sentence\n",
      "     |  order in the xml element tree. This is no good for tag_ and word_\n",
      "     |  _tag and _word will be overridden to use a non-default new parameter 'ordered'\n",
      "     |  to the overridden _normalize function. The _parse function can then remain\n",
      "     |  untouched.\n",
      "     |  \n",
      "     |  Method resolution order:\n",
      "     |      AlpinoCorpusReader\n",
      "     |      BracketParseCorpusReader\n",
      "     |      nltk.corpus.reader.api.SyntaxCorpusReader\n",
      "     |      nltk.corpus.reader.api.CorpusReader\n",
      "     |      builtins.object\n",
      "     |  \n",
      "     |  Methods defined here:\n",
      "     |  \n",
      "     |  __init__(self, root, encoding='ISO-8859-1', tagset=None)\n",
      "     |      :param root: The root directory for this corpus.\n",
      "     |      :param fileids: A list or regexp specifying the fileids in this corpus.\n",
      "     |      :param comment_char: The character which can appear at the start of\n",
      "     |          a line to indicate that the rest of the line is a comment.\n",
      "     |      :param detect_blocks: The method that is used to find blocks\n",
      "     |        in the corpus; can be 'unindented_paren' (every unindented\n",
      "     |        parenthesis starts a new parse) or 'sexpr' (brackets are\n",
      "     |        matched).\n",
      "     |      :param tagset: The name of the tagset used by this corpus, to be used\n",
      "     |            for normalizing or converting the POS tags returned by the\n",
      "     |            tagged_...() methods.\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Methods inherited from nltk.corpus.reader.api.SyntaxCorpusReader:\n",
      "     |  \n",
      "     |  parsed_sents(self, fileids=None)\n",
      "     |  \n",
      "     |  raw(self, fileids=None)\n",
      "     |  \n",
      "     |  sents(self, fileids=None)\n",
      "     |  \n",
      "     |  tagged_sents(self, fileids=None, tagset=None)\n",
      "     |  \n",
      "     |  tagged_words(self, fileids=None, tagset=None)\n",
      "     |  \n",
      "     |  words(self, fileids=None)\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Methods inherited from nltk.corpus.reader.api.CorpusReader:\n",
      "     |  \n",
      "     |  __repr__(self)\n",
      "     |      Return repr(self).\n",
      "     |  \n",
      "     |  __unicode__ = __str__(self, /)\n",
      "     |  \n",
      "     |  abspath(self, fileid)\n",
      "     |      Return the absolute path for the given file.\n",
      "     |      \n",
      "     |      :type fileid: str\n",
      "     |      :param fileid: The file identifier for the file whose path\n",
      "     |          should be returned.\n",
      "     |      :rtype: PathPointer\n",
      "     |  \n",
      "     |  abspaths(self, fileids=None, include_encoding=False, include_fileid=False)\n",
      "     |      Return a list of the absolute paths for all fileids in this corpus;\n",
      "     |      or for the given list of fileids, if specified.\n",
      "     |      \n",
      "     |      :type fileids: None or str or list\n",
      "     |      :param fileids: Specifies the set of fileids for which paths should\n",
      "     |          be returned.  Can be None, for all fileids; a list of\n",
      "     |          file identifiers, for a specified set of fileids; or a single\n",
      "     |          file identifier, for a single file.  Note that the return\n",
      "     |          value is always a list of paths, even if ``fileids`` is a\n",
      "     |          single file identifier.\n",
      "     |      \n",
      "     |      :param include_encoding: If true, then return a list of\n",
      "     |          ``(path_pointer, encoding)`` tuples.\n",
      "     |      \n",
      "     |      :rtype: list(PathPointer)\n",
      "     |  \n",
      "     |  citation(self)\n",
      "     |      Return the contents of the corpus citation.bib file, if it exists.\n",
      "     |  \n",
      "     |  encoding(self, file)\n",
      "     |      Return the unicode encoding for the given corpus file, if known.\n",
      "     |      If the encoding is unknown, or if the given file should be\n",
      "     |      processed using byte strings (str), then return None.\n",
      "     |  \n",
      "     |  ensure_loaded(self)\n",
      "     |      Load this corpus (if it has not already been loaded).  This is\n",
      "     |      used by LazyCorpusLoader as a simple method that can be used to\n",
      "     |      make sure a corpus is loaded -- e.g., in case a user wants to\n",
      "     |      do help(some_corpus).\n",
      "     |  \n",
      "     |  fileids(self)\n",
      "     |      Return a list of file identifiers for the fileids that make up\n",
      "     |      this corpus.\n",
      "     |  \n",
      "     |  license(self)\n",
      "     |      Return the contents of the corpus LICENSE file, if it exists.\n",
      "     |  \n",
      "     |  open(self, file)\n",
      "     |      Return an open stream that can be used to read the given file.\n",
      "     |      If the file's encoding is not None, then the stream will\n",
      "     |      automatically decode the file's contents into unicode.\n",
      "     |      \n",
      "     |      :param file: The file identifier of the file to read.\n",
      "     |  \n",
      "     |  readme(self)\n",
      "     |      Return the contents of the corpus README file, if it exists.\n",
      "     |  \n",
      "     |  unicode_repr = __repr__(self)\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Data descriptors inherited from nltk.corpus.reader.api.CorpusReader:\n",
      "     |  \n",
      "     |  __dict__\n",
      "     |      dictionary for instance variables (if defined)\n",
      "     |  \n",
      "     |  __weakref__\n",
      "     |      list of weak references to the object (if defined)\n",
      "     |  \n",
      "     |  root\n",
      "     |      The directory where this corpus is stored.\n",
      "     |      \n",
      "     |      :type: PathPointer\n",
      "    \n",
      "    class BNCCorpusReader(nltk.corpus.reader.xmldocs.XMLCorpusReader)\n",
      "     |  BNCCorpusReader(root, fileids, lazy=True)\n",
      "     |  \n",
      "     |  Corpus reader for the XML version of the British National Corpus.\n",
      "     |  \n",
      "     |  For access to the complete XML data structure, use the ``xml()``\n",
      "     |  method.  For access to simple word lists and tagged word lists, use\n",
      "     |  ``words()``, ``sents()``, ``tagged_words()``, and ``tagged_sents()``.\n",
      "     |  \n",
      "     |  You can obtain the full version of the BNC corpus at\n",
      "     |  http://www.ota.ox.ac.uk/desc/2554\n",
      "     |  \n",
      "     |  If you extracted the archive to a directory called `BNC`, then you can\n",
      "     |  instantiate the reader as::\n",
      "     |  \n",
      "     |      BNCCorpusReader(root='BNC/Texts/', fileids=r'[A-K]/\\w*/\\w*\\.xml')\n",
      "     |  \n",
      "     |  Method resolution order:\n",
      "     |      BNCCorpusReader\n",
      "     |      nltk.corpus.reader.xmldocs.XMLCorpusReader\n",
      "     |      nltk.corpus.reader.api.CorpusReader\n",
      "     |      builtins.object\n",
      "     |  \n",
      "     |  Methods defined here:\n",
      "     |  \n",
      "     |  __init__(self, root, fileids, lazy=True)\n",
      "     |      :type root: PathPointer or str\n",
      "     |      :param root: A path pointer identifying the root directory for\n",
      "     |          this corpus.  If a string is specified, then it will be\n",
      "     |          converted to a ``PathPointer`` automatically.\n",
      "     |      :param fileids: A list of the files that make up this corpus.\n",
      "     |          This list can either be specified explicitly, as a list of\n",
      "     |          strings; or implicitly, as a regular expression over file\n",
      "     |          paths.  The absolute path for each file will be constructed\n",
      "     |          by joining the reader's root to each file name.\n",
      "     |      :param encoding: The default unicode encoding for the files\n",
      "     |          that make up the corpus.  The value of ``encoding`` can be any\n",
      "     |          of the following:\n",
      "     |          - A string: ``encoding`` is the encoding name for all files.\n",
      "     |          - A dictionary: ``encoding[file_id]`` is the encoding\n",
      "     |            name for the file whose identifier is ``file_id``.  If\n",
      "     |            ``file_id`` is not in ``encoding``, then the file\n",
      "     |            contents will be processed using non-unicode byte strings.\n",
      "     |          - A list: ``encoding`` should be a list of ``(regexp, encoding)``\n",
      "     |            tuples.  The encoding for a file whose identifier is ``file_id``\n",
      "     |            will be the ``encoding`` value for the first tuple whose\n",
      "     |            ``regexp`` matches the ``file_id``.  If no tuple's ``regexp``\n",
      "     |            matches the ``file_id``, the file contents will be processed\n",
      "     |            using non-unicode byte strings.\n",
      "     |          - None: the file contents of all files will be\n",
      "     |            processed using non-unicode byte strings.\n",
      "     |      :param tagset: The name of the tagset used by this corpus, to be used\n",
      "     |            for normalizing or converting the POS tags returned by the\n",
      "     |            tagged_...() methods.\n",
      "     |  \n",
      "     |  sents(self, fileids=None, strip_space=True, stem=False)\n",
      "     |      :return: the given file(s) as a list of\n",
      "     |          sentences or utterances, each encoded as a list of word\n",
      "     |          strings.\n",
      "     |      :rtype: list(list(str))\n",
      "     |      \n",
      "     |      :param strip_space: If true, then strip trailing spaces from\n",
      "     |          word tokens.  Otherwise, leave the spaces on the tokens.\n",
      "     |      :param stem: If true, then use word stems instead of word strings.\n",
      "     |  \n",
      "     |  tagged_sents(self, fileids=None, c5=False, strip_space=True, stem=False)\n",
      "     |      :return: the given file(s) as a list of\n",
      "     |          sentences, each encoded as a list of ``(word,tag)`` tuples.\n",
      "     |      :rtype: list(list(tuple(str,str)))\n",
      "     |      \n",
      "     |      :param c5: If true, then the tags used will be the more detailed\n",
      "     |          c5 tags.  Otherwise, the simplified tags will be used.\n",
      "     |      :param strip_space: If true, then strip trailing spaces from\n",
      "     |          word tokens.  Otherwise, leave the spaces on the tokens.\n",
      "     |      :param stem: If true, then use word stems instead of word strings.\n",
      "     |  \n",
      "     |  tagged_words(self, fileids=None, c5=False, strip_space=True, stem=False)\n",
      "     |      :return: the given file(s) as a list of tagged\n",
      "     |          words and punctuation symbols, encoded as tuples\n",
      "     |          ``(word,tag)``.\n",
      "     |      :rtype: list(tuple(str,str))\n",
      "     |      \n",
      "     |      :param c5: If true, then the tags used will be the more detailed\n",
      "     |          c5 tags.  Otherwise, the simplified tags will be used.\n",
      "     |      :param strip_space: If true, then strip trailing spaces from\n",
      "     |          word tokens.  Otherwise, leave the spaces on the tokens.\n",
      "     |      :param stem: If true, then use word stems instead of word strings.\n",
      "     |  \n",
      "     |  words(self, fileids=None, strip_space=True, stem=False)\n",
      "     |      :return: the given file(s) as a list of words\n",
      "     |          and punctuation symbols.\n",
      "     |      :rtype: list(str)\n",
      "     |      \n",
      "     |      :param strip_space: If true, then strip trailing spaces from\n",
      "     |          word tokens.  Otherwise, leave the spaces on the tokens.\n",
      "     |      :param stem: If true, then use word stems instead of word strings.\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Methods inherited from nltk.corpus.reader.xmldocs.XMLCorpusReader:\n",
      "     |  \n",
      "     |  raw(self, fileids=None)\n",
      "     |  \n",
      "     |  xml(self, fileid=None)\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Methods inherited from nltk.corpus.reader.api.CorpusReader:\n",
      "     |  \n",
      "     |  __repr__(self)\n",
      "     |      Return repr(self).\n",
      "     |  \n",
      "     |  __unicode__ = __str__(self, /)\n",
      "     |  \n",
      "     |  abspath(self, fileid)\n",
      "     |      Return the absolute path for the given file.\n",
      "     |      \n",
      "     |      :type fileid: str\n",
      "     |      :param fileid: The file identifier for the file whose path\n",
      "     |          should be returned.\n",
      "     |      :rtype: PathPointer\n",
      "     |  \n",
      "     |  abspaths(self, fileids=None, include_encoding=False, include_fileid=False)\n",
      "     |      Return a list of the absolute paths for all fileids in this corpus;\n",
      "     |      or for the given list of fileids, if specified.\n",
      "     |      \n",
      "     |      :type fileids: None or str or list\n",
      "     |      :param fileids: Specifies the set of fileids for which paths should\n",
      "     |          be returned.  Can be None, for all fileids; a list of\n",
      "     |          file identifiers, for a specified set of fileids; or a single\n",
      "     |          file identifier, for a single file.  Note that the return\n",
      "     |          value is always a list of paths, even if ``fileids`` is a\n",
      "     |          single file identifier.\n",
      "     |      \n",
      "     |      :param include_encoding: If true, then return a list of\n",
      "     |          ``(path_pointer, encoding)`` tuples.\n",
      "     |      \n",
      "     |      :rtype: list(PathPointer)\n",
      "     |  \n",
      "     |  citation(self)\n",
      "     |      Return the contents of the corpus citation.bib file, if it exists.\n",
      "     |  \n",
      "     |  encoding(self, file)\n",
      "     |      Return the unicode encoding for the given corpus file, if known.\n",
      "     |      If the encoding is unknown, or if the given file should be\n",
      "     |      processed using byte strings (str), then return None.\n",
      "     |  \n",
      "     |  ensure_loaded(self)\n",
      "     |      Load this corpus (if it has not already been loaded).  This is\n",
      "     |      used by LazyCorpusLoader as a simple method that can be used to\n",
      "     |      make sure a corpus is loaded -- e.g., in case a user wants to\n",
      "     |      do help(some_corpus).\n",
      "     |  \n",
      "     |  fileids(self)\n",
      "     |      Return a list of file identifiers for the fileids that make up\n",
      "     |      this corpus.\n",
      "     |  \n",
      "     |  license(self)\n",
      "     |      Return the contents of the corpus LICENSE file, if it exists.\n",
      "     |  \n",
      "     |  open(self, file)\n",
      "     |      Return an open stream that can be used to read the given file.\n",
      "     |      If the file's encoding is not None, then the stream will\n",
      "     |      automatically decode the file's contents into unicode.\n",
      "     |      \n",
      "     |      :param file: The file identifier of the file to read.\n",
      "     |  \n",
      "     |  readme(self)\n",
      "     |      Return the contents of the corpus README file, if it exists.\n",
      "     |  \n",
      "     |  unicode_repr = __repr__(self)\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Data descriptors inherited from nltk.corpus.reader.api.CorpusReader:\n",
      "     |  \n",
      "     |  __dict__\n",
      "     |      dictionary for instance variables (if defined)\n",
      "     |  \n",
      "     |  __weakref__\n",
      "     |      list of weak references to the object (if defined)\n",
      "     |  \n",
      "     |  root\n",
      "     |      The directory where this corpus is stored.\n",
      "     |      \n",
      "     |      :type: PathPointer\n",
      "    \n",
      "    class BracketParseCorpusReader(nltk.corpus.reader.api.SyntaxCorpusReader)\n",
      "     |  BracketParseCorpusReader(root, fileids, comment_char=None, detect_blocks='unindented_paren', encoding='utf8', tagset=None)\n",
      "     |  \n",
      "     |  Reader for corpora that consist of parenthesis-delineated parse trees,\n",
      "     |  like those found in the \"combined\" section of the Penn Treebank,\n",
      "     |  e.g. \"(S (NP (DT the) (JJ little) (NN dog)) (VP (VBD barked)))\".\n",
      "     |  \n",
      "     |  Method resolution order:\n",
      "     |      BracketParseCorpusReader\n",
      "     |      nltk.corpus.reader.api.SyntaxCorpusReader\n",
      "     |      nltk.corpus.reader.api.CorpusReader\n",
      "     |      builtins.object\n",
      "     |  \n",
      "     |  Methods defined here:\n",
      "     |  \n",
      "     |  __init__(self, root, fileids, comment_char=None, detect_blocks='unindented_paren', encoding='utf8', tagset=None)\n",
      "     |      :param root: The root directory for this corpus.\n",
      "     |      :param fileids: A list or regexp specifying the fileids in this corpus.\n",
      "     |      :param comment_char: The character which can appear at the start of\n",
      "     |          a line to indicate that the rest of the line is a comment.\n",
      "     |      :param detect_blocks: The method that is used to find blocks\n",
      "     |        in the corpus; can be 'unindented_paren' (every unindented\n",
      "     |        parenthesis starts a new parse) or 'sexpr' (brackets are\n",
      "     |        matched).\n",
      "     |      :param tagset: The name of the tagset used by this corpus, to be used\n",
      "     |            for normalizing or converting the POS tags returned by the\n",
      "     |            tagged_...() methods.\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Methods inherited from nltk.corpus.reader.api.SyntaxCorpusReader:\n",
      "     |  \n",
      "     |  parsed_sents(self, fileids=None)\n",
      "     |  \n",
      "     |  raw(self, fileids=None)\n",
      "     |  \n",
      "     |  sents(self, fileids=None)\n",
      "     |  \n",
      "     |  tagged_sents(self, fileids=None, tagset=None)\n",
      "     |  \n",
      "     |  tagged_words(self, fileids=None, tagset=None)\n",
      "     |  \n",
      "     |  words(self, fileids=None)\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Methods inherited from nltk.corpus.reader.api.CorpusReader:\n",
      "     |  \n",
      "     |  __repr__(self)\n",
      "     |      Return repr(self).\n",
      "     |  \n",
      "     |  __unicode__ = __str__(self, /)\n",
      "     |  \n",
      "     |  abspath(self, fileid)\n",
      "     |      Return the absolute path for the given file.\n",
      "     |      \n",
      "     |      :type fileid: str\n",
      "     |      :param fileid: The file identifier for the file whose path\n",
      "     |          should be returned.\n",
      "     |      :rtype: PathPointer\n",
      "     |  \n",
      "     |  abspaths(self, fileids=None, include_encoding=False, include_fileid=False)\n",
      "     |      Return a list of the absolute paths for all fileids in this corpus;\n",
      "     |      or for the given list of fileids, if specified.\n",
      "     |      \n",
      "     |      :type fileids: None or str or list\n",
      "     |      :param fileids: Specifies the set of fileids for which paths should\n",
      "     |          be returned.  Can be None, for all fileids; a list of\n",
      "     |          file identifiers, for a specified set of fileids; or a single\n",
      "     |          file identifier, for a single file.  Note that the return\n",
      "     |          value is always a list of paths, even if ``fileids`` is a\n",
      "     |          single file identifier.\n",
      "     |      \n",
      "     |      :param include_encoding: If true, then return a list of\n",
      "     |          ``(path_pointer, encoding)`` tuples.\n",
      "     |      \n",
      "     |      :rtype: list(PathPointer)\n",
      "     |  \n",
      "     |  citation(self)\n",
      "     |      Return the contents of the corpus citation.bib file, if it exists.\n",
      "     |  \n",
      "     |  encoding(self, file)\n",
      "     |      Return the unicode encoding for the given corpus file, if known.\n",
      "     |      If the encoding is unknown, or if the given file should be\n",
      "     |      processed using byte strings (str), then return None.\n",
      "     |  \n",
      "     |  ensure_loaded(self)\n",
      "     |      Load this corpus (if it has not already been loaded).  This is\n",
      "     |      used by LazyCorpusLoader as a simple method that can be used to\n",
      "     |      make sure a corpus is loaded -- e.g., in case a user wants to\n",
      "     |      do help(some_corpus).\n",
      "     |  \n",
      "     |  fileids(self)\n",
      "     |      Return a list of file identifiers for the fileids that make up\n",
      "     |      this corpus.\n",
      "     |  \n",
      "     |  license(self)\n",
      "     |      Return the contents of the corpus LICENSE file, if it exists.\n",
      "     |  \n",
      "     |  open(self, file)\n",
      "     |      Return an open stream that can be used to read the given file.\n",
      "     |      If the file's encoding is not None, then the stream will\n",
      "     |      automatically decode the file's contents into unicode.\n",
      "     |      \n",
      "     |      :param file: The file identifier of the file to read.\n",
      "     |  \n",
      "     |  readme(self)\n",
      "     |      Return the contents of the corpus README file, if it exists.\n",
      "     |  \n",
      "     |  unicode_repr = __repr__(self)\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Data descriptors inherited from nltk.corpus.reader.api.CorpusReader:\n",
      "     |  \n",
      "     |  __dict__\n",
      "     |      dictionary for instance variables (if defined)\n",
      "     |  \n",
      "     |  __weakref__\n",
      "     |      list of weak references to the object (if defined)\n",
      "     |  \n",
      "     |  root\n",
      "     |      The directory where this corpus is stored.\n",
      "     |      \n",
      "     |      :type: PathPointer\n",
      "    \n",
      "    class CHILDESCorpusReader(nltk.corpus.reader.xmldocs.XMLCorpusReader)\n",
      "     |  CHILDESCorpusReader(root, fileids, lazy=True)\n",
      "     |  \n",
      "     |  Corpus reader for the XML version of the CHILDES corpus.\n",
      "     |  The CHILDES corpus is available at ``https://childes.talkbank.org/``. The XML\n",
      "     |  version of CHILDES is located at ``https://childes.talkbank.org/data-xml/``.\n",
      "     |  Copy the needed parts of the CHILDES XML corpus into the NLTK data directory\n",
      "     |  (``nltk_data/corpora/CHILDES/``).\n",
      "     |  \n",
      "     |  For access to the file text use the usual nltk functions,\n",
      "     |  ``words()``, ``sents()``, ``tagged_words()`` and ``tagged_sents()``.\n",
      "     |  \n",
      "     |  Method resolution order:\n",
      "     |      CHILDESCorpusReader\n",
      "     |      nltk.corpus.reader.xmldocs.XMLCorpusReader\n",
      "     |      nltk.corpus.reader.api.CorpusReader\n",
      "     |      builtins.object\n",
      "     |  \n",
      "     |  Methods defined here:\n",
      "     |  \n",
      "     |  MLU(self, fileids=None, speaker='CHI')\n",
      "     |      :return: the given file(s) as a floating number\n",
      "     |      :rtype: list(float)\n",
      "     |  \n",
      "     |  __init__(self, root, fileids, lazy=True)\n",
      "     |      :type root: PathPointer or str\n",
      "     |      :param root: A path pointer identifying the root directory for\n",
      "     |          this corpus.  If a string is specified, then it will be\n",
      "     |          converted to a ``PathPointer`` automatically.\n",
      "     |      :param fileids: A list of the files that make up this corpus.\n",
      "     |          This list can either be specified explicitly, as a list of\n",
      "     |          strings; or implicitly, as a regular expression over file\n",
      "     |          paths.  The absolute path for each file will be constructed\n",
      "     |          by joining the reader's root to each file name.\n",
      "     |      :param encoding: The default unicode encoding for the files\n",
      "     |          that make up the corpus.  The value of ``encoding`` can be any\n",
      "     |          of the following:\n",
      "     |          - A string: ``encoding`` is the encoding name for all files.\n",
      "     |          - A dictionary: ``encoding[file_id]`` is the encoding\n",
      "     |            name for the file whose identifier is ``file_id``.  If\n",
      "     |            ``file_id`` is not in ``encoding``, then the file\n",
      "     |            contents will be processed using non-unicode byte strings.\n",
      "     |          - A list: ``encoding`` should be a list of ``(regexp, encoding)``\n",
      "     |            tuples.  The encoding for a file whose identifier is ``file_id``\n",
      "     |            will be the ``encoding`` value for the first tuple whose\n",
      "     |            ``regexp`` matches the ``file_id``.  If no tuple's ``regexp``\n",
      "     |            matches the ``file_id``, the file contents will be processed\n",
      "     |            using non-unicode byte strings.\n",
      "     |          - None: the file contents of all files will be\n",
      "     |            processed using non-unicode byte strings.\n",
      "     |      :param tagset: The name of the tagset used by this corpus, to be used\n",
      "     |            for normalizing or converting the POS tags returned by the\n",
      "     |            tagged_...() methods.\n",
      "     |  \n",
      "     |  age(self, fileids=None, speaker='CHI', month=False)\n",
      "     |      :return: the given file(s) as string or int\n",
      "     |      :rtype: list or int\n",
      "     |      \n",
      "     |      :param month: If true, return months instead of year-month-date\n",
      "     |  \n",
      "     |  convert_age(self, age_year)\n",
      "     |      Caclculate age in months from a string in CHILDES format\n",
      "     |  \n",
      "     |  corpus(self, fileids=None)\n",
      "     |      :return: the given file(s) as a dict of ``(corpus_property_key, value)``\n",
      "     |      :rtype: list(dict)\n",
      "     |  \n",
      "     |  participants(self, fileids=None)\n",
      "     |      :return: the given file(s) as a dict of\n",
      "     |          ``(participant_property_key, value)``\n",
      "     |      :rtype: list(dict)\n",
      "     |  \n",
      "     |  sents(self, fileids=None, speaker='ALL', stem=False, relation=None, strip_space=True, replace=False)\n",
      "     |      :return: the given file(s) as a list of sentences or utterances, each\n",
      "     |          encoded as a list of word strings.\n",
      "     |      :rtype: list(list(str))\n",
      "     |      \n",
      "     |      :param speaker: If specified, select specific speaker(s) defined\n",
      "     |          in the corpus. Default is 'ALL' (all participants). Common choices\n",
      "     |          are 'CHI' (the child), 'MOT' (mother), ['CHI','MOT'] (exclude\n",
      "     |          researchers)\n",
      "     |      :param stem: If true, then use word stems instead of word strings.\n",
      "     |      :param relation: If true, then return tuples of ``(str,pos,relation_list)``.\n",
      "     |          If there is manually-annotated relation info, it will return\n",
      "     |          tuples of ``(str,pos,test_relation_list,str,pos,gold_relation_list)``\n",
      "     |      :param strip_space: If true, then strip trailing spaces from word\n",
      "     |          tokens. Otherwise, leave the spaces on the tokens.\n",
      "     |      :param replace: If true, then use the replaced (intended) word instead\n",
      "     |          of the original word (e.g., 'wat' will be replaced with 'watch')\n",
      "     |  \n",
      "     |  tagged_sents(self, fileids=None, speaker='ALL', stem=False, relation=None, strip_space=True, replace=False)\n",
      "     |      :return: the given file(s) as a list of\n",
      "     |          sentences, each encoded as a list of ``(word,tag)`` tuples.\n",
      "     |      :rtype: list(list(tuple(str,str)))\n",
      "     |      \n",
      "     |      :param speaker: If specified, select specific speaker(s) defined\n",
      "     |          in the corpus. Default is 'ALL' (all participants). Common choices\n",
      "     |          are 'CHI' (the child), 'MOT' (mother), ['CHI','MOT'] (exclude\n",
      "     |          researchers)\n",
      "     |      :param stem: If true, then use word stems instead of word strings.\n",
      "     |      :param relation: If true, then return tuples of ``(str,pos,relation_list)``.\n",
      "     |          If there is manually-annotated relation info, it will return\n",
      "     |          tuples of ``(str,pos,test_relation_list,str,pos,gold_relation_list)``\n",
      "     |      :param strip_space: If true, then strip trailing spaces from word\n",
      "     |          tokens. Otherwise, leave the spaces on the tokens.\n",
      "     |      :param replace: If true, then use the replaced (intended) word instead\n",
      "     |          of the original word (e.g., 'wat' will be replaced with 'watch')\n",
      "     |  \n",
      "     |  tagged_words(self, fileids=None, speaker='ALL', stem=False, relation=False, strip_space=True, replace=False)\n",
      "     |      :return: the given file(s) as a list of tagged\n",
      "     |          words and punctuation symbols, encoded as tuples\n",
      "     |          ``(word,tag)``.\n",
      "     |      :rtype: list(tuple(str,str))\n",
      "     |      \n",
      "     |      :param speaker: If specified, select specific speaker(s) defined\n",
      "     |          in the corpus. Default is 'ALL' (all participants). Common choices\n",
      "     |          are 'CHI' (the child), 'MOT' (mother), ['CHI','MOT'] (exclude\n",
      "     |          researchers)\n",
      "     |      :param stem: If true, then use word stems instead of word strings.\n",
      "     |      :param relation: If true, then return tuples of (stem, index,\n",
      "     |          dependent_index)\n",
      "     |      :param strip_space: If true, then strip trailing spaces from word\n",
      "     |          tokens. Otherwise, leave the spaces on the tokens.\n",
      "     |      :param replace: If true, then use the replaced (intended) word instead\n",
      "     |          of the original word (e.g., 'wat' will be replaced with 'watch')\n",
      "     |  \n",
      "     |  webview_file(self, fileid, urlbase=None)\n",
      "     |      Map a corpus file to its web version on the CHILDES website,\n",
      "     |      and open it in a web browser.\n",
      "     |      \n",
      "     |      The complete URL to be used is:\n",
      "     |          childes.childes_url_base + urlbase + fileid.replace('.xml', '.cha')\n",
      "     |      \n",
      "     |      If no urlbase is passed, we try to calculate it.  This\n",
      "     |      requires that the childes corpus was set up to mirror the\n",
      "     |      folder hierarchy under childes.psy.cmu.edu/data-xml/, e.g.:\n",
      "     |      nltk_data/corpora/childes/Eng-USA/Cornell/??? or\n",
      "     |      nltk_data/corpora/childes/Romance/Spanish/Aguirre/???\n",
      "     |      \n",
      "     |      The function first looks (as a special case) if \"Eng-USA\" is\n",
      "     |      on the path consisting of <corpus root>+fileid; then if\n",
      "     |      \"childes\", possibly followed by \"data-xml\", appears. If neither\n",
      "     |      one is found, we use the unmodified fileid and hope for the best.\n",
      "     |      If this is not right, specify urlbase explicitly, e.g., if the\n",
      "     |      corpus root points to the Cornell folder, urlbase='Eng-USA/Cornell'.\n",
      "     |  \n",
      "     |  words(self, fileids=None, speaker='ALL', stem=False, relation=False, strip_space=True, replace=False)\n",
      "     |      :return: the given file(s) as a list of words\n",
      "     |      :rtype: list(str)\n",
      "     |      \n",
      "     |      :param speaker: If specified, select specific speaker(s) defined\n",
      "     |          in the corpus. Default is 'ALL' (all participants). Common choices\n",
      "     |          are 'CHI' (the child), 'MOT' (mother), ['CHI','MOT'] (exclude\n",
      "     |          researchers)\n",
      "     |      :param stem: If true, then use word stems instead of word strings.\n",
      "     |      :param relation: If true, then return tuples of (stem, index,\n",
      "     |          dependent_index)\n",
      "     |      :param strip_space: If true, then strip trailing spaces from word\n",
      "     |          tokens. Otherwise, leave the spaces on the tokens.\n",
      "     |      :param replace: If true, then use the replaced (intended) word instead\n",
      "     |          of the original word (e.g., 'wat' will be replaced with 'watch')\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Data and other attributes defined here:\n",
      "     |  \n",
      "     |  childes_url_base = 'https://childes.talkbank.org/browser/index.php?url...\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Methods inherited from nltk.corpus.reader.xmldocs.XMLCorpusReader:\n",
      "     |  \n",
      "     |  raw(self, fileids=None)\n",
      "     |  \n",
      "     |  xml(self, fileid=None)\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Methods inherited from nltk.corpus.reader.api.CorpusReader:\n",
      "     |  \n",
      "     |  __repr__(self)\n",
      "     |      Return repr(self).\n",
      "     |  \n",
      "     |  __unicode__ = __str__(self, /)\n",
      "     |  \n",
      "     |  abspath(self, fileid)\n",
      "     |      Return the absolute path for the given file.\n",
      "     |      \n",
      "     |      :type fileid: str\n",
      "     |      :param fileid: The file identifier for the file whose path\n",
      "     |          should be returned.\n",
      "     |      :rtype: PathPointer\n",
      "     |  \n",
      "     |  abspaths(self, fileids=None, include_encoding=False, include_fileid=False)\n",
      "     |      Return a list of the absolute paths for all fileids in this corpus;\n",
      "     |      or for the given list of fileids, if specified.\n",
      "     |      \n",
      "     |      :type fileids: None or str or list\n",
      "     |      :param fileids: Specifies the set of fileids for which paths should\n",
      "     |          be returned.  Can be None, for all fileids; a list of\n",
      "     |          file identifiers, for a specified set of fileids; or a single\n",
      "     |          file identifier, for a single file.  Note that the return\n",
      "     |          value is always a list of paths, even if ``fileids`` is a\n",
      "     |          single file identifier.\n",
      "     |      \n",
      "     |      :param include_encoding: If true, then return a list of\n",
      "     |          ``(path_pointer, encoding)`` tuples.\n",
      "     |      \n",
      "     |      :rtype: list(PathPointer)\n",
      "     |  \n",
      "     |  citation(self)\n",
      "     |      Return the contents of the corpus citation.bib file, if it exists.\n",
      "     |  \n",
      "     |  encoding(self, file)\n",
      "     |      Return the unicode encoding for the given corpus file, if known.\n",
      "     |      If the encoding is unknown, or if the given file should be\n",
      "     |      processed using byte strings (str), then return None.\n",
      "     |  \n",
      "     |  ensure_loaded(self)\n",
      "     |      Load this corpus (if it has not already been loaded).  This is\n",
      "     |      used by LazyCorpusLoader as a simple method that can be used to\n",
      "     |      make sure a corpus is loaded -- e.g., in case a user wants to\n",
      "     |      do help(some_corpus).\n",
      "     |  \n",
      "     |  fileids(self)\n",
      "     |      Return a list of file identifiers for the fileids that make up\n",
      "     |      this corpus.\n",
      "     |  \n",
      "     |  license(self)\n",
      "     |      Return the contents of the corpus LICENSE file, if it exists.\n",
      "     |  \n",
      "     |  open(self, file)\n",
      "     |      Return an open stream that can be used to read the given file.\n",
      "     |      If the file's encoding is not None, then the stream will\n",
      "     |      automatically decode the file's contents into unicode.\n",
      "     |      \n",
      "     |      :param file: The file identifier of the file to read.\n",
      "     |  \n",
      "     |  readme(self)\n",
      "     |      Return the contents of the corpus README file, if it exists.\n",
      "     |  \n",
      "     |  unicode_repr = __repr__(self)\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Data descriptors inherited from nltk.corpus.reader.api.CorpusReader:\n",
      "     |  \n",
      "     |  __dict__\n",
      "     |      dictionary for instance variables (if defined)\n",
      "     |  \n",
      "     |  __weakref__\n",
      "     |      list of weak references to the object (if defined)\n",
      "     |  \n",
      "     |  root\n",
      "     |      The directory where this corpus is stored.\n",
      "     |      \n",
      "     |      :type: PathPointer\n",
      "    \n",
      "    class CMUDictCorpusReader(nltk.corpus.reader.api.CorpusReader)\n",
      "     |  CMUDictCorpusReader(root, fileids, encoding='utf8', tagset=None)\n",
      "     |  \n",
      "     |  A base class for \"corpus reader\" classes, each of which can be\n",
      "     |  used to read a specific corpus format.  Each individual corpus\n",
      "     |  reader instance is used to read a specific corpus, consisting of\n",
      "     |  one or more files under a common root directory.  Each file is\n",
      "     |  identified by its ``file identifier``, which is the relative path\n",
      "     |  to the file from the root directory.\n",
      "     |  \n",
      "     |  A separate subclass is defined for each corpus format.  These\n",
      "     |  subclasses define one or more methods that provide 'views' on the\n",
      "     |  corpus contents, such as ``words()`` (for a list of words) and\n",
      "     |  ``parsed_sents()`` (for a list of parsed sentences).  Called with\n",
      "     |  no arguments, these methods will return the contents of the entire\n",
      "     |  corpus.  For most corpora, these methods define one or more\n",
      "     |  selection arguments, such as ``fileids`` or ``categories``, which can\n",
      "     |  be used to select which portion of the corpus should be returned.\n",
      "     |  \n",
      "     |  Method resolution order:\n",
      "     |      CMUDictCorpusReader\n",
      "     |      nltk.corpus.reader.api.CorpusReader\n",
      "     |      builtins.object\n",
      "     |  \n",
      "     |  Methods defined here:\n",
      "     |  \n",
      "     |  dict(self)\n",
      "     |      :return: the cmudict lexicon as a dictionary, whose keys are\n",
      "     |      lowercase words and whose values are lists of pronunciations.\n",
      "     |  \n",
      "     |  entries(self)\n",
      "     |      :return: the cmudict lexicon as a list of entries\n",
      "     |      containing (word, transcriptions) tuples.\n",
      "     |  \n",
      "     |  raw(self)\n",
      "     |      :return: the cmudict lexicon as a raw string.\n",
      "     |  \n",
      "     |  words(self)\n",
      "     |      :return: a list of all words defined in the cmudict lexicon.\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Methods inherited from nltk.corpus.reader.api.CorpusReader:\n",
      "     |  \n",
      "     |  __init__(self, root, fileids, encoding='utf8', tagset=None)\n",
      "     |      :type root: PathPointer or str\n",
      "     |      :param root: A path pointer identifying the root directory for\n",
      "     |          this corpus.  If a string is specified, then it will be\n",
      "     |          converted to a ``PathPointer`` automatically.\n",
      "     |      :param fileids: A list of the files that make up this corpus.\n",
      "     |          This list can either be specified explicitly, as a list of\n",
      "     |          strings; or implicitly, as a regular expression over file\n",
      "     |          paths.  The absolute path for each file will be constructed\n",
      "     |          by joining the reader's root to each file name.\n",
      "     |      :param encoding: The default unicode encoding for the files\n",
      "     |          that make up the corpus.  The value of ``encoding`` can be any\n",
      "     |          of the following:\n",
      "     |          - A string: ``encoding`` is the encoding name for all files.\n",
      "     |          - A dictionary: ``encoding[file_id]`` is the encoding\n",
      "     |            name for the file whose identifier is ``file_id``.  If\n",
      "     |            ``file_id`` is not in ``encoding``, then the file\n",
      "     |            contents will be processed using non-unicode byte strings.\n",
      "     |          - A list: ``encoding`` should be a list of ``(regexp, encoding)``\n",
      "     |            tuples.  The encoding for a file whose identifier is ``file_id``\n",
      "     |            will be the ``encoding`` value for the first tuple whose\n",
      "     |            ``regexp`` matches the ``file_id``.  If no tuple's ``regexp``\n",
      "     |            matches the ``file_id``, the file contents will be processed\n",
      "     |            using non-unicode byte strings.\n",
      "     |          - None: the file contents of all files will be\n",
      "     |            processed using non-unicode byte strings.\n",
      "     |      :param tagset: The name of the tagset used by this corpus, to be used\n",
      "     |            for normalizing or converting the POS tags returned by the\n",
      "     |            tagged_...() methods.\n",
      "     |  \n",
      "     |  __repr__(self)\n",
      "     |      Return repr(self).\n",
      "     |  \n",
      "     |  __unicode__ = __str__(self, /)\n",
      "     |  \n",
      "     |  abspath(self, fileid)\n",
      "     |      Return the absolute path for the given file.\n",
      "     |      \n",
      "     |      :type fileid: str\n",
      "     |      :param fileid: The file identifier for the file whose path\n",
      "     |          should be returned.\n",
      "     |      :rtype: PathPointer\n",
      "     |  \n",
      "     |  abspaths(self, fileids=None, include_encoding=False, include_fileid=False)\n",
      "     |      Return a list of the absolute paths for all fileids in this corpus;\n",
      "     |      or for the given list of fileids, if specified.\n",
      "     |      \n",
      "     |      :type fileids: None or str or list\n",
      "     |      :param fileids: Specifies the set of fileids for which paths should\n",
      "     |          be returned.  Can be None, for all fileids; a list of\n",
      "     |          file identifiers, for a specified set of fileids; or a single\n",
      "     |          file identifier, for a single file.  Note that the return\n",
      "     |          value is always a list of paths, even if ``fileids`` is a\n",
      "     |          single file identifier.\n",
      "     |      \n",
      "     |      :param include_encoding: If true, then return a list of\n",
      "     |          ``(path_pointer, encoding)`` tuples.\n",
      "     |      \n",
      "     |      :rtype: list(PathPointer)\n",
      "     |  \n",
      "     |  citation(self)\n",
      "     |      Return the contents of the corpus citation.bib file, if it exists.\n",
      "     |  \n",
      "     |  encoding(self, file)\n",
      "     |      Return the unicode encoding for the given corpus file, if known.\n",
      "     |      If the encoding is unknown, or if the given file should be\n",
      "     |      processed using byte strings (str), then return None.\n",
      "     |  \n",
      "     |  ensure_loaded(self)\n",
      "     |      Load this corpus (if it has not already been loaded).  This is\n",
      "     |      used by LazyCorpusLoader as a simple method that can be used to\n",
      "     |      make sure a corpus is loaded -- e.g., in case a user wants to\n",
      "     |      do help(some_corpus).\n",
      "     |  \n",
      "     |  fileids(self)\n",
      "     |      Return a list of file identifiers for the fileids that make up\n",
      "     |      this corpus.\n",
      "     |  \n",
      "     |  license(self)\n",
      "     |      Return the contents of the corpus LICENSE file, if it exists.\n",
      "     |  \n",
      "     |  open(self, file)\n",
      "     |      Return an open stream that can be used to read the given file.\n",
      "     |      If the file's encoding is not None, then the stream will\n",
      "     |      automatically decode the file's contents into unicode.\n",
      "     |      \n",
      "     |      :param file: The file identifier of the file to read.\n",
      "     |  \n",
      "     |  readme(self)\n",
      "     |      Return the contents of the corpus README file, if it exists.\n",
      "     |  \n",
      "     |  unicode_repr = __repr__(self)\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Data descriptors inherited from nltk.corpus.reader.api.CorpusReader:\n",
      "     |  \n",
      "     |  __dict__\n",
      "     |      dictionary for instance variables (if defined)\n",
      "     |  \n",
      "     |  __weakref__\n",
      "     |      list of weak references to the object (if defined)\n",
      "     |  \n",
      "     |  root\n",
      "     |      The directory where this corpus is stored.\n",
      "     |      \n",
      "     |      :type: PathPointer\n",
      "    \n",
      "    class CategorizedBracketParseCorpusReader(nltk.corpus.reader.api.CategorizedCorpusReader, BracketParseCorpusReader)\n",
      "     |  CategorizedBracketParseCorpusReader(*args, **kwargs)\n",
      "     |  \n",
      "     |  A reader for parsed corpora whose documents are\n",
      "     |  divided into categories based on their file identifiers.\n",
      "     |  @author: Nathan Schneider <nschneid@cs.cmu.edu>\n",
      "     |  \n",
      "     |  Method resolution order:\n",
      "     |      CategorizedBracketParseCorpusReader\n",
      "     |      nltk.corpus.reader.api.CategorizedCorpusReader\n",
      "     |      BracketParseCorpusReader\n",
      "     |      nltk.corpus.reader.api.SyntaxCorpusReader\n",
      "     |      nltk.corpus.reader.api.CorpusReader\n",
      "     |      builtins.object\n",
      "     |  \n",
      "     |  Methods defined here:\n",
      "     |  \n",
      "     |  __init__(self, *args, **kwargs)\n",
      "     |      Initialize the corpus reader.  Categorization arguments\n",
      "     |      (C{cat_pattern}, C{cat_map}, and C{cat_file}) are passed to\n",
      "     |      the L{CategorizedCorpusReader constructor\n",
      "     |      <CategorizedCorpusReader.__init__>}.  The remaining arguments\n",
      "     |      are passed to the L{BracketParseCorpusReader constructor\n",
      "     |      <BracketParseCorpusReader.__init__>}.\n",
      "     |  \n",
      "     |  paras(self, fileids=None, categories=None)\n",
      "     |  \n",
      "     |  parsed_paras(self, fileids=None, categories=None)\n",
      "     |  \n",
      "     |  parsed_sents(self, fileids=None, categories=None)\n",
      "     |  \n",
      "     |  parsed_words(self, fileids=None, categories=None)\n",
      "     |  \n",
      "     |  raw(self, fileids=None, categories=None)\n",
      "     |  \n",
      "     |  sents(self, fileids=None, categories=None)\n",
      "     |  \n",
      "     |  tagged_paras(self, fileids=None, categories=None, tagset=None)\n",
      "     |  \n",
      "     |  tagged_sents(self, fileids=None, categories=None, tagset=None)\n",
      "     |  \n",
      "     |  tagged_words(self, fileids=None, categories=None, tagset=None)\n",
      "     |  \n",
      "     |  words(self, fileids=None, categories=None)\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Methods inherited from nltk.corpus.reader.api.CategorizedCorpusReader:\n",
      "     |  \n",
      "     |  categories(self, fileids=None)\n",
      "     |      Return a list of the categories that are defined for this corpus,\n",
      "     |      or for the file(s) if it is given.\n",
      "     |  \n",
      "     |  fileids(self, categories=None)\n",
      "     |      Return a list of file identifiers for the files that make up\n",
      "     |      this corpus, or that make up the given category(s) if specified.\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Data descriptors inherited from nltk.corpus.reader.api.CategorizedCorpusReader:\n",
      "     |  \n",
      "     |  __dict__\n",
      "     |      dictionary for instance variables (if defined)\n",
      "     |  \n",
      "     |  __weakref__\n",
      "     |      list of weak references to the object (if defined)\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Methods inherited from nltk.corpus.reader.api.CorpusReader:\n",
      "     |  \n",
      "     |  __repr__(self)\n",
      "     |      Return repr(self).\n",
      "     |  \n",
      "     |  __unicode__ = __str__(self, /)\n",
      "     |  \n",
      "     |  abspath(self, fileid)\n",
      "     |      Return the absolute path for the given file.\n",
      "     |      \n",
      "     |      :type fileid: str\n",
      "     |      :param fileid: The file identifier for the file whose path\n",
      "     |          should be returned.\n",
      "     |      :rtype: PathPointer\n",
      "     |  \n",
      "     |  abspaths(self, fileids=None, include_encoding=False, include_fileid=False)\n",
      "     |      Return a list of the absolute paths for all fileids in this corpus;\n",
      "     |      or for the given list of fileids, if specified.\n",
      "     |      \n",
      "     |      :type fileids: None or str or list\n",
      "     |      :param fileids: Specifies the set of fileids for which paths should\n",
      "     |          be returned.  Can be None, for all fileids; a list of\n",
      "     |          file identifiers, for a specified set of fileids; or a single\n",
      "     |          file identifier, for a single file.  Note that the return\n",
      "     |          value is always a list of paths, even if ``fileids`` is a\n",
      "     |          single file identifier.\n",
      "     |      \n",
      "     |      :param include_encoding: If true, then return a list of\n",
      "     |          ``(path_pointer, encoding)`` tuples.\n",
      "     |      \n",
      "     |      :rtype: list(PathPointer)\n",
      "     |  \n",
      "     |  citation(self)\n",
      "     |      Return the contents of the corpus citation.bib file, if it exists.\n",
      "     |  \n",
      "     |  encoding(self, file)\n",
      "     |      Return the unicode encoding for the given corpus file, if known.\n",
      "     |      If the encoding is unknown, or if the given file should be\n",
      "     |      processed using byte strings (str), then return None.\n",
      "     |  \n",
      "     |  ensure_loaded(self)\n",
      "     |      Load this corpus (if it has not already been loaded).  This is\n",
      "     |      used by LazyCorpusLoader as a simple method that can be used to\n",
      "     |      make sure a corpus is loaded -- e.g., in case a user wants to\n",
      "     |      do help(some_corpus).\n",
      "     |  \n",
      "     |  license(self)\n",
      "     |      Return the contents of the corpus LICENSE file, if it exists.\n",
      "     |  \n",
      "     |  open(self, file)\n",
      "     |      Return an open stream that can be used to read the given file.\n",
      "     |      If the file's encoding is not None, then the stream will\n",
      "     |      automatically decode the file's contents into unicode.\n",
      "     |      \n",
      "     |      :param file: The file identifier of the file to read.\n",
      "     |  \n",
      "     |  readme(self)\n",
      "     |      Return the contents of the corpus README file, if it exists.\n",
      "     |  \n",
      "     |  unicode_repr = __repr__(self)\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Data descriptors inherited from nltk.corpus.reader.api.CorpusReader:\n",
      "     |  \n",
      "     |  root\n",
      "     |      The directory where this corpus is stored.\n",
      "     |      \n",
      "     |      :type: PathPointer\n",
      "    \n",
      "    class CategorizedCorpusReader(builtins.object)\n",
      "     |  CategorizedCorpusReader(kwargs)\n",
      "     |  \n",
      "     |  A mixin class used to aid in the implementation of corpus readers\n",
      "     |  for categorized corpora.  This class defines the method\n",
      "     |  ``categories()``, which returns a list of the categories for the\n",
      "     |  corpus or for a specified set of fileids; and overrides ``fileids()``\n",
      "     |  to take a ``categories`` argument, restricting the set of fileids to\n",
      "     |  be returned.\n",
      "     |  \n",
      "     |  Subclasses are expected to:\n",
      "     |  \n",
      "     |    - Call ``__init__()`` to set up the mapping.\n",
      "     |  \n",
      "     |    - Override all view methods to accept a ``categories`` parameter,\n",
      "     |      which can be used *instead* of the ``fileids`` parameter, to\n",
      "     |      select which fileids should be included in the returned view.\n",
      "     |  \n",
      "     |  Methods defined here:\n",
      "     |  \n",
      "     |  __init__(self, kwargs)\n",
      "     |      Initialize this mapping based on keyword arguments, as\n",
      "     |      follows:\n",
      "     |      \n",
      "     |        - cat_pattern: A regular expression pattern used to find the\n",
      "     |          category for each file identifier.  The pattern will be\n",
      "     |          applied to each file identifier, and the first matching\n",
      "     |          group will be used as the category label for that file.\n",
      "     |      \n",
      "     |        - cat_map: A dictionary, mapping from file identifiers to\n",
      "     |          category labels.\n",
      "     |      \n",
      "     |        - cat_file: The name of a file that contains the mapping\n",
      "     |          from file identifiers to categories.  The argument\n",
      "     |          ``cat_delimiter`` can be used to specify a delimiter.\n",
      "     |      \n",
      "     |      The corresponding argument will be deleted from ``kwargs``.  If\n",
      "     |      more than one argument is specified, an exception will be\n",
      "     |      raised.\n",
      "     |  \n",
      "     |  categories(self, fileids=None)\n",
      "     |      Return a list of the categories that are defined for this corpus,\n",
      "     |      or for the file(s) if it is given.\n",
      "     |  \n",
      "     |  fileids(self, categories=None)\n",
      "     |      Return a list of file identifiers for the files that make up\n",
      "     |      this corpus, or that make up the given category(s) if specified.\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Data descriptors defined here:\n",
      "     |  \n",
      "     |  __dict__\n",
      "     |      dictionary for instance variables (if defined)\n",
      "     |  \n",
      "     |  __weakref__\n",
      "     |      list of weak references to the object (if defined)\n",
      "    \n",
      "    class CategorizedPlaintextCorpusReader(nltk.corpus.reader.api.CategorizedCorpusReader, PlaintextCorpusReader)\n",
      "     |  CategorizedPlaintextCorpusReader(*args, **kwargs)\n",
      "     |  \n",
      "     |  A reader for plaintext corpora whose documents are divided into\n",
      "     |  categories based on their file identifiers.\n",
      "     |  \n",
      "     |  Method resolution order:\n",
      "     |      CategorizedPlaintextCorpusReader\n",
      "     |      nltk.corpus.reader.api.CategorizedCorpusReader\n",
      "     |      PlaintextCorpusReader\n",
      "     |      nltk.corpus.reader.api.CorpusReader\n",
      "     |      builtins.object\n",
      "     |  \n",
      "     |  Methods defined here:\n",
      "     |  \n",
      "     |  __init__(self, *args, **kwargs)\n",
      "     |      Initialize the corpus reader.  Categorization arguments\n",
      "     |      (``cat_pattern``, ``cat_map``, and ``cat_file``) are passed to\n",
      "     |      the ``CategorizedCorpusReader`` constructor.  The remaining arguments\n",
      "     |      are passed to the ``PlaintextCorpusReader`` constructor.\n",
      "     |  \n",
      "     |  paras(self, fileids=None, categories=None)\n",
      "     |      :return: the given file(s) as a list of\n",
      "     |          paragraphs, each encoded as a list of sentences, which are\n",
      "     |          in turn encoded as lists of word strings.\n",
      "     |      :rtype: list(list(list(str)))\n",
      "     |  \n",
      "     |  raw(self, fileids=None, categories=None)\n",
      "     |      :return: the given file(s) as a single string.\n",
      "     |      :rtype: str\n",
      "     |  \n",
      "     |  sents(self, fileids=None, categories=None)\n",
      "     |      :return: the given file(s) as a list of\n",
      "     |          sentences or utterances, each encoded as a list of word\n",
      "     |          strings.\n",
      "     |      :rtype: list(list(str))\n",
      "     |  \n",
      "     |  words(self, fileids=None, categories=None)\n",
      "     |      :return: the given file(s) as a list of words\n",
      "     |          and punctuation symbols.\n",
      "     |      :rtype: list(str)\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Methods inherited from nltk.corpus.reader.api.CategorizedCorpusReader:\n",
      "     |  \n",
      "     |  categories(self, fileids=None)\n",
      "     |      Return a list of the categories that are defined for this corpus,\n",
      "     |      or for the file(s) if it is given.\n",
      "     |  \n",
      "     |  fileids(self, categories=None)\n",
      "     |      Return a list of file identifiers for the files that make up\n",
      "     |      this corpus, or that make up the given category(s) if specified.\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Data descriptors inherited from nltk.corpus.reader.api.CategorizedCorpusReader:\n",
      "     |  \n",
      "     |  __dict__\n",
      "     |      dictionary for instance variables (if defined)\n",
      "     |  \n",
      "     |  __weakref__\n",
      "     |      list of weak references to the object (if defined)\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Data and other attributes inherited from PlaintextCorpusReader:\n",
      "     |  \n",
      "     |  CorpusView = <class 'nltk.corpus.reader.util.StreamBackedCorpusView'>\n",
      "     |      A 'view' of a corpus file, which acts like a sequence of tokens:\n",
      "     |      it can be accessed by index, iterated over, etc.  However, the\n",
      "     |      tokens are only constructed as-needed -- the entire corpus is\n",
      "     |      never stored in memory at once.\n",
      "     |      \n",
      "     |      The constructor to ``StreamBackedCorpusView`` takes two arguments:\n",
      "     |      a corpus fileid (specified as a string or as a ``PathPointer``);\n",
      "     |      and a block reader.  A \"block reader\" is a function that reads\n",
      "     |      zero or more tokens from a stream, and returns them as a list.  A\n",
      "     |      very simple example of a block reader is:\n",
      "     |      \n",
      "     |          >>> def simple_block_reader(stream):\n",
      "     |          ...     return stream.readline().split()\n",
      "     |      \n",
      "     |      This simple block reader reads a single line at a time, and\n",
      "     |      returns a single token (consisting of a string) for each\n",
      "     |      whitespace-separated substring on the line.\n",
      "     |      \n",
      "     |      When deciding how to define the block reader for a given\n",
      "     |      corpus, careful consideration should be given to the size of\n",
      "     |      blocks handled by the block reader.  Smaller block sizes will\n",
      "     |      increase the memory requirements of the corpus view's internal\n",
      "     |      data structures (by 2 integers per block).  On the other hand,\n",
      "     |      larger block sizes may decrease performance for random access to\n",
      "     |      the corpus.  (But note that larger block sizes will *not*\n",
      "     |      decrease performance for iteration.)\n",
      "     |      \n",
      "     |      Internally, ``CorpusView`` maintains a partial mapping from token\n",
      "     |      index to file position, with one entry per block.  When a token\n",
      "     |      with a given index *i* is requested, the ``CorpusView`` constructs\n",
      "     |      it as follows:\n",
      "     |      \n",
      "     |        1. First, it searches the toknum/filepos mapping for the token\n",
      "     |           index closest to (but less than or equal to) *i*.\n",
      "     |      \n",
      "     |        2. Then, starting at the file position corresponding to that\n",
      "     |           index, it reads one block at a time using the block reader\n",
      "     |           until it reaches the requested token.\n",
      "     |      \n",
      "     |      The toknum/filepos mapping is created lazily: it is initially\n",
      "     |      empty, but every time a new block is read, the block's\n",
      "     |      initial token is added to the mapping.  (Thus, the toknum/filepos\n",
      "     |      map has one entry per block.)\n",
      "     |      \n",
      "     |      In order to increase efficiency for random access patterns that\n",
      "     |      have high degrees of locality, the corpus view may cache one or\n",
      "     |      more blocks.\n",
      "     |      \n",
      "     |      :note: Each ``CorpusView`` object internally maintains an open file\n",
      "     |          object for its underlying corpus file.  This file should be\n",
      "     |          automatically closed when the ``CorpusView`` is garbage collected,\n",
      "     |          but if you wish to close it manually, use the ``close()``\n",
      "     |          method.  If you access a ``CorpusView``'s items after it has been\n",
      "     |          closed, the file object will be automatically re-opened.\n",
      "     |      \n",
      "     |      :warning: If the contents of the file are modified during the\n",
      "     |          lifetime of the ``CorpusView``, then the ``CorpusView``'s behavior\n",
      "     |          is undefined.\n",
      "     |      \n",
      "     |      :warning: If a unicode encoding is specified when constructing a\n",
      "     |          ``CorpusView``, then the block reader may only call\n",
      "     |          ``stream.seek()`` with offsets that have been returned by\n",
      "     |          ``stream.tell()``; in particular, calling ``stream.seek()`` with\n",
      "     |          relative offsets, or with offsets based on string lengths, may\n",
      "     |          lead to incorrect behavior.\n",
      "     |      \n",
      "     |      :ivar _block_reader: The function used to read\n",
      "     |          a single block from the underlying file stream.\n",
      "     |      :ivar _toknum: A list containing the token index of each block\n",
      "     |          that has been processed.  In particular, ``_toknum[i]`` is the\n",
      "     |          token index of the first token in block ``i``.  Together\n",
      "     |          with ``_filepos``, this forms a partial mapping between token\n",
      "     |          indices and file positions.\n",
      "     |      :ivar _filepos: A list containing the file position of each block\n",
      "     |          that has been processed.  In particular, ``_toknum[i]`` is the\n",
      "     |          file position of the first character in block ``i``.  Together\n",
      "     |          with ``_toknum``, this forms a partial mapping between token\n",
      "     |          indices and file positions.\n",
      "     |      :ivar _stream: The stream used to access the underlying corpus file.\n",
      "     |      :ivar _len: The total number of tokens in the corpus, if known;\n",
      "     |          or None, if the number of tokens is not yet known.\n",
      "     |      :ivar _eofpos: The character position of the last character in the\n",
      "     |          file.  This is calculated when the corpus view is initialized,\n",
      "     |          and is used to decide when the end of file has been reached.\n",
      "     |      :ivar _cache: A cache of the most recently read block.  It\n",
      "     |         is encoded as a tuple (start_toknum, end_toknum, tokens), where\n",
      "     |         start_toknum is the token index of the first token in the block;\n",
      "     |         end_toknum is the token index of the first token not in the\n",
      "     |         block; and tokens is a list of the tokens in the block.\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Methods inherited from nltk.corpus.reader.api.CorpusReader:\n",
      "     |  \n",
      "     |  __repr__(self)\n",
      "     |      Return repr(self).\n",
      "     |  \n",
      "     |  __unicode__ = __str__(self, /)\n",
      "     |  \n",
      "     |  abspath(self, fileid)\n",
      "     |      Return the absolute path for the given file.\n",
      "     |      \n",
      "     |      :type fileid: str\n",
      "     |      :param fileid: The file identifier for the file whose path\n",
      "     |          should be returned.\n",
      "     |      :rtype: PathPointer\n",
      "     |  \n",
      "     |  abspaths(self, fileids=None, include_encoding=False, include_fileid=False)\n",
      "     |      Return a list of the absolute paths for all fileids in this corpus;\n",
      "     |      or for the given list of fileids, if specified.\n",
      "     |      \n",
      "     |      :type fileids: None or str or list\n",
      "     |      :param fileids: Specifies the set of fileids for which paths should\n",
      "     |          be returned.  Can be None, for all fileids; a list of\n",
      "     |          file identifiers, for a specified set of fileids; or a single\n",
      "     |          file identifier, for a single file.  Note that the return\n",
      "     |          value is always a list of paths, even if ``fileids`` is a\n",
      "     |          single file identifier.\n",
      "     |      \n",
      "     |      :param include_encoding: If true, then return a list of\n",
      "     |          ``(path_pointer, encoding)`` tuples.\n",
      "     |      \n",
      "     |      :rtype: list(PathPointer)\n",
      "     |  \n",
      "     |  citation(self)\n",
      "     |      Return the contents of the corpus citation.bib file, if it exists.\n",
      "     |  \n",
      "     |  encoding(self, file)\n",
      "     |      Return the unicode encoding for the given corpus file, if known.\n",
      "     |      If the encoding is unknown, or if the given file should be\n",
      "     |      processed using byte strings (str), then return None.\n",
      "     |  \n",
      "     |  ensure_loaded(self)\n",
      "     |      Load this corpus (if it has not already been loaded).  This is\n",
      "     |      used by LazyCorpusLoader as a simple method that can be used to\n",
      "     |      make sure a corpus is loaded -- e.g., in case a user wants to\n",
      "     |      do help(some_corpus).\n",
      "     |  \n",
      "     |  license(self)\n",
      "     |      Return the contents of the corpus LICENSE file, if it exists.\n",
      "     |  \n",
      "     |  open(self, file)\n",
      "     |      Return an open stream that can be used to read the given file.\n",
      "     |      If the file's encoding is not None, then the stream will\n",
      "     |      automatically decode the file's contents into unicode.\n",
      "     |      \n",
      "     |      :param file: The file identifier of the file to read.\n",
      "     |  \n",
      "     |  readme(self)\n",
      "     |      Return the contents of the corpus README file, if it exists.\n",
      "     |  \n",
      "     |  unicode_repr = __repr__(self)\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Data descriptors inherited from nltk.corpus.reader.api.CorpusReader:\n",
      "     |  \n",
      "     |  root\n",
      "     |      The directory where this corpus is stored.\n",
      "     |      \n",
      "     |      :type: PathPointer\n",
      "    \n",
      "    class CategorizedSentencesCorpusReader(nltk.corpus.reader.api.CategorizedCorpusReader, nltk.corpus.reader.api.CorpusReader)\n",
      "     |  CategorizedSentencesCorpusReader(root, fileids, word_tokenizer=WhitespaceTokenizer(pattern='\\\\s+', gaps=True, discard_empty=True, flags=<RegexFlag.UNICODE|DOTALL|MULTILINE: 56>), sent_tokenizer=None, encoding='utf8', **kwargs)\n",
      "     |  \n",
      "     |  A reader for corpora in which each row represents a single instance, mainly\n",
      "     |  a sentence. Istances are divided into categories based on their file identifiers\n",
      "     |  (see CategorizedCorpusReader).\n",
      "     |  Since many corpora allow rows that contain more than one sentence, it is\n",
      "     |  possible to specify a sentence tokenizer to retrieve all sentences instead\n",
      "     |  than all rows.\n",
      "     |  \n",
      "     |  Examples using the Subjectivity Dataset:\n",
      "     |  \n",
      "     |  >>> from nltk.corpus import subjectivity\n",
      "     |  >>> subjectivity.sents()[23]\n",
      "     |  ['television', 'made', 'him', 'famous', ',', 'but', 'his', 'biggest', 'hits',\n",
      "     |  'happened', 'off', 'screen', '.']\n",
      "     |  >>> subjectivity.categories()\n",
      "     |  ['obj', 'subj']\n",
      "     |  >>> subjectivity.words(categories='subj')\n",
      "     |  ['smart', 'and', 'alert', ',', 'thirteen', ...]\n",
      "     |  \n",
      "     |  Examples using the Sentence Polarity Dataset:\n",
      "     |  \n",
      "     |  >>> from nltk.corpus import sentence_polarity\n",
      "     |  >>> sentence_polarity.sents()\n",
      "     |  [['simplistic', ',', 'silly', 'and', 'tedious', '.'], [\"it's\", 'so', 'laddish',\n",
      "     |  'and', 'juvenile', ',', 'only', 'teenage', 'boys', 'could', 'possibly', 'find',\n",
      "     |  'it', 'funny', '.'], ...]\n",
      "     |  >>> sentence_polarity.categories()\n",
      "     |  ['neg', 'pos']\n",
      "     |  \n",
      "     |  Method resolution order:\n",
      "     |      CategorizedSentencesCorpusReader\n",
      "     |      nltk.corpus.reader.api.CategorizedCorpusReader\n",
      "     |      nltk.corpus.reader.api.CorpusReader\n",
      "     |      builtins.object\n",
      "     |  \n",
      "     |  Methods defined here:\n",
      "     |  \n",
      "     |  __init__(self, root, fileids, word_tokenizer=WhitespaceTokenizer(pattern='\\\\s+', gaps=True, discard_empty=True, flags=<RegexFlag.UNICODE|DOTALL|MULTILINE: 56>), sent_tokenizer=None, encoding='utf8', **kwargs)\n",
      "     |      :param root: The root directory for the corpus.\n",
      "     |      :param fileids: a list or regexp specifying the fileids in the corpus.\n",
      "     |      :param word_tokenizer: a tokenizer for breaking sentences or paragraphs\n",
      "     |          into words. Default: `WhitespaceTokenizer`\n",
      "     |      :param sent_tokenizer: a tokenizer for breaking paragraphs into sentences.\n",
      "     |      :param encoding: the encoding that should be used to read the corpus.\n",
      "     |      :param kwargs: additional parameters passed to CategorizedCorpusReader.\n",
      "     |  \n",
      "     |  raw(self, fileids=None, categories=None)\n",
      "     |      :param fileids: a list or regexp specifying the fileids that have to be\n",
      "     |          returned as a raw string.\n",
      "     |      :param categories: a list specifying the categories whose files have to\n",
      "     |          be returned as a raw string.\n",
      "     |      :return: the given file(s) as a single string.\n",
      "     |      :rtype: str\n",
      "     |  \n",
      "     |  readme(self)\n",
      "     |      Return the contents of the corpus Readme.txt file.\n",
      "     |  \n",
      "     |  sents(self, fileids=None, categories=None)\n",
      "     |      Return all sentences in the corpus or in the specified file(s).\n",
      "     |      \n",
      "     |      :param fileids: a list or regexp specifying the ids of the files whose\n",
      "     |          sentences have to be returned.\n",
      "     |      :param categories: a list specifying the categories whose sentences have\n",
      "     |          to be returned.\n",
      "     |      :return: the given file(s) as a list of sentences.\n",
      "     |          Each sentence is tokenized using the specified word_tokenizer.\n",
      "     |      :rtype: list(list(str))\n",
      "     |  \n",
      "     |  words(self, fileids=None, categories=None)\n",
      "     |      Return all words and punctuation symbols in the corpus or in the specified\n",
      "     |      file(s).\n",
      "     |      \n",
      "     |      :param fileids: a list or regexp specifying the ids of the files whose\n",
      "     |          words have to be returned.\n",
      "     |      :param categories: a list specifying the categories whose words have to\n",
      "     |          be returned.\n",
      "     |      :return: the given file(s) as a list of words and punctuation symbols.\n",
      "     |      :rtype: list(str)\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Data and other attributes defined here:\n",
      "     |  \n",
      "     |  CorpusView = <class 'nltk.corpus.reader.util.StreamBackedCorpusView'>\n",
      "     |      A 'view' of a corpus file, which acts like a sequence of tokens:\n",
      "     |      it can be accessed by index, iterated over, etc.  However, the\n",
      "     |      tokens are only constructed as-needed -- the entire corpus is\n",
      "     |      never stored in memory at once.\n",
      "     |      \n",
      "     |      The constructor to ``StreamBackedCorpusView`` takes two arguments:\n",
      "     |      a corpus fileid (specified as a string or as a ``PathPointer``);\n",
      "     |      and a block reader.  A \"block reader\" is a function that reads\n",
      "     |      zero or more tokens from a stream, and returns them as a list.  A\n",
      "     |      very simple example of a block reader is:\n",
      "     |      \n",
      "     |          >>> def simple_block_reader(stream):\n",
      "     |          ...     return stream.readline().split()\n",
      "     |      \n",
      "     |      This simple block reader reads a single line at a time, and\n",
      "     |      returns a single token (consisting of a string) for each\n",
      "     |      whitespace-separated substring on the line.\n",
      "     |      \n",
      "     |      When deciding how to define the block reader for a given\n",
      "     |      corpus, careful consideration should be given to the size of\n",
      "     |      blocks handled by the block reader.  Smaller block sizes will\n",
      "     |      increase the memory requirements of the corpus view's internal\n",
      "     |      data structures (by 2 integers per block).  On the other hand,\n",
      "     |      larger block sizes may decrease performance for random access to\n",
      "     |      the corpus.  (But note that larger block sizes will *not*\n",
      "     |      decrease performance for iteration.)\n",
      "     |      \n",
      "     |      Internally, ``CorpusView`` maintains a partial mapping from token\n",
      "     |      index to file position, with one entry per block.  When a token\n",
      "     |      with a given index *i* is requested, the ``CorpusView`` constructs\n",
      "     |      it as follows:\n",
      "     |      \n",
      "     |        1. First, it searches the toknum/filepos mapping for the token\n",
      "     |           index closest to (but less than or equal to) *i*.\n",
      "     |      \n",
      "     |        2. Then, starting at the file position corresponding to that\n",
      "     |           index, it reads one block at a time using the block reader\n",
      "     |           until it reaches the requested token.\n",
      "     |      \n",
      "     |      The toknum/filepos mapping is created lazily: it is initially\n",
      "     |      empty, but every time a new block is read, the block's\n",
      "     |      initial token is added to the mapping.  (Thus, the toknum/filepos\n",
      "     |      map has one entry per block.)\n",
      "     |      \n",
      "     |      In order to increase efficiency for random access patterns that\n",
      "     |      have high degrees of locality, the corpus view may cache one or\n",
      "     |      more blocks.\n",
      "     |      \n",
      "     |      :note: Each ``CorpusView`` object internally maintains an open file\n",
      "     |          object for its underlying corpus file.  This file should be\n",
      "     |          automatically closed when the ``CorpusView`` is garbage collected,\n",
      "     |          but if you wish to close it manually, use the ``close()``\n",
      "     |          method.  If you access a ``CorpusView``'s items after it has been\n",
      "     |          closed, the file object will be automatically re-opened.\n",
      "     |      \n",
      "     |      :warning: If the contents of the file are modified during the\n",
      "     |          lifetime of the ``CorpusView``, then the ``CorpusView``'s behavior\n",
      "     |          is undefined.\n",
      "     |      \n",
      "     |      :warning: If a unicode encoding is specified when constructing a\n",
      "     |          ``CorpusView``, then the block reader may only call\n",
      "     |          ``stream.seek()`` with offsets that have been returned by\n",
      "     |          ``stream.tell()``; in particular, calling ``stream.seek()`` with\n",
      "     |          relative offsets, or with offsets based on string lengths, may\n",
      "     |          lead to incorrect behavior.\n",
      "     |      \n",
      "     |      :ivar _block_reader: The function used to read\n",
      "     |          a single block from the underlying file stream.\n",
      "     |      :ivar _toknum: A list containing the token index of each block\n",
      "     |          that has been processed.  In particular, ``_toknum[i]`` is the\n",
      "     |          token index of the first token in block ``i``.  Together\n",
      "     |          with ``_filepos``, this forms a partial mapping between token\n",
      "     |          indices and file positions.\n",
      "     |      :ivar _filepos: A list containing the file position of each block\n",
      "     |          that has been processed.  In particular, ``_toknum[i]`` is the\n",
      "     |          file position of the first character in block ``i``.  Together\n",
      "     |          with ``_toknum``, this forms a partial mapping between token\n",
      "     |          indices and file positions.\n",
      "     |      :ivar _stream: The stream used to access the underlying corpus file.\n",
      "     |      :ivar _len: The total number of tokens in the corpus, if known;\n",
      "     |          or None, if the number of tokens is not yet known.\n",
      "     |      :ivar _eofpos: The character position of the last character in the\n",
      "     |          file.  This is calculated when the corpus view is initialized,\n",
      "     |          and is used to decide when the end of file has been reached.\n",
      "     |      :ivar _cache: A cache of the most recently read block.  It\n",
      "     |         is encoded as a tuple (start_toknum, end_toknum, tokens), where\n",
      "     |         start_toknum is the token index of the first token in the block;\n",
      "     |         end_toknum is the token index of the first token not in the\n",
      "     |         block; and tokens is a list of the tokens in the block.\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Methods inherited from nltk.corpus.reader.api.CategorizedCorpusReader:\n",
      "     |  \n",
      "     |  categories(self, fileids=None)\n",
      "     |      Return a list of the categories that are defined for this corpus,\n",
      "     |      or for the file(s) if it is given.\n",
      "     |  \n",
      "     |  fileids(self, categories=None)\n",
      "     |      Return a list of file identifiers for the files that make up\n",
      "     |      this corpus, or that make up the given category(s) if specified.\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Data descriptors inherited from nltk.corpus.reader.api.CategorizedCorpusReader:\n",
      "     |  \n",
      "     |  __dict__\n",
      "     |      dictionary for instance variables (if defined)\n",
      "     |  \n",
      "     |  __weakref__\n",
      "     |      list of weak references to the object (if defined)\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Methods inherited from nltk.corpus.reader.api.CorpusReader:\n",
      "     |  \n",
      "     |  __repr__(self)\n",
      "     |      Return repr(self).\n",
      "     |  \n",
      "     |  __unicode__ = __str__(self, /)\n",
      "     |  \n",
      "     |  abspath(self, fileid)\n",
      "     |      Return the absolute path for the given file.\n",
      "     |      \n",
      "     |      :type fileid: str\n",
      "     |      :param fileid: The file identifier for the file whose path\n",
      "     |          should be returned.\n",
      "     |      :rtype: PathPointer\n",
      "     |  \n",
      "     |  abspaths(self, fileids=None, include_encoding=False, include_fileid=False)\n",
      "     |      Return a list of the absolute paths for all fileids in this corpus;\n",
      "     |      or for the given list of fileids, if specified.\n",
      "     |      \n",
      "     |      :type fileids: None or str or list\n",
      "     |      :param fileids: Specifies the set of fileids for which paths should\n",
      "     |          be returned.  Can be None, for all fileids; a list of\n",
      "     |          file identifiers, for a specified set of fileids; or a single\n",
      "     |          file identifier, for a single file.  Note that the return\n",
      "     |          value is always a list of paths, even if ``fileids`` is a\n",
      "     |          single file identifier.\n",
      "     |      \n",
      "     |      :param include_encoding: If true, then return a list of\n",
      "     |          ``(path_pointer, encoding)`` tuples.\n",
      "     |      \n",
      "     |      :rtype: list(PathPointer)\n",
      "     |  \n",
      "     |  citation(self)\n",
      "     |      Return the contents of the corpus citation.bib file, if it exists.\n",
      "     |  \n",
      "     |  encoding(self, file)\n",
      "     |      Return the unicode encoding for the given corpus file, if known.\n",
      "     |      If the encoding is unknown, or if the given file should be\n",
      "     |      processed using byte strings (str), then return None.\n",
      "     |  \n",
      "     |  ensure_loaded(self)\n",
      "     |      Load this corpus (if it has not already been loaded).  This is\n",
      "     |      used by LazyCorpusLoader as a simple method that can be used to\n",
      "     |      make sure a corpus is loaded -- e.g., in case a user wants to\n",
      "     |      do help(some_corpus).\n",
      "     |  \n",
      "     |  license(self)\n",
      "     |      Return the contents of the corpus LICENSE file, if it exists.\n",
      "     |  \n",
      "     |  open(self, file)\n",
      "     |      Return an open stream that can be used to read the given file.\n",
      "     |      If the file's encoding is not None, then the stream will\n",
      "     |      automatically decode the file's contents into unicode.\n",
      "     |      \n",
      "     |      :param file: The file identifier of the file to read.\n",
      "     |  \n",
      "     |  unicode_repr = __repr__(self)\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Data descriptors inherited from nltk.corpus.reader.api.CorpusReader:\n",
      "     |  \n",
      "     |  root\n",
      "     |      The directory where this corpus is stored.\n",
      "     |      \n",
      "     |      :type: PathPointer\n",
      "    \n",
      "    class CategorizedTaggedCorpusReader(nltk.corpus.reader.api.CategorizedCorpusReader, TaggedCorpusReader)\n",
      "     |  CategorizedTaggedCorpusReader(*args, **kwargs)\n",
      "     |  \n",
      "     |  A reader for part-of-speech tagged corpora whose documents are\n",
      "     |  divided into categories based on their file identifiers.\n",
      "     |  \n",
      "     |  Method resolution order:\n",
      "     |      CategorizedTaggedCorpusReader\n",
      "     |      nltk.corpus.reader.api.CategorizedCorpusReader\n",
      "     |      TaggedCorpusReader\n",
      "     |      nltk.corpus.reader.api.CorpusReader\n",
      "     |      builtins.object\n",
      "     |  \n",
      "     |  Methods defined here:\n",
      "     |  \n",
      "     |  __init__(self, *args, **kwargs)\n",
      "     |      Initialize the corpus reader.  Categorization arguments\n",
      "     |      (``cat_pattern``, ``cat_map``, and ``cat_file``) are passed to\n",
      "     |      the ``CategorizedCorpusReader`` constructor.  The remaining arguments\n",
      "     |      are passed to the ``TaggedCorpusReader``.\n",
      "     |  \n",
      "     |  paras(self, fileids=None, categories=None)\n",
      "     |      :return: the given file(s) as a list of\n",
      "     |          paragraphs, each encoded as a list of sentences, which are\n",
      "     |          in turn encoded as lists of word strings.\n",
      "     |      :rtype: list(list(list(str)))\n",
      "     |  \n",
      "     |  raw(self, fileids=None, categories=None)\n",
      "     |      :return: the given file(s) as a single string.\n",
      "     |      :rtype: str\n",
      "     |  \n",
      "     |  sents(self, fileids=None, categories=None)\n",
      "     |      :return: the given file(s) as a list of\n",
      "     |          sentences or utterances, each encoded as a list of word\n",
      "     |          strings.\n",
      "     |      :rtype: list(list(str))\n",
      "     |  \n",
      "     |  tagged_paras(self, fileids=None, categories=None, tagset=None)\n",
      "     |      :return: the given file(s) as a list of\n",
      "     |          paragraphs, each encoded as a list of sentences, which are\n",
      "     |          in turn encoded as lists of ``(word,tag)`` tuples.\n",
      "     |      :rtype: list(list(list(tuple(str,str))))\n",
      "     |  \n",
      "     |  tagged_sents(self, fileids=None, categories=None, tagset=None)\n",
      "     |      :return: the given file(s) as a list of\n",
      "     |          sentences, each encoded as a list of ``(word,tag)`` tuples.\n",
      "     |      \n",
      "     |      :rtype: list(list(tuple(str,str)))\n",
      "     |  \n",
      "     |  tagged_words(self, fileids=None, categories=None, tagset=None)\n",
      "     |      :return: the given file(s) as a list of tagged\n",
      "     |          words and punctuation symbols, encoded as tuples\n",
      "     |          ``(word,tag)``.\n",
      "     |      :rtype: list(tuple(str,str))\n",
      "     |  \n",
      "     |  words(self, fileids=None, categories=None)\n",
      "     |      :return: the given file(s) as a list of words\n",
      "     |          and punctuation symbols.\n",
      "     |      :rtype: list(str)\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Methods inherited from nltk.corpus.reader.api.CategorizedCorpusReader:\n",
      "     |  \n",
      "     |  categories(self, fileids=None)\n",
      "     |      Return a list of the categories that are defined for this corpus,\n",
      "     |      or for the file(s) if it is given.\n",
      "     |  \n",
      "     |  fileids(self, categories=None)\n",
      "     |      Return a list of file identifiers for the files that make up\n",
      "     |      this corpus, or that make up the given category(s) if specified.\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Data descriptors inherited from nltk.corpus.reader.api.CategorizedCorpusReader:\n",
      "     |  \n",
      "     |  __dict__\n",
      "     |      dictionary for instance variables (if defined)\n",
      "     |  \n",
      "     |  __weakref__\n",
      "     |      list of weak references to the object (if defined)\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Methods inherited from nltk.corpus.reader.api.CorpusReader:\n",
      "     |  \n",
      "     |  __repr__(self)\n",
      "     |      Return repr(self).\n",
      "     |  \n",
      "     |  __unicode__ = __str__(self, /)\n",
      "     |  \n",
      "     |  abspath(self, fileid)\n",
      "     |      Return the absolute path for the given file.\n",
      "     |      \n",
      "     |      :type fileid: str\n",
      "     |      :param fileid: The file identifier for the file whose path\n",
      "     |          should be returned.\n",
      "     |      :rtype: PathPointer\n",
      "     |  \n",
      "     |  abspaths(self, fileids=None, include_encoding=False, include_fileid=False)\n",
      "     |      Return a list of the absolute paths for all fileids in this corpus;\n",
      "     |      or for the given list of fileids, if specified.\n",
      "     |      \n",
      "     |      :type fileids: None or str or list\n",
      "     |      :param fileids: Specifies the set of fileids for which paths should\n",
      "     |          be returned.  Can be None, for all fileids; a list of\n",
      "     |          file identifiers, for a specified set of fileids; or a single\n",
      "     |          file identifier, for a single file.  Note that the return\n",
      "     |          value is always a list of paths, even if ``fileids`` is a\n",
      "     |          single file identifier.\n",
      "     |      \n",
      "     |      :param include_encoding: If true, then return a list of\n",
      "     |          ``(path_pointer, encoding)`` tuples.\n",
      "     |      \n",
      "     |      :rtype: list(PathPointer)\n",
      "     |  \n",
      "     |  citation(self)\n",
      "     |      Return the contents of the corpus citation.bib file, if it exists.\n",
      "     |  \n",
      "     |  encoding(self, file)\n",
      "     |      Return the unicode encoding for the given corpus file, if known.\n",
      "     |      If the encoding is unknown, or if the given file should be\n",
      "     |      processed using byte strings (str), then return None.\n",
      "     |  \n",
      "     |  ensure_loaded(self)\n",
      "     |      Load this corpus (if it has not already been loaded).  This is\n",
      "     |      used by LazyCorpusLoader as a simple method that can be used to\n",
      "     |      make sure a corpus is loaded -- e.g., in case a user wants to\n",
      "     |      do help(some_corpus).\n",
      "     |  \n",
      "     |  license(self)\n",
      "     |      Return the contents of the corpus LICENSE file, if it exists.\n",
      "     |  \n",
      "     |  open(self, file)\n",
      "     |      Return an open stream that can be used to read the given file.\n",
      "     |      If the file's encoding is not None, then the stream will\n",
      "     |      automatically decode the file's contents into unicode.\n",
      "     |      \n",
      "     |      :param file: The file identifier of the file to read.\n",
      "     |  \n",
      "     |  readme(self)\n",
      "     |      Return the contents of the corpus README file, if it exists.\n",
      "     |  \n",
      "     |  unicode_repr = __repr__(self)\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Data descriptors inherited from nltk.corpus.reader.api.CorpusReader:\n",
      "     |  \n",
      "     |  root\n",
      "     |      The directory where this corpus is stored.\n",
      "     |      \n",
      "     |      :type: PathPointer\n",
      "    \n",
      "    class ChasenCorpusReader(nltk.corpus.reader.api.CorpusReader)\n",
      "     |  ChasenCorpusReader(root, fileids, encoding='utf8', sent_splitter=None)\n",
      "     |  \n",
      "     |  A base class for \"corpus reader\" classes, each of which can be\n",
      "     |  used to read a specific corpus format.  Each individual corpus\n",
      "     |  reader instance is used to read a specific corpus, consisting of\n",
      "     |  one or more files under a common root directory.  Each file is\n",
      "     |  identified by its ``file identifier``, which is the relative path\n",
      "     |  to the file from the root directory.\n",
      "     |  \n",
      "     |  A separate subclass is defined for each corpus format.  These\n",
      "     |  subclasses define one or more methods that provide 'views' on the\n",
      "     |  corpus contents, such as ``words()`` (for a list of words) and\n",
      "     |  ``parsed_sents()`` (for a list of parsed sentences).  Called with\n",
      "     |  no arguments, these methods will return the contents of the entire\n",
      "     |  corpus.  For most corpora, these methods define one or more\n",
      "     |  selection arguments, such as ``fileids`` or ``categories``, which can\n",
      "     |  be used to select which portion of the corpus should be returned.\n",
      "     |  \n",
      "     |  Method resolution order:\n",
      "     |      ChasenCorpusReader\n",
      "     |      nltk.corpus.reader.api.CorpusReader\n",
      "     |      builtins.object\n",
      "     |  \n",
      "     |  Methods defined here:\n",
      "     |  \n",
      "     |  __init__(self, root, fileids, encoding='utf8', sent_splitter=None)\n",
      "     |      :type root: PathPointer or str\n",
      "     |      :param root: A path pointer identifying the root directory for\n",
      "     |          this corpus.  If a string is specified, then it will be\n",
      "     |          converted to a ``PathPointer`` automatically.\n",
      "     |      :param fileids: A list of the files that make up this corpus.\n",
      "     |          This list can either be specified explicitly, as a list of\n",
      "     |          strings; or implicitly, as a regular expression over file\n",
      "     |          paths.  The absolute path for each file will be constructed\n",
      "     |          by joining the reader's root to each file name.\n",
      "     |      :param encoding: The default unicode encoding for the files\n",
      "     |          that make up the corpus.  The value of ``encoding`` can be any\n",
      "     |          of the following:\n",
      "     |          - A string: ``encoding`` is the encoding name for all files.\n",
      "     |          - A dictionary: ``encoding[file_id]`` is the encoding\n",
      "     |            name for the file whose identifier is ``file_id``.  If\n",
      "     |            ``file_id`` is not in ``encoding``, then the file\n",
      "     |            contents will be processed using non-unicode byte strings.\n",
      "     |          - A list: ``encoding`` should be a list of ``(regexp, encoding)``\n",
      "     |            tuples.  The encoding for a file whose identifier is ``file_id``\n",
      "     |            will be the ``encoding`` value for the first tuple whose\n",
      "     |            ``regexp`` matches the ``file_id``.  If no tuple's ``regexp``\n",
      "     |            matches the ``file_id``, the file contents will be processed\n",
      "     |            using non-unicode byte strings.\n",
      "     |          - None: the file contents of all files will be\n",
      "     |            processed using non-unicode byte strings.\n",
      "     |      :param tagset: The name of the tagset used by this corpus, to be used\n",
      "     |            for normalizing or converting the POS tags returned by the\n",
      "     |            tagged_...() methods.\n",
      "     |  \n",
      "     |  paras(self, fileids=None)\n",
      "     |  \n",
      "     |  raw(self, fileids=None)\n",
      "     |  \n",
      "     |  sents(self, fileids=None)\n",
      "     |  \n",
      "     |  tagged_paras(self, fileids=None)\n",
      "     |  \n",
      "     |  tagged_sents(self, fileids=None)\n",
      "     |  \n",
      "     |  tagged_words(self, fileids=None)\n",
      "     |  \n",
      "     |  words(self, fileids=None)\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Methods inherited from nltk.corpus.reader.api.CorpusReader:\n",
      "     |  \n",
      "     |  __repr__(self)\n",
      "     |      Return repr(self).\n",
      "     |  \n",
      "     |  __unicode__ = __str__(self, /)\n",
      "     |  \n",
      "     |  abspath(self, fileid)\n",
      "     |      Return the absolute path for the given file.\n",
      "     |      \n",
      "     |      :type fileid: str\n",
      "     |      :param fileid: The file identifier for the file whose path\n",
      "     |          should be returned.\n",
      "     |      :rtype: PathPointer\n",
      "     |  \n",
      "     |  abspaths(self, fileids=None, include_encoding=False, include_fileid=False)\n",
      "     |      Return a list of the absolute paths for all fileids in this corpus;\n",
      "     |      or for the given list of fileids, if specified.\n",
      "     |      \n",
      "     |      :type fileids: None or str or list\n",
      "     |      :param fileids: Specifies the set of fileids for which paths should\n",
      "     |          be returned.  Can be None, for all fileids; a list of\n",
      "     |          file identifiers, for a specified set of fileids; or a single\n",
      "     |          file identifier, for a single file.  Note that the return\n",
      "     |          value is always a list of paths, even if ``fileids`` is a\n",
      "     |          single file identifier.\n",
      "     |      \n",
      "     |      :param include_encoding: If true, then return a list of\n",
      "     |          ``(path_pointer, encoding)`` tuples.\n",
      "     |      \n",
      "     |      :rtype: list(PathPointer)\n",
      "     |  \n",
      "     |  citation(self)\n",
      "     |      Return the contents of the corpus citation.bib file, if it exists.\n",
      "     |  \n",
      "     |  encoding(self, file)\n",
      "     |      Return the unicode encoding for the given corpus file, if known.\n",
      "     |      If the encoding is unknown, or if the given file should be\n",
      "     |      processed using byte strings (str), then return None.\n",
      "     |  \n",
      "     |  ensure_loaded(self)\n",
      "     |      Load this corpus (if it has not already been loaded).  This is\n",
      "     |      used by LazyCorpusLoader as a simple method that can be used to\n",
      "     |      make sure a corpus is loaded -- e.g., in case a user wants to\n",
      "     |      do help(some_corpus).\n",
      "     |  \n",
      "     |  fileids(self)\n",
      "     |      Return a list of file identifiers for the fileids that make up\n",
      "     |      this corpus.\n",
      "     |  \n",
      "     |  license(self)\n",
      "     |      Return the contents of the corpus LICENSE file, if it exists.\n",
      "     |  \n",
      "     |  open(self, file)\n",
      "     |      Return an open stream that can be used to read the given file.\n",
      "     |      If the file's encoding is not None, then the stream will\n",
      "     |      automatically decode the file's contents into unicode.\n",
      "     |      \n",
      "     |      :param file: The file identifier of the file to read.\n",
      "     |  \n",
      "     |  readme(self)\n",
      "     |      Return the contents of the corpus README file, if it exists.\n",
      "     |  \n",
      "     |  unicode_repr = __repr__(self)\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Data descriptors inherited from nltk.corpus.reader.api.CorpusReader:\n",
      "     |  \n",
      "     |  __dict__\n",
      "     |      dictionary for instance variables (if defined)\n",
      "     |  \n",
      "     |  __weakref__\n",
      "     |      list of weak references to the object (if defined)\n",
      "     |  \n",
      "     |  root\n",
      "     |      The directory where this corpus is stored.\n",
      "     |      \n",
      "     |      :type: PathPointer\n",
      "    \n",
      "    class ChunkedCorpusReader(nltk.corpus.reader.api.CorpusReader)\n",
      "     |  ChunkedCorpusReader(root, fileids, extension='', str2chunktree=<function tagstr2tree at 0x000001F4CEBF8DC8>, sent_tokenizer=RegexpTokenizer(pattern='\\n', gaps=True, discard_empty=True, flags=<RegexFlag.UNICODE|DOTALL|MULTILINE: 56>), para_block_reader=<function read_blankline_block at 0x000001F4CED359D8>, encoding='utf8', tagset=None)\n",
      "     |  \n",
      "     |  Reader for chunked (and optionally tagged) corpora.  Paragraphs\n",
      "     |  are split using a block reader.  They are then tokenized into\n",
      "     |  sentences using a sentence tokenizer.  Finally, these sentences\n",
      "     |  are parsed into chunk trees using a string-to-chunktree conversion\n",
      "     |  function.  Each of these steps can be performed using a default\n",
      "     |  function or a custom function.  By default, paragraphs are split\n",
      "     |  on blank lines; sentences are listed one per line; and sentences\n",
      "     |  are parsed into chunk trees using ``nltk.chunk.tagstr2tree``.\n",
      "     |  \n",
      "     |  Method resolution order:\n",
      "     |      ChunkedCorpusReader\n",
      "     |      nltk.corpus.reader.api.CorpusReader\n",
      "     |      builtins.object\n",
      "     |  \n",
      "     |  Methods defined here:\n",
      "     |  \n",
      "     |  __init__(self, root, fileids, extension='', str2chunktree=<function tagstr2tree at 0x000001F4CEBF8DC8>, sent_tokenizer=RegexpTokenizer(pattern='\\n', gaps=True, discard_empty=True, flags=<RegexFlag.UNICODE|DOTALL|MULTILINE: 56>), para_block_reader=<function read_blankline_block at 0x000001F4CED359D8>, encoding='utf8', tagset=None)\n",
      "     |      :param root: The root directory for this corpus.\n",
      "     |      :param fileids: A list or regexp specifying the fileids in this corpus.\n",
      "     |  \n",
      "     |  chunked_paras(self, fileids=None, tagset=None)\n",
      "     |      :return: the given file(s) as a list of\n",
      "     |          paragraphs, each encoded as a list of sentences, which are\n",
      "     |          in turn encoded as a shallow Tree.  The leaves of these\n",
      "     |          trees are encoded as ``(word, tag)`` tuples (if the corpus\n",
      "     |          has tags) or word strings (if the corpus has no tags).\n",
      "     |      :rtype: list(list(Tree))\n",
      "     |  \n",
      "     |  chunked_sents(self, fileids=None, tagset=None)\n",
      "     |      :return: the given file(s) as a list of\n",
      "     |          sentences, each encoded as a shallow Tree.  The leaves\n",
      "     |          of these trees are encoded as ``(word, tag)`` tuples (if\n",
      "     |          the corpus has tags) or word strings (if the corpus has no\n",
      "     |          tags).\n",
      "     |      :rtype: list(Tree)\n",
      "     |  \n",
      "     |  chunked_words(self, fileids=None, tagset=None)\n",
      "     |      :return: the given file(s) as a list of tagged\n",
      "     |          words and chunks.  Words are encoded as ``(word, tag)``\n",
      "     |          tuples (if the corpus has tags) or word strings (if the\n",
      "     |          corpus has no tags).  Chunks are encoded as depth-one\n",
      "     |          trees over ``(word,tag)`` tuples or word strings.\n",
      "     |      :rtype: list(tuple(str,str) and Tree)\n",
      "     |  \n",
      "     |  paras(self, fileids=None)\n",
      "     |      :return: the given file(s) as a list of\n",
      "     |          paragraphs, each encoded as a list of sentences, which are\n",
      "     |          in turn encoded as lists of word strings.\n",
      "     |      :rtype: list(list(list(str)))\n",
      "     |  \n",
      "     |  raw(self, fileids=None)\n",
      "     |      :return: the given file(s) as a single string.\n",
      "     |      :rtype: str\n",
      "     |  \n",
      "     |  sents(self, fileids=None)\n",
      "     |      :return: the given file(s) as a list of\n",
      "     |          sentences or utterances, each encoded as a list of word\n",
      "     |          strings.\n",
      "     |      :rtype: list(list(str))\n",
      "     |  \n",
      "     |  tagged_paras(self, fileids=None, tagset=None)\n",
      "     |      :return: the given file(s) as a list of\n",
      "     |          paragraphs, each encoded as a list of sentences, which are\n",
      "     |          in turn encoded as lists of ``(word,tag)`` tuples.\n",
      "     |      :rtype: list(list(list(tuple(str,str))))\n",
      "     |  \n",
      "     |  tagged_sents(self, fileids=None, tagset=None)\n",
      "     |      :return: the given file(s) as a list of\n",
      "     |          sentences, each encoded as a list of ``(word,tag)`` tuples.\n",
      "     |      \n",
      "     |      :rtype: list(list(tuple(str,str)))\n",
      "     |  \n",
      "     |  tagged_words(self, fileids=None, tagset=None)\n",
      "     |      :return: the given file(s) as a list of tagged\n",
      "     |          words and punctuation symbols, encoded as tuples\n",
      "     |          ``(word,tag)``.\n",
      "     |      :rtype: list(tuple(str,str))\n",
      "     |  \n",
      "     |  words(self, fileids=None)\n",
      "     |      :return: the given file(s) as a list of words\n",
      "     |          and punctuation symbols.\n",
      "     |      :rtype: list(str)\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Methods inherited from nltk.corpus.reader.api.CorpusReader:\n",
      "     |  \n",
      "     |  __repr__(self)\n",
      "     |      Return repr(self).\n",
      "     |  \n",
      "     |  __unicode__ = __str__(self, /)\n",
      "     |  \n",
      "     |  abspath(self, fileid)\n",
      "     |      Return the absolute path for the given file.\n",
      "     |      \n",
      "     |      :type fileid: str\n",
      "     |      :param fileid: The file identifier for the file whose path\n",
      "     |          should be returned.\n",
      "     |      :rtype: PathPointer\n",
      "     |  \n",
      "     |  abspaths(self, fileids=None, include_encoding=False, include_fileid=False)\n",
      "     |      Return a list of the absolute paths for all fileids in this corpus;\n",
      "     |      or for the given list of fileids, if specified.\n",
      "     |      \n",
      "     |      :type fileids: None or str or list\n",
      "     |      :param fileids: Specifies the set of fileids for which paths should\n",
      "     |          be returned.  Can be None, for all fileids; a list of\n",
      "     |          file identifiers, for a specified set of fileids; or a single\n",
      "     |          file identifier, for a single file.  Note that the return\n",
      "     |          value is always a list of paths, even if ``fileids`` is a\n",
      "     |          single file identifier.\n",
      "     |      \n",
      "     |      :param include_encoding: If true, then return a list of\n",
      "     |          ``(path_pointer, encoding)`` tuples.\n",
      "     |      \n",
      "     |      :rtype: list(PathPointer)\n",
      "     |  \n",
      "     |  citation(self)\n",
      "     |      Return the contents of the corpus citation.bib file, if it exists.\n",
      "     |  \n",
      "     |  encoding(self, file)\n",
      "     |      Return the unicode encoding for the given corpus file, if known.\n",
      "     |      If the encoding is unknown, or if the given file should be\n",
      "     |      processed using byte strings (str), then return None.\n",
      "     |  \n",
      "     |  ensure_loaded(self)\n",
      "     |      Load this corpus (if it has not already been loaded).  This is\n",
      "     |      used by LazyCorpusLoader as a simple method that can be used to\n",
      "     |      make sure a corpus is loaded -- e.g., in case a user wants to\n",
      "     |      do help(some_corpus).\n",
      "     |  \n",
      "     |  fileids(self)\n",
      "     |      Return a list of file identifiers for the fileids that make up\n",
      "     |      this corpus.\n",
      "     |  \n",
      "     |  license(self)\n",
      "     |      Return the contents of the corpus LICENSE file, if it exists.\n",
      "     |  \n",
      "     |  open(self, file)\n",
      "     |      Return an open stream that can be used to read the given file.\n",
      "     |      If the file's encoding is not None, then the stream will\n",
      "     |      automatically decode the file's contents into unicode.\n",
      "     |      \n",
      "     |      :param file: The file identifier of the file to read.\n",
      "     |  \n",
      "     |  readme(self)\n",
      "     |      Return the contents of the corpus README file, if it exists.\n",
      "     |  \n",
      "     |  unicode_repr = __repr__(self)\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Data descriptors inherited from nltk.corpus.reader.api.CorpusReader:\n",
      "     |  \n",
      "     |  __dict__\n",
      "     |      dictionary for instance variables (if defined)\n",
      "     |  \n",
      "     |  __weakref__\n",
      "     |      list of weak references to the object (if defined)\n",
      "     |  \n",
      "     |  root\n",
      "     |      The directory where this corpus is stored.\n",
      "     |      \n",
      "     |      :type: PathPointer\n",
      "    \n",
      "    class ComparativeSentencesCorpusReader(nltk.corpus.reader.api.CorpusReader)\n",
      "     |  ComparativeSentencesCorpusReader(root, fileids, word_tokenizer=WhitespaceTokenizer(pattern='\\\\s+', gaps=True, discard_empty=True, flags=<RegexFlag.UNICODE|DOTALL|MULTILINE: 56>), sent_tokenizer=None, encoding='utf8')\n",
      "     |  \n",
      "     |  Reader for the Comparative Sentence Dataset by Jindal and Liu (2006).\n",
      "     |  \n",
      "     |      >>> from nltk.corpus import comparative_sentences\n",
      "     |      >>> comparison = comparative_sentences.comparisons()[0]\n",
      "     |      >>> comparison.text\n",
      "     |      ['its', 'fast-forward', 'and', 'rewind', 'work', 'much', 'more', 'smoothly',\n",
      "     |      'and', 'consistently', 'than', 'those', 'of', 'other', 'models', 'i', \"'ve\",\n",
      "     |      'had', '.']\n",
      "     |      >>> comparison.entity_2\n",
      "     |      'models'\n",
      "     |      >>> (comparison.feature, comparison.keyword)\n",
      "     |      ('rewind', 'more')\n",
      "     |      >>> len(comparative_sentences.comparisons())\n",
      "     |      853\n",
      "     |  \n",
      "     |  Method resolution order:\n",
      "     |      ComparativeSentencesCorpusReader\n",
      "     |      nltk.corpus.reader.api.CorpusReader\n",
      "     |      builtins.object\n",
      "     |  \n",
      "     |  Methods defined here:\n",
      "     |  \n",
      "     |  __init__(self, root, fileids, word_tokenizer=WhitespaceTokenizer(pattern='\\\\s+', gaps=True, discard_empty=True, flags=<RegexFlag.UNICODE|DOTALL|MULTILINE: 56>), sent_tokenizer=None, encoding='utf8')\n",
      "     |      :param root: The root directory for this corpus.\n",
      "     |      :param fileids: a list or regexp specifying the fileids in this corpus.\n",
      "     |      :param word_tokenizer: tokenizer for breaking sentences or paragraphs\n",
      "     |          into words. Default: `WhitespaceTokenizer`\n",
      "     |      :param sent_tokenizer: tokenizer for breaking paragraphs into sentences.\n",
      "     |      :param encoding: the encoding that should be used to read the corpus.\n",
      "     |  \n",
      "     |  comparisons(self, fileids=None)\n",
      "     |      Return all comparisons in the corpus.\n",
      "     |      \n",
      "     |      :param fileids: a list or regexp specifying the ids of the files whose\n",
      "     |          comparisons have to be returned.\n",
      "     |      :return: the given file(s) as a list of Comparison objects.\n",
      "     |      :rtype: list(Comparison)\n",
      "     |  \n",
      "     |  keywords(self, fileids=None)\n",
      "     |      Return a set of all keywords used in the corpus.\n",
      "     |      \n",
      "     |      :param fileids: a list or regexp specifying the ids of the files whose\n",
      "     |          keywords have to be returned.\n",
      "     |      :return: the set of keywords and comparative phrases used in the corpus.\n",
      "     |      :rtype: set(str)\n",
      "     |  \n",
      "     |  keywords_readme(self)\n",
      "     |      Return the list of words and constituents considered as clues of a\n",
      "     |      comparison (from listOfkeywords.txt).\n",
      "     |  \n",
      "     |  raw(self, fileids=None)\n",
      "     |      :param fileids: a list or regexp specifying the fileids that have to be\n",
      "     |          returned as a raw string.\n",
      "     |      :return: the given file(s) as a single string.\n",
      "     |      :rtype: str\n",
      "     |  \n",
      "     |  readme(self)\n",
      "     |      Return the contents of the corpus readme file.\n",
      "     |  \n",
      "     |  sents(self, fileids=None)\n",
      "     |      Return all sentences in the corpus.\n",
      "     |      \n",
      "     |      :param fileids: a list or regexp specifying the ids of the files whose\n",
      "     |          sentences have to be returned.\n",
      "     |      :return: all sentences of the corpus as lists of tokens (or as plain\n",
      "     |          strings, if no word tokenizer is specified).\n",
      "     |      :rtype: list(list(str)) or list(str)\n",
      "     |  \n",
      "     |  words(self, fileids=None)\n",
      "     |      Return all words and punctuation symbols in the corpus.\n",
      "     |      \n",
      "     |      :param fileids: a list or regexp specifying the ids of the files whose\n",
      "     |          words have to be returned.\n",
      "     |      :return: the given file(s) as a list of words and punctuation symbols.\n",
      "     |      :rtype: list(str)\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Data and other attributes defined here:\n",
      "     |  \n",
      "     |  CorpusView = <class 'nltk.corpus.reader.util.StreamBackedCorpusView'>\n",
      "     |      A 'view' of a corpus file, which acts like a sequence of tokens:\n",
      "     |      it can be accessed by index, iterated over, etc.  However, the\n",
      "     |      tokens are only constructed as-needed -- the entire corpus is\n",
      "     |      never stored in memory at once.\n",
      "     |      \n",
      "     |      The constructor to ``StreamBackedCorpusView`` takes two arguments:\n",
      "     |      a corpus fileid (specified as a string or as a ``PathPointer``);\n",
      "     |      and a block reader.  A \"block reader\" is a function that reads\n",
      "     |      zero or more tokens from a stream, and returns them as a list.  A\n",
      "     |      very simple example of a block reader is:\n",
      "     |      \n",
      "     |          >>> def simple_block_reader(stream):\n",
      "     |          ...     return stream.readline().split()\n",
      "     |      \n",
      "     |      This simple block reader reads a single line at a time, and\n",
      "     |      returns a single token (consisting of a string) for each\n",
      "     |      whitespace-separated substring on the line.\n",
      "     |      \n",
      "     |      When deciding how to define the block reader for a given\n",
      "     |      corpus, careful consideration should be given to the size of\n",
      "     |      blocks handled by the block reader.  Smaller block sizes will\n",
      "     |      increase the memory requirements of the corpus view's internal\n",
      "     |      data structures (by 2 integers per block).  On the other hand,\n",
      "     |      larger block sizes may decrease performance for random access to\n",
      "     |      the corpus.  (But note that larger block sizes will *not*\n",
      "     |      decrease performance for iteration.)\n",
      "     |      \n",
      "     |      Internally, ``CorpusView`` maintains a partial mapping from token\n",
      "     |      index to file position, with one entry per block.  When a token\n",
      "     |      with a given index *i* is requested, the ``CorpusView`` constructs\n",
      "     |      it as follows:\n",
      "     |      \n",
      "     |        1. First, it searches the toknum/filepos mapping for the token\n",
      "     |           index closest to (but less than or equal to) *i*.\n",
      "     |      \n",
      "     |        2. Then, starting at the file position corresponding to that\n",
      "     |           index, it reads one block at a time using the block reader\n",
      "     |           until it reaches the requested token.\n",
      "     |      \n",
      "     |      The toknum/filepos mapping is created lazily: it is initially\n",
      "     |      empty, but every time a new block is read, the block's\n",
      "     |      initial token is added to the mapping.  (Thus, the toknum/filepos\n",
      "     |      map has one entry per block.)\n",
      "     |      \n",
      "     |      In order to increase efficiency for random access patterns that\n",
      "     |      have high degrees of locality, the corpus view may cache one or\n",
      "     |      more blocks.\n",
      "     |      \n",
      "     |      :note: Each ``CorpusView`` object internally maintains an open file\n",
      "     |          object for its underlying corpus file.  This file should be\n",
      "     |          automatically closed when the ``CorpusView`` is garbage collected,\n",
      "     |          but if you wish to close it manually, use the ``close()``\n",
      "     |          method.  If you access a ``CorpusView``'s items after it has been\n",
      "     |          closed, the file object will be automatically re-opened.\n",
      "     |      \n",
      "     |      :warning: If the contents of the file are modified during the\n",
      "     |          lifetime of the ``CorpusView``, then the ``CorpusView``'s behavior\n",
      "     |          is undefined.\n",
      "     |      \n",
      "     |      :warning: If a unicode encoding is specified when constructing a\n",
      "     |          ``CorpusView``, then the block reader may only call\n",
      "     |          ``stream.seek()`` with offsets that have been returned by\n",
      "     |          ``stream.tell()``; in particular, calling ``stream.seek()`` with\n",
      "     |          relative offsets, or with offsets based on string lengths, may\n",
      "     |          lead to incorrect behavior.\n",
      "     |      \n",
      "     |      :ivar _block_reader: The function used to read\n",
      "     |          a single block from the underlying file stream.\n",
      "     |      :ivar _toknum: A list containing the token index of each block\n",
      "     |          that has been processed.  In particular, ``_toknum[i]`` is the\n",
      "     |          token index of the first token in block ``i``.  Together\n",
      "     |          with ``_filepos``, this forms a partial mapping between token\n",
      "     |          indices and file positions.\n",
      "     |      :ivar _filepos: A list containing the file position of each block\n",
      "     |          that has been processed.  In particular, ``_toknum[i]`` is the\n",
      "     |          file position of the first character in block ``i``.  Together\n",
      "     |          with ``_toknum``, this forms a partial mapping between token\n",
      "     |          indices and file positions.\n",
      "     |      :ivar _stream: The stream used to access the underlying corpus file.\n",
      "     |      :ivar _len: The total number of tokens in the corpus, if known;\n",
      "     |          or None, if the number of tokens is not yet known.\n",
      "     |      :ivar _eofpos: The character position of the last character in the\n",
      "     |          file.  This is calculated when the corpus view is initialized,\n",
      "     |          and is used to decide when the end of file has been reached.\n",
      "     |      :ivar _cache: A cache of the most recently read block.  It\n",
      "     |         is encoded as a tuple (start_toknum, end_toknum, tokens), where\n",
      "     |         start_toknum is the token index of the first token in the block;\n",
      "     |         end_toknum is the token index of the first token not in the\n",
      "     |         block; and tokens is a list of the tokens in the block.\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Methods inherited from nltk.corpus.reader.api.CorpusReader:\n",
      "     |  \n",
      "     |  __repr__(self)\n",
      "     |      Return repr(self).\n",
      "     |  \n",
      "     |  __unicode__ = __str__(self, /)\n",
      "     |  \n",
      "     |  abspath(self, fileid)\n",
      "     |      Return the absolute path for the given file.\n",
      "     |      \n",
      "     |      :type fileid: str\n",
      "     |      :param fileid: The file identifier for the file whose path\n",
      "     |          should be returned.\n",
      "     |      :rtype: PathPointer\n",
      "     |  \n",
      "     |  abspaths(self, fileids=None, include_encoding=False, include_fileid=False)\n",
      "     |      Return a list of the absolute paths for all fileids in this corpus;\n",
      "     |      or for the given list of fileids, if specified.\n",
      "     |      \n",
      "     |      :type fileids: None or str or list\n",
      "     |      :param fileids: Specifies the set of fileids for which paths should\n",
      "     |          be returned.  Can be None, for all fileids; a list of\n",
      "     |          file identifiers, for a specified set of fileids; or a single\n",
      "     |          file identifier, for a single file.  Note that the return\n",
      "     |          value is always a list of paths, even if ``fileids`` is a\n",
      "     |          single file identifier.\n",
      "     |      \n",
      "     |      :param include_encoding: If true, then return a list of\n",
      "     |          ``(path_pointer, encoding)`` tuples.\n",
      "     |      \n",
      "     |      :rtype: list(PathPointer)\n",
      "     |  \n",
      "     |  citation(self)\n",
      "     |      Return the contents of the corpus citation.bib file, if it exists.\n",
      "     |  \n",
      "     |  encoding(self, file)\n",
      "     |      Return the unicode encoding for the given corpus file, if known.\n",
      "     |      If the encoding is unknown, or if the given file should be\n",
      "     |      processed using byte strings (str), then return None.\n",
      "     |  \n",
      "     |  ensure_loaded(self)\n",
      "     |      Load this corpus (if it has not already been loaded).  This is\n",
      "     |      used by LazyCorpusLoader as a simple method that can be used to\n",
      "     |      make sure a corpus is loaded -- e.g., in case a user wants to\n",
      "     |      do help(some_corpus).\n",
      "     |  \n",
      "     |  fileids(self)\n",
      "     |      Return a list of file identifiers for the fileids that make up\n",
      "     |      this corpus.\n",
      "     |  \n",
      "     |  license(self)\n",
      "     |      Return the contents of the corpus LICENSE file, if it exists.\n",
      "     |  \n",
      "     |  open(self, file)\n",
      "     |      Return an open stream that can be used to read the given file.\n",
      "     |      If the file's encoding is not None, then the stream will\n",
      "     |      automatically decode the file's contents into unicode.\n",
      "     |      \n",
      "     |      :param file: The file identifier of the file to read.\n",
      "     |  \n",
      "     |  unicode_repr = __repr__(self)\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Data descriptors inherited from nltk.corpus.reader.api.CorpusReader:\n",
      "     |  \n",
      "     |  __dict__\n",
      "     |      dictionary for instance variables (if defined)\n",
      "     |  \n",
      "     |  __weakref__\n",
      "     |      list of weak references to the object (if defined)\n",
      "     |  \n",
      "     |  root\n",
      "     |      The directory where this corpus is stored.\n",
      "     |      \n",
      "     |      :type: PathPointer\n",
      "    \n",
      "    class ConllChunkCorpusReader(ConllCorpusReader)\n",
      "     |  ConllChunkCorpusReader(root, fileids, chunk_types, encoding='utf8', tagset=None, separator=None)\n",
      "     |  \n",
      "     |  A ConllCorpusReader whose data file contains three columns: words,\n",
      "     |  pos, and chunk.\n",
      "     |  \n",
      "     |  Method resolution order:\n",
      "     |      ConllChunkCorpusReader\n",
      "     |      ConllCorpusReader\n",
      "     |      nltk.corpus.reader.api.CorpusReader\n",
      "     |      builtins.object\n",
      "     |  \n",
      "     |  Methods defined here:\n",
      "     |  \n",
      "     |  __init__(self, root, fileids, chunk_types, encoding='utf8', tagset=None, separator=None)\n",
      "     |      :type root: PathPointer or str\n",
      "     |      :param root: A path pointer identifying the root directory for\n",
      "     |          this corpus.  If a string is specified, then it will be\n",
      "     |          converted to a ``PathPointer`` automatically.\n",
      "     |      :param fileids: A list of the files that make up this corpus.\n",
      "     |          This list can either be specified explicitly, as a list of\n",
      "     |          strings; or implicitly, as a regular expression over file\n",
      "     |          paths.  The absolute path for each file will be constructed\n",
      "     |          by joining the reader's root to each file name.\n",
      "     |      :param encoding: The default unicode encoding for the files\n",
      "     |          that make up the corpus.  The value of ``encoding`` can be any\n",
      "     |          of the following:\n",
      "     |          - A string: ``encoding`` is the encoding name for all files.\n",
      "     |          - A dictionary: ``encoding[file_id]`` is the encoding\n",
      "     |            name for the file whose identifier is ``file_id``.  If\n",
      "     |            ``file_id`` is not in ``encoding``, then the file\n",
      "     |            contents will be processed using non-unicode byte strings.\n",
      "     |          - A list: ``encoding`` should be a list of ``(regexp, encoding)``\n",
      "     |            tuples.  The encoding for a file whose identifier is ``file_id``\n",
      "     |            will be the ``encoding`` value for the first tuple whose\n",
      "     |            ``regexp`` matches the ``file_id``.  If no tuple's ``regexp``\n",
      "     |            matches the ``file_id``, the file contents will be processed\n",
      "     |            using non-unicode byte strings.\n",
      "     |          - None: the file contents of all files will be\n",
      "     |            processed using non-unicode byte strings.\n",
      "     |      :param tagset: The name of the tagset used by this corpus, to be used\n",
      "     |            for normalizing or converting the POS tags returned by the\n",
      "     |            tagged_...() methods.\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Methods inherited from ConllCorpusReader:\n",
      "     |  \n",
      "     |  chunked_sents(self, fileids=None, chunk_types=None, tagset=None)\n",
      "     |  \n",
      "     |  chunked_words(self, fileids=None, chunk_types=None, tagset=None)\n",
      "     |  \n",
      "     |  iob_sents(self, fileids=None, tagset=None)\n",
      "     |      :return: a list of lists of word/tag/IOB tuples\n",
      "     |      :rtype: list(list)\n",
      "     |      :param fileids: the list of fileids that make up this corpus\n",
      "     |      :type fileids: None or str or list\n",
      "     |  \n",
      "     |  iob_words(self, fileids=None, tagset=None)\n",
      "     |      :return: a list of word/tag/IOB tuples\n",
      "     |      :rtype: list(tuple)\n",
      "     |      :param fileids: the list of fileids that make up this corpus\n",
      "     |      :type fileids: None or str or list\n",
      "     |  \n",
      "     |  parsed_sents(self, fileids=None, pos_in_tree=None, tagset=None)\n",
      "     |  \n",
      "     |  raw(self, fileids=None)\n",
      "     |  \n",
      "     |  sents(self, fileids=None)\n",
      "     |  \n",
      "     |  srl_instances(self, fileids=None, pos_in_tree=None, flatten=True)\n",
      "     |  \n",
      "     |  srl_spans(self, fileids=None)\n",
      "     |  \n",
      "     |  tagged_sents(self, fileids=None, tagset=None)\n",
      "     |  \n",
      "     |  tagged_words(self, fileids=None, tagset=None)\n",
      "     |  \n",
      "     |  words(self, fileids=None)\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Data and other attributes inherited from ConllCorpusReader:\n",
      "     |  \n",
      "     |  CHUNK = 'chunk'\n",
      "     |  \n",
      "     |  COLUMN_TYPES = ('words', 'pos', 'tree', 'chunk', 'ne', 'srl', 'ignore'...\n",
      "     |  \n",
      "     |  IGNORE = 'ignore'\n",
      "     |  \n",
      "     |  NE = 'ne'\n",
      "     |  \n",
      "     |  POS = 'pos'\n",
      "     |  \n",
      "     |  SRL = 'srl'\n",
      "     |  \n",
      "     |  TREE = 'tree'\n",
      "     |  \n",
      "     |  WORDS = 'words'\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Methods inherited from nltk.corpus.reader.api.CorpusReader:\n",
      "     |  \n",
      "     |  __repr__(self)\n",
      "     |      Return repr(self).\n",
      "     |  \n",
      "     |  __unicode__ = __str__(self, /)\n",
      "     |  \n",
      "     |  abspath(self, fileid)\n",
      "     |      Return the absolute path for the given file.\n",
      "     |      \n",
      "     |      :type fileid: str\n",
      "     |      :param fileid: The file identifier for the file whose path\n",
      "     |          should be returned.\n",
      "     |      :rtype: PathPointer\n",
      "     |  \n",
      "     |  abspaths(self, fileids=None, include_encoding=False, include_fileid=False)\n",
      "     |      Return a list of the absolute paths for all fileids in this corpus;\n",
      "     |      or for the given list of fileids, if specified.\n",
      "     |      \n",
      "     |      :type fileids: None or str or list\n",
      "     |      :param fileids: Specifies the set of fileids for which paths should\n",
      "     |          be returned.  Can be None, for all fileids; a list of\n",
      "     |          file identifiers, for a specified set of fileids; or a single\n",
      "     |          file identifier, for a single file.  Note that the return\n",
      "     |          value is always a list of paths, even if ``fileids`` is a\n",
      "     |          single file identifier.\n",
      "     |      \n",
      "     |      :param include_encoding: If true, then return a list of\n",
      "     |          ``(path_pointer, encoding)`` tuples.\n",
      "     |      \n",
      "     |      :rtype: list(PathPointer)\n",
      "     |  \n",
      "     |  citation(self)\n",
      "     |      Return the contents of the corpus citation.bib file, if it exists.\n",
      "     |  \n",
      "     |  encoding(self, file)\n",
      "     |      Return the unicode encoding for the given corpus file, if known.\n",
      "     |      If the encoding is unknown, or if the given file should be\n",
      "     |      processed using byte strings (str), then return None.\n",
      "     |  \n",
      "     |  ensure_loaded(self)\n",
      "     |      Load this corpus (if it has not already been loaded).  This is\n",
      "     |      used by LazyCorpusLoader as a simple method that can be used to\n",
      "     |      make sure a corpus is loaded -- e.g., in case a user wants to\n",
      "     |      do help(some_corpus).\n",
      "     |  \n",
      "     |  fileids(self)\n",
      "     |      Return a list of file identifiers for the fileids that make up\n",
      "     |      this corpus.\n",
      "     |  \n",
      "     |  license(self)\n",
      "     |      Return the contents of the corpus LICENSE file, if it exists.\n",
      "     |  \n",
      "     |  open(self, file)\n",
      "     |      Return an open stream that can be used to read the given file.\n",
      "     |      If the file's encoding is not None, then the stream will\n",
      "     |      automatically decode the file's contents into unicode.\n",
      "     |      \n",
      "     |      :param file: The file identifier of the file to read.\n",
      "     |  \n",
      "     |  readme(self)\n",
      "     |      Return the contents of the corpus README file, if it exists.\n",
      "     |  \n",
      "     |  unicode_repr = __repr__(self)\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Data descriptors inherited from nltk.corpus.reader.api.CorpusReader:\n",
      "     |  \n",
      "     |  __dict__\n",
      "     |      dictionary for instance variables (if defined)\n",
      "     |  \n",
      "     |  __weakref__\n",
      "     |      list of weak references to the object (if defined)\n",
      "     |  \n",
      "     |  root\n",
      "     |      The directory where this corpus is stored.\n",
      "     |      \n",
      "     |      :type: PathPointer\n",
      "    \n",
      "    class ConllCorpusReader(nltk.corpus.reader.api.CorpusReader)\n",
      "     |  ConllCorpusReader(root, fileids, columntypes, chunk_types=None, root_label='S', pos_in_tree=False, srl_includes_roleset=True, encoding='utf8', tree_class=<class 'nltk.tree.Tree'>, tagset=None, separator=None)\n",
      "     |  \n",
      "     |  A corpus reader for CoNLL-style files.  These files consist of a\n",
      "     |  series of sentences, separated by blank lines.  Each sentence is\n",
      "     |  encoded using a table (or \"grid\") of values, where each line\n",
      "     |  corresponds to a single word, and each column corresponds to an\n",
      "     |  annotation type.  The set of columns used by CoNLL-style files can\n",
      "     |  vary from corpus to corpus; the ``ConllCorpusReader`` constructor\n",
      "     |  therefore takes an argument, ``columntypes``, which is used to\n",
      "     |  specify the columns that are used by a given corpus. By default\n",
      "     |  columns are split by consecutive whitespaces, with the\n",
      "     |  ``separator`` argument you can set a string to split by (e.g.\n",
      "     |  ``' '``).\n",
      "     |  \n",
      "     |  \n",
      "     |  @todo: Add support for reading from corpora where different\n",
      "     |      parallel files contain different columns.\n",
      "     |  @todo: Possibly add caching of the grid corpus view?  This would\n",
      "     |      allow the same grid view to be used by different data access\n",
      "     |      methods (eg words() and parsed_sents() could both share the\n",
      "     |      same grid corpus view object).\n",
      "     |  @todo: Better support for -DOCSTART-.  Currently, we just ignore\n",
      "     |      it, but it could be used to define methods that retrieve a\n",
      "     |      document at a time (eg parsed_documents()).\n",
      "     |  \n",
      "     |  Method resolution order:\n",
      "     |      ConllCorpusReader\n",
      "     |      nltk.corpus.reader.api.CorpusReader\n",
      "     |      builtins.object\n",
      "     |  \n",
      "     |  Methods defined here:\n",
      "     |  \n",
      "     |  __init__(self, root, fileids, columntypes, chunk_types=None, root_label='S', pos_in_tree=False, srl_includes_roleset=True, encoding='utf8', tree_class=<class 'nltk.tree.Tree'>, tagset=None, separator=None)\n",
      "     |      :type root: PathPointer or str\n",
      "     |      :param root: A path pointer identifying the root directory for\n",
      "     |          this corpus.  If a string is specified, then it will be\n",
      "     |          converted to a ``PathPointer`` automatically.\n",
      "     |      :param fileids: A list of the files that make up this corpus.\n",
      "     |          This list can either be specified explicitly, as a list of\n",
      "     |          strings; or implicitly, as a regular expression over file\n",
      "     |          paths.  The absolute path for each file will be constructed\n",
      "     |          by joining the reader's root to each file name.\n",
      "     |      :param encoding: The default unicode encoding for the files\n",
      "     |          that make up the corpus.  The value of ``encoding`` can be any\n",
      "     |          of the following:\n",
      "     |          - A string: ``encoding`` is the encoding name for all files.\n",
      "     |          - A dictionary: ``encoding[file_id]`` is the encoding\n",
      "     |            name for the file whose identifier is ``file_id``.  If\n",
      "     |            ``file_id`` is not in ``encoding``, then the file\n",
      "     |            contents will be processed using non-unicode byte strings.\n",
      "     |          - A list: ``encoding`` should be a list of ``(regexp, encoding)``\n",
      "     |            tuples.  The encoding for a file whose identifier is ``file_id``\n",
      "     |            will be the ``encoding`` value for the first tuple whose\n",
      "     |            ``regexp`` matches the ``file_id``.  If no tuple's ``regexp``\n",
      "     |            matches the ``file_id``, the file contents will be processed\n",
      "     |            using non-unicode byte strings.\n",
      "     |          - None: the file contents of all files will be\n",
      "     |            processed using non-unicode byte strings.\n",
      "     |      :param tagset: The name of the tagset used by this corpus, to be used\n",
      "     |            for normalizing or converting the POS tags returned by the\n",
      "     |            tagged_...() methods.\n",
      "     |  \n",
      "     |  chunked_sents(self, fileids=None, chunk_types=None, tagset=None)\n",
      "     |  \n",
      "     |  chunked_words(self, fileids=None, chunk_types=None, tagset=None)\n",
      "     |  \n",
      "     |  iob_sents(self, fileids=None, tagset=None)\n",
      "     |      :return: a list of lists of word/tag/IOB tuples\n",
      "     |      :rtype: list(list)\n",
      "     |      :param fileids: the list of fileids that make up this corpus\n",
      "     |      :type fileids: None or str or list\n",
      "     |  \n",
      "     |  iob_words(self, fileids=None, tagset=None)\n",
      "     |      :return: a list of word/tag/IOB tuples\n",
      "     |      :rtype: list(tuple)\n",
      "     |      :param fileids: the list of fileids that make up this corpus\n",
      "     |      :type fileids: None or str or list\n",
      "     |  \n",
      "     |  parsed_sents(self, fileids=None, pos_in_tree=None, tagset=None)\n",
      "     |  \n",
      "     |  raw(self, fileids=None)\n",
      "     |  \n",
      "     |  sents(self, fileids=None)\n",
      "     |  \n",
      "     |  srl_instances(self, fileids=None, pos_in_tree=None, flatten=True)\n",
      "     |  \n",
      "     |  srl_spans(self, fileids=None)\n",
      "     |  \n",
      "     |  tagged_sents(self, fileids=None, tagset=None)\n",
      "     |  \n",
      "     |  tagged_words(self, fileids=None, tagset=None)\n",
      "     |  \n",
      "     |  words(self, fileids=None)\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Data and other attributes defined here:\n",
      "     |  \n",
      "     |  CHUNK = 'chunk'\n",
      "     |  \n",
      "     |  COLUMN_TYPES = ('words', 'pos', 'tree', 'chunk', 'ne', 'srl', 'ignore'...\n",
      "     |  \n",
      "     |  IGNORE = 'ignore'\n",
      "     |  \n",
      "     |  NE = 'ne'\n",
      "     |  \n",
      "     |  POS = 'pos'\n",
      "     |  \n",
      "     |  SRL = 'srl'\n",
      "     |  \n",
      "     |  TREE = 'tree'\n",
      "     |  \n",
      "     |  WORDS = 'words'\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Methods inherited from nltk.corpus.reader.api.CorpusReader:\n",
      "     |  \n",
      "     |  __repr__(self)\n",
      "     |      Return repr(self).\n",
      "     |  \n",
      "     |  __unicode__ = __str__(self, /)\n",
      "     |  \n",
      "     |  abspath(self, fileid)\n",
      "     |      Return the absolute path for the given file.\n",
      "     |      \n",
      "     |      :type fileid: str\n",
      "     |      :param fileid: The file identifier for the file whose path\n",
      "     |          should be returned.\n",
      "     |      :rtype: PathPointer\n",
      "     |  \n",
      "     |  abspaths(self, fileids=None, include_encoding=False, include_fileid=False)\n",
      "     |      Return a list of the absolute paths for all fileids in this corpus;\n",
      "     |      or for the given list of fileids, if specified.\n",
      "     |      \n",
      "     |      :type fileids: None or str or list\n",
      "     |      :param fileids: Specifies the set of fileids for which paths should\n",
      "     |          be returned.  Can be None, for all fileids; a list of\n",
      "     |          file identifiers, for a specified set of fileids; or a single\n",
      "     |          file identifier, for a single file.  Note that the return\n",
      "     |          value is always a list of paths, even if ``fileids`` is a\n",
      "     |          single file identifier.\n",
      "     |      \n",
      "     |      :param include_encoding: If true, then return a list of\n",
      "     |          ``(path_pointer, encoding)`` tuples.\n",
      "     |      \n",
      "     |      :rtype: list(PathPointer)\n",
      "     |  \n",
      "     |  citation(self)\n",
      "     |      Return the contents of the corpus citation.bib file, if it exists.\n",
      "     |  \n",
      "     |  encoding(self, file)\n",
      "     |      Return the unicode encoding for the given corpus file, if known.\n",
      "     |      If the encoding is unknown, or if the given file should be\n",
      "     |      processed using byte strings (str), then return None.\n",
      "     |  \n",
      "     |  ensure_loaded(self)\n",
      "     |      Load this corpus (if it has not already been loaded).  This is\n",
      "     |      used by LazyCorpusLoader as a simple method that can be used to\n",
      "     |      make sure a corpus is loaded -- e.g., in case a user wants to\n",
      "     |      do help(some_corpus).\n",
      "     |  \n",
      "     |  fileids(self)\n",
      "     |      Return a list of file identifiers for the fileids that make up\n",
      "     |      this corpus.\n",
      "     |  \n",
      "     |  license(self)\n",
      "     |      Return the contents of the corpus LICENSE file, if it exists.\n",
      "     |  \n",
      "     |  open(self, file)\n",
      "     |      Return an open stream that can be used to read the given file.\n",
      "     |      If the file's encoding is not None, then the stream will\n",
      "     |      automatically decode the file's contents into unicode.\n",
      "     |      \n",
      "     |      :param file: The file identifier of the file to read.\n",
      "     |  \n",
      "     |  readme(self)\n",
      "     |      Return the contents of the corpus README file, if it exists.\n",
      "     |  \n",
      "     |  unicode_repr = __repr__(self)\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Data descriptors inherited from nltk.corpus.reader.api.CorpusReader:\n",
      "     |  \n",
      "     |  __dict__\n",
      "     |      dictionary for instance variables (if defined)\n",
      "     |  \n",
      "     |  __weakref__\n",
      "     |      list of weak references to the object (if defined)\n",
      "     |  \n",
      "     |  root\n",
      "     |      The directory where this corpus is stored.\n",
      "     |      \n",
      "     |      :type: PathPointer\n",
      "    \n",
      "    class CorpusReader(builtins.object)\n",
      "     |  CorpusReader(root, fileids, encoding='utf8', tagset=None)\n",
      "     |  \n",
      "     |  A base class for \"corpus reader\" classes, each of which can be\n",
      "     |  used to read a specific corpus format.  Each individual corpus\n",
      "     |  reader instance is used to read a specific corpus, consisting of\n",
      "     |  one or more files under a common root directory.  Each file is\n",
      "     |  identified by its ``file identifier``, which is the relative path\n",
      "     |  to the file from the root directory.\n",
      "     |  \n",
      "     |  A separate subclass is defined for each corpus format.  These\n",
      "     |  subclasses define one or more methods that provide 'views' on the\n",
      "     |  corpus contents, such as ``words()`` (for a list of words) and\n",
      "     |  ``parsed_sents()`` (for a list of parsed sentences).  Called with\n",
      "     |  no arguments, these methods will return the contents of the entire\n",
      "     |  corpus.  For most corpora, these methods define one or more\n",
      "     |  selection arguments, such as ``fileids`` or ``categories``, which can\n",
      "     |  be used to select which portion of the corpus should be returned.\n",
      "     |  \n",
      "     |  Methods defined here:\n",
      "     |  \n",
      "     |  __init__(self, root, fileids, encoding='utf8', tagset=None)\n",
      "     |      :type root: PathPointer or str\n",
      "     |      :param root: A path pointer identifying the root directory for\n",
      "     |          this corpus.  If a string is specified, then it will be\n",
      "     |          converted to a ``PathPointer`` automatically.\n",
      "     |      :param fileids: A list of the files that make up this corpus.\n",
      "     |          This list can either be specified explicitly, as a list of\n",
      "     |          strings; or implicitly, as a regular expression over file\n",
      "     |          paths.  The absolute path for each file will be constructed\n",
      "     |          by joining the reader's root to each file name.\n",
      "     |      :param encoding: The default unicode encoding for the files\n",
      "     |          that make up the corpus.  The value of ``encoding`` can be any\n",
      "     |          of the following:\n",
      "     |          - A string: ``encoding`` is the encoding name for all files.\n",
      "     |          - A dictionary: ``encoding[file_id]`` is the encoding\n",
      "     |            name for the file whose identifier is ``file_id``.  If\n",
      "     |            ``file_id`` is not in ``encoding``, then the file\n",
      "     |            contents will be processed using non-unicode byte strings.\n",
      "     |          - A list: ``encoding`` should be a list of ``(regexp, encoding)``\n",
      "     |            tuples.  The encoding for a file whose identifier is ``file_id``\n",
      "     |            will be the ``encoding`` value for the first tuple whose\n",
      "     |            ``regexp`` matches the ``file_id``.  If no tuple's ``regexp``\n",
      "     |            matches the ``file_id``, the file contents will be processed\n",
      "     |            using non-unicode byte strings.\n",
      "     |          - None: the file contents of all files will be\n",
      "     |            processed using non-unicode byte strings.\n",
      "     |      :param tagset: The name of the tagset used by this corpus, to be used\n",
      "     |            for normalizing or converting the POS tags returned by the\n",
      "     |            tagged_...() methods.\n",
      "     |  \n",
      "     |  __repr__(self)\n",
      "     |      Return repr(self).\n",
      "     |  \n",
      "     |  __unicode__ = __str__(self, /)\n",
      "     |  \n",
      "     |  abspath(self, fileid)\n",
      "     |      Return the absolute path for the given file.\n",
      "     |      \n",
      "     |      :type fileid: str\n",
      "     |      :param fileid: The file identifier for the file whose path\n",
      "     |          should be returned.\n",
      "     |      :rtype: PathPointer\n",
      "     |  \n",
      "     |  abspaths(self, fileids=None, include_encoding=False, include_fileid=False)\n",
      "     |      Return a list of the absolute paths for all fileids in this corpus;\n",
      "     |      or for the given list of fileids, if specified.\n",
      "     |      \n",
      "     |      :type fileids: None or str or list\n",
      "     |      :param fileids: Specifies the set of fileids for which paths should\n",
      "     |          be returned.  Can be None, for all fileids; a list of\n",
      "     |          file identifiers, for a specified set of fileids; or a single\n",
      "     |          file identifier, for a single file.  Note that the return\n",
      "     |          value is always a list of paths, even if ``fileids`` is a\n",
      "     |          single file identifier.\n",
      "     |      \n",
      "     |      :param include_encoding: If true, then return a list of\n",
      "     |          ``(path_pointer, encoding)`` tuples.\n",
      "     |      \n",
      "     |      :rtype: list(PathPointer)\n",
      "     |  \n",
      "     |  citation(self)\n",
      "     |      Return the contents of the corpus citation.bib file, if it exists.\n",
      "     |  \n",
      "     |  encoding(self, file)\n",
      "     |      Return the unicode encoding for the given corpus file, if known.\n",
      "     |      If the encoding is unknown, or if the given file should be\n",
      "     |      processed using byte strings (str), then return None.\n",
      "     |  \n",
      "     |  ensure_loaded(self)\n",
      "     |      Load this corpus (if it has not already been loaded).  This is\n",
      "     |      used by LazyCorpusLoader as a simple method that can be used to\n",
      "     |      make sure a corpus is loaded -- e.g., in case a user wants to\n",
      "     |      do help(some_corpus).\n",
      "     |  \n",
      "     |  fileids(self)\n",
      "     |      Return a list of file identifiers for the fileids that make up\n",
      "     |      this corpus.\n",
      "     |  \n",
      "     |  license(self)\n",
      "     |      Return the contents of the corpus LICENSE file, if it exists.\n",
      "     |  \n",
      "     |  open(self, file)\n",
      "     |      Return an open stream that can be used to read the given file.\n",
      "     |      If the file's encoding is not None, then the stream will\n",
      "     |      automatically decode the file's contents into unicode.\n",
      "     |      \n",
      "     |      :param file: The file identifier of the file to read.\n",
      "     |  \n",
      "     |  readme(self)\n",
      "     |      Return the contents of the corpus README file, if it exists.\n",
      "     |  \n",
      "     |  unicode_repr = __repr__(self)\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Data descriptors defined here:\n",
      "     |  \n",
      "     |  __dict__\n",
      "     |      dictionary for instance variables (if defined)\n",
      "     |  \n",
      "     |  __weakref__\n",
      "     |      list of weak references to the object (if defined)\n",
      "     |  \n",
      "     |  root\n",
      "     |      The directory where this corpus is stored.\n",
      "     |      \n",
      "     |      :type: PathPointer\n",
      "    \n",
      "    class CrubadanCorpusReader(nltk.corpus.reader.api.CorpusReader)\n",
      "     |  CrubadanCorpusReader(root, fileids, encoding='utf8', tagset=None)\n",
      "     |  \n",
      "     |  A corpus reader used to access language An Crubadan n-gram files.\n",
      "     |  \n",
      "     |  Method resolution order:\n",
      "     |      CrubadanCorpusReader\n",
      "     |      nltk.corpus.reader.api.CorpusReader\n",
      "     |      builtins.object\n",
      "     |  \n",
      "     |  Methods defined here:\n",
      "     |  \n",
      "     |  __init__(self, root, fileids, encoding='utf8', tagset=None)\n",
      "     |      :type root: PathPointer or str\n",
      "     |      :param root: A path pointer identifying the root directory for\n",
      "     |          this corpus.  If a string is specified, then it will be\n",
      "     |          converted to a ``PathPointer`` automatically.\n",
      "     |      :param fileids: A list of the files that make up this corpus.\n",
      "     |          This list can either be specified explicitly, as a list of\n",
      "     |          strings; or implicitly, as a regular expression over file\n",
      "     |          paths.  The absolute path for each file will be constructed\n",
      "     |          by joining the reader's root to each file name.\n",
      "     |      :param encoding: The default unicode encoding for the files\n",
      "     |          that make up the corpus.  The value of ``encoding`` can be any\n",
      "     |          of the following:\n",
      "     |          - A string: ``encoding`` is the encoding name for all files.\n",
      "     |          - A dictionary: ``encoding[file_id]`` is the encoding\n",
      "     |            name for the file whose identifier is ``file_id``.  If\n",
      "     |            ``file_id`` is not in ``encoding``, then the file\n",
      "     |            contents will be processed using non-unicode byte strings.\n",
      "     |          - A list: ``encoding`` should be a list of ``(regexp, encoding)``\n",
      "     |            tuples.  The encoding for a file whose identifier is ``file_id``\n",
      "     |            will be the ``encoding`` value for the first tuple whose\n",
      "     |            ``regexp`` matches the ``file_id``.  If no tuple's ``regexp``\n",
      "     |            matches the ``file_id``, the file contents will be processed\n",
      "     |            using non-unicode byte strings.\n",
      "     |          - None: the file contents of all files will be\n",
      "     |            processed using non-unicode byte strings.\n",
      "     |      :param tagset: The name of the tagset used by this corpus, to be used\n",
      "     |            for normalizing or converting the POS tags returned by the\n",
      "     |            tagged_...() methods.\n",
      "     |  \n",
      "     |  crubadan_to_iso(self, lang)\n",
      "     |      Return ISO 639-3 code given internal Crubadan code\n",
      "     |  \n",
      "     |  iso_to_crubadan(self, lang)\n",
      "     |      Return internal Crubadan code based on ISO 639-3 code\n",
      "     |  \n",
      "     |  lang_freq(self, lang)\n",
      "     |      Return n-gram FreqDist for a specific language\n",
      "     |      given ISO 639-3 language code\n",
      "     |  \n",
      "     |  langs(self)\n",
      "     |      Return a list of supported languages as ISO 639-3 codes\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Methods inherited from nltk.corpus.reader.api.CorpusReader:\n",
      "     |  \n",
      "     |  __repr__(self)\n",
      "     |      Return repr(self).\n",
      "     |  \n",
      "     |  __unicode__ = __str__(self, /)\n",
      "     |  \n",
      "     |  abspath(self, fileid)\n",
      "     |      Return the absolute path for the given file.\n",
      "     |      \n",
      "     |      :type fileid: str\n",
      "     |      :param fileid: The file identifier for the file whose path\n",
      "     |          should be returned.\n",
      "     |      :rtype: PathPointer\n",
      "     |  \n",
      "     |  abspaths(self, fileids=None, include_encoding=False, include_fileid=False)\n",
      "     |      Return a list of the absolute paths for all fileids in this corpus;\n",
      "     |      or for the given list of fileids, if specified.\n",
      "     |      \n",
      "     |      :type fileids: None or str or list\n",
      "     |      :param fileids: Specifies the set of fileids for which paths should\n",
      "     |          be returned.  Can be None, for all fileids; a list of\n",
      "     |          file identifiers, for a specified set of fileids; or a single\n",
      "     |          file identifier, for a single file.  Note that the return\n",
      "     |          value is always a list of paths, even if ``fileids`` is a\n",
      "     |          single file identifier.\n",
      "     |      \n",
      "     |      :param include_encoding: If true, then return a list of\n",
      "     |          ``(path_pointer, encoding)`` tuples.\n",
      "     |      \n",
      "     |      :rtype: list(PathPointer)\n",
      "     |  \n",
      "     |  citation(self)\n",
      "     |      Return the contents of the corpus citation.bib file, if it exists.\n",
      "     |  \n",
      "     |  encoding(self, file)\n",
      "     |      Return the unicode encoding for the given corpus file, if known.\n",
      "     |      If the encoding is unknown, or if the given file should be\n",
      "     |      processed using byte strings (str), then return None.\n",
      "     |  \n",
      "     |  ensure_loaded(self)\n",
      "     |      Load this corpus (if it has not already been loaded).  This is\n",
      "     |      used by LazyCorpusLoader as a simple method that can be used to\n",
      "     |      make sure a corpus is loaded -- e.g., in case a user wants to\n",
      "     |      do help(some_corpus).\n",
      "     |  \n",
      "     |  fileids(self)\n",
      "     |      Return a list of file identifiers for the fileids that make up\n",
      "     |      this corpus.\n",
      "     |  \n",
      "     |  license(self)\n",
      "     |      Return the contents of the corpus LICENSE file, if it exists.\n",
      "     |  \n",
      "     |  open(self, file)\n",
      "     |      Return an open stream that can be used to read the given file.\n",
      "     |      If the file's encoding is not None, then the stream will\n",
      "     |      automatically decode the file's contents into unicode.\n",
      "     |      \n",
      "     |      :param file: The file identifier of the file to read.\n",
      "     |  \n",
      "     |  readme(self)\n",
      "     |      Return the contents of the corpus README file, if it exists.\n",
      "     |  \n",
      "     |  unicode_repr = __repr__(self)\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Data descriptors inherited from nltk.corpus.reader.api.CorpusReader:\n",
      "     |  \n",
      "     |  __dict__\n",
      "     |      dictionary for instance variables (if defined)\n",
      "     |  \n",
      "     |  __weakref__\n",
      "     |      list of weak references to the object (if defined)\n",
      "     |  \n",
      "     |  root\n",
      "     |      The directory where this corpus is stored.\n",
      "     |      \n",
      "     |      :type: PathPointer\n",
      "    \n",
      "    class DependencyCorpusReader(nltk.corpus.reader.api.SyntaxCorpusReader)\n",
      "     |  DependencyCorpusReader(root, fileids, encoding='utf8', word_tokenizer=<nltk.tokenize.simple.TabTokenizer object at 0x000001F4CEDF6348>, sent_tokenizer=RegexpTokenizer(pattern='\\n', gaps=True, discard_empty=True, flags=<RegexFlag.UNICODE|DOTALL|MULTILINE: 56>), para_block_reader=<function read_blankline_block at 0x000001F4CED359D8>)\n",
      "     |  \n",
      "     |  An abstract base class for reading corpora consisting of\n",
      "     |  syntactically parsed text.  Subclasses should define:\n",
      "     |  \n",
      "     |    - ``__init__``, which specifies the location of the corpus\n",
      "     |      and a method for detecting the sentence blocks in corpus files.\n",
      "     |    - ``_read_block``, which reads a block from the input stream.\n",
      "     |    - ``_word``, which takes a block and returns a list of list of words.\n",
      "     |    - ``_tag``, which takes a block and returns a list of list of tagged\n",
      "     |      words.\n",
      "     |    - ``_parse``, which takes a block and returns a list of parsed\n",
      "     |      sentences.\n",
      "     |  \n",
      "     |  Method resolution order:\n",
      "     |      DependencyCorpusReader\n",
      "     |      nltk.corpus.reader.api.SyntaxCorpusReader\n",
      "     |      nltk.corpus.reader.api.CorpusReader\n",
      "     |      builtins.object\n",
      "     |  \n",
      "     |  Methods defined here:\n",
      "     |  \n",
      "     |  __init__(self, root, fileids, encoding='utf8', word_tokenizer=<nltk.tokenize.simple.TabTokenizer object at 0x000001F4CEDF6348>, sent_tokenizer=RegexpTokenizer(pattern='\\n', gaps=True, discard_empty=True, flags=<RegexFlag.UNICODE|DOTALL|MULTILINE: 56>), para_block_reader=<function read_blankline_block at 0x000001F4CED359D8>)\n",
      "     |      :type root: PathPointer or str\n",
      "     |      :param root: A path pointer identifying the root directory for\n",
      "     |          this corpus.  If a string is specified, then it will be\n",
      "     |          converted to a ``PathPointer`` automatically.\n",
      "     |      :param fileids: A list of the files that make up this corpus.\n",
      "     |          This list can either be specified explicitly, as a list of\n",
      "     |          strings; or implicitly, as a regular expression over file\n",
      "     |          paths.  The absolute path for each file will be constructed\n",
      "     |          by joining the reader's root to each file name.\n",
      "     |      :param encoding: The default unicode encoding for the files\n",
      "     |          that make up the corpus.  The value of ``encoding`` can be any\n",
      "     |          of the following:\n",
      "     |          - A string: ``encoding`` is the encoding name for all files.\n",
      "     |          - A dictionary: ``encoding[file_id]`` is the encoding\n",
      "     |            name for the file whose identifier is ``file_id``.  If\n",
      "     |            ``file_id`` is not in ``encoding``, then the file\n",
      "     |            contents will be processed using non-unicode byte strings.\n",
      "     |          - A list: ``encoding`` should be a list of ``(regexp, encoding)``\n",
      "     |            tuples.  The encoding for a file whose identifier is ``file_id``\n",
      "     |            will be the ``encoding`` value for the first tuple whose\n",
      "     |            ``regexp`` matches the ``file_id``.  If no tuple's ``regexp``\n",
      "     |            matches the ``file_id``, the file contents will be processed\n",
      "     |            using non-unicode byte strings.\n",
      "     |          - None: the file contents of all files will be\n",
      "     |            processed using non-unicode byte strings.\n",
      "     |      :param tagset: The name of the tagset used by this corpus, to be used\n",
      "     |            for normalizing or converting the POS tags returned by the\n",
      "     |            tagged_...() methods.\n",
      "     |  \n",
      "     |  parsed_sents(self, fileids=None)\n",
      "     |  \n",
      "     |  raw(self, fileids=None)\n",
      "     |      :return: the given file(s) as a single string.\n",
      "     |      :rtype: str\n",
      "     |  \n",
      "     |  sents(self, fileids=None)\n",
      "     |  \n",
      "     |  tagged_sents(self, fileids=None)\n",
      "     |  \n",
      "     |  tagged_words(self, fileids=None)\n",
      "     |  \n",
      "     |  words(self, fileids=None)\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Methods inherited from nltk.corpus.reader.api.CorpusReader:\n",
      "     |  \n",
      "     |  __repr__(self)\n",
      "     |      Return repr(self).\n",
      "     |  \n",
      "     |  __unicode__ = __str__(self, /)\n",
      "     |  \n",
      "     |  abspath(self, fileid)\n",
      "     |      Return the absolute path for the given file.\n",
      "     |      \n",
      "     |      :type fileid: str\n",
      "     |      :param fileid: The file identifier for the file whose path\n",
      "     |          should be returned.\n",
      "     |      :rtype: PathPointer\n",
      "     |  \n",
      "     |  abspaths(self, fileids=None, include_encoding=False, include_fileid=False)\n",
      "     |      Return a list of the absolute paths for all fileids in this corpus;\n",
      "     |      or for the given list of fileids, if specified.\n",
      "     |      \n",
      "     |      :type fileids: None or str or list\n",
      "     |      :param fileids: Specifies the set of fileids for which paths should\n",
      "     |          be returned.  Can be None, for all fileids; a list of\n",
      "     |          file identifiers, for a specified set of fileids; or a single\n",
      "     |          file identifier, for a single file.  Note that the return\n",
      "     |          value is always a list of paths, even if ``fileids`` is a\n",
      "     |          single file identifier.\n",
      "     |      \n",
      "     |      :param include_encoding: If true, then return a list of\n",
      "     |          ``(path_pointer, encoding)`` tuples.\n",
      "     |      \n",
      "     |      :rtype: list(PathPointer)\n",
      "     |  \n",
      "     |  citation(self)\n",
      "     |      Return the contents of the corpus citation.bib file, if it exists.\n",
      "     |  \n",
      "     |  encoding(self, file)\n",
      "     |      Return the unicode encoding for the given corpus file, if known.\n",
      "     |      If the encoding is unknown, or if the given file should be\n",
      "     |      processed using byte strings (str), then return None.\n",
      "     |  \n",
      "     |  ensure_loaded(self)\n",
      "     |      Load this corpus (if it has not already been loaded).  This is\n",
      "     |      used by LazyCorpusLoader as a simple method that can be used to\n",
      "     |      make sure a corpus is loaded -- e.g., in case a user wants to\n",
      "     |      do help(some_corpus).\n",
      "     |  \n",
      "     |  fileids(self)\n",
      "     |      Return a list of file identifiers for the fileids that make up\n",
      "     |      this corpus.\n",
      "     |  \n",
      "     |  license(self)\n",
      "     |      Return the contents of the corpus LICENSE file, if it exists.\n",
      "     |  \n",
      "     |  open(self, file)\n",
      "     |      Return an open stream that can be used to read the given file.\n",
      "     |      If the file's encoding is not None, then the stream will\n",
      "     |      automatically decode the file's contents into unicode.\n",
      "     |      \n",
      "     |      :param file: The file identifier of the file to read.\n",
      "     |  \n",
      "     |  readme(self)\n",
      "     |      Return the contents of the corpus README file, if it exists.\n",
      "     |  \n",
      "     |  unicode_repr = __repr__(self)\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Data descriptors inherited from nltk.corpus.reader.api.CorpusReader:\n",
      "     |  \n",
      "     |  __dict__\n",
      "     |      dictionary for instance variables (if defined)\n",
      "     |  \n",
      "     |  __weakref__\n",
      "     |      list of weak references to the object (if defined)\n",
      "     |  \n",
      "     |  root\n",
      "     |      The directory where this corpus is stored.\n",
      "     |      \n",
      "     |      :type: PathPointer\n",
      "    \n",
      "    class EuroparlCorpusReader(PlaintextCorpusReader)\n",
      "     |  EuroparlCorpusReader(root, fileids, word_tokenizer=WordPunctTokenizer(pattern='\\\\w+|[^\\\\w\\\\s]+', gaps=False, discard_empty=True, flags=<RegexFlag.UNICODE|DOTALL|MULTILINE: 56>), sent_tokenizer=<nltk.tokenize.punkt.PunktSentenceTokenizer object at 0x000001F4CED298C8>, para_block_reader=<function read_blankline_block at 0x000001F4CED359D8>, encoding='utf8')\n",
      "     |  \n",
      "     |  Reader for Europarl corpora that consist of plaintext documents.\n",
      "     |  Documents are divided into chapters instead of paragraphs as\n",
      "     |  for regular plaintext documents. Chapters are separated using blank\n",
      "     |  lines. Everything is inherited from ``PlaintextCorpusReader`` except\n",
      "     |  that:\n",
      "     |    - Since the corpus is pre-processed and pre-tokenized, the\n",
      "     |      word tokenizer should just split the line at whitespaces.\n",
      "     |    - For the same reason, the sentence tokenizer should just\n",
      "     |      split the paragraph at line breaks.\n",
      "     |    - There is a new 'chapters()' method that returns chapters instead\n",
      "     |      instead of paragraphs.\n",
      "     |    - The 'paras()' method inherited from PlaintextCorpusReader is\n",
      "     |      made non-functional to remove any confusion between chapters\n",
      "     |      and paragraphs for Europarl.\n",
      "     |  \n",
      "     |  Method resolution order:\n",
      "     |      EuroparlCorpusReader\n",
      "     |      PlaintextCorpusReader\n",
      "     |      nltk.corpus.reader.api.CorpusReader\n",
      "     |      builtins.object\n",
      "     |  \n",
      "     |  Methods defined here:\n",
      "     |  \n",
      "     |  chapters(self, fileids=None)\n",
      "     |      :return: the given file(s) as a list of\n",
      "     |          chapters, each encoded as a list of sentences, which are\n",
      "     |          in turn encoded as lists of word strings.\n",
      "     |      :rtype: list(list(list(str)))\n",
      "     |  \n",
      "     |  paras(self, fileids=None)\n",
      "     |      :return: the given file(s) as a list of\n",
      "     |          paragraphs, each encoded as a list of sentences, which are\n",
      "     |          in turn encoded as lists of word strings.\n",
      "     |      :rtype: list(list(list(str)))\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Methods inherited from PlaintextCorpusReader:\n",
      "     |  \n",
      "     |  __init__(self, root, fileids, word_tokenizer=WordPunctTokenizer(pattern='\\\\w+|[^\\\\w\\\\s]+', gaps=False, discard_empty=True, flags=<RegexFlag.UNICODE|DOTALL|MULTILINE: 56>), sent_tokenizer=<nltk.tokenize.punkt.PunktSentenceTokenizer object at 0x000001F4CED298C8>, para_block_reader=<function read_blankline_block at 0x000001F4CED359D8>, encoding='utf8')\n",
      "     |      Construct a new plaintext corpus reader for a set of documents\n",
      "     |      located at the given root directory.  Example usage:\n",
      "     |      \n",
      "     |          >>> root = '/usr/local/share/nltk_data/corpora/webtext/'\n",
      "     |          >>> reader = PlaintextCorpusReader(root, '.*\\.txt') # doctest: +SKIP\n",
      "     |      \n",
      "     |      :param root: The root directory for this corpus.\n",
      "     |      :param fileids: A list or regexp specifying the fileids in this corpus.\n",
      "     |      :param word_tokenizer: Tokenizer for breaking sentences or\n",
      "     |          paragraphs into words.\n",
      "     |      :param sent_tokenizer: Tokenizer for breaking paragraphs\n",
      "     |          into words.\n",
      "     |      :param para_block_reader: The block reader used to divide the\n",
      "     |          corpus into paragraph blocks.\n",
      "     |  \n",
      "     |  raw(self, fileids=None)\n",
      "     |      :return: the given file(s) as a single string.\n",
      "     |      :rtype: str\n",
      "     |  \n",
      "     |  sents(self, fileids=None)\n",
      "     |      :return: the given file(s) as a list of\n",
      "     |          sentences or utterances, each encoded as a list of word\n",
      "     |          strings.\n",
      "     |      :rtype: list(list(str))\n",
      "     |  \n",
      "     |  words(self, fileids=None)\n",
      "     |      :return: the given file(s) as a list of words\n",
      "     |          and punctuation symbols.\n",
      "     |      :rtype: list(str)\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Data and other attributes inherited from PlaintextCorpusReader:\n",
      "     |  \n",
      "     |  CorpusView = <class 'nltk.corpus.reader.util.StreamBackedCorpusView'>\n",
      "     |      A 'view' of a corpus file, which acts like a sequence of tokens:\n",
      "     |      it can be accessed by index, iterated over, etc.  However, the\n",
      "     |      tokens are only constructed as-needed -- the entire corpus is\n",
      "     |      never stored in memory at once.\n",
      "     |      \n",
      "     |      The constructor to ``StreamBackedCorpusView`` takes two arguments:\n",
      "     |      a corpus fileid (specified as a string or as a ``PathPointer``);\n",
      "     |      and a block reader.  A \"block reader\" is a function that reads\n",
      "     |      zero or more tokens from a stream, and returns them as a list.  A\n",
      "     |      very simple example of a block reader is:\n",
      "     |      \n",
      "     |          >>> def simple_block_reader(stream):\n",
      "     |          ...     return stream.readline().split()\n",
      "     |      \n",
      "     |      This simple block reader reads a single line at a time, and\n",
      "     |      returns a single token (consisting of a string) for each\n",
      "     |      whitespace-separated substring on the line.\n",
      "     |      \n",
      "     |      When deciding how to define the block reader for a given\n",
      "     |      corpus, careful consideration should be given to the size of\n",
      "     |      blocks handled by the block reader.  Smaller block sizes will\n",
      "     |      increase the memory requirements of the corpus view's internal\n",
      "     |      data structures (by 2 integers per block).  On the other hand,\n",
      "     |      larger block sizes may decrease performance for random access to\n",
      "     |      the corpus.  (But note that larger block sizes will *not*\n",
      "     |      decrease performance for iteration.)\n",
      "     |      \n",
      "     |      Internally, ``CorpusView`` maintains a partial mapping from token\n",
      "     |      index to file position, with one entry per block.  When a token\n",
      "     |      with a given index *i* is requested, the ``CorpusView`` constructs\n",
      "     |      it as follows:\n",
      "     |      \n",
      "     |        1. First, it searches the toknum/filepos mapping for the token\n",
      "     |           index closest to (but less than or equal to) *i*.\n",
      "     |      \n",
      "     |        2. Then, starting at the file position corresponding to that\n",
      "     |           index, it reads one block at a time using the block reader\n",
      "     |           until it reaches the requested token.\n",
      "     |      \n",
      "     |      The toknum/filepos mapping is created lazily: it is initially\n",
      "     |      empty, but every time a new block is read, the block's\n",
      "     |      initial token is added to the mapping.  (Thus, the toknum/filepos\n",
      "     |      map has one entry per block.)\n",
      "     |      \n",
      "     |      In order to increase efficiency for random access patterns that\n",
      "     |      have high degrees of locality, the corpus view may cache one or\n",
      "     |      more blocks.\n",
      "     |      \n",
      "     |      :note: Each ``CorpusView`` object internally maintains an open file\n",
      "     |          object for its underlying corpus file.  This file should be\n",
      "     |          automatically closed when the ``CorpusView`` is garbage collected,\n",
      "     |          but if you wish to close it manually, use the ``close()``\n",
      "     |          method.  If you access a ``CorpusView``'s items after it has been\n",
      "     |          closed, the file object will be automatically re-opened.\n",
      "     |      \n",
      "     |      :warning: If the contents of the file are modified during the\n",
      "     |          lifetime of the ``CorpusView``, then the ``CorpusView``'s behavior\n",
      "     |          is undefined.\n",
      "     |      \n",
      "     |      :warning: If a unicode encoding is specified when constructing a\n",
      "     |          ``CorpusView``, then the block reader may only call\n",
      "     |          ``stream.seek()`` with offsets that have been returned by\n",
      "     |          ``stream.tell()``; in particular, calling ``stream.seek()`` with\n",
      "     |          relative offsets, or with offsets based on string lengths, may\n",
      "     |          lead to incorrect behavior.\n",
      "     |      \n",
      "     |      :ivar _block_reader: The function used to read\n",
      "     |          a single block from the underlying file stream.\n",
      "     |      :ivar _toknum: A list containing the token index of each block\n",
      "     |          that has been processed.  In particular, ``_toknum[i]`` is the\n",
      "     |          token index of the first token in block ``i``.  Together\n",
      "     |          with ``_filepos``, this forms a partial mapping between token\n",
      "     |          indices and file positions.\n",
      "     |      :ivar _filepos: A list containing the file position of each block\n",
      "     |          that has been processed.  In particular, ``_toknum[i]`` is the\n",
      "     |          file position of the first character in block ``i``.  Together\n",
      "     |          with ``_toknum``, this forms a partial mapping between token\n",
      "     |          indices and file positions.\n",
      "     |      :ivar _stream: The stream used to access the underlying corpus file.\n",
      "     |      :ivar _len: The total number of tokens in the corpus, if known;\n",
      "     |          or None, if the number of tokens is not yet known.\n",
      "     |      :ivar _eofpos: The character position of the last character in the\n",
      "     |          file.  This is calculated when the corpus view is initialized,\n",
      "     |          and is used to decide when the end of file has been reached.\n",
      "     |      :ivar _cache: A cache of the most recently read block.  It\n",
      "     |         is encoded as a tuple (start_toknum, end_toknum, tokens), where\n",
      "     |         start_toknum is the token index of the first token in the block;\n",
      "     |         end_toknum is the token index of the first token not in the\n",
      "     |         block; and tokens is a list of the tokens in the block.\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Methods inherited from nltk.corpus.reader.api.CorpusReader:\n",
      "     |  \n",
      "     |  __repr__(self)\n",
      "     |      Return repr(self).\n",
      "     |  \n",
      "     |  __unicode__ = __str__(self, /)\n",
      "     |  \n",
      "     |  abspath(self, fileid)\n",
      "     |      Return the absolute path for the given file.\n",
      "     |      \n",
      "     |      :type fileid: str\n",
      "     |      :param fileid: The file identifier for the file whose path\n",
      "     |          should be returned.\n",
      "     |      :rtype: PathPointer\n",
      "     |  \n",
      "     |  abspaths(self, fileids=None, include_encoding=False, include_fileid=False)\n",
      "     |      Return a list of the absolute paths for all fileids in this corpus;\n",
      "     |      or for the given list of fileids, if specified.\n",
      "     |      \n",
      "     |      :type fileids: None or str or list\n",
      "     |      :param fileids: Specifies the set of fileids for which paths should\n",
      "     |          be returned.  Can be None, for all fileids; a list of\n",
      "     |          file identifiers, for a specified set of fileids; or a single\n",
      "     |          file identifier, for a single file.  Note that the return\n",
      "     |          value is always a list of paths, even if ``fileids`` is a\n",
      "     |          single file identifier.\n",
      "     |      \n",
      "     |      :param include_encoding: If true, then return a list of\n",
      "     |          ``(path_pointer, encoding)`` tuples.\n",
      "     |      \n",
      "     |      :rtype: list(PathPointer)\n",
      "     |  \n",
      "     |  citation(self)\n",
      "     |      Return the contents of the corpus citation.bib file, if it exists.\n",
      "     |  \n",
      "     |  encoding(self, file)\n",
      "     |      Return the unicode encoding for the given corpus file, if known.\n",
      "     |      If the encoding is unknown, or if the given file should be\n",
      "     |      processed using byte strings (str), then return None.\n",
      "     |  \n",
      "     |  ensure_loaded(self)\n",
      "     |      Load this corpus (if it has not already been loaded).  This is\n",
      "     |      used by LazyCorpusLoader as a simple method that can be used to\n",
      "     |      make sure a corpus is loaded -- e.g., in case a user wants to\n",
      "     |      do help(some_corpus).\n",
      "     |  \n",
      "     |  fileids(self)\n",
      "     |      Return a list of file identifiers for the fileids that make up\n",
      "     |      this corpus.\n",
      "     |  \n",
      "     |  license(self)\n",
      "     |      Return the contents of the corpus LICENSE file, if it exists.\n",
      "     |  \n",
      "     |  open(self, file)\n",
      "     |      Return an open stream that can be used to read the given file.\n",
      "     |      If the file's encoding is not None, then the stream will\n",
      "     |      automatically decode the file's contents into unicode.\n",
      "     |      \n",
      "     |      :param file: The file identifier of the file to read.\n",
      "     |  \n",
      "     |  readme(self)\n",
      "     |      Return the contents of the corpus README file, if it exists.\n",
      "     |  \n",
      "     |  unicode_repr = __repr__(self)\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Data descriptors inherited from nltk.corpus.reader.api.CorpusReader:\n",
      "     |  \n",
      "     |  __dict__\n",
      "     |      dictionary for instance variables (if defined)\n",
      "     |  \n",
      "     |  __weakref__\n",
      "     |      list of weak references to the object (if defined)\n",
      "     |  \n",
      "     |  root\n",
      "     |      The directory where this corpus is stored.\n",
      "     |      \n",
      "     |      :type: PathPointer\n",
      "    \n",
      "    class FramenetCorpusReader(nltk.corpus.reader.xmldocs.XMLCorpusReader)\n",
      "     |  FramenetCorpusReader(root, fileids)\n",
      "     |  \n",
      "     |  A corpus reader for the Framenet Corpus.\n",
      "     |  \n",
      "     |  >>> from nltk.corpus import framenet as fn\n",
      "     |  >>> fn.lu(3238).frame.lexUnit['glint.v'] is fn.lu(3238)\n",
      "     |  True\n",
      "     |  >>> fn.frame_by_name('Replacing') is fn.lus('replace.v')[0].frame\n",
      "     |  True\n",
      "     |  >>> fn.lus('prejudice.n')[0].frame.frameRelations == fn.frame_relations('Partiality')\n",
      "     |  True\n",
      "     |  \n",
      "     |  Method resolution order:\n",
      "     |      FramenetCorpusReader\n",
      "     |      nltk.corpus.reader.xmldocs.XMLCorpusReader\n",
      "     |      nltk.corpus.reader.api.CorpusReader\n",
      "     |      builtins.object\n",
      "     |  \n",
      "     |  Methods defined here:\n",
      "     |  \n",
      "     |  __init__(self, root, fileids)\n",
      "     |      :type root: PathPointer or str\n",
      "     |      :param root: A path pointer identifying the root directory for\n",
      "     |          this corpus.  If a string is specified, then it will be\n",
      "     |          converted to a ``PathPointer`` automatically.\n",
      "     |      :param fileids: A list of the files that make up this corpus.\n",
      "     |          This list can either be specified explicitly, as a list of\n",
      "     |          strings; or implicitly, as a regular expression over file\n",
      "     |          paths.  The absolute path for each file will be constructed\n",
      "     |          by joining the reader's root to each file name.\n",
      "     |      :param encoding: The default unicode encoding for the files\n",
      "     |          that make up the corpus.  The value of ``encoding`` can be any\n",
      "     |          of the following:\n",
      "     |          - A string: ``encoding`` is the encoding name for all files.\n",
      "     |          - A dictionary: ``encoding[file_id]`` is the encoding\n",
      "     |            name for the file whose identifier is ``file_id``.  If\n",
      "     |            ``file_id`` is not in ``encoding``, then the file\n",
      "     |            contents will be processed using non-unicode byte strings.\n",
      "     |          - A list: ``encoding`` should be a list of ``(regexp, encoding)``\n",
      "     |            tuples.  The encoding for a file whose identifier is ``file_id``\n",
      "     |            will be the ``encoding`` value for the first tuple whose\n",
      "     |            ``regexp`` matches the ``file_id``.  If no tuple's ``regexp``\n",
      "     |            matches the ``file_id``, the file contents will be processed\n",
      "     |            using non-unicode byte strings.\n",
      "     |          - None: the file contents of all files will be\n",
      "     |            processed using non-unicode byte strings.\n",
      "     |      :param tagset: The name of the tagset used by this corpus, to be used\n",
      "     |            for normalizing or converting the POS tags returned by the\n",
      "     |            tagged_...() methods.\n",
      "     |  \n",
      "     |  annotations(self, luNamePattern=None, exemplars=True, full_text=True)\n",
      "     |      Frame annotation sets matching the specified criteria.\n",
      "     |  \n",
      "     |  buildindexes(self)\n",
      "     |      Build the internal indexes to make look-ups faster.\n",
      "     |  \n",
      "     |  doc(self, fn_docid)\n",
      "     |      Returns the annotated document whose id number is\n",
      "     |      ``fn_docid``. This id number can be obtained by calling the\n",
      "     |      Documents() function.\n",
      "     |      \n",
      "     |      The dict that is returned from this function will contain the\n",
      "     |      following keys:\n",
      "     |      \n",
      "     |      - '_type'      : 'fulltextannotation'\n",
      "     |      - 'sentence'   : a list of sentences in the document\n",
      "     |         - Each item in the list is a dict containing the following keys:\n",
      "     |            - 'ID'    : the ID number of the sentence\n",
      "     |            - '_type' : 'sentence'\n",
      "     |            - 'text'  : the text of the sentence\n",
      "     |            - 'paragNo' : the paragraph number\n",
      "     |            - 'sentNo'  : the sentence number\n",
      "     |            - 'docID'   : the document ID number\n",
      "     |            - 'corpID'  : the corpus ID number\n",
      "     |            - 'aPos'    : the annotation position\n",
      "     |            - 'annotationSet' : a list of annotation layers for the sentence\n",
      "     |               - Each item in the list is a dict containing the following keys:\n",
      "     |                  - 'ID'       : the ID number of the annotation set\n",
      "     |                  - '_type'    : 'annotationset'\n",
      "     |                  - 'status'   : either 'MANUAL' or 'UNANN'\n",
      "     |                  - 'luName'   : (only if status is 'MANUAL')\n",
      "     |                  - 'luID'     : (only if status is 'MANUAL')\n",
      "     |                  - 'frameID'  : (only if status is 'MANUAL')\n",
      "     |                  - 'frameName': (only if status is 'MANUAL')\n",
      "     |                  - 'layer' : a list of labels for the layer\n",
      "     |                     - Each item in the layer is a dict containing the\n",
      "     |                       following keys:\n",
      "     |                        - '_type': 'layer'\n",
      "     |                        - 'rank'\n",
      "     |                        - 'name'\n",
      "     |                        - 'label' : a list of labels in the layer\n",
      "     |                           - Each item is a dict containing the following keys:\n",
      "     |                              - 'start'\n",
      "     |                              - 'end'\n",
      "     |                              - 'name'\n",
      "     |                              - 'feID' (optional)\n",
      "     |      \n",
      "     |      :param fn_docid: The Framenet id number of the document\n",
      "     |      :type fn_docid: int\n",
      "     |      :return: Information about the annotated document\n",
      "     |      :rtype: dict\n",
      "     |  \n",
      "     |  docs(self, name=None)\n",
      "     |      Return a list of the annotated full-text documents in FrameNet,\n",
      "     |      optionally filtered by a regex to be matched against the document name.\n",
      "     |  \n",
      "     |  docs_metadata(self, name=None)\n",
      "     |      Return an index of the annotated documents in Framenet.\n",
      "     |      \n",
      "     |      Details for a specific annotated document can be obtained using this\n",
      "     |      class's doc() function and pass it the value of the 'ID' field.\n",
      "     |      \n",
      "     |      >>> from nltk.corpus import framenet as fn\n",
      "     |      >>> len(fn.docs()) in (78, 107) # FN 1.5 and 1.7, resp.\n",
      "     |      True\n",
      "     |      >>> set([x.corpname for x in fn.docs_metadata()])>=set(['ANC', 'KBEval',                     'LUCorpus-v0.3', 'Miscellaneous', 'NTI', 'PropBank'])\n",
      "     |      True\n",
      "     |      \n",
      "     |      :param name: A regular expression pattern used to search the\n",
      "     |          file name of each annotated document. The document's\n",
      "     |          file name contains the name of the corpus that the\n",
      "     |          document is from, followed by two underscores \"__\"\n",
      "     |          followed by the document name. So, for example, the\n",
      "     |          file name \"LUCorpus-v0.3__20000410_nyt-NEW.xml\" is\n",
      "     |          from the corpus named \"LUCorpus-v0.3\" and the\n",
      "     |          document name is \"20000410_nyt-NEW.xml\".\n",
      "     |      :type name: str\n",
      "     |      :return: A list of selected (or all) annotated documents\n",
      "     |      :rtype: list of dicts, where each dict object contains the following\n",
      "     |              keys:\n",
      "     |      \n",
      "     |              - 'name'\n",
      "     |              - 'ID'\n",
      "     |              - 'corpid'\n",
      "     |              - 'corpname'\n",
      "     |              - 'description'\n",
      "     |              - 'filename'\n",
      "     |  \n",
      "     |  exemplars(self, luNamePattern=None, frame=None, fe=None, fe2=None)\n",
      "     |      Lexicographic exemplar sentences, optionally filtered by LU name and/or 1-2 FEs that\n",
      "     |      are realized overtly. 'frame' may be a name pattern, frame ID, or frame instance.\n",
      "     |      'fe' may be a name pattern or FE instance; if specified, 'fe2' may also\n",
      "     |      be specified to retrieve sentences with both overt FEs (in either order).\n",
      "     |  \n",
      "     |  fe_relations(self)\n",
      "     |      Obtain a list of frame element relations.\n",
      "     |      \n",
      "     |      >>> from nltk.corpus import framenet as fn\n",
      "     |      >>> ferels = fn.fe_relations()\n",
      "     |      >>> isinstance(ferels, list)\n",
      "     |      True\n",
      "     |      >>> len(ferels) in (10020, 12393)   # FN 1.5 and 1.7, resp.\n",
      "     |      True\n",
      "     |      >>> PrettyDict(ferels[0], breakLines=True)\n",
      "     |      {'ID': 14642,\n",
      "     |      '_type': 'ferelation',\n",
      "     |      'frameRelation': <Parent=Abounding_with -- Inheritance -> Child=Lively_place>,\n",
      "     |      'subFE': <fe ID=11370 name=Degree>,\n",
      "     |      'subFEName': 'Degree',\n",
      "     |      'subFrame': <frame ID=1904 name=Lively_place>,\n",
      "     |      'subID': 11370,\n",
      "     |      'supID': 2271,\n",
      "     |      'superFE': <fe ID=2271 name=Degree>,\n",
      "     |      'superFEName': 'Degree',\n",
      "     |      'superFrame': <frame ID=262 name=Abounding_with>,\n",
      "     |      'type': <framerelationtype ID=1 name=Inheritance>}\n",
      "     |      \n",
      "     |      :return: A list of all of the frame element relations in framenet\n",
      "     |      :rtype: list(dict)\n",
      "     |  \n",
      "     |  fes(self, name=None, frame=None)\n",
      "     |      Lists frame element objects. If 'name' is provided, this is treated as\n",
      "     |      a case-insensitive regular expression to filter by frame name.\n",
      "     |      (Case-insensitivity is because casing of frame element names is not always\n",
      "     |      consistent across frames.) Specify 'frame' to filter by a frame name pattern,\n",
      "     |      ID, or object.\n",
      "     |      \n",
      "     |      >>> from nltk.corpus import framenet as fn\n",
      "     |      >>> fn.fes('Noise_maker')\n",
      "     |      [<fe ID=6043 name=Noise_maker>]\n",
      "     |      >>> sorted([(fe.frame.name,fe.name) for fe in fn.fes('sound')])\n",
      "     |      [('Cause_to_make_noise', 'Sound_maker'), ('Make_noise', 'Sound'),\n",
      "     |       ('Make_noise', 'Sound_source'), ('Sound_movement', 'Location_of_sound_source'),\n",
      "     |       ('Sound_movement', 'Sound'), ('Sound_movement', 'Sound_source'),\n",
      "     |       ('Sounds', 'Component_sound'), ('Sounds', 'Location_of_sound_source'),\n",
      "     |       ('Sounds', 'Sound_source'), ('Vocalizations', 'Location_of_sound_source'),\n",
      "     |       ('Vocalizations', 'Sound_source')]\n",
      "     |      >>> sorted([(fe.frame.name,fe.name) for fe in fn.fes('sound',r'(?i)make_noise')])\n",
      "     |      [('Cause_to_make_noise', 'Sound_maker'),\n",
      "     |       ('Make_noise', 'Sound'),\n",
      "     |       ('Make_noise', 'Sound_source')]\n",
      "     |      >>> sorted(set(fe.name for fe in fn.fes('^sound')))\n",
      "     |      ['Sound', 'Sound_maker', 'Sound_source']\n",
      "     |      >>> len(fn.fes('^sound$'))\n",
      "     |      2\n",
      "     |      \n",
      "     |      :param name: A regular expression pattern used to match against\n",
      "     |          frame element names. If 'name' is None, then a list of all\n",
      "     |          frame elements will be returned.\n",
      "     |      :type name: str\n",
      "     |      :return: A list of matching frame elements\n",
      "     |      :rtype: list(AttrDict)\n",
      "     |  \n",
      "     |  frame(self, fn_fid_or_fname, ignorekeys=[])\n",
      "     |      Get the details for the specified Frame using the frame's name\n",
      "     |      or id number.\n",
      "     |      \n",
      "     |      Usage examples:\n",
      "     |      \n",
      "     |      >>> from nltk.corpus import framenet as fn\n",
      "     |      >>> f = fn.frame(256)\n",
      "     |      >>> f.name\n",
      "     |      'Medical_specialties'\n",
      "     |      >>> f = fn.frame('Medical_specialties')\n",
      "     |      >>> f.ID\n",
      "     |      256\n",
      "     |      >>> # ensure non-ASCII character in definition doesn't trigger an encoding error:\n",
      "     |      >>> fn.frame('Imposing_obligation')\n",
      "     |      frame (1494): Imposing_obligation...\n",
      "     |      \n",
      "     |      The dict that is returned from this function will contain the\n",
      "     |      following information about the Frame:\n",
      "     |      \n",
      "     |      - 'name'       : the name of the Frame (e.g. 'Birth', 'Apply_heat', etc.)\n",
      "     |      - 'definition' : textual definition of the Frame\n",
      "     |      - 'ID'         : the internal ID number of the Frame\n",
      "     |      - 'semTypes'   : a list of semantic types for this frame\n",
      "     |         - Each item in the list is a dict containing the following keys:\n",
      "     |            - 'name' : can be used with the semtype() function\n",
      "     |            - 'ID'   : can be used with the semtype() function\n",
      "     |      \n",
      "     |      - 'lexUnit'    : a dict containing all of the LUs for this frame.\n",
      "     |                       The keys in this dict are the names of the LUs and\n",
      "     |                       the value for each key is itself a dict containing\n",
      "     |                       info about the LU (see the lu() function for more info.)\n",
      "     |      \n",
      "     |      - 'FE' : a dict containing the Frame Elements that are part of this frame\n",
      "     |               The keys in this dict are the names of the FEs (e.g. 'Body_system')\n",
      "     |               and the values are dicts containing the following keys\n",
      "     |            - 'definition' : The definition of the FE\n",
      "     |            - 'name'       : The name of the FE e.g. 'Body_system'\n",
      "     |            - 'ID'         : The id number\n",
      "     |            - '_type'      : 'fe'\n",
      "     |            - 'abbrev'     : Abbreviation e.g. 'bod'\n",
      "     |            - 'coreType'   : one of \"Core\", \"Peripheral\", or \"Extra-Thematic\"\n",
      "     |            - 'semType'    : if not None, a dict with the following two keys:\n",
      "     |               - 'name' : name of the semantic type. can be used with\n",
      "     |                          the semtype() function\n",
      "     |               - 'ID'   : id number of the semantic type. can be used with\n",
      "     |                          the semtype() function\n",
      "     |            - 'requiresFE' : if not None, a dict with the following two keys:\n",
      "     |               - 'name' : the name of another FE in this frame\n",
      "     |               - 'ID'   : the id of the other FE in this frame\n",
      "     |            - 'excludesFE' : if not None, a dict with the following two keys:\n",
      "     |               - 'name' : the name of another FE in this frame\n",
      "     |               - 'ID'   : the id of the other FE in this frame\n",
      "     |      \n",
      "     |      - 'frameRelation'      : a list of objects describing frame relations\n",
      "     |      - 'FEcoreSets'  : a list of Frame Element core sets for this frame\n",
      "     |         - Each item in the list is a list of FE objects\n",
      "     |      \n",
      "     |      :param fn_fid_or_fname: The Framenet name or id number of the frame\n",
      "     |      :type fn_fid_or_fname: int or str\n",
      "     |      :param ignorekeys: The keys to ignore. These keys will not be\n",
      "     |          included in the output. (optional)\n",
      "     |      :type ignorekeys: list(str)\n",
      "     |      :return: Information about a frame\n",
      "     |      :rtype: dict\n",
      "     |  \n",
      "     |  frame_by_id(self, fn_fid, ignorekeys=[])\n",
      "     |      Get the details for the specified Frame using the frame's id\n",
      "     |      number.\n",
      "     |      \n",
      "     |      Usage examples:\n",
      "     |      \n",
      "     |      >>> from nltk.corpus import framenet as fn\n",
      "     |      >>> f = fn.frame_by_id(256)\n",
      "     |      >>> f.ID\n",
      "     |      256\n",
      "     |      >>> f.name\n",
      "     |      'Medical_specialties'\n",
      "     |      >>> f.definition\n",
      "     |      \"This frame includes words that name ...\"\n",
      "     |      \n",
      "     |      :param fn_fid: The Framenet id number of the frame\n",
      "     |      :type fn_fid: int\n",
      "     |      :param ignorekeys: The keys to ignore. These keys will not be\n",
      "     |          included in the output. (optional)\n",
      "     |      :type ignorekeys: list(str)\n",
      "     |      :return: Information about a frame\n",
      "     |      :rtype: dict\n",
      "     |      \n",
      "     |      Also see the ``frame()`` function for details about what is\n",
      "     |      contained in the dict that is returned.\n",
      "     |  \n",
      "     |  frame_by_name(self, fn_fname, ignorekeys=[], check_cache=True)\n",
      "     |      Get the details for the specified Frame using the frame's name.\n",
      "     |      \n",
      "     |      Usage examples:\n",
      "     |      \n",
      "     |      >>> from nltk.corpus import framenet as fn\n",
      "     |      >>> f = fn.frame_by_name('Medical_specialties')\n",
      "     |      >>> f.ID\n",
      "     |      256\n",
      "     |      >>> f.name\n",
      "     |      'Medical_specialties'\n",
      "     |      >>> f.definition\n",
      "     |      \"This frame includes words that name ...\"\n",
      "     |      \n",
      "     |      :param fn_fname: The name of the frame\n",
      "     |      :type fn_fname: str\n",
      "     |      :param ignorekeys: The keys to ignore. These keys will not be\n",
      "     |          included in the output. (optional)\n",
      "     |      :type ignorekeys: list(str)\n",
      "     |      :return: Information about a frame\n",
      "     |      :rtype: dict\n",
      "     |      \n",
      "     |      Also see the ``frame()`` function for details about what is\n",
      "     |      contained in the dict that is returned.\n",
      "     |  \n",
      "     |  frame_ids_and_names(self, name=None)\n",
      "     |      Uses the frame index, which is much faster than looking up each frame definition\n",
      "     |      if only the names and IDs are needed.\n",
      "     |  \n",
      "     |  frame_relation_types(self)\n",
      "     |      Obtain a list of frame relation types.\n",
      "     |      \n",
      "     |      >>> from nltk.corpus import framenet as fn\n",
      "     |      >>> frts = sorted(fn.frame_relation_types(), key=itemgetter('ID'))\n",
      "     |      >>> isinstance(frts, list)\n",
      "     |      True\n",
      "     |      >>> len(frts) in (9, 10)    # FN 1.5 and 1.7, resp.\n",
      "     |      True\n",
      "     |      >>> PrettyDict(frts[0], breakLines=True)\n",
      "     |      {'ID': 1,\n",
      "     |       '_type': 'framerelationtype',\n",
      "     |       'frameRelations': [<Parent=Event -- Inheritance -> Child=Change_of_consistency>, <Parent=Event -- Inheritance -> Child=Rotting>, ...],\n",
      "     |       'name': 'Inheritance',\n",
      "     |       'subFrameName': 'Child',\n",
      "     |       'superFrameName': 'Parent'}\n",
      "     |      \n",
      "     |      :return: A list of all of the frame relation types in framenet\n",
      "     |      :rtype: list(dict)\n",
      "     |  \n",
      "     |  frame_relations(self, frame=None, frame2=None, type=None)\n",
      "     |      :param frame: (optional) frame object, name, or ID; only relations involving\n",
      "     |      this frame will be returned\n",
      "     |      :param frame2: (optional; 'frame' must be a different frame) only show relations\n",
      "     |      between the two specified frames, in either direction\n",
      "     |      :param type: (optional) frame relation type (name or object); show only relations\n",
      "     |      of this type\n",
      "     |      :type frame: int or str or AttrDict\n",
      "     |      :return: A list of all of the frame relations in framenet\n",
      "     |      :rtype: list(dict)\n",
      "     |      \n",
      "     |      >>> from nltk.corpus import framenet as fn\n",
      "     |      >>> frels = fn.frame_relations()\n",
      "     |      >>> isinstance(frels, list)\n",
      "     |      True\n",
      "     |      >>> len(frels) in (1676, 2070)  # FN 1.5 and 1.7, resp.\n",
      "     |      True\n",
      "     |      >>> PrettyList(fn.frame_relations('Cooking_creation'), maxReprSize=0, breakLines=True)\n",
      "     |      [<Parent=Intentionally_create -- Inheritance -> Child=Cooking_creation>,\n",
      "     |       <Parent=Apply_heat -- Using -> Child=Cooking_creation>,\n",
      "     |       <MainEntry=Apply_heat -- See_also -> ReferringEntry=Cooking_creation>]\n",
      "     |      >>> PrettyList(fn.frame_relations(274), breakLines=True)\n",
      "     |      [<Parent=Avoiding -- Inheritance -> Child=Dodging>,\n",
      "     |       <Parent=Avoiding -- Inheritance -> Child=Evading>, ...]\n",
      "     |      >>> PrettyList(fn.frame_relations(fn.frame('Cooking_creation')), breakLines=True)\n",
      "     |      [<Parent=Intentionally_create -- Inheritance -> Child=Cooking_creation>,\n",
      "     |       <Parent=Apply_heat -- Using -> Child=Cooking_creation>, ...]\n",
      "     |      >>> PrettyList(fn.frame_relations('Cooking_creation', type='Inheritance'))\n",
      "     |      [<Parent=Intentionally_create -- Inheritance -> Child=Cooking_creation>]\n",
      "     |      >>> PrettyList(fn.frame_relations('Cooking_creation', 'Apply_heat'), breakLines=True)\n",
      "     |      [<Parent=Apply_heat -- Using -> Child=Cooking_creation>,\n",
      "     |      <MainEntry=Apply_heat -- See_also -> ReferringEntry=Cooking_creation>]\n",
      "     |  \n",
      "     |  frames(self, name=None)\n",
      "     |      Obtain details for a specific frame.\n",
      "     |      \n",
      "     |      >>> from nltk.corpus import framenet as fn\n",
      "     |      >>> len(fn.frames()) in (1019, 1221)    # FN 1.5 and 1.7, resp.\n",
      "     |      True\n",
      "     |      >>> x = PrettyList(fn.frames(r'(?i)crim'), maxReprSize=0, breakLines=True)\n",
      "     |      >>> x.sort(key=itemgetter('ID'))\n",
      "     |      >>> x\n",
      "     |      [<frame ID=200 name=Criminal_process>,\n",
      "     |       <frame ID=500 name=Criminal_investigation>,\n",
      "     |       <frame ID=692 name=Crime_scenario>,\n",
      "     |       <frame ID=700 name=Committing_crime>]\n",
      "     |      \n",
      "     |      A brief intro to Frames (excerpted from \"FrameNet II: Extended\n",
      "     |      Theory and Practice\" by Ruppenhofer et. al., 2010):\n",
      "     |      \n",
      "     |      A Frame is a script-like conceptual structure that describes a\n",
      "     |      particular type of situation, object, or event along with the\n",
      "     |      participants and props that are needed for that Frame. For\n",
      "     |      example, the \"Apply_heat\" frame describes a common situation\n",
      "     |      involving a Cook, some Food, and a Heating_Instrument, and is\n",
      "     |      evoked by words such as bake, blanch, boil, broil, brown,\n",
      "     |      simmer, steam, etc.\n",
      "     |      \n",
      "     |      We call the roles of a Frame \"frame elements\" (FEs) and the\n",
      "     |      frame-evoking words are called \"lexical units\" (LUs).\n",
      "     |      \n",
      "     |      FrameNet includes relations between Frames. Several types of\n",
      "     |      relations are defined, of which the most important are:\n",
      "     |      \n",
      "     |         - Inheritance: An IS-A relation. The child frame is a subtype\n",
      "     |           of the parent frame, and each FE in the parent is bound to\n",
      "     |           a corresponding FE in the child. An example is the\n",
      "     |           \"Revenge\" frame which inherits from the\n",
      "     |           \"Rewards_and_punishments\" frame.\n",
      "     |      \n",
      "     |         - Using: The child frame presupposes the parent frame as\n",
      "     |           background, e.g the \"Speed\" frame \"uses\" (or presupposes)\n",
      "     |           the \"Motion\" frame; however, not all parent FEs need to be\n",
      "     |           bound to child FEs.\n",
      "     |      \n",
      "     |         - Subframe: The child frame is a subevent of a complex event\n",
      "     |           represented by the parent, e.g. the \"Criminal_process\" frame\n",
      "     |           has subframes of \"Arrest\", \"Arraignment\", \"Trial\", and\n",
      "     |           \"Sentencing\".\n",
      "     |      \n",
      "     |         - Perspective_on: The child frame provides a particular\n",
      "     |           perspective on an un-perspectivized parent frame. A pair of\n",
      "     |           examples consists of the \"Hiring\" and \"Get_a_job\" frames,\n",
      "     |           which perspectivize the \"Employment_start\" frame from the\n",
      "     |           Employer's and the Employee's point of view, respectively.\n",
      "     |      \n",
      "     |      :param name: A regular expression pattern used to match against\n",
      "     |          Frame names. If 'name' is None, then a list of all\n",
      "     |          Framenet Frames will be returned.\n",
      "     |      :type name: str\n",
      "     |      :return: A list of matching Frames (or all Frames).\n",
      "     |      :rtype: list(AttrDict)\n",
      "     |  \n",
      "     |  frames_by_lemma(self, pat)\n",
      "     |      Returns a list of all frames that contain LUs in which the\n",
      "     |      ``name`` attribute of the LU matchs the given regular expression\n",
      "     |      ``pat``. Note that LU names are composed of \"lemma.POS\", where\n",
      "     |      the \"lemma\" part can be made up of either a single lexeme\n",
      "     |      (e.g. 'run') or multiple lexemes (e.g. 'a little').\n",
      "     |      \n",
      "     |      Note: if you are going to be doing a lot of this type of\n",
      "     |      searching, you'd want to build an index that maps from lemmas to\n",
      "     |      frames because each time frames_by_lemma() is called, it has to\n",
      "     |      search through ALL of the frame XML files in the db.\n",
      "     |      \n",
      "     |      >>> from nltk.corpus import framenet as fn\n",
      "     |      >>> from nltk.corpus.reader.framenet import PrettyList\n",
      "     |      >>> PrettyList(sorted(fn.frames_by_lemma(r'(?i)a little'), key=itemgetter('ID'))) # doctest: +ELLIPSIS\n",
      "     |      [<frame ID=189 name=Quanti...>, <frame ID=2001 name=Degree>]\n",
      "     |      \n",
      "     |      :return: A list of frame objects.\n",
      "     |      :rtype: list(AttrDict)\n",
      "     |  \n",
      "     |  ft_sents(self, docNamePattern=None)\n",
      "     |      Full-text annotation sentences, optionally filtered by document name.\n",
      "     |  \n",
      "     |  help(self, attrname=None)\n",
      "     |      Display help information summarizing the main methods.\n",
      "     |  \n",
      "     |  lu(self, fn_luid, ignorekeys=[], luName=None, frameID=None, frameName=None)\n",
      "     |      Access a lexical unit by its ID. luName, frameID, and frameName are used\n",
      "     |      only in the event that the LU does not have a file in the database\n",
      "     |      (which is the case for LUs with \"Problem\" status); in this case,\n",
      "     |      a placeholder LU is created which just contains its name, ID, and frame.\n",
      "     |      \n",
      "     |      \n",
      "     |      Usage examples:\n",
      "     |      \n",
      "     |      >>> from nltk.corpus import framenet as fn\n",
      "     |      >>> fn.lu(256).name\n",
      "     |      'foresee.v'\n",
      "     |      >>> fn.lu(256).definition\n",
      "     |      'COD: be aware of beforehand; predict.'\n",
      "     |      >>> fn.lu(256).frame.name\n",
      "     |      'Expectation'\n",
      "     |      >>> pprint(list(map(PrettyDict, fn.lu(256).lexemes)))\n",
      "     |      [{'POS': 'V', 'breakBefore': 'false', 'headword': 'false', 'name': 'foresee', 'order': 1}]\n",
      "     |      \n",
      "     |      >>> fn.lu(227).exemplars[23]\n",
      "     |      exemplar sentence (352962):\n",
      "     |      [sentNo] 0\n",
      "     |      [aPos] 59699508\n",
      "     |      <BLANKLINE>\n",
      "     |      [LU] (227) guess.v in Coming_to_believe\n",
      "     |      <BLANKLINE>\n",
      "     |      [frame] (23) Coming_to_believe\n",
      "     |      <BLANKLINE>\n",
      "     |      [annotationSet] 2 annotation sets\n",
      "     |      <BLANKLINE>\n",
      "     |      [POS] 18 tags\n",
      "     |      <BLANKLINE>\n",
      "     |      [POS_tagset] BNC\n",
      "     |      <BLANKLINE>\n",
      "     |      [GF] 3 relations\n",
      "     |      <BLANKLINE>\n",
      "     |      [PT] 3 phrases\n",
      "     |      <BLANKLINE>\n",
      "     |      [Other] 1 entry\n",
      "     |      <BLANKLINE>\n",
      "     |      [text] + [Target] + [FE]\n",
      "     |      <BLANKLINE>\n",
      "     |      When he was inside the house , Culley noticed the characteristic\n",
      "     |                                                    ------------------\n",
      "     |                                                    Content\n",
      "     |      <BLANKLINE>\n",
      "     |      he would n't have guessed at .\n",
      "     |      --                ******* --\n",
      "     |      Co                        C1 [Evidence:INI]\n",
      "     |       (Co=Cognizer, C1=Content)\n",
      "     |      <BLANKLINE>\n",
      "     |      <BLANKLINE>\n",
      "     |      \n",
      "     |      The dict that is returned from this function will contain most of the\n",
      "     |      following information about the LU. Note that some LUs do not contain\n",
      "     |      all of these pieces of information - particularly 'totalAnnotated' and\n",
      "     |      'incorporatedFE' may be missing in some LUs:\n",
      "     |      \n",
      "     |      - 'name'       : the name of the LU (e.g. 'merger.n')\n",
      "     |      - 'definition' : textual definition of the LU\n",
      "     |      - 'ID'         : the internal ID number of the LU\n",
      "     |      - '_type'      : 'lu'\n",
      "     |      - 'status'     : e.g. 'Created'\n",
      "     |      - 'frame'      : Frame that this LU belongs to\n",
      "     |      - 'POS'        : the part of speech of this LU (e.g. 'N')\n",
      "     |      - 'totalAnnotated' : total number of examples annotated with this LU\n",
      "     |      - 'incorporatedFE' : FE that incorporates this LU (e.g. 'Ailment')\n",
      "     |      - 'sentenceCount'  : a dict with the following two keys:\n",
      "     |               - 'annotated': number of sentences annotated with this LU\n",
      "     |               - 'total'    : total number of sentences with this LU\n",
      "     |      \n",
      "     |      - 'lexemes'  : a list of dicts describing the lemma of this LU.\n",
      "     |         Each dict in the list contains these keys:\n",
      "     |         - 'POS'     : part of speech e.g. 'N'\n",
      "     |         - 'name'    : either single-lexeme e.g. 'merger' or\n",
      "     |                       multi-lexeme e.g. 'a little'\n",
      "     |         - 'order': the order of the lexeme in the lemma (starting from 1)\n",
      "     |         - 'headword': a boolean ('true' or 'false')\n",
      "     |         - 'breakBefore': Can this lexeme be separated from the previous lexeme?\n",
      "     |              Consider: \"take over.v\" as in:\n",
      "     |                       Germany took over the Netherlands in 2 days.\n",
      "     |                       Germany took the Netherlands over in 2 days.\n",
      "     |              In this case, 'breakBefore' would be \"true\" for the lexeme\n",
      "     |              \"over\". Contrast this with \"take after.v\" as in:\n",
      "     |                       Mary takes after her grandmother.\n",
      "     |                      *Mary takes her grandmother after.\n",
      "     |              In this case, 'breakBefore' would be \"false\" for the lexeme \"after\"\n",
      "     |      \n",
      "     |      - 'lemmaID'    : Can be used to connect lemmas in different LUs\n",
      "     |      - 'semTypes'   : a list of semantic type objects for this LU\n",
      "     |      - 'subCorpus'  : a list of subcorpora\n",
      "     |         - Each item in the list is a dict containing the following keys:\n",
      "     |            - 'name' :\n",
      "     |            - 'sentence' : a list of sentences in the subcorpus\n",
      "     |               - each item in the list is a dict with the following keys:\n",
      "     |                  - 'ID':\n",
      "     |                  - 'sentNo':\n",
      "     |                  - 'text': the text of the sentence\n",
      "     |                  - 'aPos':\n",
      "     |                  - 'annotationSet': a list of annotation sets\n",
      "     |                     - each item in the list is a dict with the following keys:\n",
      "     |                        - 'ID':\n",
      "     |                        - 'status':\n",
      "     |                        - 'layer': a list of layers\n",
      "     |                           - each layer is a dict containing the following keys:\n",
      "     |                              - 'name': layer name (e.g. 'BNC')\n",
      "     |                              - 'rank':\n",
      "     |                              - 'label': a list of labels for the layer\n",
      "     |                                 - each label is a dict containing the following keys:\n",
      "     |                                    - 'start': start pos of label in sentence 'text' (0-based)\n",
      "     |                                    - 'end': end pos of label in sentence 'text' (0-based)\n",
      "     |                                    - 'name': name of label (e.g. 'NN1')\n",
      "     |      \n",
      "     |      Under the hood, this implementation looks up the lexical unit information\n",
      "     |      in the *frame* definition file. That file does not contain\n",
      "     |      corpus annotations, so the LU files will be accessed on demand if those are\n",
      "     |      needed. In principle, valence patterns could be loaded here too,\n",
      "     |      though these are not currently supported.\n",
      "     |      \n",
      "     |      :param fn_luid: The id number of the lexical unit\n",
      "     |      :type fn_luid: int\n",
      "     |      :param ignorekeys: The keys to ignore. These keys will not be\n",
      "     |          included in the output. (optional)\n",
      "     |      :type ignorekeys: list(str)\n",
      "     |      :return: All information about the lexical unit\n",
      "     |      :rtype: dict\n",
      "     |  \n",
      "     |  lu_basic(self, fn_luid)\n",
      "     |      Returns basic information about the LU whose id is\n",
      "     |      ``fn_luid``. This is basically just a wrapper around the\n",
      "     |      ``lu()`` function with \"subCorpus\" info excluded.\n",
      "     |      \n",
      "     |      >>> from nltk.corpus import framenet as fn\n",
      "     |      >>> lu = PrettyDict(fn.lu_basic(256), breakLines=True)\n",
      "     |      >>> # ellipses account for differences between FN 1.5 and 1.7\n",
      "     |      >>> lu # doctest: +ELLIPSIS\n",
      "     |      {'ID': 256,\n",
      "     |       'POS': 'V',\n",
      "     |       'URL': u'https://framenet2.icsi.berkeley.edu/fnReports/data/lu/lu256.xml',\n",
      "     |       '_type': 'lu',\n",
      "     |       'cBy': ...,\n",
      "     |       'cDate': '02/08/2001 01:27:50 PST Thu',\n",
      "     |       'definition': 'COD: be aware of beforehand; predict.',\n",
      "     |       'definitionMarkup': 'COD: be aware of beforehand; predict.',\n",
      "     |       'frame': <frame ID=26 name=Expectation>,\n",
      "     |       'lemmaID': 15082,\n",
      "     |       'lexemes': [{'POS': 'V', 'breakBefore': 'false', 'headword': 'false', 'name': 'foresee', 'order': 1}],\n",
      "     |       'name': 'foresee.v',\n",
      "     |       'semTypes': [],\n",
      "     |       'sentenceCount': {'annotated': ..., 'total': ...},\n",
      "     |       'status': 'FN1_Sent'}\n",
      "     |      \n",
      "     |      :param fn_luid: The id number of the desired LU\n",
      "     |      :type fn_luid: int\n",
      "     |      :return: Basic information about the lexical unit\n",
      "     |      :rtype: dict\n",
      "     |  \n",
      "     |  lu_ids_and_names(self, name=None)\n",
      "     |      Uses the LU index, which is much faster than looking up each LU definition\n",
      "     |      if only the names and IDs are needed.\n",
      "     |  \n",
      "     |  lus(self, name=None, frame=None)\n",
      "     |      Obtain details for lexical units.\n",
      "     |      Optionally restrict by lexical unit name pattern, and/or to a certain frame\n",
      "     |      or frames whose name matches a pattern.\n",
      "     |      \n",
      "     |      >>> from nltk.corpus import framenet as fn\n",
      "     |      >>> len(fn.lus()) in (11829, 13572) # FN 1.5 and 1.7, resp.\n",
      "     |      True\n",
      "     |      >>> PrettyList(sorted(fn.lus(r'(?i)a little'), key=itemgetter('ID')), maxReprSize=0, breakLines=True)\n",
      "     |      [<lu ID=14733 name=a little.n>,\n",
      "     |       <lu ID=14743 name=a little.adv>,\n",
      "     |       <lu ID=14744 name=a little bit.adv>]\n",
      "     |      >>> PrettyList(sorted(fn.lus(r'interest', r'(?i)stimulus'), key=itemgetter('ID')))\n",
      "     |      [<lu ID=14894 name=interested.a>, <lu ID=14920 name=interesting.a>]\n",
      "     |      \n",
      "     |      A brief intro to Lexical Units (excerpted from \"FrameNet II:\n",
      "     |      Extended Theory and Practice\" by Ruppenhofer et. al., 2010):\n",
      "     |      \n",
      "     |      A lexical unit (LU) is a pairing of a word with a meaning. For\n",
      "     |      example, the \"Apply_heat\" Frame describes a common situation\n",
      "     |      involving a Cook, some Food, and a Heating Instrument, and is\n",
      "     |      _evoked_ by words such as bake, blanch, boil, broil, brown,\n",
      "     |      simmer, steam, etc. These frame-evoking words are the LUs in the\n",
      "     |      Apply_heat frame. Each sense of a polysemous word is a different\n",
      "     |      LU.\n",
      "     |      \n",
      "     |      We have used the word \"word\" in talking about LUs. The reality\n",
      "     |      is actually rather complex. When we say that the word \"bake\" is\n",
      "     |      polysemous, we mean that the lemma \"bake.v\" (which has the\n",
      "     |      word-forms \"bake\", \"bakes\", \"baked\", and \"baking\") is linked to\n",
      "     |      three different frames:\n",
      "     |      \n",
      "     |         - Apply_heat: \"Michelle baked the potatoes for 45 minutes.\"\n",
      "     |      \n",
      "     |         - Cooking_creation: \"Michelle baked her mother a cake for her birthday.\"\n",
      "     |      \n",
      "     |         - Absorb_heat: \"The potatoes have to bake for more than 30 minutes.\"\n",
      "     |      \n",
      "     |      These constitute three different LUs, with different\n",
      "     |      definitions.\n",
      "     |      \n",
      "     |      Multiword expressions such as \"given name\" and hyphenated words\n",
      "     |      like \"shut-eye\" can also be LUs. Idiomatic phrases such as\n",
      "     |      \"middle of nowhere\" and \"give the slip (to)\" are also defined as\n",
      "     |      LUs in the appropriate frames (\"Isolated_places\" and \"Evading\",\n",
      "     |      respectively), and their internal structure is not analyzed.\n",
      "     |      \n",
      "     |      Framenet provides multiple annotated examples of each sense of a\n",
      "     |      word (i.e. each LU).  Moreover, the set of examples\n",
      "     |      (approximately 20 per LU) illustrates all of the combinatorial\n",
      "     |      possibilities of the lexical unit.\n",
      "     |      \n",
      "     |      Each LU is linked to a Frame, and hence to the other words which\n",
      "     |      evoke that Frame. This makes the FrameNet database similar to a\n",
      "     |      thesaurus, grouping together semantically similar words.\n",
      "     |      \n",
      "     |      In the simplest case, frame-evoking words are verbs such as\n",
      "     |      \"fried\" in:\n",
      "     |      \n",
      "     |         \"Matilde fried the catfish in a heavy iron skillet.\"\n",
      "     |      \n",
      "     |      Sometimes event nouns may evoke a Frame. For example,\n",
      "     |      \"reduction\" evokes \"Cause_change_of_scalar_position\" in:\n",
      "     |      \n",
      "     |         \"...the reduction of debt levels to $665 million from $2.6 billion.\"\n",
      "     |      \n",
      "     |      Adjectives may also evoke a Frame. For example, \"asleep\" may\n",
      "     |      evoke the \"Sleep\" frame as in:\n",
      "     |      \n",
      "     |         \"They were asleep for hours.\"\n",
      "     |      \n",
      "     |      Many common nouns, such as artifacts like \"hat\" or \"tower\",\n",
      "     |      typically serve as dependents rather than clearly evoking their\n",
      "     |      own frames.\n",
      "     |      \n",
      "     |      :param name: A regular expression pattern used to search the LU\n",
      "     |          names. Note that LU names take the form of a dotted\n",
      "     |          string (e.g. \"run.v\" or \"a little.adv\") in which a\n",
      "     |          lemma preceeds the \".\" and a POS follows the\n",
      "     |          dot. The lemma may be composed of a single lexeme\n",
      "     |          (e.g. \"run\") or of multiple lexemes (e.g. \"a\n",
      "     |          little\"). If 'name' is not given, then all LUs will\n",
      "     |          be returned.\n",
      "     |      \n",
      "     |          The valid POSes are:\n",
      "     |      \n",
      "     |                 v    - verb\n",
      "     |                 n    - noun\n",
      "     |                 a    - adjective\n",
      "     |                 adv  - adverb\n",
      "     |                 prep - preposition\n",
      "     |                 num  - numbers\n",
      "     |                 intj - interjection\n",
      "     |                 art  - article\n",
      "     |                 c    - conjunction\n",
      "     |                 scon - subordinating conjunction\n",
      "     |      \n",
      "     |      :type name: str\n",
      "     |      :type frame: str or int or frame\n",
      "     |      :return: A list of selected (or all) lexical units\n",
      "     |      :rtype: list of LU objects (dicts). See the lu() function for info\n",
      "     |        about the specifics of LU objects.\n",
      "     |  \n",
      "     |  propagate_semtypes(self)\n",
      "     |      Apply inference rules to distribute semtypes over relations between FEs.\n",
      "     |      For FrameNet 1.5, this results in 1011 semtypes being propagated.\n",
      "     |      (Not done by default because it requires loading all frame files,\n",
      "     |      which takes several seconds. If this needed to be fast, it could be rewritten\n",
      "     |      to traverse the neighboring relations on demand for each FE semtype.)\n",
      "     |      \n",
      "     |      >>> from nltk.corpus import framenet as fn\n",
      "     |      >>> x = sum(1 for f in fn.frames() for fe in f.FE.values() if fe.semType)\n",
      "     |      >>> fn.propagate_semtypes()\n",
      "     |      >>> y = sum(1 for f in fn.frames() for fe in f.FE.values() if fe.semType)\n",
      "     |      >>> y-x > 1000\n",
      "     |      True\n",
      "     |  \n",
      "     |  readme(self)\n",
      "     |      Return the contents of the corpus README.txt (or README) file.\n",
      "     |  \n",
      "     |  semtype(self, key)\n",
      "     |      >>> from nltk.corpus import framenet as fn\n",
      "     |      >>> fn.semtype(233).name\n",
      "     |      'Temperature'\n",
      "     |      >>> fn.semtype(233).abbrev\n",
      "     |      'Temp'\n",
      "     |      >>> fn.semtype('Temperature').ID\n",
      "     |      233\n",
      "     |      \n",
      "     |      :param key: The name, abbreviation, or id number of the semantic type\n",
      "     |      :type key: string or int\n",
      "     |      :return: Information about a semantic type\n",
      "     |      :rtype: dict\n",
      "     |  \n",
      "     |  semtype_inherits(self, st, superST)\n",
      "     |  \n",
      "     |  semtypes(self)\n",
      "     |      Obtain a list of semantic types.\n",
      "     |      \n",
      "     |      >>> from nltk.corpus import framenet as fn\n",
      "     |      >>> stypes = fn.semtypes()\n",
      "     |      >>> len(stypes) in (73, 109) # FN 1.5 and 1.7, resp.\n",
      "     |      True\n",
      "     |      >>> sorted(stypes[0].keys())\n",
      "     |      ['ID', '_type', 'abbrev', 'definition', 'definitionMarkup', 'name', 'rootType', 'subTypes', 'superType']\n",
      "     |      \n",
      "     |      :return: A list of all of the semantic types in framenet\n",
      "     |      :rtype: list(dict)\n",
      "     |  \n",
      "     |  sents(self, exemplars=True, full_text=True)\n",
      "     |      Annotated sentences matching the specified criteria.\n",
      "     |  \n",
      "     |  warnings(self, v)\n",
      "     |      Enable or disable warnings of data integrity issues as they are encountered.\n",
      "     |      If v is truthy, warnings will be enabled.\n",
      "     |      \n",
      "     |      (This is a function rather than just an attribute/property to ensure that if\n",
      "     |      enabling warnings is the first action taken, the corpus reader is instantiated first.)\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Methods inherited from nltk.corpus.reader.xmldocs.XMLCorpusReader:\n",
      "     |  \n",
      "     |  raw(self, fileids=None)\n",
      "     |  \n",
      "     |  words(self, fileid=None)\n",
      "     |      Returns all of the words and punctuation symbols in the specified file\n",
      "     |      that were in text nodes -- ie, tags are ignored. Like the xml() method,\n",
      "     |      fileid can only specify one file.\n",
      "     |      \n",
      "     |      :return: the given file's text nodes as a list of words and punctuation symbols\n",
      "     |      :rtype: list(str)\n",
      "     |  \n",
      "     |  xml(self, fileid=None)\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Methods inherited from nltk.corpus.reader.api.CorpusReader:\n",
      "     |  \n",
      "     |  __repr__(self)\n",
      "     |      Return repr(self).\n",
      "     |  \n",
      "     |  __unicode__ = __str__(self, /)\n",
      "     |  \n",
      "     |  abspath(self, fileid)\n",
      "     |      Return the absolute path for the given file.\n",
      "     |      \n",
      "     |      :type fileid: str\n",
      "     |      :param fileid: The file identifier for the file whose path\n",
      "     |          should be returned.\n",
      "     |      :rtype: PathPointer\n",
      "     |  \n",
      "     |  abspaths(self, fileids=None, include_encoding=False, include_fileid=False)\n",
      "     |      Return a list of the absolute paths for all fileids in this corpus;\n",
      "     |      or for the given list of fileids, if specified.\n",
      "     |      \n",
      "     |      :type fileids: None or str or list\n",
      "     |      :param fileids: Specifies the set of fileids for which paths should\n",
      "     |          be returned.  Can be None, for all fileids; a list of\n",
      "     |          file identifiers, for a specified set of fileids; or a single\n",
      "     |          file identifier, for a single file.  Note that the return\n",
      "     |          value is always a list of paths, even if ``fileids`` is a\n",
      "     |          single file identifier.\n",
      "     |      \n",
      "     |      :param include_encoding: If true, then return a list of\n",
      "     |          ``(path_pointer, encoding)`` tuples.\n",
      "     |      \n",
      "     |      :rtype: list(PathPointer)\n",
      "     |  \n",
      "     |  citation(self)\n",
      "     |      Return the contents of the corpus citation.bib file, if it exists.\n",
      "     |  \n",
      "     |  encoding(self, file)\n",
      "     |      Return the unicode encoding for the given corpus file, if known.\n",
      "     |      If the encoding is unknown, or if the given file should be\n",
      "     |      processed using byte strings (str), then return None.\n",
      "     |  \n",
      "     |  ensure_loaded(self)\n",
      "     |      Load this corpus (if it has not already been loaded).  This is\n",
      "     |      used by LazyCorpusLoader as a simple method that can be used to\n",
      "     |      make sure a corpus is loaded -- e.g., in case a user wants to\n",
      "     |      do help(some_corpus).\n",
      "     |  \n",
      "     |  fileids(self)\n",
      "     |      Return a list of file identifiers for the fileids that make up\n",
      "     |      this corpus.\n",
      "     |  \n",
      "     |  license(self)\n",
      "     |      Return the contents of the corpus LICENSE file, if it exists.\n",
      "     |  \n",
      "     |  open(self, file)\n",
      "     |      Return an open stream that can be used to read the given file.\n",
      "     |      If the file's encoding is not None, then the stream will\n",
      "     |      automatically decode the file's contents into unicode.\n",
      "     |      \n",
      "     |      :param file: The file identifier of the file to read.\n",
      "     |  \n",
      "     |  unicode_repr = __repr__(self)\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Data descriptors inherited from nltk.corpus.reader.api.CorpusReader:\n",
      "     |  \n",
      "     |  __dict__\n",
      "     |      dictionary for instance variables (if defined)\n",
      "     |  \n",
      "     |  __weakref__\n",
      "     |      list of weak references to the object (if defined)\n",
      "     |  \n",
      "     |  root\n",
      "     |      The directory where this corpus is stored.\n",
      "     |      \n",
      "     |      :type: PathPointer\n",
      "    \n",
      "    class IEERCorpusReader(nltk.corpus.reader.api.CorpusReader)\n",
      "     |  IEERCorpusReader(root, fileids, encoding='utf8', tagset=None)\n",
      "     |  \n",
      "     |  Method resolution order:\n",
      "     |      IEERCorpusReader\n",
      "     |      nltk.corpus.reader.api.CorpusReader\n",
      "     |      builtins.object\n",
      "     |  \n",
      "     |  Methods defined here:\n",
      "     |  \n",
      "     |  docs(self, fileids=None)\n",
      "     |  \n",
      "     |  parsed_docs(self, fileids=None)\n",
      "     |  \n",
      "     |  raw(self, fileids=None)\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Methods inherited from nltk.corpus.reader.api.CorpusReader:\n",
      "     |  \n",
      "     |  __init__(self, root, fileids, encoding='utf8', tagset=None)\n",
      "     |      :type root: PathPointer or str\n",
      "     |      :param root: A path pointer identifying the root directory for\n",
      "     |          this corpus.  If a string is specified, then it will be\n",
      "     |          converted to a ``PathPointer`` automatically.\n",
      "     |      :param fileids: A list of the files that make up this corpus.\n",
      "     |          This list can either be specified explicitly, as a list of\n",
      "     |          strings; or implicitly, as a regular expression over file\n",
      "     |          paths.  The absolute path for each file will be constructed\n",
      "     |          by joining the reader's root to each file name.\n",
      "     |      :param encoding: The default unicode encoding for the files\n",
      "     |          that make up the corpus.  The value of ``encoding`` can be any\n",
      "     |          of the following:\n",
      "     |          - A string: ``encoding`` is the encoding name for all files.\n",
      "     |          - A dictionary: ``encoding[file_id]`` is the encoding\n",
      "     |            name for the file whose identifier is ``file_id``.  If\n",
      "     |            ``file_id`` is not in ``encoding``, then the file\n",
      "     |            contents will be processed using non-unicode byte strings.\n",
      "     |          - A list: ``encoding`` should be a list of ``(regexp, encoding)``\n",
      "     |            tuples.  The encoding for a file whose identifier is ``file_id``\n",
      "     |            will be the ``encoding`` value for the first tuple whose\n",
      "     |            ``regexp`` matches the ``file_id``.  If no tuple's ``regexp``\n",
      "     |            matches the ``file_id``, the file contents will be processed\n",
      "     |            using non-unicode byte strings.\n",
      "     |          - None: the file contents of all files will be\n",
      "     |            processed using non-unicode byte strings.\n",
      "     |      :param tagset: The name of the tagset used by this corpus, to be used\n",
      "     |            for normalizing or converting the POS tags returned by the\n",
      "     |            tagged_...() methods.\n",
      "     |  \n",
      "     |  __repr__(self)\n",
      "     |      Return repr(self).\n",
      "     |  \n",
      "     |  __unicode__ = __str__(self, /)\n",
      "     |  \n",
      "     |  abspath(self, fileid)\n",
      "     |      Return the absolute path for the given file.\n",
      "     |      \n",
      "     |      :type fileid: str\n",
      "     |      :param fileid: The file identifier for the file whose path\n",
      "     |          should be returned.\n",
      "     |      :rtype: PathPointer\n",
      "     |  \n",
      "     |  abspaths(self, fileids=None, include_encoding=False, include_fileid=False)\n",
      "     |      Return a list of the absolute paths for all fileids in this corpus;\n",
      "     |      or for the given list of fileids, if specified.\n",
      "     |      \n",
      "     |      :type fileids: None or str or list\n",
      "     |      :param fileids: Specifies the set of fileids for which paths should\n",
      "     |          be returned.  Can be None, for all fileids; a list of\n",
      "     |          file identifiers, for a specified set of fileids; or a single\n",
      "     |          file identifier, for a single file.  Note that the return\n",
      "     |          value is always a list of paths, even if ``fileids`` is a\n",
      "     |          single file identifier.\n",
      "     |      \n",
      "     |      :param include_encoding: If true, then return a list of\n",
      "     |          ``(path_pointer, encoding)`` tuples.\n",
      "     |      \n",
      "     |      :rtype: list(PathPointer)\n",
      "     |  \n",
      "     |  citation(self)\n",
      "     |      Return the contents of the corpus citation.bib file, if it exists.\n",
      "     |  \n",
      "     |  encoding(self, file)\n",
      "     |      Return the unicode encoding for the given corpus file, if known.\n",
      "     |      If the encoding is unknown, or if the given file should be\n",
      "     |      processed using byte strings (str), then return None.\n",
      "     |  \n",
      "     |  ensure_loaded(self)\n",
      "     |      Load this corpus (if it has not already been loaded).  This is\n",
      "     |      used by LazyCorpusLoader as a simple method that can be used to\n",
      "     |      make sure a corpus is loaded -- e.g., in case a user wants to\n",
      "     |      do help(some_corpus).\n",
      "     |  \n",
      "     |  fileids(self)\n",
      "     |      Return a list of file identifiers for the fileids that make up\n",
      "     |      this corpus.\n",
      "     |  \n",
      "     |  license(self)\n",
      "     |      Return the contents of the corpus LICENSE file, if it exists.\n",
      "     |  \n",
      "     |  open(self, file)\n",
      "     |      Return an open stream that can be used to read the given file.\n",
      "     |      If the file's encoding is not None, then the stream will\n",
      "     |      automatically decode the file's contents into unicode.\n",
      "     |      \n",
      "     |      :param file: The file identifier of the file to read.\n",
      "     |  \n",
      "     |  readme(self)\n",
      "     |      Return the contents of the corpus README file, if it exists.\n",
      "     |  \n",
      "     |  unicode_repr = __repr__(self)\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Data descriptors inherited from nltk.corpus.reader.api.CorpusReader:\n",
      "     |  \n",
      "     |  __dict__\n",
      "     |      dictionary for instance variables (if defined)\n",
      "     |  \n",
      "     |  __weakref__\n",
      "     |      list of weak references to the object (if defined)\n",
      "     |  \n",
      "     |  root\n",
      "     |      The directory where this corpus is stored.\n",
      "     |      \n",
      "     |      :type: PathPointer\n",
      "    \n",
      "    class IPIPANCorpusReader(nltk.corpus.reader.api.CorpusReader)\n",
      "     |  IPIPANCorpusReader(root, fileids)\n",
      "     |  \n",
      "     |  Corpus reader designed to work with corpus created by IPI PAN.\n",
      "     |  See http://korpus.pl/en/ for more details about IPI PAN corpus.\n",
      "     |  \n",
      "     |  The corpus includes information about text domain, channel and categories.\n",
      "     |  You can access possible values using ``domains()``, ``channels()`` and\n",
      "     |  ``categories()``. You can use also this metadata to filter files, e.g.:\n",
      "     |  ``fileids(channel='prasa')``, ``fileids(categories='publicystyczny')``.\n",
      "     |  \n",
      "     |  The reader supports methods: words, sents, paras and their tagged versions.\n",
      "     |  You can get part of speech instead of full tag by giving \"simplify_tags=True\"\n",
      "     |  parameter, e.g.: ``tagged_sents(simplify_tags=True)``.\n",
      "     |  \n",
      "     |  Also you can get all tags disambiguated tags specifying parameter\n",
      "     |  \"one_tag=False\", e.g.: ``tagged_paras(one_tag=False)``.\n",
      "     |  \n",
      "     |  You can get all tags that were assigned by a morphological analyzer specifying\n",
      "     |  parameter \"disamb_only=False\", e.g. ``tagged_words(disamb_only=False)``.\n",
      "     |  \n",
      "     |  The IPIPAN Corpus contains tags indicating if there is a space between two\n",
      "     |  tokens. To add special \"no space\" markers, you should specify parameter\n",
      "     |  \"append_no_space=True\", e.g. ``tagged_words(append_no_space=True)``.\n",
      "     |  As a result in place where there should be no space between two tokens new\n",
      "     |  pair ('', 'no-space') will be inserted (for tagged data) and just '' for\n",
      "     |  methods without tags.\n",
      "     |  \n",
      "     |  The corpus reader can also try to append spaces between words. To enable this\n",
      "     |  option, specify parameter \"append_space=True\", e.g. ``words(append_space=True)``.\n",
      "     |  As a result either ' ' or (' ', 'space') will be inserted between tokens.\n",
      "     |  \n",
      "     |  By default, xml entities like &quot; and &amp; are replaced by corresponding\n",
      "     |  characters. You can turn off this feature, specifying parameter\n",
      "     |  \"replace_xmlentities=False\", e.g. ``words(replace_xmlentities=False)``.\n",
      "     |  \n",
      "     |  Method resolution order:\n",
      "     |      IPIPANCorpusReader\n",
      "     |      nltk.corpus.reader.api.CorpusReader\n",
      "     |      builtins.object\n",
      "     |  \n",
      "     |  Methods defined here:\n",
      "     |  \n",
      "     |  __init__(self, root, fileids)\n",
      "     |      :type root: PathPointer or str\n",
      "     |      :param root: A path pointer identifying the root directory for\n",
      "     |          this corpus.  If a string is specified, then it will be\n",
      "     |          converted to a ``PathPointer`` automatically.\n",
      "     |      :param fileids: A list of the files that make up this corpus.\n",
      "     |          This list can either be specified explicitly, as a list of\n",
      "     |          strings; or implicitly, as a regular expression over file\n",
      "     |          paths.  The absolute path for each file will be constructed\n",
      "     |          by joining the reader's root to each file name.\n",
      "     |      :param encoding: The default unicode encoding for the files\n",
      "     |          that make up the corpus.  The value of ``encoding`` can be any\n",
      "     |          of the following:\n",
      "     |          - A string: ``encoding`` is the encoding name for all files.\n",
      "     |          - A dictionary: ``encoding[file_id]`` is the encoding\n",
      "     |            name for the file whose identifier is ``file_id``.  If\n",
      "     |            ``file_id`` is not in ``encoding``, then the file\n",
      "     |            contents will be processed using non-unicode byte strings.\n",
      "     |          - A list: ``encoding`` should be a list of ``(regexp, encoding)``\n",
      "     |            tuples.  The encoding for a file whose identifier is ``file_id``\n",
      "     |            will be the ``encoding`` value for the first tuple whose\n",
      "     |            ``regexp`` matches the ``file_id``.  If no tuple's ``regexp``\n",
      "     |            matches the ``file_id``, the file contents will be processed\n",
      "     |            using non-unicode byte strings.\n",
      "     |          - None: the file contents of all files will be\n",
      "     |            processed using non-unicode byte strings.\n",
      "     |      :param tagset: The name of the tagset used by this corpus, to be used\n",
      "     |            for normalizing or converting the POS tags returned by the\n",
      "     |            tagged_...() methods.\n",
      "     |  \n",
      "     |  categories(self, fileids=None)\n",
      "     |  \n",
      "     |  channels(self, fileids=None)\n",
      "     |  \n",
      "     |  domains(self, fileids=None)\n",
      "     |  \n",
      "     |  fileids(self, channels=None, domains=None, categories=None)\n",
      "     |      Return a list of file identifiers for the fileids that make up\n",
      "     |      this corpus.\n",
      "     |  \n",
      "     |  paras(self, fileids=None, **kwargs)\n",
      "     |  \n",
      "     |  raw(self, fileids=None)\n",
      "     |  \n",
      "     |  sents(self, fileids=None, **kwargs)\n",
      "     |  \n",
      "     |  tagged_paras(self, fileids=None, **kwargs)\n",
      "     |  \n",
      "     |  tagged_sents(self, fileids=None, **kwargs)\n",
      "     |  \n",
      "     |  tagged_words(self, fileids=None, **kwargs)\n",
      "     |  \n",
      "     |  words(self, fileids=None, **kwargs)\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Methods inherited from nltk.corpus.reader.api.CorpusReader:\n",
      "     |  \n",
      "     |  __repr__(self)\n",
      "     |      Return repr(self).\n",
      "     |  \n",
      "     |  __unicode__ = __str__(self, /)\n",
      "     |  \n",
      "     |  abspath(self, fileid)\n",
      "     |      Return the absolute path for the given file.\n",
      "     |      \n",
      "     |      :type fileid: str\n",
      "     |      :param fileid: The file identifier for the file whose path\n",
      "     |          should be returned.\n",
      "     |      :rtype: PathPointer\n",
      "     |  \n",
      "     |  abspaths(self, fileids=None, include_encoding=False, include_fileid=False)\n",
      "     |      Return a list of the absolute paths for all fileids in this corpus;\n",
      "     |      or for the given list of fileids, if specified.\n",
      "     |      \n",
      "     |      :type fileids: None or str or list\n",
      "     |      :param fileids: Specifies the set of fileids for which paths should\n",
      "     |          be returned.  Can be None, for all fileids; a list of\n",
      "     |          file identifiers, for a specified set of fileids; or a single\n",
      "     |          file identifier, for a single file.  Note that the return\n",
      "     |          value is always a list of paths, even if ``fileids`` is a\n",
      "     |          single file identifier.\n",
      "     |      \n",
      "     |      :param include_encoding: If true, then return a list of\n",
      "     |          ``(path_pointer, encoding)`` tuples.\n",
      "     |      \n",
      "     |      :rtype: list(PathPointer)\n",
      "     |  \n",
      "     |  citation(self)\n",
      "     |      Return the contents of the corpus citation.bib file, if it exists.\n",
      "     |  \n",
      "     |  encoding(self, file)\n",
      "     |      Return the unicode encoding for the given corpus file, if known.\n",
      "     |      If the encoding is unknown, or if the given file should be\n",
      "     |      processed using byte strings (str), then return None.\n",
      "     |  \n",
      "     |  ensure_loaded(self)\n",
      "     |      Load this corpus (if it has not already been loaded).  This is\n",
      "     |      used by LazyCorpusLoader as a simple method that can be used to\n",
      "     |      make sure a corpus is loaded -- e.g., in case a user wants to\n",
      "     |      do help(some_corpus).\n",
      "     |  \n",
      "     |  license(self)\n",
      "     |      Return the contents of the corpus LICENSE file, if it exists.\n",
      "     |  \n",
      "     |  open(self, file)\n",
      "     |      Return an open stream that can be used to read the given file.\n",
      "     |      If the file's encoding is not None, then the stream will\n",
      "     |      automatically decode the file's contents into unicode.\n",
      "     |      \n",
      "     |      :param file: The file identifier of the file to read.\n",
      "     |  \n",
      "     |  readme(self)\n",
      "     |      Return the contents of the corpus README file, if it exists.\n",
      "     |  \n",
      "     |  unicode_repr = __repr__(self)\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Data descriptors inherited from nltk.corpus.reader.api.CorpusReader:\n",
      "     |  \n",
      "     |  __dict__\n",
      "     |      dictionary for instance variables (if defined)\n",
      "     |  \n",
      "     |  __weakref__\n",
      "     |      list of weak references to the object (if defined)\n",
      "     |  \n",
      "     |  root\n",
      "     |      The directory where this corpus is stored.\n",
      "     |      \n",
      "     |      :type: PathPointer\n",
      "    \n",
      "    class IndianCorpusReader(nltk.corpus.reader.api.CorpusReader)\n",
      "     |  IndianCorpusReader(root, fileids, encoding='utf8', tagset=None)\n",
      "     |  \n",
      "     |  List of words, one per line.  Blank lines are ignored.\n",
      "     |  \n",
      "     |  Method resolution order:\n",
      "     |      IndianCorpusReader\n",
      "     |      nltk.corpus.reader.api.CorpusReader\n",
      "     |      builtins.object\n",
      "     |  \n",
      "     |  Methods defined here:\n",
      "     |  \n",
      "     |  raw(self, fileids=None)\n",
      "     |  \n",
      "     |  sents(self, fileids=None)\n",
      "     |  \n",
      "     |  tagged_sents(self, fileids=None, tagset=None)\n",
      "     |  \n",
      "     |  tagged_words(self, fileids=None, tagset=None)\n",
      "     |  \n",
      "     |  words(self, fileids=None)\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Methods inherited from nltk.corpus.reader.api.CorpusReader:\n",
      "     |  \n",
      "     |  __init__(self, root, fileids, encoding='utf8', tagset=None)\n",
      "     |      :type root: PathPointer or str\n",
      "     |      :param root: A path pointer identifying the root directory for\n",
      "     |          this corpus.  If a string is specified, then it will be\n",
      "     |          converted to a ``PathPointer`` automatically.\n",
      "     |      :param fileids: A list of the files that make up this corpus.\n",
      "     |          This list can either be specified explicitly, as a list of\n",
      "     |          strings; or implicitly, as a regular expression over file\n",
      "     |          paths.  The absolute path for each file will be constructed\n",
      "     |          by joining the reader's root to each file name.\n",
      "     |      :param encoding: The default unicode encoding for the files\n",
      "     |          that make up the corpus.  The value of ``encoding`` can be any\n",
      "     |          of the following:\n",
      "     |          - A string: ``encoding`` is the encoding name for all files.\n",
      "     |          - A dictionary: ``encoding[file_id]`` is the encoding\n",
      "     |            name for the file whose identifier is ``file_id``.  If\n",
      "     |            ``file_id`` is not in ``encoding``, then the file\n",
      "     |            contents will be processed using non-unicode byte strings.\n",
      "     |          - A list: ``encoding`` should be a list of ``(regexp, encoding)``\n",
      "     |            tuples.  The encoding for a file whose identifier is ``file_id``\n",
      "     |            will be the ``encoding`` value for the first tuple whose\n",
      "     |            ``regexp`` matches the ``file_id``.  If no tuple's ``regexp``\n",
      "     |            matches the ``file_id``, the file contents will be processed\n",
      "     |            using non-unicode byte strings.\n",
      "     |          - None: the file contents of all files will be\n",
      "     |            processed using non-unicode byte strings.\n",
      "     |      :param tagset: The name of the tagset used by this corpus, to be used\n",
      "     |            for normalizing or converting the POS tags returned by the\n",
      "     |            tagged_...() methods.\n",
      "     |  \n",
      "     |  __repr__(self)\n",
      "     |      Return repr(self).\n",
      "     |  \n",
      "     |  __unicode__ = __str__(self, /)\n",
      "     |  \n",
      "     |  abspath(self, fileid)\n",
      "     |      Return the absolute path for the given file.\n",
      "     |      \n",
      "     |      :type fileid: str\n",
      "     |      :param fileid: The file identifier for the file whose path\n",
      "     |          should be returned.\n",
      "     |      :rtype: PathPointer\n",
      "     |  \n",
      "     |  abspaths(self, fileids=None, include_encoding=False, include_fileid=False)\n",
      "     |      Return a list of the absolute paths for all fileids in this corpus;\n",
      "     |      or for the given list of fileids, if specified.\n",
      "     |      \n",
      "     |      :type fileids: None or str or list\n",
      "     |      :param fileids: Specifies the set of fileids for which paths should\n",
      "     |          be returned.  Can be None, for all fileids; a list of\n",
      "     |          file identifiers, for a specified set of fileids; or a single\n",
      "     |          file identifier, for a single file.  Note that the return\n",
      "     |          value is always a list of paths, even if ``fileids`` is a\n",
      "     |          single file identifier.\n",
      "     |      \n",
      "     |      :param include_encoding: If true, then return a list of\n",
      "     |          ``(path_pointer, encoding)`` tuples.\n",
      "     |      \n",
      "     |      :rtype: list(PathPointer)\n",
      "     |  \n",
      "     |  citation(self)\n",
      "     |      Return the contents of the corpus citation.bib file, if it exists.\n",
      "     |  \n",
      "     |  encoding(self, file)\n",
      "     |      Return the unicode encoding for the given corpus file, if known.\n",
      "     |      If the encoding is unknown, or if the given file should be\n",
      "     |      processed using byte strings (str), then return None.\n",
      "     |  \n",
      "     |  ensure_loaded(self)\n",
      "     |      Load this corpus (if it has not already been loaded).  This is\n",
      "     |      used by LazyCorpusLoader as a simple method that can be used to\n",
      "     |      make sure a corpus is loaded -- e.g., in case a user wants to\n",
      "     |      do help(some_corpus).\n",
      "     |  \n",
      "     |  fileids(self)\n",
      "     |      Return a list of file identifiers for the fileids that make up\n",
      "     |      this corpus.\n",
      "     |  \n",
      "     |  license(self)\n",
      "     |      Return the contents of the corpus LICENSE file, if it exists.\n",
      "     |  \n",
      "     |  open(self, file)\n",
      "     |      Return an open stream that can be used to read the given file.\n",
      "     |      If the file's encoding is not None, then the stream will\n",
      "     |      automatically decode the file's contents into unicode.\n",
      "     |      \n",
      "     |      :param file: The file identifier of the file to read.\n",
      "     |  \n",
      "     |  readme(self)\n",
      "     |      Return the contents of the corpus README file, if it exists.\n",
      "     |  \n",
      "     |  unicode_repr = __repr__(self)\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Data descriptors inherited from nltk.corpus.reader.api.CorpusReader:\n",
      "     |  \n",
      "     |  __dict__\n",
      "     |      dictionary for instance variables (if defined)\n",
      "     |  \n",
      "     |  __weakref__\n",
      "     |      list of weak references to the object (if defined)\n",
      "     |  \n",
      "     |  root\n",
      "     |      The directory where this corpus is stored.\n",
      "     |      \n",
      "     |      :type: PathPointer\n",
      "    \n",
      "    class KNBCorpusReader(nltk.corpus.reader.api.SyntaxCorpusReader)\n",
      "     |  KNBCorpusReader(root, fileids, encoding='utf8', morphs2str=<function <lambda> at 0x000001F4CEDFBA68>)\n",
      "     |  \n",
      "     |  This class implements:\n",
      "     |    - ``__init__``, which specifies the location of the corpus\n",
      "     |      and a method for detecting the sentence blocks in corpus files.\n",
      "     |    - ``_read_block``, which reads a block from the input stream.\n",
      "     |    - ``_word``, which takes a block and returns a list of list of words.\n",
      "     |    - ``_tag``, which takes a block and returns a list of list of tagged\n",
      "     |      words.\n",
      "     |    - ``_parse``, which takes a block and returns a list of parsed\n",
      "     |      sentences.\n",
      "     |  \n",
      "     |  The structure of tagged words:\n",
      "     |    tagged_word = (word(str), tags(tuple))\n",
      "     |    tags = (surface, reading, lemma, pos1, posid1, pos2, posid2, pos3, posid3, others ...)\n",
      "     |  \n",
      "     |  Usage example\n",
      "     |  -------------\n",
      "     |  \n",
      "     |  >>> from nltk.corpus.util import LazyCorpusLoader\n",
      "     |  >>> knbc = LazyCorpusLoader(\n",
      "     |  ...     'knbc/corpus1',\n",
      "     |  ...     KNBCorpusReader,\n",
      "     |  ...     r'.*/KN.*',\n",
      "     |  ...     encoding='euc-jp',\n",
      "     |  ... )\n",
      "     |  \n",
      "     |  >>> len(knbc.sents()[0])\n",
      "     |  9\n",
      "     |  \n",
      "     |  Method resolution order:\n",
      "     |      KNBCorpusReader\n",
      "     |      nltk.corpus.reader.api.SyntaxCorpusReader\n",
      "     |      nltk.corpus.reader.api.CorpusReader\n",
      "     |      builtins.object\n",
      "     |  \n",
      "     |  Methods defined here:\n",
      "     |  \n",
      "     |  __init__(self, root, fileids, encoding='utf8', morphs2str=<function <lambda> at 0x000001F4CEDFBA68>)\n",
      "     |      Initialize KNBCorpusReader\n",
      "     |      morphs2str is a function to convert morphlist to str for tree representation\n",
      "     |      for _parse()\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Methods inherited from nltk.corpus.reader.api.SyntaxCorpusReader:\n",
      "     |  \n",
      "     |  parsed_sents(self, fileids=None)\n",
      "     |  \n",
      "     |  raw(self, fileids=None)\n",
      "     |  \n",
      "     |  sents(self, fileids=None)\n",
      "     |  \n",
      "     |  tagged_sents(self, fileids=None, tagset=None)\n",
      "     |  \n",
      "     |  tagged_words(self, fileids=None, tagset=None)\n",
      "     |  \n",
      "     |  words(self, fileids=None)\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Methods inherited from nltk.corpus.reader.api.CorpusReader:\n",
      "     |  \n",
      "     |  __repr__(self)\n",
      "     |      Return repr(self).\n",
      "     |  \n",
      "     |  __unicode__ = __str__(self, /)\n",
      "     |  \n",
      "     |  abspath(self, fileid)\n",
      "     |      Return the absolute path for the given file.\n",
      "     |      \n",
      "     |      :type fileid: str\n",
      "     |      :param fileid: The file identifier for the file whose path\n",
      "     |          should be returned.\n",
      "     |      :rtype: PathPointer\n",
      "     |  \n",
      "     |  abspaths(self, fileids=None, include_encoding=False, include_fileid=False)\n",
      "     |      Return a list of the absolute paths for all fileids in this corpus;\n",
      "     |      or for the given list of fileids, if specified.\n",
      "     |      \n",
      "     |      :type fileids: None or str or list\n",
      "     |      :param fileids: Specifies the set of fileids for which paths should\n",
      "     |          be returned.  Can be None, for all fileids; a list of\n",
      "     |          file identifiers, for a specified set of fileids; or a single\n",
      "     |          file identifier, for a single file.  Note that the return\n",
      "     |          value is always a list of paths, even if ``fileids`` is a\n",
      "     |          single file identifier.\n",
      "     |      \n",
      "     |      :param include_encoding: If true, then return a list of\n",
      "     |          ``(path_pointer, encoding)`` tuples.\n",
      "     |      \n",
      "     |      :rtype: list(PathPointer)\n",
      "     |  \n",
      "     |  citation(self)\n",
      "     |      Return the contents of the corpus citation.bib file, if it exists.\n",
      "     |  \n",
      "     |  encoding(self, file)\n",
      "     |      Return the unicode encoding for the given corpus file, if known.\n",
      "     |      If the encoding is unknown, or if the given file should be\n",
      "     |      processed using byte strings (str), then return None.\n",
      "     |  \n",
      "     |  ensure_loaded(self)\n",
      "     |      Load this corpus (if it has not already been loaded).  This is\n",
      "     |      used by LazyCorpusLoader as a simple method that can be used to\n",
      "     |      make sure a corpus is loaded -- e.g., in case a user wants to\n",
      "     |      do help(some_corpus).\n",
      "     |  \n",
      "     |  fileids(self)\n",
      "     |      Return a list of file identifiers for the fileids that make up\n",
      "     |      this corpus.\n",
      "     |  \n",
      "     |  license(self)\n",
      "     |      Return the contents of the corpus LICENSE file, if it exists.\n",
      "     |  \n",
      "     |  open(self, file)\n",
      "     |      Return an open stream that can be used to read the given file.\n",
      "     |      If the file's encoding is not None, then the stream will\n",
      "     |      automatically decode the file's contents into unicode.\n",
      "     |      \n",
      "     |      :param file: The file identifier of the file to read.\n",
      "     |  \n",
      "     |  readme(self)\n",
      "     |      Return the contents of the corpus README file, if it exists.\n",
      "     |  \n",
      "     |  unicode_repr = __repr__(self)\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Data descriptors inherited from nltk.corpus.reader.api.CorpusReader:\n",
      "     |  \n",
      "     |  __dict__\n",
      "     |      dictionary for instance variables (if defined)\n",
      "     |  \n",
      "     |  __weakref__\n",
      "     |      list of weak references to the object (if defined)\n",
      "     |  \n",
      "     |  root\n",
      "     |      The directory where this corpus is stored.\n",
      "     |      \n",
      "     |      :type: PathPointer\n",
      "    \n",
      "    class LinThesaurusCorpusReader(nltk.corpus.reader.api.CorpusReader)\n",
      "     |  LinThesaurusCorpusReader(root, badscore=0.0)\n",
      "     |  \n",
      "     |  Wrapper for the LISP-formatted thesauruses distributed by Dekang Lin.\n",
      "     |  \n",
      "     |  Method resolution order:\n",
      "     |      LinThesaurusCorpusReader\n",
      "     |      nltk.corpus.reader.api.CorpusReader\n",
      "     |      builtins.object\n",
      "     |  \n",
      "     |  Methods defined here:\n",
      "     |  \n",
      "     |  __contains__(self, ngram)\n",
      "     |      Determines whether or not the given ngram is in the thesaurus.\n",
      "     |      \n",
      "     |      :param ngram: ngram to lookup\n",
      "     |      :type ngram: C{string}\n",
      "     |      :return: whether the given ngram is in the thesaurus.\n",
      "     |  \n",
      "     |  __init__(self, root, badscore=0.0)\n",
      "     |      Initialize the thesaurus.\n",
      "     |      \n",
      "     |      :param root: root directory containing thesaurus LISP files\n",
      "     |      :type root: C{string}\n",
      "     |      :param badscore: the score to give to words which do not appear in each other's sets of synonyms\n",
      "     |      :type badscore: C{float}\n",
      "     |  \n",
      "     |  scored_synonyms(self, ngram, fileid=None)\n",
      "     |      Returns a list of scored synonyms (tuples of synonyms and scores) for the current ngram\n",
      "     |      \n",
      "     |      :param ngram: ngram to lookup\n",
      "     |      :type ngram: C{string}\n",
      "     |      :param fileid: thesaurus fileid to search in. If None, search all fileids.\n",
      "     |      :type fileid: C{string}\n",
      "     |      :return: If fileid is specified, list of tuples of scores and synonyms; otherwise,\n",
      "     |               list of tuples of fileids and lists, where inner lists consist of tuples of\n",
      "     |               scores and synonyms.\n",
      "     |  \n",
      "     |  similarity(self, ngram1, ngram2, fileid=None)\n",
      "     |      Returns the similarity score for two ngrams.\n",
      "     |      \n",
      "     |      :param ngram1: first ngram to compare\n",
      "     |      :type ngram1: C{string}\n",
      "     |      :param ngram2: second ngram to compare\n",
      "     |      :type ngram2: C{string}\n",
      "     |      :param fileid: thesaurus fileid to search in. If None, search all fileids.\n",
      "     |      :type fileid: C{string}\n",
      "     |      :return: If fileid is specified, just the score for the two ngrams; otherwise,\n",
      "     |               list of tuples of fileids and scores.\n",
      "     |  \n",
      "     |  synonyms(self, ngram, fileid=None)\n",
      "     |      Returns a list of synonyms for the current ngram.\n",
      "     |      \n",
      "     |      :param ngram: ngram to lookup\n",
      "     |      :type ngram: C{string}\n",
      "     |      :param fileid: thesaurus fileid to search in. If None, search all fileids.\n",
      "     |      :type fileid: C{string}\n",
      "     |      :return: If fileid is specified, list of synonyms; otherwise, list of tuples of fileids and\n",
      "     |               lists, where inner lists contain synonyms.\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Methods inherited from nltk.corpus.reader.api.CorpusReader:\n",
      "     |  \n",
      "     |  __repr__(self)\n",
      "     |      Return repr(self).\n",
      "     |  \n",
      "     |  __unicode__ = __str__(self, /)\n",
      "     |  \n",
      "     |  abspath(self, fileid)\n",
      "     |      Return the absolute path for the given file.\n",
      "     |      \n",
      "     |      :type fileid: str\n",
      "     |      :param fileid: The file identifier for the file whose path\n",
      "     |          should be returned.\n",
      "     |      :rtype: PathPointer\n",
      "     |  \n",
      "     |  abspaths(self, fileids=None, include_encoding=False, include_fileid=False)\n",
      "     |      Return a list of the absolute paths for all fileids in this corpus;\n",
      "     |      or for the given list of fileids, if specified.\n",
      "     |      \n",
      "     |      :type fileids: None or str or list\n",
      "     |      :param fileids: Specifies the set of fileids for which paths should\n",
      "     |          be returned.  Can be None, for all fileids; a list of\n",
      "     |          file identifiers, for a specified set of fileids; or a single\n",
      "     |          file identifier, for a single file.  Note that the return\n",
      "     |          value is always a list of paths, even if ``fileids`` is a\n",
      "     |          single file identifier.\n",
      "     |      \n",
      "     |      :param include_encoding: If true, then return a list of\n",
      "     |          ``(path_pointer, encoding)`` tuples.\n",
      "     |      \n",
      "     |      :rtype: list(PathPointer)\n",
      "     |  \n",
      "     |  citation(self)\n",
      "     |      Return the contents of the corpus citation.bib file, if it exists.\n",
      "     |  \n",
      "     |  encoding(self, file)\n",
      "     |      Return the unicode encoding for the given corpus file, if known.\n",
      "     |      If the encoding is unknown, or if the given file should be\n",
      "     |      processed using byte strings (str), then return None.\n",
      "     |  \n",
      "     |  ensure_loaded(self)\n",
      "     |      Load this corpus (if it has not already been loaded).  This is\n",
      "     |      used by LazyCorpusLoader as a simple method that can be used to\n",
      "     |      make sure a corpus is loaded -- e.g., in case a user wants to\n",
      "     |      do help(some_corpus).\n",
      "     |  \n",
      "     |  fileids(self)\n",
      "     |      Return a list of file identifiers for the fileids that make up\n",
      "     |      this corpus.\n",
      "     |  \n",
      "     |  license(self)\n",
      "     |      Return the contents of the corpus LICENSE file, if it exists.\n",
      "     |  \n",
      "     |  open(self, file)\n",
      "     |      Return an open stream that can be used to read the given file.\n",
      "     |      If the file's encoding is not None, then the stream will\n",
      "     |      automatically decode the file's contents into unicode.\n",
      "     |      \n",
      "     |      :param file: The file identifier of the file to read.\n",
      "     |  \n",
      "     |  readme(self)\n",
      "     |      Return the contents of the corpus README file, if it exists.\n",
      "     |  \n",
      "     |  unicode_repr = __repr__(self)\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Data descriptors inherited from nltk.corpus.reader.api.CorpusReader:\n",
      "     |  \n",
      "     |  __dict__\n",
      "     |      dictionary for instance variables (if defined)\n",
      "     |  \n",
      "     |  __weakref__\n",
      "     |      list of weak references to the object (if defined)\n",
      "     |  \n",
      "     |  root\n",
      "     |      The directory where this corpus is stored.\n",
      "     |      \n",
      "     |      :type: PathPointer\n",
      "    \n",
      "    class MTECorpusReader(nltk.corpus.reader.tagged.TaggedCorpusReader)\n",
      "     |  MTECorpusReader(root=None, fileids=None, encoding='utf8')\n",
      "     |  \n",
      "     |  Reader for corpora following the TEI-p5 xml scheme, such as MULTEXT-East.\n",
      "     |  MULTEXT-East contains part-of-speech-tagged words with a quite precise tagging\n",
      "     |  scheme. These tags can be converted to the Universal tagset\n",
      "     |  \n",
      "     |  Method resolution order:\n",
      "     |      MTECorpusReader\n",
      "     |      nltk.corpus.reader.tagged.TaggedCorpusReader\n",
      "     |      nltk.corpus.reader.api.CorpusReader\n",
      "     |      builtins.object\n",
      "     |  \n",
      "     |  Methods defined here:\n",
      "     |  \n",
      "     |  __init__(self, root=None, fileids=None, encoding='utf8')\n",
      "     |      Construct a new MTECorpusreader for a set of documents\n",
      "     |      located at the given root directory.  Example usage:\n",
      "     |      \n",
      "     |          >>> root = '/...path to corpus.../'\n",
      "     |          >>> reader = MTECorpusReader(root, 'oana-*.xml', 'utf8') # doctest: +SKIP\n",
      "     |      \n",
      "     |      :param root: The root directory for this corpus. (default points to location in multext config file)\n",
      "     |      :param fileids: A list or regexp specifying the fileids in this corpus. (default is oana-en.xml)\n",
      "     |      :param enconding: The encoding of the given files (default is utf8)\n",
      "     |  \n",
      "     |  lemma_paras(self, fileids=None)\n",
      "     |          :param fileids: A list specifying the fileids that should be used.\n",
      "     |      :return: the given file(s) as a list of paragraphs, each encoded as a\n",
      "     |               list of sentences, which are in turn encoded as a list of\n",
      "     |               tuples of the word and the corresponding lemma (word, lemma)\n",
      "     |      :rtype: list(List(List(tuple(str, str))))\n",
      "     |  \n",
      "     |  lemma_sents(self, fileids=None)\n",
      "     |          :param fileids: A list specifying the fileids that should be used.\n",
      "     |      :return: the given file(s) as a list of sentences or utterances, each\n",
      "     |               encoded as a list of tuples of the word and the corresponding\n",
      "     |               lemma (word, lemma)\n",
      "     |      :rtype: list(list(tuple(str, str)))\n",
      "     |  \n",
      "     |  lemma_words(self, fileids=None)\n",
      "     |          :param fileids: A list specifying the fileids that should be used.\n",
      "     |      :return: the given file(s) as a list of words, the corresponding lemmas\n",
      "     |               and punctuation symbols, encoded as tuples (word, lemma)\n",
      "     |      :rtype: list(tuple(str,str))\n",
      "     |  \n",
      "     |  paras(self, fileids=None)\n",
      "     |          :param fileids: A list specifying the fileids that should be used.\n",
      "     |      :return: the given file(s) as a list of paragraphs, each encoded as a list\n",
      "     |               of sentences, which are in turn encoded as lists of word string\n",
      "     |      :rtype: list(list(list(str)))\n",
      "     |  \n",
      "     |  raw(self, fileids=None)\n",
      "     |          :param fileids: A list specifying the fileids that should be used.\n",
      "     |      :return: the given file(s) as a single string.\n",
      "     |      :rtype: str\n",
      "     |  \n",
      "     |  readme(self)\n",
      "     |      Prints some information about this corpus.\n",
      "     |      :return: the content of the attached README file\n",
      "     |      :rtype: str\n",
      "     |  \n",
      "     |  sents(self, fileids=None)\n",
      "     |          :param fileids: A list specifying the fileids that should be used.\n",
      "     |      :return: the given file(s) as a list of sentences or utterances,\n",
      "     |               each encoded as a list of word strings\n",
      "     |      :rtype: list(list(str))\n",
      "     |  \n",
      "     |  tagged_paras(self, fileids=None, tagset='msd', tags='')\n",
      "     |          :param fileids: A list specifying the fileids that should be used.\n",
      "     |      :param tagset: The tagset that should be used in the returned object,\n",
      "     |                     either \"universal\" or \"msd\", \"msd\" is the default\n",
      "     |      :param tags: An MSD Tag that is used to filter all parts of the used corpus\n",
      "     |                   that are not more precise or at least equal to the given tag\n",
      "     |      :return: the given file(s) as a list of paragraphs, each encoded as a\n",
      "     |               list of sentences, which are in turn encoded as a list\n",
      "     |               of (word,tag) tuples\n",
      "     |      :rtype: list(list(list(tuple(str, str))))\n",
      "     |  \n",
      "     |  tagged_sents(self, fileids=None, tagset='msd', tags='')\n",
      "     |          :param fileids: A list specifying the fileids that should be used.\n",
      "     |      :param tagset: The tagset that should be used in the returned object,\n",
      "     |                     either \"universal\" or \"msd\", \"msd\" is the default\n",
      "     |      :param tags: An MSD Tag that is used to filter all parts of the used corpus\n",
      "     |                   that are not more precise or at least equal to the given tag\n",
      "     |      :return: the given file(s) as a list of sentences or utterances, each\n",
      "     |               each encoded as a list of (word,tag) tuples\n",
      "     |      :rtype: list(list(tuple(str, str)))\n",
      "     |  \n",
      "     |  tagged_words(self, fileids=None, tagset='msd', tags='')\n",
      "     |          :param fileids: A list specifying the fileids that should be used.\n",
      "     |      :param tagset: The tagset that should be used in the returned object,\n",
      "     |                     either \"universal\" or \"msd\", \"msd\" is the default\n",
      "     |      :param tags: An MSD Tag that is used to filter all parts of the used corpus\n",
      "     |                   that are not more precise or at least equal to the given tag\n",
      "     |      :return: the given file(s) as a list of tagged words and punctuation symbols\n",
      "     |               encoded as tuples (word, tag)\n",
      "     |      :rtype: list(tuple(str, str))\n",
      "     |  \n",
      "     |  words(self, fileids=None)\n",
      "     |          :param fileids: A list specifying the fileids that should be used.\n",
      "     |      :return: the given file(s) as a list of words and punctuation symbols.\n",
      "     |      :rtype: list(str)\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Methods inherited from nltk.corpus.reader.api.CorpusReader:\n",
      "     |  \n",
      "     |  __repr__(self)\n",
      "     |      Return repr(self).\n",
      "     |  \n",
      "     |  __unicode__ = __str__(self, /)\n",
      "     |  \n",
      "     |  abspath(self, fileid)\n",
      "     |      Return the absolute path for the given file.\n",
      "     |      \n",
      "     |      :type fileid: str\n",
      "     |      :param fileid: The file identifier for the file whose path\n",
      "     |          should be returned.\n",
      "     |      :rtype: PathPointer\n",
      "     |  \n",
      "     |  abspaths(self, fileids=None, include_encoding=False, include_fileid=False)\n",
      "     |      Return a list of the absolute paths for all fileids in this corpus;\n",
      "     |      or for the given list of fileids, if specified.\n",
      "     |      \n",
      "     |      :type fileids: None or str or list\n",
      "     |      :param fileids: Specifies the set of fileids for which paths should\n",
      "     |          be returned.  Can be None, for all fileids; a list of\n",
      "     |          file identifiers, for a specified set of fileids; or a single\n",
      "     |          file identifier, for a single file.  Note that the return\n",
      "     |          value is always a list of paths, even if ``fileids`` is a\n",
      "     |          single file identifier.\n",
      "     |      \n",
      "     |      :param include_encoding: If true, then return a list of\n",
      "     |          ``(path_pointer, encoding)`` tuples.\n",
      "     |      \n",
      "     |      :rtype: list(PathPointer)\n",
      "     |  \n",
      "     |  citation(self)\n",
      "     |      Return the contents of the corpus citation.bib file, if it exists.\n",
      "     |  \n",
      "     |  encoding(self, file)\n",
      "     |      Return the unicode encoding for the given corpus file, if known.\n",
      "     |      If the encoding is unknown, or if the given file should be\n",
      "     |      processed using byte strings (str), then return None.\n",
      "     |  \n",
      "     |  ensure_loaded(self)\n",
      "     |      Load this corpus (if it has not already been loaded).  This is\n",
      "     |      used by LazyCorpusLoader as a simple method that can be used to\n",
      "     |      make sure a corpus is loaded -- e.g., in case a user wants to\n",
      "     |      do help(some_corpus).\n",
      "     |  \n",
      "     |  fileids(self)\n",
      "     |      Return a list of file identifiers for the fileids that make up\n",
      "     |      this corpus.\n",
      "     |  \n",
      "     |  license(self)\n",
      "     |      Return the contents of the corpus LICENSE file, if it exists.\n",
      "     |  \n",
      "     |  open(self, file)\n",
      "     |      Return an open stream that can be used to read the given file.\n",
      "     |      If the file's encoding is not None, then the stream will\n",
      "     |      automatically decode the file's contents into unicode.\n",
      "     |      \n",
      "     |      :param file: The file identifier of the file to read.\n",
      "     |  \n",
      "     |  unicode_repr = __repr__(self)\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Data descriptors inherited from nltk.corpus.reader.api.CorpusReader:\n",
      "     |  \n",
      "     |  __dict__\n",
      "     |      dictionary for instance variables (if defined)\n",
      "     |  \n",
      "     |  __weakref__\n",
      "     |      list of weak references to the object (if defined)\n",
      "     |  \n",
      "     |  root\n",
      "     |      The directory where this corpus is stored.\n",
      "     |      \n",
      "     |      :type: PathPointer\n",
      "    \n",
      "    class MWAPPDBCorpusReader(WordListCorpusReader)\n",
      "     |  MWAPPDBCorpusReader(root, fileids, encoding='utf8', tagset=None)\n",
      "     |  \n",
      "     |  This class is used to read the list of word pairs from the subset of lexical\n",
      "     |  pairs of The Paraphrase Database (PPDB) XXXL used in the Monolingual Word\n",
      "     |  Alignment (MWA) algorithm described in Sultan et al. (2014a, 2014b, 2015):\n",
      "     |   - http://acl2014.org/acl2014/Q14/pdf/Q14-1017\n",
      "     |   - http://www.aclweb.org/anthology/S14-2039\n",
      "     |   - http://www.aclweb.org/anthology/S15-2027\n",
      "     |  \n",
      "     |  The original source of the full PPDB corpus can be found on\n",
      "     |  http://www.cis.upenn.edu/~ccb/ppdb/\n",
      "     |  \n",
      "     |  :return: a list of tuples of similar lexical terms.\n",
      "     |  \n",
      "     |  Method resolution order:\n",
      "     |      MWAPPDBCorpusReader\n",
      "     |      WordListCorpusReader\n",
      "     |      nltk.corpus.reader.api.CorpusReader\n",
      "     |      builtins.object\n",
      "     |  \n",
      "     |  Methods defined here:\n",
      "     |  \n",
      "     |  entries(self, fileids='ppdb-1.0-xxxl-lexical.extended.synonyms.uniquepairs')\n",
      "     |      :return: a tuple of synonym word pairs.\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Data and other attributes defined here:\n",
      "     |  \n",
      "     |  mwa_ppdb_xxxl_file = 'ppdb-1.0-xxxl-lexical.extended.synonyms.uniquepa...\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Methods inherited from WordListCorpusReader:\n",
      "     |  \n",
      "     |  raw(self, fileids=None)\n",
      "     |  \n",
      "     |  words(self, fileids=None, ignore_lines_startswith='\\n')\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Methods inherited from nltk.corpus.reader.api.CorpusReader:\n",
      "     |  \n",
      "     |  __init__(self, root, fileids, encoding='utf8', tagset=None)\n",
      "     |      :type root: PathPointer or str\n",
      "     |      :param root: A path pointer identifying the root directory for\n",
      "     |          this corpus.  If a string is specified, then it will be\n",
      "     |          converted to a ``PathPointer`` automatically.\n",
      "     |      :param fileids: A list of the files that make up this corpus.\n",
      "     |          This list can either be specified explicitly, as a list of\n",
      "     |          strings; or implicitly, as a regular expression over file\n",
      "     |          paths.  The absolute path for each file will be constructed\n",
      "     |          by joining the reader's root to each file name.\n",
      "     |      :param encoding: The default unicode encoding for the files\n",
      "     |          that make up the corpus.  The value of ``encoding`` can be any\n",
      "     |          of the following:\n",
      "     |          - A string: ``encoding`` is the encoding name for all files.\n",
      "     |          - A dictionary: ``encoding[file_id]`` is the encoding\n",
      "     |            name for the file whose identifier is ``file_id``.  If\n",
      "     |            ``file_id`` is not in ``encoding``, then the file\n",
      "     |            contents will be processed using non-unicode byte strings.\n",
      "     |          - A list: ``encoding`` should be a list of ``(regexp, encoding)``\n",
      "     |            tuples.  The encoding for a file whose identifier is ``file_id``\n",
      "     |            will be the ``encoding`` value for the first tuple whose\n",
      "     |            ``regexp`` matches the ``file_id``.  If no tuple's ``regexp``\n",
      "     |            matches the ``file_id``, the file contents will be processed\n",
      "     |            using non-unicode byte strings.\n",
      "     |          - None: the file contents of all files will be\n",
      "     |            processed using non-unicode byte strings.\n",
      "     |      :param tagset: The name of the tagset used by this corpus, to be used\n",
      "     |            for normalizing or converting the POS tags returned by the\n",
      "     |            tagged_...() methods.\n",
      "     |  \n",
      "     |  __repr__(self)\n",
      "     |      Return repr(self).\n",
      "     |  \n",
      "     |  __unicode__ = __str__(self, /)\n",
      "     |  \n",
      "     |  abspath(self, fileid)\n",
      "     |      Return the absolute path for the given file.\n",
      "     |      \n",
      "     |      :type fileid: str\n",
      "     |      :param fileid: The file identifier for the file whose path\n",
      "     |          should be returned.\n",
      "     |      :rtype: PathPointer\n",
      "     |  \n",
      "     |  abspaths(self, fileids=None, include_encoding=False, include_fileid=False)\n",
      "     |      Return a list of the absolute paths for all fileids in this corpus;\n",
      "     |      or for the given list of fileids, if specified.\n",
      "     |      \n",
      "     |      :type fileids: None or str or list\n",
      "     |      :param fileids: Specifies the set of fileids for which paths should\n",
      "     |          be returned.  Can be None, for all fileids; a list of\n",
      "     |          file identifiers, for a specified set of fileids; or a single\n",
      "     |          file identifier, for a single file.  Note that the return\n",
      "     |          value is always a list of paths, even if ``fileids`` is a\n",
      "     |          single file identifier.\n",
      "     |      \n",
      "     |      :param include_encoding: If true, then return a list of\n",
      "     |          ``(path_pointer, encoding)`` tuples.\n",
      "     |      \n",
      "     |      :rtype: list(PathPointer)\n",
      "     |  \n",
      "     |  citation(self)\n",
      "     |      Return the contents of the corpus citation.bib file, if it exists.\n",
      "     |  \n",
      "     |  encoding(self, file)\n",
      "     |      Return the unicode encoding for the given corpus file, if known.\n",
      "     |      If the encoding is unknown, or if the given file should be\n",
      "     |      processed using byte strings (str), then return None.\n",
      "     |  \n",
      "     |  ensure_loaded(self)\n",
      "     |      Load this corpus (if it has not already been loaded).  This is\n",
      "     |      used by LazyCorpusLoader as a simple method that can be used to\n",
      "     |      make sure a corpus is loaded -- e.g., in case a user wants to\n",
      "     |      do help(some_corpus).\n",
      "     |  \n",
      "     |  fileids(self)\n",
      "     |      Return a list of file identifiers for the fileids that make up\n",
      "     |      this corpus.\n",
      "     |  \n",
      "     |  license(self)\n",
      "     |      Return the contents of the corpus LICENSE file, if it exists.\n",
      "     |  \n",
      "     |  open(self, file)\n",
      "     |      Return an open stream that can be used to read the given file.\n",
      "     |      If the file's encoding is not None, then the stream will\n",
      "     |      automatically decode the file's contents into unicode.\n",
      "     |      \n",
      "     |      :param file: The file identifier of the file to read.\n",
      "     |  \n",
      "     |  readme(self)\n",
      "     |      Return the contents of the corpus README file, if it exists.\n",
      "     |  \n",
      "     |  unicode_repr = __repr__(self)\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Data descriptors inherited from nltk.corpus.reader.api.CorpusReader:\n",
      "     |  \n",
      "     |  __dict__\n",
      "     |      dictionary for instance variables (if defined)\n",
      "     |  \n",
      "     |  __weakref__\n",
      "     |      list of weak references to the object (if defined)\n",
      "     |  \n",
      "     |  root\n",
      "     |      The directory where this corpus is stored.\n",
      "     |      \n",
      "     |      :type: PathPointer\n",
      "    \n",
      "    class MacMorphoCorpusReader(TaggedCorpusReader)\n",
      "     |  MacMorphoCorpusReader(root, fileids, encoding='utf8', tagset=None)\n",
      "     |  \n",
      "     |  A corpus reader for the MAC_MORPHO corpus.  Each line contains a\n",
      "     |  single tagged word, using '_' as a separator.  Sentence boundaries\n",
      "     |  are based on the end-sentence tag ('_.').  Paragraph information\n",
      "     |  is not included in the corpus, so each paragraph returned by\n",
      "     |  ``self.paras()`` and ``self.tagged_paras()`` contains a single\n",
      "     |  sentence.\n",
      "     |  \n",
      "     |  Method resolution order:\n",
      "     |      MacMorphoCorpusReader\n",
      "     |      TaggedCorpusReader\n",
      "     |      nltk.corpus.reader.api.CorpusReader\n",
      "     |      builtins.object\n",
      "     |  \n",
      "     |  Methods defined here:\n",
      "     |  \n",
      "     |  __init__(self, root, fileids, encoding='utf8', tagset=None)\n",
      "     |      Construct a new Tagged Corpus reader for a set of documents\n",
      "     |      located at the given root directory.  Example usage:\n",
      "     |      \n",
      "     |          >>> root = '/...path to corpus.../'\n",
      "     |          >>> reader = TaggedCorpusReader(root, '.*', '.txt') # doctest: +SKIP\n",
      "     |      \n",
      "     |      :param root: The root directory for this corpus.\n",
      "     |      :param fileids: A list or regexp specifying the fileids in this corpus.\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Methods inherited from TaggedCorpusReader:\n",
      "     |  \n",
      "     |  paras(self, fileids=None)\n",
      "     |      :return: the given file(s) as a list of\n",
      "     |          paragraphs, each encoded as a list of sentences, which are\n",
      "     |          in turn encoded as lists of word strings.\n",
      "     |      :rtype: list(list(list(str)))\n",
      "     |  \n",
      "     |  raw(self, fileids=None)\n",
      "     |      :return: the given file(s) as a single string.\n",
      "     |      :rtype: str\n",
      "     |  \n",
      "     |  sents(self, fileids=None)\n",
      "     |      :return: the given file(s) as a list of\n",
      "     |          sentences or utterances, each encoded as a list of word\n",
      "     |          strings.\n",
      "     |      :rtype: list(list(str))\n",
      "     |  \n",
      "     |  tagged_paras(self, fileids=None, tagset=None)\n",
      "     |      :return: the given file(s) as a list of\n",
      "     |          paragraphs, each encoded as a list of sentences, which are\n",
      "     |          in turn encoded as lists of ``(word,tag)`` tuples.\n",
      "     |      :rtype: list(list(list(tuple(str,str))))\n",
      "     |  \n",
      "     |  tagged_sents(self, fileids=None, tagset=None)\n",
      "     |      :return: the given file(s) as a list of\n",
      "     |          sentences, each encoded as a list of ``(word,tag)`` tuples.\n",
      "     |      \n",
      "     |      :rtype: list(list(tuple(str,str)))\n",
      "     |  \n",
      "     |  tagged_words(self, fileids=None, tagset=None)\n",
      "     |      :return: the given file(s) as a list of tagged\n",
      "     |          words and punctuation symbols, encoded as tuples\n",
      "     |          ``(word,tag)``.\n",
      "     |      :rtype: list(tuple(str,str))\n",
      "     |  \n",
      "     |  words(self, fileids=None)\n",
      "     |      :return: the given file(s) as a list of words\n",
      "     |          and punctuation symbols.\n",
      "     |      :rtype: list(str)\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Methods inherited from nltk.corpus.reader.api.CorpusReader:\n",
      "     |  \n",
      "     |  __repr__(self)\n",
      "     |      Return repr(self).\n",
      "     |  \n",
      "     |  __unicode__ = __str__(self, /)\n",
      "     |  \n",
      "     |  abspath(self, fileid)\n",
      "     |      Return the absolute path for the given file.\n",
      "     |      \n",
      "     |      :type fileid: str\n",
      "     |      :param fileid: The file identifier for the file whose path\n",
      "     |          should be returned.\n",
      "     |      :rtype: PathPointer\n",
      "     |  \n",
      "     |  abspaths(self, fileids=None, include_encoding=False, include_fileid=False)\n",
      "     |      Return a list of the absolute paths for all fileids in this corpus;\n",
      "     |      or for the given list of fileids, if specified.\n",
      "     |      \n",
      "     |      :type fileids: None or str or list\n",
      "     |      :param fileids: Specifies the set of fileids for which paths should\n",
      "     |          be returned.  Can be None, for all fileids; a list of\n",
      "     |          file identifiers, for a specified set of fileids; or a single\n",
      "     |          file identifier, for a single file.  Note that the return\n",
      "     |          value is always a list of paths, even if ``fileids`` is a\n",
      "     |          single file identifier.\n",
      "     |      \n",
      "     |      :param include_encoding: If true, then return a list of\n",
      "     |          ``(path_pointer, encoding)`` tuples.\n",
      "     |      \n",
      "     |      :rtype: list(PathPointer)\n",
      "     |  \n",
      "     |  citation(self)\n",
      "     |      Return the contents of the corpus citation.bib file, if it exists.\n",
      "     |  \n",
      "     |  encoding(self, file)\n",
      "     |      Return the unicode encoding for the given corpus file, if known.\n",
      "     |      If the encoding is unknown, or if the given file should be\n",
      "     |      processed using byte strings (str), then return None.\n",
      "     |  \n",
      "     |  ensure_loaded(self)\n",
      "     |      Load this corpus (if it has not already been loaded).  This is\n",
      "     |      used by LazyCorpusLoader as a simple method that can be used to\n",
      "     |      make sure a corpus is loaded -- e.g., in case a user wants to\n",
      "     |      do help(some_corpus).\n",
      "     |  \n",
      "     |  fileids(self)\n",
      "     |      Return a list of file identifiers for the fileids that make up\n",
      "     |      this corpus.\n",
      "     |  \n",
      "     |  license(self)\n",
      "     |      Return the contents of the corpus LICENSE file, if it exists.\n",
      "     |  \n",
      "     |  open(self, file)\n",
      "     |      Return an open stream that can be used to read the given file.\n",
      "     |      If the file's encoding is not None, then the stream will\n",
      "     |      automatically decode the file's contents into unicode.\n",
      "     |      \n",
      "     |      :param file: The file identifier of the file to read.\n",
      "     |  \n",
      "     |  readme(self)\n",
      "     |      Return the contents of the corpus README file, if it exists.\n",
      "     |  \n",
      "     |  unicode_repr = __repr__(self)\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Data descriptors inherited from nltk.corpus.reader.api.CorpusReader:\n",
      "     |  \n",
      "     |  __dict__\n",
      "     |      dictionary for instance variables (if defined)\n",
      "     |  \n",
      "     |  __weakref__\n",
      "     |      list of weak references to the object (if defined)\n",
      "     |  \n",
      "     |  root\n",
      "     |      The directory where this corpus is stored.\n",
      "     |      \n",
      "     |      :type: PathPointer\n",
      "    \n",
      "    class NKJPCorpusReader(nltk.corpus.reader.xmldocs.XMLCorpusReader)\n",
      "     |  NKJPCorpusReader(root, fileids='.*')\n",
      "     |  \n",
      "     |  Corpus reader for corpora whose documents are xml files.\n",
      "     |  \n",
      "     |  Note that the ``XMLCorpusReader`` constructor does not take an\n",
      "     |  ``encoding`` argument, because the unicode encoding is specified by\n",
      "     |  the XML files themselves.  See the XML specs for more info.\n",
      "     |  \n",
      "     |  Method resolution order:\n",
      "     |      NKJPCorpusReader\n",
      "     |      nltk.corpus.reader.xmldocs.XMLCorpusReader\n",
      "     |      nltk.corpus.reader.api.CorpusReader\n",
      "     |      builtins.object\n",
      "     |  \n",
      "     |  Methods defined here:\n",
      "     |  \n",
      "     |  __init__(self, root, fileids='.*')\n",
      "     |      Corpus reader designed to work with National Corpus of Polish.\n",
      "     |      See http://nkjp.pl/ for more details about NKJP.\n",
      "     |      use example:\n",
      "     |      import nltk\n",
      "     |      import nkjp\n",
      "     |      from nkjp import NKJPCorpusReader\n",
      "     |      x = NKJPCorpusReader(root='/home/USER/nltk_data/corpora/nkjp/', fileids='') # obtain the whole corpus\n",
      "     |      x.header()\n",
      "     |      x.raw()\n",
      "     |      x.words()\n",
      "     |      x.tagged_words(tags=['subst', 'comp'])  #Link to find more tags: nkjp.pl/poliqarp/help/ense2.html\n",
      "     |      x.sents()\n",
      "     |      x = NKJPCorpusReader(root='/home/USER/nltk_data/corpora/nkjp/', fileids='Wilk*') # obtain particular file(s)\n",
      "     |      x.header(fileids=['WilkDom', '/home/USER/nltk_data/corpora/nkjp/WilkWilczy'])\n",
      "     |      x.tagged_words(fileids=['WilkDom', '/home/USER/nltk_data/corpora/nkjp/WilkWilczy'], tags=['subst', 'comp'])\n",
      "     |  \n",
      "     |  add_root(self, fileid)\n",
      "     |      Add root if necessary to specified fileid.\n",
      "     |  \n",
      "     |  fileids(self)\n",
      "     |      Returns a list of file identifiers for the fileids that make up\n",
      "     |      this corpus.\n",
      "     |  \n",
      "     |  get_paths(self)\n",
      "     |  \n",
      "     |  header(self, fileids=None, **kwargs)\n",
      "     |      Returns header(s) of specified fileids.\n",
      "     |  \n",
      "     |  raw(self, fileids=None, **kwargs)\n",
      "     |      Returns words in specified fileids.\n",
      "     |  \n",
      "     |  sents(self, fileids=None, **kwargs)\n",
      "     |      Returns sentences in specified fileids.\n",
      "     |  \n",
      "     |  tagged_words(self, fileids=None, **kwargs)\n",
      "     |      Call with specified tags as a list, e.g. tags=['subst', 'comp'].\n",
      "     |      Returns tagged words in specified fileids.\n",
      "     |  \n",
      "     |  words(self, fileids=None, **kwargs)\n",
      "     |      Returns words in specified fileids.\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Data and other attributes defined here:\n",
      "     |  \n",
      "     |  HEADER_MODE = 2\n",
      "     |  \n",
      "     |  RAW_MODE = 3\n",
      "     |  \n",
      "     |  SENTS_MODE = 1\n",
      "     |  \n",
      "     |  WORDS_MODE = 0\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Methods inherited from nltk.corpus.reader.xmldocs.XMLCorpusReader:\n",
      "     |  \n",
      "     |  xml(self, fileid=None)\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Methods inherited from nltk.corpus.reader.api.CorpusReader:\n",
      "     |  \n",
      "     |  __repr__(self)\n",
      "     |      Return repr(self).\n",
      "     |  \n",
      "     |  __unicode__ = __str__(self, /)\n",
      "     |  \n",
      "     |  abspath(self, fileid)\n",
      "     |      Return the absolute path for the given file.\n",
      "     |      \n",
      "     |      :type fileid: str\n",
      "     |      :param fileid: The file identifier for the file whose path\n",
      "     |          should be returned.\n",
      "     |      :rtype: PathPointer\n",
      "     |  \n",
      "     |  abspaths(self, fileids=None, include_encoding=False, include_fileid=False)\n",
      "     |      Return a list of the absolute paths for all fileids in this corpus;\n",
      "     |      or for the given list of fileids, if specified.\n",
      "     |      \n",
      "     |      :type fileids: None or str or list\n",
      "     |      :param fileids: Specifies the set of fileids for which paths should\n",
      "     |          be returned.  Can be None, for all fileids; a list of\n",
      "     |          file identifiers, for a specified set of fileids; or a single\n",
      "     |          file identifier, for a single file.  Note that the return\n",
      "     |          value is always a list of paths, even if ``fileids`` is a\n",
      "     |          single file identifier.\n",
      "     |      \n",
      "     |      :param include_encoding: If true, then return a list of\n",
      "     |          ``(path_pointer, encoding)`` tuples.\n",
      "     |      \n",
      "     |      :rtype: list(PathPointer)\n",
      "     |  \n",
      "     |  citation(self)\n",
      "     |      Return the contents of the corpus citation.bib file, if it exists.\n",
      "     |  \n",
      "     |  encoding(self, file)\n",
      "     |      Return the unicode encoding for the given corpus file, if known.\n",
      "     |      If the encoding is unknown, or if the given file should be\n",
      "     |      processed using byte strings (str), then return None.\n",
      "     |  \n",
      "     |  ensure_loaded(self)\n",
      "     |      Load this corpus (if it has not already been loaded).  This is\n",
      "     |      used by LazyCorpusLoader as a simple method that can be used to\n",
      "     |      make sure a corpus is loaded -- e.g., in case a user wants to\n",
      "     |      do help(some_corpus).\n",
      "     |  \n",
      "     |  license(self)\n",
      "     |      Return the contents of the corpus LICENSE file, if it exists.\n",
      "     |  \n",
      "     |  open(self, file)\n",
      "     |      Return an open stream that can be used to read the given file.\n",
      "     |      If the file's encoding is not None, then the stream will\n",
      "     |      automatically decode the file's contents into unicode.\n",
      "     |      \n",
      "     |      :param file: The file identifier of the file to read.\n",
      "     |  \n",
      "     |  readme(self)\n",
      "     |      Return the contents of the corpus README file, if it exists.\n",
      "     |  \n",
      "     |  unicode_repr = __repr__(self)\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Data descriptors inherited from nltk.corpus.reader.api.CorpusReader:\n",
      "     |  \n",
      "     |  __dict__\n",
      "     |      dictionary for instance variables (if defined)\n",
      "     |  \n",
      "     |  __weakref__\n",
      "     |      list of weak references to the object (if defined)\n",
      "     |  \n",
      "     |  root\n",
      "     |      The directory where this corpus is stored.\n",
      "     |      \n",
      "     |      :type: PathPointer\n",
      "    \n",
      "    class NPSChatCorpusReader(nltk.corpus.reader.xmldocs.XMLCorpusReader)\n",
      "     |  NPSChatCorpusReader(root, fileids, wrap_etree=False, tagset=None)\n",
      "     |  \n",
      "     |  Corpus reader for corpora whose documents are xml files.\n",
      "     |  \n",
      "     |  Note that the ``XMLCorpusReader`` constructor does not take an\n",
      "     |  ``encoding`` argument, because the unicode encoding is specified by\n",
      "     |  the XML files themselves.  See the XML specs for more info.\n",
      "     |  \n",
      "     |  Method resolution order:\n",
      "     |      NPSChatCorpusReader\n",
      "     |      nltk.corpus.reader.xmldocs.XMLCorpusReader\n",
      "     |      nltk.corpus.reader.api.CorpusReader\n",
      "     |      builtins.object\n",
      "     |  \n",
      "     |  Methods defined here:\n",
      "     |  \n",
      "     |  __init__(self, root, fileids, wrap_etree=False, tagset=None)\n",
      "     |      :type root: PathPointer or str\n",
      "     |      :param root: A path pointer identifying the root directory for\n",
      "     |          this corpus.  If a string is specified, then it will be\n",
      "     |          converted to a ``PathPointer`` automatically.\n",
      "     |      :param fileids: A list of the files that make up this corpus.\n",
      "     |          This list can either be specified explicitly, as a list of\n",
      "     |          strings; or implicitly, as a regular expression over file\n",
      "     |          paths.  The absolute path for each file will be constructed\n",
      "     |          by joining the reader's root to each file name.\n",
      "     |      :param encoding: The default unicode encoding for the files\n",
      "     |          that make up the corpus.  The value of ``encoding`` can be any\n",
      "     |          of the following:\n",
      "     |          - A string: ``encoding`` is the encoding name for all files.\n",
      "     |          - A dictionary: ``encoding[file_id]`` is the encoding\n",
      "     |            name for the file whose identifier is ``file_id``.  If\n",
      "     |            ``file_id`` is not in ``encoding``, then the file\n",
      "     |            contents will be processed using non-unicode byte strings.\n",
      "     |          - A list: ``encoding`` should be a list of ``(regexp, encoding)``\n",
      "     |            tuples.  The encoding for a file whose identifier is ``file_id``\n",
      "     |            will be the ``encoding`` value for the first tuple whose\n",
      "     |            ``regexp`` matches the ``file_id``.  If no tuple's ``regexp``\n",
      "     |            matches the ``file_id``, the file contents will be processed\n",
      "     |            using non-unicode byte strings.\n",
      "     |          - None: the file contents of all files will be\n",
      "     |            processed using non-unicode byte strings.\n",
      "     |      :param tagset: The name of the tagset used by this corpus, to be used\n",
      "     |            for normalizing or converting the POS tags returned by the\n",
      "     |            tagged_...() methods.\n",
      "     |  \n",
      "     |  posts(self, fileids=None)\n",
      "     |  \n",
      "     |  tagged_posts(self, fileids=None, tagset=None)\n",
      "     |  \n",
      "     |  tagged_words(self, fileids=None, tagset=None)\n",
      "     |  \n",
      "     |  words(self, fileids=None)\n",
      "     |      Returns all of the words and punctuation symbols in the specified file\n",
      "     |      that were in text nodes -- ie, tags are ignored. Like the xml() method,\n",
      "     |      fileid can only specify one file.\n",
      "     |      \n",
      "     |      :return: the given file's text nodes as a list of words and punctuation symbols\n",
      "     |      :rtype: list(str)\n",
      "     |  \n",
      "     |  xml_posts(self, fileids=None)\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Methods inherited from nltk.corpus.reader.xmldocs.XMLCorpusReader:\n",
      "     |  \n",
      "     |  raw(self, fileids=None)\n",
      "     |  \n",
      "     |  xml(self, fileid=None)\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Methods inherited from nltk.corpus.reader.api.CorpusReader:\n",
      "     |  \n",
      "     |  __repr__(self)\n",
      "     |      Return repr(self).\n",
      "     |  \n",
      "     |  __unicode__ = __str__(self, /)\n",
      "     |  \n",
      "     |  abspath(self, fileid)\n",
      "     |      Return the absolute path for the given file.\n",
      "     |      \n",
      "     |      :type fileid: str\n",
      "     |      :param fileid: The file identifier for the file whose path\n",
      "     |          should be returned.\n",
      "     |      :rtype: PathPointer\n",
      "     |  \n",
      "     |  abspaths(self, fileids=None, include_encoding=False, include_fileid=False)\n",
      "     |      Return a list of the absolute paths for all fileids in this corpus;\n",
      "     |      or for the given list of fileids, if specified.\n",
      "     |      \n",
      "     |      :type fileids: None or str or list\n",
      "     |      :param fileids: Specifies the set of fileids for which paths should\n",
      "     |          be returned.  Can be None, for all fileids; a list of\n",
      "     |          file identifiers, for a specified set of fileids; or a single\n",
      "     |          file identifier, for a single file.  Note that the return\n",
      "     |          value is always a list of paths, even if ``fileids`` is a\n",
      "     |          single file identifier.\n",
      "     |      \n",
      "     |      :param include_encoding: If true, then return a list of\n",
      "     |          ``(path_pointer, encoding)`` tuples.\n",
      "     |      \n",
      "     |      :rtype: list(PathPointer)\n",
      "     |  \n",
      "     |  citation(self)\n",
      "     |      Return the contents of the corpus citation.bib file, if it exists.\n",
      "     |  \n",
      "     |  encoding(self, file)\n",
      "     |      Return the unicode encoding for the given corpus file, if known.\n",
      "     |      If the encoding is unknown, or if the given file should be\n",
      "     |      processed using byte strings (str), then return None.\n",
      "     |  \n",
      "     |  ensure_loaded(self)\n",
      "     |      Load this corpus (if it has not already been loaded).  This is\n",
      "     |      used by LazyCorpusLoader as a simple method that can be used to\n",
      "     |      make sure a corpus is loaded -- e.g., in case a user wants to\n",
      "     |      do help(some_corpus).\n",
      "     |  \n",
      "     |  fileids(self)\n",
      "     |      Return a list of file identifiers for the fileids that make up\n",
      "     |      this corpus.\n",
      "     |  \n",
      "     |  license(self)\n",
      "     |      Return the contents of the corpus LICENSE file, if it exists.\n",
      "     |  \n",
      "     |  open(self, file)\n",
      "     |      Return an open stream that can be used to read the given file.\n",
      "     |      If the file's encoding is not None, then the stream will\n",
      "     |      automatically decode the file's contents into unicode.\n",
      "     |      \n",
      "     |      :param file: The file identifier of the file to read.\n",
      "     |  \n",
      "     |  readme(self)\n",
      "     |      Return the contents of the corpus README file, if it exists.\n",
      "     |  \n",
      "     |  unicode_repr = __repr__(self)\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Data descriptors inherited from nltk.corpus.reader.api.CorpusReader:\n",
      "     |  \n",
      "     |  __dict__\n",
      "     |      dictionary for instance variables (if defined)\n",
      "     |  \n",
      "     |  __weakref__\n",
      "     |      list of weak references to the object (if defined)\n",
      "     |  \n",
      "     |  root\n",
      "     |      The directory where this corpus is stored.\n",
      "     |      \n",
      "     |      :type: PathPointer\n",
      "    \n",
      "    class NombankCorpusReader(nltk.corpus.reader.api.CorpusReader)\n",
      "     |  NombankCorpusReader(root, nomfile, framefiles='', nounsfile=None, parse_fileid_xform=None, parse_corpus=None, encoding='utf8')\n",
      "     |  \n",
      "     |  Corpus reader for the nombank corpus, which augments the Penn\n",
      "     |  Treebank with information about the predicate argument structure\n",
      "     |  of every noun instance.  The corpus consists of two parts: the\n",
      "     |  predicate-argument annotations themselves, and a set of \"frameset\n",
      "     |  files\" which define the argument labels used by the annotations,\n",
      "     |  on a per-noun basis.  Each \"frameset file\" contains one or more\n",
      "     |  predicates, such as ``'turn'`` or ``'turn_on'``, each of which is\n",
      "     |  divided into coarse-grained word senses called \"rolesets\".  For\n",
      "     |  each \"roleset\", the frameset file provides descriptions of the\n",
      "     |  argument roles, along with examples.\n",
      "     |  \n",
      "     |  Method resolution order:\n",
      "     |      NombankCorpusReader\n",
      "     |      nltk.corpus.reader.api.CorpusReader\n",
      "     |      builtins.object\n",
      "     |  \n",
      "     |  Methods defined here:\n",
      "     |  \n",
      "     |  __init__(self, root, nomfile, framefiles='', nounsfile=None, parse_fileid_xform=None, parse_corpus=None, encoding='utf8')\n",
      "     |      :param root: The root directory for this corpus.\n",
      "     |      :param nomfile: The name of the file containing the predicate-\n",
      "     |          argument annotations (relative to ``root``).\n",
      "     |      :param framefiles: A list or regexp specifying the frameset\n",
      "     |          fileids for this corpus.\n",
      "     |      :param parse_fileid_xform: A transform that should be applied\n",
      "     |          to the fileids in this corpus.  This should be a function\n",
      "     |          of one argument (a fileid) that returns a string (the new\n",
      "     |          fileid).\n",
      "     |      :param parse_corpus: The corpus containing the parse trees\n",
      "     |          corresponding to this corpus.  These parse trees are\n",
      "     |          necessary to resolve the tree pointers used by nombank.\n",
      "     |  \n",
      "     |  instances(self, baseform=None)\n",
      "     |      :return: a corpus view that acts as a list of\n",
      "     |      ``NombankInstance`` objects, one for each noun in the corpus.\n",
      "     |  \n",
      "     |  lines(self)\n",
      "     |      :return: a corpus view that acts as a list of strings, one for\n",
      "     |      each line in the predicate-argument annotation file.\n",
      "     |  \n",
      "     |  nouns(self)\n",
      "     |      :return: a corpus view that acts as a list of all noun lemmas\n",
      "     |      in this corpus (from the nombank.1.0.words file).\n",
      "     |  \n",
      "     |  raw(self, fileids=None)\n",
      "     |      :return: the text contents of the given fileids, as a single string.\n",
      "     |  \n",
      "     |  roleset(self, roleset_id)\n",
      "     |      :return: the xml description for the given roleset.\n",
      "     |  \n",
      "     |  rolesets(self, baseform=None)\n",
      "     |      :return: list of xml descriptions for rolesets.\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Methods inherited from nltk.corpus.reader.api.CorpusReader:\n",
      "     |  \n",
      "     |  __repr__(self)\n",
      "     |      Return repr(self).\n",
      "     |  \n",
      "     |  __unicode__ = __str__(self, /)\n",
      "     |  \n",
      "     |  abspath(self, fileid)\n",
      "     |      Return the absolute path for the given file.\n",
      "     |      \n",
      "     |      :type fileid: str\n",
      "     |      :param fileid: The file identifier for the file whose path\n",
      "     |          should be returned.\n",
      "     |      :rtype: PathPointer\n",
      "     |  \n",
      "     |  abspaths(self, fileids=None, include_encoding=False, include_fileid=False)\n",
      "     |      Return a list of the absolute paths for all fileids in this corpus;\n",
      "     |      or for the given list of fileids, if specified.\n",
      "     |      \n",
      "     |      :type fileids: None or str or list\n",
      "     |      :param fileids: Specifies the set of fileids for which paths should\n",
      "     |          be returned.  Can be None, for all fileids; a list of\n",
      "     |          file identifiers, for a specified set of fileids; or a single\n",
      "     |          file identifier, for a single file.  Note that the return\n",
      "     |          value is always a list of paths, even if ``fileids`` is a\n",
      "     |          single file identifier.\n",
      "     |      \n",
      "     |      :param include_encoding: If true, then return a list of\n",
      "     |          ``(path_pointer, encoding)`` tuples.\n",
      "     |      \n",
      "     |      :rtype: list(PathPointer)\n",
      "     |  \n",
      "     |  citation(self)\n",
      "     |      Return the contents of the corpus citation.bib file, if it exists.\n",
      "     |  \n",
      "     |  encoding(self, file)\n",
      "     |      Return the unicode encoding for the given corpus file, if known.\n",
      "     |      If the encoding is unknown, or if the given file should be\n",
      "     |      processed using byte strings (str), then return None.\n",
      "     |  \n",
      "     |  ensure_loaded(self)\n",
      "     |      Load this corpus (if it has not already been loaded).  This is\n",
      "     |      used by LazyCorpusLoader as a simple method that can be used to\n",
      "     |      make sure a corpus is loaded -- e.g., in case a user wants to\n",
      "     |      do help(some_corpus).\n",
      "     |  \n",
      "     |  fileids(self)\n",
      "     |      Return a list of file identifiers for the fileids that make up\n",
      "     |      this corpus.\n",
      "     |  \n",
      "     |  license(self)\n",
      "     |      Return the contents of the corpus LICENSE file, if it exists.\n",
      "     |  \n",
      "     |  open(self, file)\n",
      "     |      Return an open stream that can be used to read the given file.\n",
      "     |      If the file's encoding is not None, then the stream will\n",
      "     |      automatically decode the file's contents into unicode.\n",
      "     |      \n",
      "     |      :param file: The file identifier of the file to read.\n",
      "     |  \n",
      "     |  readme(self)\n",
      "     |      Return the contents of the corpus README file, if it exists.\n",
      "     |  \n",
      "     |  unicode_repr = __repr__(self)\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Data descriptors inherited from nltk.corpus.reader.api.CorpusReader:\n",
      "     |  \n",
      "     |  __dict__\n",
      "     |      dictionary for instance variables (if defined)\n",
      "     |  \n",
      "     |  __weakref__\n",
      "     |      list of weak references to the object (if defined)\n",
      "     |  \n",
      "     |  root\n",
      "     |      The directory where this corpus is stored.\n",
      "     |      \n",
      "     |      :type: PathPointer\n",
      "    \n",
      "    class NonbreakingPrefixesCorpusReader(WordListCorpusReader)\n",
      "     |  NonbreakingPrefixesCorpusReader(root, fileids, encoding='utf8', tagset=None)\n",
      "     |  \n",
      "     |  This is a class to read the nonbreaking prefixes textfiles from the\n",
      "     |  Moses Machine Translation toolkit. These lists are used in the Python port\n",
      "     |  of the Moses' word tokenizer.\n",
      "     |  \n",
      "     |  Method resolution order:\n",
      "     |      NonbreakingPrefixesCorpusReader\n",
      "     |      WordListCorpusReader\n",
      "     |      nltk.corpus.reader.api.CorpusReader\n",
      "     |      builtins.object\n",
      "     |  \n",
      "     |  Methods defined here:\n",
      "     |  \n",
      "     |  words(self, lang=None, fileids=None, ignore_lines_startswith='#')\n",
      "     |      This module returns a list of nonbreaking prefixes for the specified\n",
      "     |      language(s).\n",
      "     |      \n",
      "     |      >>> from nltk.corpus import nonbreaking_prefixes as nbp\n",
      "     |      >>> nbp.words('en')[:10] == [u'A', u'B', u'C', u'D', u'E', u'F', u'G', u'H', u'I', u'J']\n",
      "     |      True\n",
      "     |      >>> nbp.words('ta')[:5] == [u'அ', u'ஆ', u'இ', u'ஈ', u'உ']\n",
      "     |      True\n",
      "     |      \n",
      "     |      :return: a list words for the specified language(s).\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Data and other attributes defined here:\n",
      "     |  \n",
      "     |  available_langs = {'ca': 'ca', 'catalan': 'ca', 'cs': 'cs', 'czech': '...\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Methods inherited from WordListCorpusReader:\n",
      "     |  \n",
      "     |  raw(self, fileids=None)\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Methods inherited from nltk.corpus.reader.api.CorpusReader:\n",
      "     |  \n",
      "     |  __init__(self, root, fileids, encoding='utf8', tagset=None)\n",
      "     |      :type root: PathPointer or str\n",
      "     |      :param root: A path pointer identifying the root directory for\n",
      "     |          this corpus.  If a string is specified, then it will be\n",
      "     |          converted to a ``PathPointer`` automatically.\n",
      "     |      :param fileids: A list of the files that make up this corpus.\n",
      "     |          This list can either be specified explicitly, as a list of\n",
      "     |          strings; or implicitly, as a regular expression over file\n",
      "     |          paths.  The absolute path for each file will be constructed\n",
      "     |          by joining the reader's root to each file name.\n",
      "     |      :param encoding: The default unicode encoding for the files\n",
      "     |          that make up the corpus.  The value of ``encoding`` can be any\n",
      "     |          of the following:\n",
      "     |          - A string: ``encoding`` is the encoding name for all files.\n",
      "     |          - A dictionary: ``encoding[file_id]`` is the encoding\n",
      "     |            name for the file whose identifier is ``file_id``.  If\n",
      "     |            ``file_id`` is not in ``encoding``, then the file\n",
      "     |            contents will be processed using non-unicode byte strings.\n",
      "     |          - A list: ``encoding`` should be a list of ``(regexp, encoding)``\n",
      "     |            tuples.  The encoding for a file whose identifier is ``file_id``\n",
      "     |            will be the ``encoding`` value for the first tuple whose\n",
      "     |            ``regexp`` matches the ``file_id``.  If no tuple's ``regexp``\n",
      "     |            matches the ``file_id``, the file contents will be processed\n",
      "     |            using non-unicode byte strings.\n",
      "     |          - None: the file contents of all files will be\n",
      "     |            processed using non-unicode byte strings.\n",
      "     |      :param tagset: The name of the tagset used by this corpus, to be used\n",
      "     |            for normalizing or converting the POS tags returned by the\n",
      "     |            tagged_...() methods.\n",
      "     |  \n",
      "     |  __repr__(self)\n",
      "     |      Return repr(self).\n",
      "     |  \n",
      "     |  __unicode__ = __str__(self, /)\n",
      "     |  \n",
      "     |  abspath(self, fileid)\n",
      "     |      Return the absolute path for the given file.\n",
      "     |      \n",
      "     |      :type fileid: str\n",
      "     |      :param fileid: The file identifier for the file whose path\n",
      "     |          should be returned.\n",
      "     |      :rtype: PathPointer\n",
      "     |  \n",
      "     |  abspaths(self, fileids=None, include_encoding=False, include_fileid=False)\n",
      "     |      Return a list of the absolute paths for all fileids in this corpus;\n",
      "     |      or for the given list of fileids, if specified.\n",
      "     |      \n",
      "     |      :type fileids: None or str or list\n",
      "     |      :param fileids: Specifies the set of fileids for which paths should\n",
      "     |          be returned.  Can be None, for all fileids; a list of\n",
      "     |          file identifiers, for a specified set of fileids; or a single\n",
      "     |          file identifier, for a single file.  Note that the return\n",
      "     |          value is always a list of paths, even if ``fileids`` is a\n",
      "     |          single file identifier.\n",
      "     |      \n",
      "     |      :param include_encoding: If true, then return a list of\n",
      "     |          ``(path_pointer, encoding)`` tuples.\n",
      "     |      \n",
      "     |      :rtype: list(PathPointer)\n",
      "     |  \n",
      "     |  citation(self)\n",
      "     |      Return the contents of the corpus citation.bib file, if it exists.\n",
      "     |  \n",
      "     |  encoding(self, file)\n",
      "     |      Return the unicode encoding for the given corpus file, if known.\n",
      "     |      If the encoding is unknown, or if the given file should be\n",
      "     |      processed using byte strings (str), then return None.\n",
      "     |  \n",
      "     |  ensure_loaded(self)\n",
      "     |      Load this corpus (if it has not already been loaded).  This is\n",
      "     |      used by LazyCorpusLoader as a simple method that can be used to\n",
      "     |      make sure a corpus is loaded -- e.g., in case a user wants to\n",
      "     |      do help(some_corpus).\n",
      "     |  \n",
      "     |  fileids(self)\n",
      "     |      Return a list of file identifiers for the fileids that make up\n",
      "     |      this corpus.\n",
      "     |  \n",
      "     |  license(self)\n",
      "     |      Return the contents of the corpus LICENSE file, if it exists.\n",
      "     |  \n",
      "     |  open(self, file)\n",
      "     |      Return an open stream that can be used to read the given file.\n",
      "     |      If the file's encoding is not None, then the stream will\n",
      "     |      automatically decode the file's contents into unicode.\n",
      "     |      \n",
      "     |      :param file: The file identifier of the file to read.\n",
      "     |  \n",
      "     |  readme(self)\n",
      "     |      Return the contents of the corpus README file, if it exists.\n",
      "     |  \n",
      "     |  unicode_repr = __repr__(self)\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Data descriptors inherited from nltk.corpus.reader.api.CorpusReader:\n",
      "     |  \n",
      "     |  __dict__\n",
      "     |      dictionary for instance variables (if defined)\n",
      "     |  \n",
      "     |  __weakref__\n",
      "     |      list of weak references to the object (if defined)\n",
      "     |  \n",
      "     |  root\n",
      "     |      The directory where this corpus is stored.\n",
      "     |      \n",
      "     |      :type: PathPointer\n",
      "    \n",
      "    class OpinionLexiconCorpusReader(nltk.corpus.reader.wordlist.WordListCorpusReader)\n",
      "     |  OpinionLexiconCorpusReader(root, fileids, encoding='utf8', tagset=None)\n",
      "     |  \n",
      "     |  Reader for Liu and Hu opinion lexicon.  Blank lines and readme are ignored.\n",
      "     |  \n",
      "     |      >>> from nltk.corpus import opinion_lexicon\n",
      "     |      >>> opinion_lexicon.words()\n",
      "     |      ['2-faced', '2-faces', 'abnormal', 'abolish', ...]\n",
      "     |  \n",
      "     |  The OpinionLexiconCorpusReader provides shortcuts to retrieve positive/negative\n",
      "     |  words:\n",
      "     |  \n",
      "     |      >>> opinion_lexicon.negative()\n",
      "     |      ['2-faced', '2-faces', 'abnormal', 'abolish', ...]\n",
      "     |  \n",
      "     |  Note that words from `words()` method are sorted by file id, not alphabetically:\n",
      "     |  \n",
      "     |      >>> opinion_lexicon.words()[0:10]\n",
      "     |      ['2-faced', '2-faces', 'abnormal', 'abolish', 'abominable', 'abominably',\n",
      "     |      'abominate', 'abomination', 'abort', 'aborted']\n",
      "     |      >>> sorted(opinion_lexicon.words())[0:10]\n",
      "     |      ['2-faced', '2-faces', 'a+', 'abnormal', 'abolish', 'abominable', 'abominably',\n",
      "     |      'abominate', 'abomination', 'abort']\n",
      "     |  \n",
      "     |  Method resolution order:\n",
      "     |      OpinionLexiconCorpusReader\n",
      "     |      nltk.corpus.reader.wordlist.WordListCorpusReader\n",
      "     |      nltk.corpus.reader.api.CorpusReader\n",
      "     |      builtins.object\n",
      "     |  \n",
      "     |  Methods defined here:\n",
      "     |  \n",
      "     |  negative(self)\n",
      "     |      Return all negative words in alphabetical order.\n",
      "     |      \n",
      "     |      :return: a list of negative words.\n",
      "     |      :rtype: list(str)\n",
      "     |  \n",
      "     |  positive(self)\n",
      "     |      Return all positive words in alphabetical order.\n",
      "     |      \n",
      "     |      :return: a list of positive words.\n",
      "     |      :rtype: list(str)\n",
      "     |  \n",
      "     |  words(self, fileids=None)\n",
      "     |      Return all words in the opinion lexicon. Note that these words are not\n",
      "     |      sorted in alphabetical order.\n",
      "     |      \n",
      "     |      :param fileids: a list or regexp specifying the ids of the files whose\n",
      "     |          words have to be returned.\n",
      "     |      :return: the given file(s) as a list of words and punctuation symbols.\n",
      "     |      :rtype: list(str)\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Data and other attributes defined here:\n",
      "     |  \n",
      "     |  CorpusView = <class 'nltk.corpus.reader.opinion_lexicon.IgnoreReadmeCo...\n",
      "     |      This CorpusView is used to skip the initial readme block of the corpus.\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Methods inherited from nltk.corpus.reader.wordlist.WordListCorpusReader:\n",
      "     |  \n",
      "     |  raw(self, fileids=None)\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Methods inherited from nltk.corpus.reader.api.CorpusReader:\n",
      "     |  \n",
      "     |  __init__(self, root, fileids, encoding='utf8', tagset=None)\n",
      "     |      :type root: PathPointer or str\n",
      "     |      :param root: A path pointer identifying the root directory for\n",
      "     |          this corpus.  If a string is specified, then it will be\n",
      "     |          converted to a ``PathPointer`` automatically.\n",
      "     |      :param fileids: A list of the files that make up this corpus.\n",
      "     |          This list can either be specified explicitly, as a list of\n",
      "     |          strings; or implicitly, as a regular expression over file\n",
      "     |          paths.  The absolute path for each file will be constructed\n",
      "     |          by joining the reader's root to each file name.\n",
      "     |      :param encoding: The default unicode encoding for the files\n",
      "     |          that make up the corpus.  The value of ``encoding`` can be any\n",
      "     |          of the following:\n",
      "     |          - A string: ``encoding`` is the encoding name for all files.\n",
      "     |          - A dictionary: ``encoding[file_id]`` is the encoding\n",
      "     |            name for the file whose identifier is ``file_id``.  If\n",
      "     |            ``file_id`` is not in ``encoding``, then the file\n",
      "     |            contents will be processed using non-unicode byte strings.\n",
      "     |          - A list: ``encoding`` should be a list of ``(regexp, encoding)``\n",
      "     |            tuples.  The encoding for a file whose identifier is ``file_id``\n",
      "     |            will be the ``encoding`` value for the first tuple whose\n",
      "     |            ``regexp`` matches the ``file_id``.  If no tuple's ``regexp``\n",
      "     |            matches the ``file_id``, the file contents will be processed\n",
      "     |            using non-unicode byte strings.\n",
      "     |          - None: the file contents of all files will be\n",
      "     |            processed using non-unicode byte strings.\n",
      "     |      :param tagset: The name of the tagset used by this corpus, to be used\n",
      "     |            for normalizing or converting the POS tags returned by the\n",
      "     |            tagged_...() methods.\n",
      "     |  \n",
      "     |  __repr__(self)\n",
      "     |      Return repr(self).\n",
      "     |  \n",
      "     |  __unicode__ = __str__(self, /)\n",
      "     |  \n",
      "     |  abspath(self, fileid)\n",
      "     |      Return the absolute path for the given file.\n",
      "     |      \n",
      "     |      :type fileid: str\n",
      "     |      :param fileid: The file identifier for the file whose path\n",
      "     |          should be returned.\n",
      "     |      :rtype: PathPointer\n",
      "     |  \n",
      "     |  abspaths(self, fileids=None, include_encoding=False, include_fileid=False)\n",
      "     |      Return a list of the absolute paths for all fileids in this corpus;\n",
      "     |      or for the given list of fileids, if specified.\n",
      "     |      \n",
      "     |      :type fileids: None or str or list\n",
      "     |      :param fileids: Specifies the set of fileids for which paths should\n",
      "     |          be returned.  Can be None, for all fileids; a list of\n",
      "     |          file identifiers, for a specified set of fileids; or a single\n",
      "     |          file identifier, for a single file.  Note that the return\n",
      "     |          value is always a list of paths, even if ``fileids`` is a\n",
      "     |          single file identifier.\n",
      "     |      \n",
      "     |      :param include_encoding: If true, then return a list of\n",
      "     |          ``(path_pointer, encoding)`` tuples.\n",
      "     |      \n",
      "     |      :rtype: list(PathPointer)\n",
      "     |  \n",
      "     |  citation(self)\n",
      "     |      Return the contents of the corpus citation.bib file, if it exists.\n",
      "     |  \n",
      "     |  encoding(self, file)\n",
      "     |      Return the unicode encoding for the given corpus file, if known.\n",
      "     |      If the encoding is unknown, or if the given file should be\n",
      "     |      processed using byte strings (str), then return None.\n",
      "     |  \n",
      "     |  ensure_loaded(self)\n",
      "     |      Load this corpus (if it has not already been loaded).  This is\n",
      "     |      used by LazyCorpusLoader as a simple method that can be used to\n",
      "     |      make sure a corpus is loaded -- e.g., in case a user wants to\n",
      "     |      do help(some_corpus).\n",
      "     |  \n",
      "     |  fileids(self)\n",
      "     |      Return a list of file identifiers for the fileids that make up\n",
      "     |      this corpus.\n",
      "     |  \n",
      "     |  license(self)\n",
      "     |      Return the contents of the corpus LICENSE file, if it exists.\n",
      "     |  \n",
      "     |  open(self, file)\n",
      "     |      Return an open stream that can be used to read the given file.\n",
      "     |      If the file's encoding is not None, then the stream will\n",
      "     |      automatically decode the file's contents into unicode.\n",
      "     |      \n",
      "     |      :param file: The file identifier of the file to read.\n",
      "     |  \n",
      "     |  readme(self)\n",
      "     |      Return the contents of the corpus README file, if it exists.\n",
      "     |  \n",
      "     |  unicode_repr = __repr__(self)\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Data descriptors inherited from nltk.corpus.reader.api.CorpusReader:\n",
      "     |  \n",
      "     |  __dict__\n",
      "     |      dictionary for instance variables (if defined)\n",
      "     |  \n",
      "     |  __weakref__\n",
      "     |      list of weak references to the object (if defined)\n",
      "     |  \n",
      "     |  root\n",
      "     |      The directory where this corpus is stored.\n",
      "     |      \n",
      "     |      :type: PathPointer\n",
      "    \n",
      "    class PPAttachmentCorpusReader(nltk.corpus.reader.api.CorpusReader)\n",
      "     |  PPAttachmentCorpusReader(root, fileids, encoding='utf8', tagset=None)\n",
      "     |  \n",
      "     |  sentence_id verb noun1 preposition noun2 attachment\n",
      "     |  \n",
      "     |  Method resolution order:\n",
      "     |      PPAttachmentCorpusReader\n",
      "     |      nltk.corpus.reader.api.CorpusReader\n",
      "     |      builtins.object\n",
      "     |  \n",
      "     |  Methods defined here:\n",
      "     |  \n",
      "     |  attachments(self, fileids)\n",
      "     |  \n",
      "     |  raw(self, fileids=None)\n",
      "     |  \n",
      "     |  tuples(self, fileids)\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Methods inherited from nltk.corpus.reader.api.CorpusReader:\n",
      "     |  \n",
      "     |  __init__(self, root, fileids, encoding='utf8', tagset=None)\n",
      "     |      :type root: PathPointer or str\n",
      "     |      :param root: A path pointer identifying the root directory for\n",
      "     |          this corpus.  If a string is specified, then it will be\n",
      "     |          converted to a ``PathPointer`` automatically.\n",
      "     |      :param fileids: A list of the files that make up this corpus.\n",
      "     |          This list can either be specified explicitly, as a list of\n",
      "     |          strings; or implicitly, as a regular expression over file\n",
      "     |          paths.  The absolute path for each file will be constructed\n",
      "     |          by joining the reader's root to each file name.\n",
      "     |      :param encoding: The default unicode encoding for the files\n",
      "     |          that make up the corpus.  The value of ``encoding`` can be any\n",
      "     |          of the following:\n",
      "     |          - A string: ``encoding`` is the encoding name for all files.\n",
      "     |          - A dictionary: ``encoding[file_id]`` is the encoding\n",
      "     |            name for the file whose identifier is ``file_id``.  If\n",
      "     |            ``file_id`` is not in ``encoding``, then the file\n",
      "     |            contents will be processed using non-unicode byte strings.\n",
      "     |          - A list: ``encoding`` should be a list of ``(regexp, encoding)``\n",
      "     |            tuples.  The encoding for a file whose identifier is ``file_id``\n",
      "     |            will be the ``encoding`` value for the first tuple whose\n",
      "     |            ``regexp`` matches the ``file_id``.  If no tuple's ``regexp``\n",
      "     |            matches the ``file_id``, the file contents will be processed\n",
      "     |            using non-unicode byte strings.\n",
      "     |          - None: the file contents of all files will be\n",
      "     |            processed using non-unicode byte strings.\n",
      "     |      :param tagset: The name of the tagset used by this corpus, to be used\n",
      "     |            for normalizing or converting the POS tags returned by the\n",
      "     |            tagged_...() methods.\n",
      "     |  \n",
      "     |  __repr__(self)\n",
      "     |      Return repr(self).\n",
      "     |  \n",
      "     |  __unicode__ = __str__(self, /)\n",
      "     |  \n",
      "     |  abspath(self, fileid)\n",
      "     |      Return the absolute path for the given file.\n",
      "     |      \n",
      "     |      :type fileid: str\n",
      "     |      :param fileid: The file identifier for the file whose path\n",
      "     |          should be returned.\n",
      "     |      :rtype: PathPointer\n",
      "     |  \n",
      "     |  abspaths(self, fileids=None, include_encoding=False, include_fileid=False)\n",
      "     |      Return a list of the absolute paths for all fileids in this corpus;\n",
      "     |      or for the given list of fileids, if specified.\n",
      "     |      \n",
      "     |      :type fileids: None or str or list\n",
      "     |      :param fileids: Specifies the set of fileids for which paths should\n",
      "     |          be returned.  Can be None, for all fileids; a list of\n",
      "     |          file identifiers, for a specified set of fileids; or a single\n",
      "     |          file identifier, for a single file.  Note that the return\n",
      "     |          value is always a list of paths, even if ``fileids`` is a\n",
      "     |          single file identifier.\n",
      "     |      \n",
      "     |      :param include_encoding: If true, then return a list of\n",
      "     |          ``(path_pointer, encoding)`` tuples.\n",
      "     |      \n",
      "     |      :rtype: list(PathPointer)\n",
      "     |  \n",
      "     |  citation(self)\n",
      "     |      Return the contents of the corpus citation.bib file, if it exists.\n",
      "     |  \n",
      "     |  encoding(self, file)\n",
      "     |      Return the unicode encoding for the given corpus file, if known.\n",
      "     |      If the encoding is unknown, or if the given file should be\n",
      "     |      processed using byte strings (str), then return None.\n",
      "     |  \n",
      "     |  ensure_loaded(self)\n",
      "     |      Load this corpus (if it has not already been loaded).  This is\n",
      "     |      used by LazyCorpusLoader as a simple method that can be used to\n",
      "     |      make sure a corpus is loaded -- e.g., in case a user wants to\n",
      "     |      do help(some_corpus).\n",
      "     |  \n",
      "     |  fileids(self)\n",
      "     |      Return a list of file identifiers for the fileids that make up\n",
      "     |      this corpus.\n",
      "     |  \n",
      "     |  license(self)\n",
      "     |      Return the contents of the corpus LICENSE file, if it exists.\n",
      "     |  \n",
      "     |  open(self, file)\n",
      "     |      Return an open stream that can be used to read the given file.\n",
      "     |      If the file's encoding is not None, then the stream will\n",
      "     |      automatically decode the file's contents into unicode.\n",
      "     |      \n",
      "     |      :param file: The file identifier of the file to read.\n",
      "     |  \n",
      "     |  readme(self)\n",
      "     |      Return the contents of the corpus README file, if it exists.\n",
      "     |  \n",
      "     |  unicode_repr = __repr__(self)\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Data descriptors inherited from nltk.corpus.reader.api.CorpusReader:\n",
      "     |  \n",
      "     |  __dict__\n",
      "     |      dictionary for instance variables (if defined)\n",
      "     |  \n",
      "     |  __weakref__\n",
      "     |      list of weak references to the object (if defined)\n",
      "     |  \n",
      "     |  root\n",
      "     |      The directory where this corpus is stored.\n",
      "     |      \n",
      "     |      :type: PathPointer\n",
      "    \n",
      "    class PanLexLiteCorpusReader(nltk.corpus.reader.api.CorpusReader)\n",
      "     |  PanLexLiteCorpusReader(root)\n",
      "     |  \n",
      "     |  A base class for \"corpus reader\" classes, each of which can be\n",
      "     |  used to read a specific corpus format.  Each individual corpus\n",
      "     |  reader instance is used to read a specific corpus, consisting of\n",
      "     |  one or more files under a common root directory.  Each file is\n",
      "     |  identified by its ``file identifier``, which is the relative path\n",
      "     |  to the file from the root directory.\n",
      "     |  \n",
      "     |  A separate subclass is defined for each corpus format.  These\n",
      "     |  subclasses define one or more methods that provide 'views' on the\n",
      "     |  corpus contents, such as ``words()`` (for a list of words) and\n",
      "     |  ``parsed_sents()`` (for a list of parsed sentences).  Called with\n",
      "     |  no arguments, these methods will return the contents of the entire\n",
      "     |  corpus.  For most corpora, these methods define one or more\n",
      "     |  selection arguments, such as ``fileids`` or ``categories``, which can\n",
      "     |  be used to select which portion of the corpus should be returned.\n",
      "     |  \n",
      "     |  Method resolution order:\n",
      "     |      PanLexLiteCorpusReader\n",
      "     |      nltk.corpus.reader.api.CorpusReader\n",
      "     |      builtins.object\n",
      "     |  \n",
      "     |  Methods defined here:\n",
      "     |  \n",
      "     |  __init__(self, root)\n",
      "     |      :type root: PathPointer or str\n",
      "     |      :param root: A path pointer identifying the root directory for\n",
      "     |          this corpus.  If a string is specified, then it will be\n",
      "     |          converted to a ``PathPointer`` automatically.\n",
      "     |      :param fileids: A list of the files that make up this corpus.\n",
      "     |          This list can either be specified explicitly, as a list of\n",
      "     |          strings; or implicitly, as a regular expression over file\n",
      "     |          paths.  The absolute path for each file will be constructed\n",
      "     |          by joining the reader's root to each file name.\n",
      "     |      :param encoding: The default unicode encoding for the files\n",
      "     |          that make up the corpus.  The value of ``encoding`` can be any\n",
      "     |          of the following:\n",
      "     |          - A string: ``encoding`` is the encoding name for all files.\n",
      "     |          - A dictionary: ``encoding[file_id]`` is the encoding\n",
      "     |            name for the file whose identifier is ``file_id``.  If\n",
      "     |            ``file_id`` is not in ``encoding``, then the file\n",
      "     |            contents will be processed using non-unicode byte strings.\n",
      "     |          - A list: ``encoding`` should be a list of ``(regexp, encoding)``\n",
      "     |            tuples.  The encoding for a file whose identifier is ``file_id``\n",
      "     |            will be the ``encoding`` value for the first tuple whose\n",
      "     |            ``regexp`` matches the ``file_id``.  If no tuple's ``regexp``\n",
      "     |            matches the ``file_id``, the file contents will be processed\n",
      "     |            using non-unicode byte strings.\n",
      "     |          - None: the file contents of all files will be\n",
      "     |            processed using non-unicode byte strings.\n",
      "     |      :param tagset: The name of the tagset used by this corpus, to be used\n",
      "     |            for normalizing or converting the POS tags returned by the\n",
      "     |            tagged_...() methods.\n",
      "     |  \n",
      "     |  language_varieties(self, lc=None)\n",
      "     |      Return a list of PanLex language varieties.\n",
      "     |      \n",
      "     |      :param lc: ISO 639 alpha-3 code. If specified, filters returned varieties\n",
      "     |          by this code. If unspecified, all varieties are returned.\n",
      "     |      :return: the specified language varieties as a list of tuples. The first\n",
      "     |          element is the language variety's seven-character uniform identifier,\n",
      "     |          and the second element is its default name.\n",
      "     |      :rtype: list(tuple)\n",
      "     |  \n",
      "     |  meanings(self, expr_uid, expr_tt)\n",
      "     |      Return a list of meanings for an expression.\n",
      "     |      \n",
      "     |      :param expr_uid: the expression's language variety, as a seven-character\n",
      "     |          uniform identifier.\n",
      "     |      :param expr_tt: the expression's text.\n",
      "     |      :return: a list of Meaning objects.\n",
      "     |      :rtype: list(Meaning)\n",
      "     |  \n",
      "     |  translations(self, from_uid, from_tt, to_uid)\n",
      "     |      Return a list of translations for an expression into a single language\n",
      "     |          variety.\n",
      "     |      \n",
      "     |      :param from_uid: the source expression's language variety, as a\n",
      "     |          seven-character uniform identifier.\n",
      "     |      :param from_tt: the source expression's text.\n",
      "     |      :param to_uid: the target language variety, as a seven-character\n",
      "     |          uniform identifier.\n",
      "     |      :return a list of translation tuples. The first element is the expression\n",
      "     |          text and the second element is the translation quality.\n",
      "     |      :rtype: list(tuple)\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Data and other attributes defined here:\n",
      "     |  \n",
      "     |  MEANING_Q = '\\n        SELECT dnx2.mn, dnx2.uq, dnx2.ap, dnx2.... AND ...\n",
      "     |  \n",
      "     |  TRANSLATION_Q = '\\n        SELECT s.tt, sum(s.uq) AS trq FROM (\\n  ......\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Methods inherited from nltk.corpus.reader.api.CorpusReader:\n",
      "     |  \n",
      "     |  __repr__(self)\n",
      "     |      Return repr(self).\n",
      "     |  \n",
      "     |  __unicode__ = __str__(self, /)\n",
      "     |  \n",
      "     |  abspath(self, fileid)\n",
      "     |      Return the absolute path for the given file.\n",
      "     |      \n",
      "     |      :type fileid: str\n",
      "     |      :param fileid: The file identifier for the file whose path\n",
      "     |          should be returned.\n",
      "     |      :rtype: PathPointer\n",
      "     |  \n",
      "     |  abspaths(self, fileids=None, include_encoding=False, include_fileid=False)\n",
      "     |      Return a list of the absolute paths for all fileids in this corpus;\n",
      "     |      or for the given list of fileids, if specified.\n",
      "     |      \n",
      "     |      :type fileids: None or str or list\n",
      "     |      :param fileids: Specifies the set of fileids for which paths should\n",
      "     |          be returned.  Can be None, for all fileids; a list of\n",
      "     |          file identifiers, for a specified set of fileids; or a single\n",
      "     |          file identifier, for a single file.  Note that the return\n",
      "     |          value is always a list of paths, even if ``fileids`` is a\n",
      "     |          single file identifier.\n",
      "     |      \n",
      "     |      :param include_encoding: If true, then return a list of\n",
      "     |          ``(path_pointer, encoding)`` tuples.\n",
      "     |      \n",
      "     |      :rtype: list(PathPointer)\n",
      "     |  \n",
      "     |  citation(self)\n",
      "     |      Return the contents of the corpus citation.bib file, if it exists.\n",
      "     |  \n",
      "     |  encoding(self, file)\n",
      "     |      Return the unicode encoding for the given corpus file, if known.\n",
      "     |      If the encoding is unknown, or if the given file should be\n",
      "     |      processed using byte strings (str), then return None.\n",
      "     |  \n",
      "     |  ensure_loaded(self)\n",
      "     |      Load this corpus (if it has not already been loaded).  This is\n",
      "     |      used by LazyCorpusLoader as a simple method that can be used to\n",
      "     |      make sure a corpus is loaded -- e.g., in case a user wants to\n",
      "     |      do help(some_corpus).\n",
      "     |  \n",
      "     |  fileids(self)\n",
      "     |      Return a list of file identifiers for the fileids that make up\n",
      "     |      this corpus.\n",
      "     |  \n",
      "     |  license(self)\n",
      "     |      Return the contents of the corpus LICENSE file, if it exists.\n",
      "     |  \n",
      "     |  open(self, file)\n",
      "     |      Return an open stream that can be used to read the given file.\n",
      "     |      If the file's encoding is not None, then the stream will\n",
      "     |      automatically decode the file's contents into unicode.\n",
      "     |      \n",
      "     |      :param file: The file identifier of the file to read.\n",
      "     |  \n",
      "     |  readme(self)\n",
      "     |      Return the contents of the corpus README file, if it exists.\n",
      "     |  \n",
      "     |  unicode_repr = __repr__(self)\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Data descriptors inherited from nltk.corpus.reader.api.CorpusReader:\n",
      "     |  \n",
      "     |  __dict__\n",
      "     |      dictionary for instance variables (if defined)\n",
      "     |  \n",
      "     |  __weakref__\n",
      "     |      list of weak references to the object (if defined)\n",
      "     |  \n",
      "     |  root\n",
      "     |      The directory where this corpus is stored.\n",
      "     |      \n",
      "     |      :type: PathPointer\n",
      "    \n",
      "    class PanlexSwadeshCorpusReader(nltk.corpus.reader.wordlist.WordListCorpusReader)\n",
      "     |  PanlexSwadeshCorpusReader(*args, **kwargs)\n",
      "     |  \n",
      "     |  This is a class to read the PanLex Swadesh list from\n",
      "     |  \n",
      "     |  David Kamholz, Jonathan Pool, and Susan M. Colowick (2014).\n",
      "     |  PanLex: Building a Resource for Panlingual Lexical Translation.\n",
      "     |  In LREC. http://www.lrec-conf.org/proceedings/lrec2014/pdf/1029_Paper.pdf\n",
      "     |  \n",
      "     |  License: CC0 1.0 Universal\n",
      "     |  https://creativecommons.org/publicdomain/zero/1.0/legalcode\n",
      "     |  \n",
      "     |  Method resolution order:\n",
      "     |      PanlexSwadeshCorpusReader\n",
      "     |      nltk.corpus.reader.wordlist.WordListCorpusReader\n",
      "     |      nltk.corpus.reader.api.CorpusReader\n",
      "     |      builtins.object\n",
      "     |  \n",
      "     |  Methods defined here:\n",
      "     |  \n",
      "     |  __init__(self, *args, **kwargs)\n",
      "     |      :type root: PathPointer or str\n",
      "     |      :param root: A path pointer identifying the root directory for\n",
      "     |          this corpus.  If a string is specified, then it will be\n",
      "     |          converted to a ``PathPointer`` automatically.\n",
      "     |      :param fileids: A list of the files that make up this corpus.\n",
      "     |          This list can either be specified explicitly, as a list of\n",
      "     |          strings; or implicitly, as a regular expression over file\n",
      "     |          paths.  The absolute path for each file will be constructed\n",
      "     |          by joining the reader's root to each file name.\n",
      "     |      :param encoding: The default unicode encoding for the files\n",
      "     |          that make up the corpus.  The value of ``encoding`` can be any\n",
      "     |          of the following:\n",
      "     |          - A string: ``encoding`` is the encoding name for all files.\n",
      "     |          - A dictionary: ``encoding[file_id]`` is the encoding\n",
      "     |            name for the file whose identifier is ``file_id``.  If\n",
      "     |            ``file_id`` is not in ``encoding``, then the file\n",
      "     |            contents will be processed using non-unicode byte strings.\n",
      "     |          - A list: ``encoding`` should be a list of ``(regexp, encoding)``\n",
      "     |            tuples.  The encoding for a file whose identifier is ``file_id``\n",
      "     |            will be the ``encoding`` value for the first tuple whose\n",
      "     |            ``regexp`` matches the ``file_id``.  If no tuple's ``regexp``\n",
      "     |            matches the ``file_id``, the file contents will be processed\n",
      "     |            using non-unicode byte strings.\n",
      "     |          - None: the file contents of all files will be\n",
      "     |            processed using non-unicode byte strings.\n",
      "     |      :param tagset: The name of the tagset used by this corpus, to be used\n",
      "     |            for normalizing or converting the POS tags returned by the\n",
      "     |            tagged_...() methods.\n",
      "     |  \n",
      "     |  entries(self, fileids=None)\n",
      "     |      :return: a tuple of words for the specified fileids.\n",
      "     |  \n",
      "     |  get_languages(self)\n",
      "     |  \n",
      "     |  get_macrolanguages(self)\n",
      "     |  \n",
      "     |  language_codes(self)\n",
      "     |  \n",
      "     |  license(self)\n",
      "     |      Return the contents of the corpus LICENSE file, if it exists.\n",
      "     |  \n",
      "     |  readme(self)\n",
      "     |      Return the contents of the corpus README file, if it exists.\n",
      "     |  \n",
      "     |  words_by_iso639(self, iso63_code)\n",
      "     |      :return: a list of list(str)\n",
      "     |  \n",
      "     |  words_by_lang(self, lang_code)\n",
      "     |      :return: a list of list(str)\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Methods inherited from nltk.corpus.reader.wordlist.WordListCorpusReader:\n",
      "     |  \n",
      "     |  raw(self, fileids=None)\n",
      "     |  \n",
      "     |  words(self, fileids=None, ignore_lines_startswith='\\n')\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Methods inherited from nltk.corpus.reader.api.CorpusReader:\n",
      "     |  \n",
      "     |  __repr__(self)\n",
      "     |      Return repr(self).\n",
      "     |  \n",
      "     |  __unicode__ = __str__(self, /)\n",
      "     |  \n",
      "     |  abspath(self, fileid)\n",
      "     |      Return the absolute path for the given file.\n",
      "     |      \n",
      "     |      :type fileid: str\n",
      "     |      :param fileid: The file identifier for the file whose path\n",
      "     |          should be returned.\n",
      "     |      :rtype: PathPointer\n",
      "     |  \n",
      "     |  abspaths(self, fileids=None, include_encoding=False, include_fileid=False)\n",
      "     |      Return a list of the absolute paths for all fileids in this corpus;\n",
      "     |      or for the given list of fileids, if specified.\n",
      "     |      \n",
      "     |      :type fileids: None or str or list\n",
      "     |      :param fileids: Specifies the set of fileids for which paths should\n",
      "     |          be returned.  Can be None, for all fileids; a list of\n",
      "     |          file identifiers, for a specified set of fileids; or a single\n",
      "     |          file identifier, for a single file.  Note that the return\n",
      "     |          value is always a list of paths, even if ``fileids`` is a\n",
      "     |          single file identifier.\n",
      "     |      \n",
      "     |      :param include_encoding: If true, then return a list of\n",
      "     |          ``(path_pointer, encoding)`` tuples.\n",
      "     |      \n",
      "     |      :rtype: list(PathPointer)\n",
      "     |  \n",
      "     |  citation(self)\n",
      "     |      Return the contents of the corpus citation.bib file, if it exists.\n",
      "     |  \n",
      "     |  encoding(self, file)\n",
      "     |      Return the unicode encoding for the given corpus file, if known.\n",
      "     |      If the encoding is unknown, or if the given file should be\n",
      "     |      processed using byte strings (str), then return None.\n",
      "     |  \n",
      "     |  ensure_loaded(self)\n",
      "     |      Load this corpus (if it has not already been loaded).  This is\n",
      "     |      used by LazyCorpusLoader as a simple method that can be used to\n",
      "     |      make sure a corpus is loaded -- e.g., in case a user wants to\n",
      "     |      do help(some_corpus).\n",
      "     |  \n",
      "     |  fileids(self)\n",
      "     |      Return a list of file identifiers for the fileids that make up\n",
      "     |      this corpus.\n",
      "     |  \n",
      "     |  open(self, file)\n",
      "     |      Return an open stream that can be used to read the given file.\n",
      "     |      If the file's encoding is not None, then the stream will\n",
      "     |      automatically decode the file's contents into unicode.\n",
      "     |      \n",
      "     |      :param file: The file identifier of the file to read.\n",
      "     |  \n",
      "     |  unicode_repr = __repr__(self)\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Data descriptors inherited from nltk.corpus.reader.api.CorpusReader:\n",
      "     |  \n",
      "     |  __dict__\n",
      "     |      dictionary for instance variables (if defined)\n",
      "     |  \n",
      "     |  __weakref__\n",
      "     |      list of weak references to the object (if defined)\n",
      "     |  \n",
      "     |  root\n",
      "     |      The directory where this corpus is stored.\n",
      "     |      \n",
      "     |      :type: PathPointer\n",
      "    \n",
      "    class Pl196xCorpusReader(nltk.corpus.reader.api.CategorizedCorpusReader, nltk.corpus.reader.xmldocs.XMLCorpusReader)\n",
      "     |  Pl196xCorpusReader(*args, **kwargs)\n",
      "     |  \n",
      "     |  A mixin class used to aid in the implementation of corpus readers\n",
      "     |  for categorized corpora.  This class defines the method\n",
      "     |  ``categories()``, which returns a list of the categories for the\n",
      "     |  corpus or for a specified set of fileids; and overrides ``fileids()``\n",
      "     |  to take a ``categories`` argument, restricting the set of fileids to\n",
      "     |  be returned.\n",
      "     |  \n",
      "     |  Subclasses are expected to:\n",
      "     |  \n",
      "     |    - Call ``__init__()`` to set up the mapping.\n",
      "     |  \n",
      "     |    - Override all view methods to accept a ``categories`` parameter,\n",
      "     |      which can be used *instead* of the ``fileids`` parameter, to\n",
      "     |      select which fileids should be included in the returned view.\n",
      "     |  \n",
      "     |  Method resolution order:\n",
      "     |      Pl196xCorpusReader\n",
      "     |      nltk.corpus.reader.api.CategorizedCorpusReader\n",
      "     |      nltk.corpus.reader.xmldocs.XMLCorpusReader\n",
      "     |      nltk.corpus.reader.api.CorpusReader\n",
      "     |      builtins.object\n",
      "     |  \n",
      "     |  Methods defined here:\n",
      "     |  \n",
      "     |  __init__(self, *args, **kwargs)\n",
      "     |      Initialize this mapping based on keyword arguments, as\n",
      "     |      follows:\n",
      "     |      \n",
      "     |        - cat_pattern: A regular expression pattern used to find the\n",
      "     |          category for each file identifier.  The pattern will be\n",
      "     |          applied to each file identifier, and the first matching\n",
      "     |          group will be used as the category label for that file.\n",
      "     |      \n",
      "     |        - cat_map: A dictionary, mapping from file identifiers to\n",
      "     |          category labels.\n",
      "     |      \n",
      "     |        - cat_file: The name of a file that contains the mapping\n",
      "     |          from file identifiers to categories.  The argument\n",
      "     |          ``cat_delimiter`` can be used to specify a delimiter.\n",
      "     |      \n",
      "     |      The corresponding argument will be deleted from ``kwargs``.  If\n",
      "     |      more than one argument is specified, an exception will be\n",
      "     |      raised.\n",
      "     |  \n",
      "     |  decode_tag(self, tag)\n",
      "     |  \n",
      "     |  paras(self, fileids=None, categories=None, textids=None)\n",
      "     |  \n",
      "     |  raw(self, fileids=None, categories=None)\n",
      "     |  \n",
      "     |  sents(self, fileids=None, categories=None, textids=None)\n",
      "     |  \n",
      "     |  tagged_paras(self, fileids=None, categories=None, textids=None)\n",
      "     |  \n",
      "     |  tagged_sents(self, fileids=None, categories=None, textids=None)\n",
      "     |  \n",
      "     |  tagged_words(self, fileids=None, categories=None, textids=None)\n",
      "     |  \n",
      "     |  textids(self, fileids=None, categories=None)\n",
      "     |      In the pl196x corpus each category is stored in single\n",
      "     |      file and thus both methods provide identical functionality. In order\n",
      "     |      to accommodate finer granularity, a non-standard textids() method was\n",
      "     |      implemented. All the main functions can be supplied with a list\n",
      "     |      of required chunks---giving much more control to the user.\n",
      "     |  \n",
      "     |  words(self, fileids=None, categories=None, textids=None)\n",
      "     |      Returns all of the words and punctuation symbols in the specified file\n",
      "     |      that were in text nodes -- ie, tags are ignored. Like the xml() method,\n",
      "     |      fileid can only specify one file.\n",
      "     |      \n",
      "     |      :return: the given file's text nodes as a list of words and punctuation symbols\n",
      "     |      :rtype: list(str)\n",
      "     |  \n",
      "     |  xml(self, fileids=None, categories=None)\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Data and other attributes defined here:\n",
      "     |  \n",
      "     |  head_len = 2770\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Methods inherited from nltk.corpus.reader.api.CategorizedCorpusReader:\n",
      "     |  \n",
      "     |  categories(self, fileids=None)\n",
      "     |      Return a list of the categories that are defined for this corpus,\n",
      "     |      or for the file(s) if it is given.\n",
      "     |  \n",
      "     |  fileids(self, categories=None)\n",
      "     |      Return a list of file identifiers for the files that make up\n",
      "     |      this corpus, or that make up the given category(s) if specified.\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Data descriptors inherited from nltk.corpus.reader.api.CategorizedCorpusReader:\n",
      "     |  \n",
      "     |  __dict__\n",
      "     |      dictionary for instance variables (if defined)\n",
      "     |  \n",
      "     |  __weakref__\n",
      "     |      list of weak references to the object (if defined)\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Methods inherited from nltk.corpus.reader.api.CorpusReader:\n",
      "     |  \n",
      "     |  __repr__(self)\n",
      "     |      Return repr(self).\n",
      "     |  \n",
      "     |  __unicode__ = __str__(self, /)\n",
      "     |  \n",
      "     |  abspath(self, fileid)\n",
      "     |      Return the absolute path for the given file.\n",
      "     |      \n",
      "     |      :type fileid: str\n",
      "     |      :param fileid: The file identifier for the file whose path\n",
      "     |          should be returned.\n",
      "     |      :rtype: PathPointer\n",
      "     |  \n",
      "     |  abspaths(self, fileids=None, include_encoding=False, include_fileid=False)\n",
      "     |      Return a list of the absolute paths for all fileids in this corpus;\n",
      "     |      or for the given list of fileids, if specified.\n",
      "     |      \n",
      "     |      :type fileids: None or str or list\n",
      "     |      :param fileids: Specifies the set of fileids for which paths should\n",
      "     |          be returned.  Can be None, for all fileids; a list of\n",
      "     |          file identifiers, for a specified set of fileids; or a single\n",
      "     |          file identifier, for a single file.  Note that the return\n",
      "     |          value is always a list of paths, even if ``fileids`` is a\n",
      "     |          single file identifier.\n",
      "     |      \n",
      "     |      :param include_encoding: If true, then return a list of\n",
      "     |          ``(path_pointer, encoding)`` tuples.\n",
      "     |      \n",
      "     |      :rtype: list(PathPointer)\n",
      "     |  \n",
      "     |  citation(self)\n",
      "     |      Return the contents of the corpus citation.bib file, if it exists.\n",
      "     |  \n",
      "     |  encoding(self, file)\n",
      "     |      Return the unicode encoding for the given corpus file, if known.\n",
      "     |      If the encoding is unknown, or if the given file should be\n",
      "     |      processed using byte strings (str), then return None.\n",
      "     |  \n",
      "     |  ensure_loaded(self)\n",
      "     |      Load this corpus (if it has not already been loaded).  This is\n",
      "     |      used by LazyCorpusLoader as a simple method that can be used to\n",
      "     |      make sure a corpus is loaded -- e.g., in case a user wants to\n",
      "     |      do help(some_corpus).\n",
      "     |  \n",
      "     |  license(self)\n",
      "     |      Return the contents of the corpus LICENSE file, if it exists.\n",
      "     |  \n",
      "     |  open(self, file)\n",
      "     |      Return an open stream that can be used to read the given file.\n",
      "     |      If the file's encoding is not None, then the stream will\n",
      "     |      automatically decode the file's contents into unicode.\n",
      "     |      \n",
      "     |      :param file: The file identifier of the file to read.\n",
      "     |  \n",
      "     |  readme(self)\n",
      "     |      Return the contents of the corpus README file, if it exists.\n",
      "     |  \n",
      "     |  unicode_repr = __repr__(self)\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Data descriptors inherited from nltk.corpus.reader.api.CorpusReader:\n",
      "     |  \n",
      "     |  root\n",
      "     |      The directory where this corpus is stored.\n",
      "     |      \n",
      "     |      :type: PathPointer\n",
      "    \n",
      "    class PlaintextCorpusReader(nltk.corpus.reader.api.CorpusReader)\n",
      "     |  PlaintextCorpusReader(root, fileids, word_tokenizer=WordPunctTokenizer(pattern='\\\\w+|[^\\\\w\\\\s]+', gaps=False, discard_empty=True, flags=<RegexFlag.UNICODE|DOTALL|MULTILINE: 56>), sent_tokenizer=<nltk.tokenize.punkt.PunktSentenceTokenizer object at 0x000001F4CED298C8>, para_block_reader=<function read_blankline_block at 0x000001F4CED359D8>, encoding='utf8')\n",
      "     |  \n",
      "     |  Reader for corpora that consist of plaintext documents.  Paragraphs\n",
      "     |  are assumed to be split using blank lines.  Sentences and words can\n",
      "     |  be tokenized using the default tokenizers, or by custom tokenizers\n",
      "     |  specificed as parameters to the constructor.\n",
      "     |  \n",
      "     |  This corpus reader can be customized (e.g., to skip preface\n",
      "     |  sections of specific document formats) by creating a subclass and\n",
      "     |  overriding the ``CorpusView`` class variable.\n",
      "     |  \n",
      "     |  Method resolution order:\n",
      "     |      PlaintextCorpusReader\n",
      "     |      nltk.corpus.reader.api.CorpusReader\n",
      "     |      builtins.object\n",
      "     |  \n",
      "     |  Methods defined here:\n",
      "     |  \n",
      "     |  __init__(self, root, fileids, word_tokenizer=WordPunctTokenizer(pattern='\\\\w+|[^\\\\w\\\\s]+', gaps=False, discard_empty=True, flags=<RegexFlag.UNICODE|DOTALL|MULTILINE: 56>), sent_tokenizer=<nltk.tokenize.punkt.PunktSentenceTokenizer object at 0x000001F4CED298C8>, para_block_reader=<function read_blankline_block at 0x000001F4CED359D8>, encoding='utf8')\n",
      "     |      Construct a new plaintext corpus reader for a set of documents\n",
      "     |      located at the given root directory.  Example usage:\n",
      "     |      \n",
      "     |          >>> root = '/usr/local/share/nltk_data/corpora/webtext/'\n",
      "     |          >>> reader = PlaintextCorpusReader(root, '.*\\.txt') # doctest: +SKIP\n",
      "     |      \n",
      "     |      :param root: The root directory for this corpus.\n",
      "     |      :param fileids: A list or regexp specifying the fileids in this corpus.\n",
      "     |      :param word_tokenizer: Tokenizer for breaking sentences or\n",
      "     |          paragraphs into words.\n",
      "     |      :param sent_tokenizer: Tokenizer for breaking paragraphs\n",
      "     |          into words.\n",
      "     |      :param para_block_reader: The block reader used to divide the\n",
      "     |          corpus into paragraph blocks.\n",
      "     |  \n",
      "     |  paras(self, fileids=None)\n",
      "     |      :return: the given file(s) as a list of\n",
      "     |          paragraphs, each encoded as a list of sentences, which are\n",
      "     |          in turn encoded as lists of word strings.\n",
      "     |      :rtype: list(list(list(str)))\n",
      "     |  \n",
      "     |  raw(self, fileids=None)\n",
      "     |      :return: the given file(s) as a single string.\n",
      "     |      :rtype: str\n",
      "     |  \n",
      "     |  sents(self, fileids=None)\n",
      "     |      :return: the given file(s) as a list of\n",
      "     |          sentences or utterances, each encoded as a list of word\n",
      "     |          strings.\n",
      "     |      :rtype: list(list(str))\n",
      "     |  \n",
      "     |  words(self, fileids=None)\n",
      "     |      :return: the given file(s) as a list of words\n",
      "     |          and punctuation symbols.\n",
      "     |      :rtype: list(str)\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Data and other attributes defined here:\n",
      "     |  \n",
      "     |  CorpusView = <class 'nltk.corpus.reader.util.StreamBackedCorpusView'>\n",
      "     |      A 'view' of a corpus file, which acts like a sequence of tokens:\n",
      "     |      it can be accessed by index, iterated over, etc.  However, the\n",
      "     |      tokens are only constructed as-needed -- the entire corpus is\n",
      "     |      never stored in memory at once.\n",
      "     |      \n",
      "     |      The constructor to ``StreamBackedCorpusView`` takes two arguments:\n",
      "     |      a corpus fileid (specified as a string or as a ``PathPointer``);\n",
      "     |      and a block reader.  A \"block reader\" is a function that reads\n",
      "     |      zero or more tokens from a stream, and returns them as a list.  A\n",
      "     |      very simple example of a block reader is:\n",
      "     |      \n",
      "     |          >>> def simple_block_reader(stream):\n",
      "     |          ...     return stream.readline().split()\n",
      "     |      \n",
      "     |      This simple block reader reads a single line at a time, and\n",
      "     |      returns a single token (consisting of a string) for each\n",
      "     |      whitespace-separated substring on the line.\n",
      "     |      \n",
      "     |      When deciding how to define the block reader for a given\n",
      "     |      corpus, careful consideration should be given to the size of\n",
      "     |      blocks handled by the block reader.  Smaller block sizes will\n",
      "     |      increase the memory requirements of the corpus view's internal\n",
      "     |      data structures (by 2 integers per block).  On the other hand,\n",
      "     |      larger block sizes may decrease performance for random access to\n",
      "     |      the corpus.  (But note that larger block sizes will *not*\n",
      "     |      decrease performance for iteration.)\n",
      "     |      \n",
      "     |      Internally, ``CorpusView`` maintains a partial mapping from token\n",
      "     |      index to file position, with one entry per block.  When a token\n",
      "     |      with a given index *i* is requested, the ``CorpusView`` constructs\n",
      "     |      it as follows:\n",
      "     |      \n",
      "     |        1. First, it searches the toknum/filepos mapping for the token\n",
      "     |           index closest to (but less than or equal to) *i*.\n",
      "     |      \n",
      "     |        2. Then, starting at the file position corresponding to that\n",
      "     |           index, it reads one block at a time using the block reader\n",
      "     |           until it reaches the requested token.\n",
      "     |      \n",
      "     |      The toknum/filepos mapping is created lazily: it is initially\n",
      "     |      empty, but every time a new block is read, the block's\n",
      "     |      initial token is added to the mapping.  (Thus, the toknum/filepos\n",
      "     |      map has one entry per block.)\n",
      "     |      \n",
      "     |      In order to increase efficiency for random access patterns that\n",
      "     |      have high degrees of locality, the corpus view may cache one or\n",
      "     |      more blocks.\n",
      "     |      \n",
      "     |      :note: Each ``CorpusView`` object internally maintains an open file\n",
      "     |          object for its underlying corpus file.  This file should be\n",
      "     |          automatically closed when the ``CorpusView`` is garbage collected,\n",
      "     |          but if you wish to close it manually, use the ``close()``\n",
      "     |          method.  If you access a ``CorpusView``'s items after it has been\n",
      "     |          closed, the file object will be automatically re-opened.\n",
      "     |      \n",
      "     |      :warning: If the contents of the file are modified during the\n",
      "     |          lifetime of the ``CorpusView``, then the ``CorpusView``'s behavior\n",
      "     |          is undefined.\n",
      "     |      \n",
      "     |      :warning: If a unicode encoding is specified when constructing a\n",
      "     |          ``CorpusView``, then the block reader may only call\n",
      "     |          ``stream.seek()`` with offsets that have been returned by\n",
      "     |          ``stream.tell()``; in particular, calling ``stream.seek()`` with\n",
      "     |          relative offsets, or with offsets based on string lengths, may\n",
      "     |          lead to incorrect behavior.\n",
      "     |      \n",
      "     |      :ivar _block_reader: The function used to read\n",
      "     |          a single block from the underlying file stream.\n",
      "     |      :ivar _toknum: A list containing the token index of each block\n",
      "     |          that has been processed.  In particular, ``_toknum[i]`` is the\n",
      "     |          token index of the first token in block ``i``.  Together\n",
      "     |          with ``_filepos``, this forms a partial mapping between token\n",
      "     |          indices and file positions.\n",
      "     |      :ivar _filepos: A list containing the file position of each block\n",
      "     |          that has been processed.  In particular, ``_toknum[i]`` is the\n",
      "     |          file position of the first character in block ``i``.  Together\n",
      "     |          with ``_toknum``, this forms a partial mapping between token\n",
      "     |          indices and file positions.\n",
      "     |      :ivar _stream: The stream used to access the underlying corpus file.\n",
      "     |      :ivar _len: The total number of tokens in the corpus, if known;\n",
      "     |          or None, if the number of tokens is not yet known.\n",
      "     |      :ivar _eofpos: The character position of the last character in the\n",
      "     |          file.  This is calculated when the corpus view is initialized,\n",
      "     |          and is used to decide when the end of file has been reached.\n",
      "     |      :ivar _cache: A cache of the most recently read block.  It\n",
      "     |         is encoded as a tuple (start_toknum, end_toknum, tokens), where\n",
      "     |         start_toknum is the token index of the first token in the block;\n",
      "     |         end_toknum is the token index of the first token not in the\n",
      "     |         block; and tokens is a list of the tokens in the block.\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Methods inherited from nltk.corpus.reader.api.CorpusReader:\n",
      "     |  \n",
      "     |  __repr__(self)\n",
      "     |      Return repr(self).\n",
      "     |  \n",
      "     |  __unicode__ = __str__(self, /)\n",
      "     |  \n",
      "     |  abspath(self, fileid)\n",
      "     |      Return the absolute path for the given file.\n",
      "     |      \n",
      "     |      :type fileid: str\n",
      "     |      :param fileid: The file identifier for the file whose path\n",
      "     |          should be returned.\n",
      "     |      :rtype: PathPointer\n",
      "     |  \n",
      "     |  abspaths(self, fileids=None, include_encoding=False, include_fileid=False)\n",
      "     |      Return a list of the absolute paths for all fileids in this corpus;\n",
      "     |      or for the given list of fileids, if specified.\n",
      "     |      \n",
      "     |      :type fileids: None or str or list\n",
      "     |      :param fileids: Specifies the set of fileids for which paths should\n",
      "     |          be returned.  Can be None, for all fileids; a list of\n",
      "     |          file identifiers, for a specified set of fileids; or a single\n",
      "     |          file identifier, for a single file.  Note that the return\n",
      "     |          value is always a list of paths, even if ``fileids`` is a\n",
      "     |          single file identifier.\n",
      "     |      \n",
      "     |      :param include_encoding: If true, then return a list of\n",
      "     |          ``(path_pointer, encoding)`` tuples.\n",
      "     |      \n",
      "     |      :rtype: list(PathPointer)\n",
      "     |  \n",
      "     |  citation(self)\n",
      "     |      Return the contents of the corpus citation.bib file, if it exists.\n",
      "     |  \n",
      "     |  encoding(self, file)\n",
      "     |      Return the unicode encoding for the given corpus file, if known.\n",
      "     |      If the encoding is unknown, or if the given file should be\n",
      "     |      processed using byte strings (str), then return None.\n",
      "     |  \n",
      "     |  ensure_loaded(self)\n",
      "     |      Load this corpus (if it has not already been loaded).  This is\n",
      "     |      used by LazyCorpusLoader as a simple method that can be used to\n",
      "     |      make sure a corpus is loaded -- e.g., in case a user wants to\n",
      "     |      do help(some_corpus).\n",
      "     |  \n",
      "     |  fileids(self)\n",
      "     |      Return a list of file identifiers for the fileids that make up\n",
      "     |      this corpus.\n",
      "     |  \n",
      "     |  license(self)\n",
      "     |      Return the contents of the corpus LICENSE file, if it exists.\n",
      "     |  \n",
      "     |  open(self, file)\n",
      "     |      Return an open stream that can be used to read the given file.\n",
      "     |      If the file's encoding is not None, then the stream will\n",
      "     |      automatically decode the file's contents into unicode.\n",
      "     |      \n",
      "     |      :param file: The file identifier of the file to read.\n",
      "     |  \n",
      "     |  readme(self)\n",
      "     |      Return the contents of the corpus README file, if it exists.\n",
      "     |  \n",
      "     |  unicode_repr = __repr__(self)\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Data descriptors inherited from nltk.corpus.reader.api.CorpusReader:\n",
      "     |  \n",
      "     |  __dict__\n",
      "     |      dictionary for instance variables (if defined)\n",
      "     |  \n",
      "     |  __weakref__\n",
      "     |      list of weak references to the object (if defined)\n",
      "     |  \n",
      "     |  root\n",
      "     |      The directory where this corpus is stored.\n",
      "     |      \n",
      "     |      :type: PathPointer\n",
      "    \n",
      "    class PortugueseCategorizedPlaintextCorpusReader(CategorizedPlaintextCorpusReader)\n",
      "     |  PortugueseCategorizedPlaintextCorpusReader(*args, **kwargs)\n",
      "     |  \n",
      "     |  A reader for plaintext corpora whose documents are divided into\n",
      "     |  categories based on their file identifiers.\n",
      "     |  \n",
      "     |  Method resolution order:\n",
      "     |      PortugueseCategorizedPlaintextCorpusReader\n",
      "     |      CategorizedPlaintextCorpusReader\n",
      "     |      nltk.corpus.reader.api.CategorizedCorpusReader\n",
      "     |      PlaintextCorpusReader\n",
      "     |      nltk.corpus.reader.api.CorpusReader\n",
      "     |      builtins.object\n",
      "     |  \n",
      "     |  Methods defined here:\n",
      "     |  \n",
      "     |  __init__(self, *args, **kwargs)\n",
      "     |      Initialize the corpus reader.  Categorization arguments\n",
      "     |      (``cat_pattern``, ``cat_map``, and ``cat_file``) are passed to\n",
      "     |      the ``CategorizedCorpusReader`` constructor.  The remaining arguments\n",
      "     |      are passed to the ``PlaintextCorpusReader`` constructor.\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Methods inherited from CategorizedPlaintextCorpusReader:\n",
      "     |  \n",
      "     |  paras(self, fileids=None, categories=None)\n",
      "     |      :return: the given file(s) as a list of\n",
      "     |          paragraphs, each encoded as a list of sentences, which are\n",
      "     |          in turn encoded as lists of word strings.\n",
      "     |      :rtype: list(list(list(str)))\n",
      "     |  \n",
      "     |  raw(self, fileids=None, categories=None)\n",
      "     |      :return: the given file(s) as a single string.\n",
      "     |      :rtype: str\n",
      "     |  \n",
      "     |  sents(self, fileids=None, categories=None)\n",
      "     |      :return: the given file(s) as a list of\n",
      "     |          sentences or utterances, each encoded as a list of word\n",
      "     |          strings.\n",
      "     |      :rtype: list(list(str))\n",
      "     |  \n",
      "     |  words(self, fileids=None, categories=None)\n",
      "     |      :return: the given file(s) as a list of words\n",
      "     |          and punctuation symbols.\n",
      "     |      :rtype: list(str)\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Methods inherited from nltk.corpus.reader.api.CategorizedCorpusReader:\n",
      "     |  \n",
      "     |  categories(self, fileids=None)\n",
      "     |      Return a list of the categories that are defined for this corpus,\n",
      "     |      or for the file(s) if it is given.\n",
      "     |  \n",
      "     |  fileids(self, categories=None)\n",
      "     |      Return a list of file identifiers for the files that make up\n",
      "     |      this corpus, or that make up the given category(s) if specified.\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Data descriptors inherited from nltk.corpus.reader.api.CategorizedCorpusReader:\n",
      "     |  \n",
      "     |  __dict__\n",
      "     |      dictionary for instance variables (if defined)\n",
      "     |  \n",
      "     |  __weakref__\n",
      "     |      list of weak references to the object (if defined)\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Data and other attributes inherited from PlaintextCorpusReader:\n",
      "     |  \n",
      "     |  CorpusView = <class 'nltk.corpus.reader.util.StreamBackedCorpusView'>\n",
      "     |      A 'view' of a corpus file, which acts like a sequence of tokens:\n",
      "     |      it can be accessed by index, iterated over, etc.  However, the\n",
      "     |      tokens are only constructed as-needed -- the entire corpus is\n",
      "     |      never stored in memory at once.\n",
      "     |      \n",
      "     |      The constructor to ``StreamBackedCorpusView`` takes two arguments:\n",
      "     |      a corpus fileid (specified as a string or as a ``PathPointer``);\n",
      "     |      and a block reader.  A \"block reader\" is a function that reads\n",
      "     |      zero or more tokens from a stream, and returns them as a list.  A\n",
      "     |      very simple example of a block reader is:\n",
      "     |      \n",
      "     |          >>> def simple_block_reader(stream):\n",
      "     |          ...     return stream.readline().split()\n",
      "     |      \n",
      "     |      This simple block reader reads a single line at a time, and\n",
      "     |      returns a single token (consisting of a string) for each\n",
      "     |      whitespace-separated substring on the line.\n",
      "     |      \n",
      "     |      When deciding how to define the block reader for a given\n",
      "     |      corpus, careful consideration should be given to the size of\n",
      "     |      blocks handled by the block reader.  Smaller block sizes will\n",
      "     |      increase the memory requirements of the corpus view's internal\n",
      "     |      data structures (by 2 integers per block).  On the other hand,\n",
      "     |      larger block sizes may decrease performance for random access to\n",
      "     |      the corpus.  (But note that larger block sizes will *not*\n",
      "     |      decrease performance for iteration.)\n",
      "     |      \n",
      "     |      Internally, ``CorpusView`` maintains a partial mapping from token\n",
      "     |      index to file position, with one entry per block.  When a token\n",
      "     |      with a given index *i* is requested, the ``CorpusView`` constructs\n",
      "     |      it as follows:\n",
      "     |      \n",
      "     |        1. First, it searches the toknum/filepos mapping for the token\n",
      "     |           index closest to (but less than or equal to) *i*.\n",
      "     |      \n",
      "     |        2. Then, starting at the file position corresponding to that\n",
      "     |           index, it reads one block at a time using the block reader\n",
      "     |           until it reaches the requested token.\n",
      "     |      \n",
      "     |      The toknum/filepos mapping is created lazily: it is initially\n",
      "     |      empty, but every time a new block is read, the block's\n",
      "     |      initial token is added to the mapping.  (Thus, the toknum/filepos\n",
      "     |      map has one entry per block.)\n",
      "     |      \n",
      "     |      In order to increase efficiency for random access patterns that\n",
      "     |      have high degrees of locality, the corpus view may cache one or\n",
      "     |      more blocks.\n",
      "     |      \n",
      "     |      :note: Each ``CorpusView`` object internally maintains an open file\n",
      "     |          object for its underlying corpus file.  This file should be\n",
      "     |          automatically closed when the ``CorpusView`` is garbage collected,\n",
      "     |          but if you wish to close it manually, use the ``close()``\n",
      "     |          method.  If you access a ``CorpusView``'s items after it has been\n",
      "     |          closed, the file object will be automatically re-opened.\n",
      "     |      \n",
      "     |      :warning: If the contents of the file are modified during the\n",
      "     |          lifetime of the ``CorpusView``, then the ``CorpusView``'s behavior\n",
      "     |          is undefined.\n",
      "     |      \n",
      "     |      :warning: If a unicode encoding is specified when constructing a\n",
      "     |          ``CorpusView``, then the block reader may only call\n",
      "     |          ``stream.seek()`` with offsets that have been returned by\n",
      "     |          ``stream.tell()``; in particular, calling ``stream.seek()`` with\n",
      "     |          relative offsets, or with offsets based on string lengths, may\n",
      "     |          lead to incorrect behavior.\n",
      "     |      \n",
      "     |      :ivar _block_reader: The function used to read\n",
      "     |          a single block from the underlying file stream.\n",
      "     |      :ivar _toknum: A list containing the token index of each block\n",
      "     |          that has been processed.  In particular, ``_toknum[i]`` is the\n",
      "     |          token index of the first token in block ``i``.  Together\n",
      "     |          with ``_filepos``, this forms a partial mapping between token\n",
      "     |          indices and file positions.\n",
      "     |      :ivar _filepos: A list containing the file position of each block\n",
      "     |          that has been processed.  In particular, ``_toknum[i]`` is the\n",
      "     |          file position of the first character in block ``i``.  Together\n",
      "     |          with ``_toknum``, this forms a partial mapping between token\n",
      "     |          indices and file positions.\n",
      "     |      :ivar _stream: The stream used to access the underlying corpus file.\n",
      "     |      :ivar _len: The total number of tokens in the corpus, if known;\n",
      "     |          or None, if the number of tokens is not yet known.\n",
      "     |      :ivar _eofpos: The character position of the last character in the\n",
      "     |          file.  This is calculated when the corpus view is initialized,\n",
      "     |          and is used to decide when the end of file has been reached.\n",
      "     |      :ivar _cache: A cache of the most recently read block.  It\n",
      "     |         is encoded as a tuple (start_toknum, end_toknum, tokens), where\n",
      "     |         start_toknum is the token index of the first token in the block;\n",
      "     |         end_toknum is the token index of the first token not in the\n",
      "     |         block; and tokens is a list of the tokens in the block.\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Methods inherited from nltk.corpus.reader.api.CorpusReader:\n",
      "     |  \n",
      "     |  __repr__(self)\n",
      "     |      Return repr(self).\n",
      "     |  \n",
      "     |  __unicode__ = __str__(self, /)\n",
      "     |  \n",
      "     |  abspath(self, fileid)\n",
      "     |      Return the absolute path for the given file.\n",
      "     |      \n",
      "     |      :type fileid: str\n",
      "     |      :param fileid: The file identifier for the file whose path\n",
      "     |          should be returned.\n",
      "     |      :rtype: PathPointer\n",
      "     |  \n",
      "     |  abspaths(self, fileids=None, include_encoding=False, include_fileid=False)\n",
      "     |      Return a list of the absolute paths for all fileids in this corpus;\n",
      "     |      or for the given list of fileids, if specified.\n",
      "     |      \n",
      "     |      :type fileids: None or str or list\n",
      "     |      :param fileids: Specifies the set of fileids for which paths should\n",
      "     |          be returned.  Can be None, for all fileids; a list of\n",
      "     |          file identifiers, for a specified set of fileids; or a single\n",
      "     |          file identifier, for a single file.  Note that the return\n",
      "     |          value is always a list of paths, even if ``fileids`` is a\n",
      "     |          single file identifier.\n",
      "     |      \n",
      "     |      :param include_encoding: If true, then return a list of\n",
      "     |          ``(path_pointer, encoding)`` tuples.\n",
      "     |      \n",
      "     |      :rtype: list(PathPointer)\n",
      "     |  \n",
      "     |  citation(self)\n",
      "     |      Return the contents of the corpus citation.bib file, if it exists.\n",
      "     |  \n",
      "     |  encoding(self, file)\n",
      "     |      Return the unicode encoding for the given corpus file, if known.\n",
      "     |      If the encoding is unknown, or if the given file should be\n",
      "     |      processed using byte strings (str), then return None.\n",
      "     |  \n",
      "     |  ensure_loaded(self)\n",
      "     |      Load this corpus (if it has not already been loaded).  This is\n",
      "     |      used by LazyCorpusLoader as a simple method that can be used to\n",
      "     |      make sure a corpus is loaded -- e.g., in case a user wants to\n",
      "     |      do help(some_corpus).\n",
      "     |  \n",
      "     |  license(self)\n",
      "     |      Return the contents of the corpus LICENSE file, if it exists.\n",
      "     |  \n",
      "     |  open(self, file)\n",
      "     |      Return an open stream that can be used to read the given file.\n",
      "     |      If the file's encoding is not None, then the stream will\n",
      "     |      automatically decode the file's contents into unicode.\n",
      "     |      \n",
      "     |      :param file: The file identifier of the file to read.\n",
      "     |  \n",
      "     |  readme(self)\n",
      "     |      Return the contents of the corpus README file, if it exists.\n",
      "     |  \n",
      "     |  unicode_repr = __repr__(self)\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Data descriptors inherited from nltk.corpus.reader.api.CorpusReader:\n",
      "     |  \n",
      "     |  root\n",
      "     |      The directory where this corpus is stored.\n",
      "     |      \n",
      "     |      :type: PathPointer\n",
      "    \n",
      "    class PropbankCorpusReader(nltk.corpus.reader.api.CorpusReader)\n",
      "     |  PropbankCorpusReader(root, propfile, framefiles='', verbsfile=None, parse_fileid_xform=None, parse_corpus=None, encoding='utf8')\n",
      "     |  \n",
      "     |  Corpus reader for the propbank corpus, which augments the Penn\n",
      "     |  Treebank with information about the predicate argument structure\n",
      "     |  of every verb instance.  The corpus consists of two parts: the\n",
      "     |  predicate-argument annotations themselves, and a set of \"frameset\n",
      "     |  files\" which define the argument labels used by the annotations,\n",
      "     |  on a per-verb basis.  Each \"frameset file\" contains one or more\n",
      "     |  predicates, such as ``'turn'`` or ``'turn_on'``, each of which is\n",
      "     |  divided into coarse-grained word senses called \"rolesets\".  For\n",
      "     |  each \"roleset\", the frameset file provides descriptions of the\n",
      "     |  argument roles, along with examples.\n",
      "     |  \n",
      "     |  Method resolution order:\n",
      "     |      PropbankCorpusReader\n",
      "     |      nltk.corpus.reader.api.CorpusReader\n",
      "     |      builtins.object\n",
      "     |  \n",
      "     |  Methods defined here:\n",
      "     |  \n",
      "     |  __init__(self, root, propfile, framefiles='', verbsfile=None, parse_fileid_xform=None, parse_corpus=None, encoding='utf8')\n",
      "     |      :param root: The root directory for this corpus.\n",
      "     |      :param propfile: The name of the file containing the predicate-\n",
      "     |          argument annotations (relative to ``root``).\n",
      "     |      :param framefiles: A list or regexp specifying the frameset\n",
      "     |          fileids for this corpus.\n",
      "     |      :param parse_fileid_xform: A transform that should be applied\n",
      "     |          to the fileids in this corpus.  This should be a function\n",
      "     |          of one argument (a fileid) that returns a string (the new\n",
      "     |          fileid).\n",
      "     |      :param parse_corpus: The corpus containing the parse trees\n",
      "     |          corresponding to this corpus.  These parse trees are\n",
      "     |          necessary to resolve the tree pointers used by propbank.\n",
      "     |  \n",
      "     |  instances(self, baseform=None)\n",
      "     |      :return: a corpus view that acts as a list of\n",
      "     |      ``PropBankInstance`` objects, one for each noun in the corpus.\n",
      "     |  \n",
      "     |  lines(self)\n",
      "     |      :return: a corpus view that acts as a list of strings, one for\n",
      "     |      each line in the predicate-argument annotation file.\n",
      "     |  \n",
      "     |  raw(self, fileids=None)\n",
      "     |      :return: the text contents of the given fileids, as a single string.\n",
      "     |  \n",
      "     |  roleset(self, roleset_id)\n",
      "     |      :return: the xml description for the given roleset.\n",
      "     |  \n",
      "     |  rolesets(self, baseform=None)\n",
      "     |      :return: list of xml descriptions for rolesets.\n",
      "     |  \n",
      "     |  verbs(self)\n",
      "     |      :return: a corpus view that acts as a list of all verb lemmas\n",
      "     |      in this corpus (from the verbs.txt file).\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Methods inherited from nltk.corpus.reader.api.CorpusReader:\n",
      "     |  \n",
      "     |  __repr__(self)\n",
      "     |      Return repr(self).\n",
      "     |  \n",
      "     |  __unicode__ = __str__(self, /)\n",
      "     |  \n",
      "     |  abspath(self, fileid)\n",
      "     |      Return the absolute path for the given file.\n",
      "     |      \n",
      "     |      :type fileid: str\n",
      "     |      :param fileid: The file identifier for the file whose path\n",
      "     |          should be returned.\n",
      "     |      :rtype: PathPointer\n",
      "     |  \n",
      "     |  abspaths(self, fileids=None, include_encoding=False, include_fileid=False)\n",
      "     |      Return a list of the absolute paths for all fileids in this corpus;\n",
      "     |      or for the given list of fileids, if specified.\n",
      "     |      \n",
      "     |      :type fileids: None or str or list\n",
      "     |      :param fileids: Specifies the set of fileids for which paths should\n",
      "     |          be returned.  Can be None, for all fileids; a list of\n",
      "     |          file identifiers, for a specified set of fileids; or a single\n",
      "     |          file identifier, for a single file.  Note that the return\n",
      "     |          value is always a list of paths, even if ``fileids`` is a\n",
      "     |          single file identifier.\n",
      "     |      \n",
      "     |      :param include_encoding: If true, then return a list of\n",
      "     |          ``(path_pointer, encoding)`` tuples.\n",
      "     |      \n",
      "     |      :rtype: list(PathPointer)\n",
      "     |  \n",
      "     |  citation(self)\n",
      "     |      Return the contents of the corpus citation.bib file, if it exists.\n",
      "     |  \n",
      "     |  encoding(self, file)\n",
      "     |      Return the unicode encoding for the given corpus file, if known.\n",
      "     |      If the encoding is unknown, or if the given file should be\n",
      "     |      processed using byte strings (str), then return None.\n",
      "     |  \n",
      "     |  ensure_loaded(self)\n",
      "     |      Load this corpus (if it has not already been loaded).  This is\n",
      "     |      used by LazyCorpusLoader as a simple method that can be used to\n",
      "     |      make sure a corpus is loaded -- e.g., in case a user wants to\n",
      "     |      do help(some_corpus).\n",
      "     |  \n",
      "     |  fileids(self)\n",
      "     |      Return a list of file identifiers for the fileids that make up\n",
      "     |      this corpus.\n",
      "     |  \n",
      "     |  license(self)\n",
      "     |      Return the contents of the corpus LICENSE file, if it exists.\n",
      "     |  \n",
      "     |  open(self, file)\n",
      "     |      Return an open stream that can be used to read the given file.\n",
      "     |      If the file's encoding is not None, then the stream will\n",
      "     |      automatically decode the file's contents into unicode.\n",
      "     |      \n",
      "     |      :param file: The file identifier of the file to read.\n",
      "     |  \n",
      "     |  readme(self)\n",
      "     |      Return the contents of the corpus README file, if it exists.\n",
      "     |  \n",
      "     |  unicode_repr = __repr__(self)\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Data descriptors inherited from nltk.corpus.reader.api.CorpusReader:\n",
      "     |  \n",
      "     |  __dict__\n",
      "     |      dictionary for instance variables (if defined)\n",
      "     |  \n",
      "     |  __weakref__\n",
      "     |      list of weak references to the object (if defined)\n",
      "     |  \n",
      "     |  root\n",
      "     |      The directory where this corpus is stored.\n",
      "     |      \n",
      "     |      :type: PathPointer\n",
      "    \n",
      "    class ProsConsCorpusReader(nltk.corpus.reader.api.CategorizedCorpusReader, nltk.corpus.reader.api.CorpusReader)\n",
      "     |  ProsConsCorpusReader(root, fileids, word_tokenizer=WordPunctTokenizer(pattern='\\\\w+|[^\\\\w\\\\s]+', gaps=False, discard_empty=True, flags=<RegexFlag.UNICODE|DOTALL|MULTILINE: 56>), encoding='utf8', **kwargs)\n",
      "     |  \n",
      "     |  Reader for the Pros and Cons sentence dataset.\n",
      "     |  \n",
      "     |      >>> from nltk.corpus import pros_cons\n",
      "     |      >>> pros_cons.sents(categories='Cons')\n",
      "     |      [['East', 'batteries', '!', 'On', '-', 'off', 'switch', 'too', 'easy',\n",
      "     |      'to', 'maneuver', '.'], ['Eats', '...', 'no', ',', 'GULPS', 'batteries'],\n",
      "     |      ...]\n",
      "     |      >>> pros_cons.words('IntegratedPros.txt')\n",
      "     |      ['Easy', 'to', 'use', ',', 'economical', '!', ...]\n",
      "     |  \n",
      "     |  Method resolution order:\n",
      "     |      ProsConsCorpusReader\n",
      "     |      nltk.corpus.reader.api.CategorizedCorpusReader\n",
      "     |      nltk.corpus.reader.api.CorpusReader\n",
      "     |      builtins.object\n",
      "     |  \n",
      "     |  Methods defined here:\n",
      "     |  \n",
      "     |  __init__(self, root, fileids, word_tokenizer=WordPunctTokenizer(pattern='\\\\w+|[^\\\\w\\\\s]+', gaps=False, discard_empty=True, flags=<RegexFlag.UNICODE|DOTALL|MULTILINE: 56>), encoding='utf8', **kwargs)\n",
      "     |      :param root: The root directory for the corpus.\n",
      "     |      :param fileids: a list or regexp specifying the fileids in the corpus.\n",
      "     |      :param word_tokenizer: a tokenizer for breaking sentences or paragraphs\n",
      "     |          into words. Default: `WhitespaceTokenizer`\n",
      "     |      :param encoding: the encoding that should be used to read the corpus.\n",
      "     |      :param kwargs: additional parameters passed to CategorizedCorpusReader.\n",
      "     |  \n",
      "     |  sents(self, fileids=None, categories=None)\n",
      "     |      Return all sentences in the corpus or in the specified files/categories.\n",
      "     |      \n",
      "     |      :param fileids: a list or regexp specifying the ids of the files whose\n",
      "     |          sentences have to be returned.\n",
      "     |      :param categories: a list specifying the categories whose sentences\n",
      "     |          have to be returned.\n",
      "     |      :return: the given file(s) as a list of sentences. Each sentence is\n",
      "     |          tokenized using the specified word_tokenizer.\n",
      "     |      :rtype: list(list(str))\n",
      "     |  \n",
      "     |  words(self, fileids=None, categories=None)\n",
      "     |      Return all words and punctuation symbols in the corpus or in the specified\n",
      "     |      files/categories.\n",
      "     |      \n",
      "     |      :param fileids: a list or regexp specifying the ids of the files whose\n",
      "     |          words have to be returned.\n",
      "     |      :param categories: a list specifying the categories whose words have\n",
      "     |          to be returned.\n",
      "     |      :return: the given file(s) as a list of words and punctuation symbols.\n",
      "     |      :rtype: list(str)\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Data and other attributes defined here:\n",
      "     |  \n",
      "     |  CorpusView = <class 'nltk.corpus.reader.util.StreamBackedCorpusView'>\n",
      "     |      A 'view' of a corpus file, which acts like a sequence of tokens:\n",
      "     |      it can be accessed by index, iterated over, etc.  However, the\n",
      "     |      tokens are only constructed as-needed -- the entire corpus is\n",
      "     |      never stored in memory at once.\n",
      "     |      \n",
      "     |      The constructor to ``StreamBackedCorpusView`` takes two arguments:\n",
      "     |      a corpus fileid (specified as a string or as a ``PathPointer``);\n",
      "     |      and a block reader.  A \"block reader\" is a function that reads\n",
      "     |      zero or more tokens from a stream, and returns them as a list.  A\n",
      "     |      very simple example of a block reader is:\n",
      "     |      \n",
      "     |          >>> def simple_block_reader(stream):\n",
      "     |          ...     return stream.readline().split()\n",
      "     |      \n",
      "     |      This simple block reader reads a single line at a time, and\n",
      "     |      returns a single token (consisting of a string) for each\n",
      "     |      whitespace-separated substring on the line.\n",
      "     |      \n",
      "     |      When deciding how to define the block reader for a given\n",
      "     |      corpus, careful consideration should be given to the size of\n",
      "     |      blocks handled by the block reader.  Smaller block sizes will\n",
      "     |      increase the memory requirements of the corpus view's internal\n",
      "     |      data structures (by 2 integers per block).  On the other hand,\n",
      "     |      larger block sizes may decrease performance for random access to\n",
      "     |      the corpus.  (But note that larger block sizes will *not*\n",
      "     |      decrease performance for iteration.)\n",
      "     |      \n",
      "     |      Internally, ``CorpusView`` maintains a partial mapping from token\n",
      "     |      index to file position, with one entry per block.  When a token\n",
      "     |      with a given index *i* is requested, the ``CorpusView`` constructs\n",
      "     |      it as follows:\n",
      "     |      \n",
      "     |        1. First, it searches the toknum/filepos mapping for the token\n",
      "     |           index closest to (but less than or equal to) *i*.\n",
      "     |      \n",
      "     |        2. Then, starting at the file position corresponding to that\n",
      "     |           index, it reads one block at a time using the block reader\n",
      "     |           until it reaches the requested token.\n",
      "     |      \n",
      "     |      The toknum/filepos mapping is created lazily: it is initially\n",
      "     |      empty, but every time a new block is read, the block's\n",
      "     |      initial token is added to the mapping.  (Thus, the toknum/filepos\n",
      "     |      map has one entry per block.)\n",
      "     |      \n",
      "     |      In order to increase efficiency for random access patterns that\n",
      "     |      have high degrees of locality, the corpus view may cache one or\n",
      "     |      more blocks.\n",
      "     |      \n",
      "     |      :note: Each ``CorpusView`` object internally maintains an open file\n",
      "     |          object for its underlying corpus file.  This file should be\n",
      "     |          automatically closed when the ``CorpusView`` is garbage collected,\n",
      "     |          but if you wish to close it manually, use the ``close()``\n",
      "     |          method.  If you access a ``CorpusView``'s items after it has been\n",
      "     |          closed, the file object will be automatically re-opened.\n",
      "     |      \n",
      "     |      :warning: If the contents of the file are modified during the\n",
      "     |          lifetime of the ``CorpusView``, then the ``CorpusView``'s behavior\n",
      "     |          is undefined.\n",
      "     |      \n",
      "     |      :warning: If a unicode encoding is specified when constructing a\n",
      "     |          ``CorpusView``, then the block reader may only call\n",
      "     |          ``stream.seek()`` with offsets that have been returned by\n",
      "     |          ``stream.tell()``; in particular, calling ``stream.seek()`` with\n",
      "     |          relative offsets, or with offsets based on string lengths, may\n",
      "     |          lead to incorrect behavior.\n",
      "     |      \n",
      "     |      :ivar _block_reader: The function used to read\n",
      "     |          a single block from the underlying file stream.\n",
      "     |      :ivar _toknum: A list containing the token index of each block\n",
      "     |          that has been processed.  In particular, ``_toknum[i]`` is the\n",
      "     |          token index of the first token in block ``i``.  Together\n",
      "     |          with ``_filepos``, this forms a partial mapping between token\n",
      "     |          indices and file positions.\n",
      "     |      :ivar _filepos: A list containing the file position of each block\n",
      "     |          that has been processed.  In particular, ``_toknum[i]`` is the\n",
      "     |          file position of the first character in block ``i``.  Together\n",
      "     |          with ``_toknum``, this forms a partial mapping between token\n",
      "     |          indices and file positions.\n",
      "     |      :ivar _stream: The stream used to access the underlying corpus file.\n",
      "     |      :ivar _len: The total number of tokens in the corpus, if known;\n",
      "     |          or None, if the number of tokens is not yet known.\n",
      "     |      :ivar _eofpos: The character position of the last character in the\n",
      "     |          file.  This is calculated when the corpus view is initialized,\n",
      "     |          and is used to decide when the end of file has been reached.\n",
      "     |      :ivar _cache: A cache of the most recently read block.  It\n",
      "     |         is encoded as a tuple (start_toknum, end_toknum, tokens), where\n",
      "     |         start_toknum is the token index of the first token in the block;\n",
      "     |         end_toknum is the token index of the first token not in the\n",
      "     |         block; and tokens is a list of the tokens in the block.\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Methods inherited from nltk.corpus.reader.api.CategorizedCorpusReader:\n",
      "     |  \n",
      "     |  categories(self, fileids=None)\n",
      "     |      Return a list of the categories that are defined for this corpus,\n",
      "     |      or for the file(s) if it is given.\n",
      "     |  \n",
      "     |  fileids(self, categories=None)\n",
      "     |      Return a list of file identifiers for the files that make up\n",
      "     |      this corpus, or that make up the given category(s) if specified.\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Data descriptors inherited from nltk.corpus.reader.api.CategorizedCorpusReader:\n",
      "     |  \n",
      "     |  __dict__\n",
      "     |      dictionary for instance variables (if defined)\n",
      "     |  \n",
      "     |  __weakref__\n",
      "     |      list of weak references to the object (if defined)\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Methods inherited from nltk.corpus.reader.api.CorpusReader:\n",
      "     |  \n",
      "     |  __repr__(self)\n",
      "     |      Return repr(self).\n",
      "     |  \n",
      "     |  __unicode__ = __str__(self, /)\n",
      "     |  \n",
      "     |  abspath(self, fileid)\n",
      "     |      Return the absolute path for the given file.\n",
      "     |      \n",
      "     |      :type fileid: str\n",
      "     |      :param fileid: The file identifier for the file whose path\n",
      "     |          should be returned.\n",
      "     |      :rtype: PathPointer\n",
      "     |  \n",
      "     |  abspaths(self, fileids=None, include_encoding=False, include_fileid=False)\n",
      "     |      Return a list of the absolute paths for all fileids in this corpus;\n",
      "     |      or for the given list of fileids, if specified.\n",
      "     |      \n",
      "     |      :type fileids: None or str or list\n",
      "     |      :param fileids: Specifies the set of fileids for which paths should\n",
      "     |          be returned.  Can be None, for all fileids; a list of\n",
      "     |          file identifiers, for a specified set of fileids; or a single\n",
      "     |          file identifier, for a single file.  Note that the return\n",
      "     |          value is always a list of paths, even if ``fileids`` is a\n",
      "     |          single file identifier.\n",
      "     |      \n",
      "     |      :param include_encoding: If true, then return a list of\n",
      "     |          ``(path_pointer, encoding)`` tuples.\n",
      "     |      \n",
      "     |      :rtype: list(PathPointer)\n",
      "     |  \n",
      "     |  citation(self)\n",
      "     |      Return the contents of the corpus citation.bib file, if it exists.\n",
      "     |  \n",
      "     |  encoding(self, file)\n",
      "     |      Return the unicode encoding for the given corpus file, if known.\n",
      "     |      If the encoding is unknown, or if the given file should be\n",
      "     |      processed using byte strings (str), then return None.\n",
      "     |  \n",
      "     |  ensure_loaded(self)\n",
      "     |      Load this corpus (if it has not already been loaded).  This is\n",
      "     |      used by LazyCorpusLoader as a simple method that can be used to\n",
      "     |      make sure a corpus is loaded -- e.g., in case a user wants to\n",
      "     |      do help(some_corpus).\n",
      "     |  \n",
      "     |  license(self)\n",
      "     |      Return the contents of the corpus LICENSE file, if it exists.\n",
      "     |  \n",
      "     |  open(self, file)\n",
      "     |      Return an open stream that can be used to read the given file.\n",
      "     |      If the file's encoding is not None, then the stream will\n",
      "     |      automatically decode the file's contents into unicode.\n",
      "     |      \n",
      "     |      :param file: The file identifier of the file to read.\n",
      "     |  \n",
      "     |  readme(self)\n",
      "     |      Return the contents of the corpus README file, if it exists.\n",
      "     |  \n",
      "     |  unicode_repr = __repr__(self)\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Data descriptors inherited from nltk.corpus.reader.api.CorpusReader:\n",
      "     |  \n",
      "     |  root\n",
      "     |      The directory where this corpus is stored.\n",
      "     |      \n",
      "     |      :type: PathPointer\n",
      "    \n",
      "    class RTECorpusReader(nltk.corpus.reader.xmldocs.XMLCorpusReader)\n",
      "     |  RTECorpusReader(root, fileids, wrap_etree=False)\n",
      "     |  \n",
      "     |  Corpus reader for corpora in RTE challenges.\n",
      "     |  \n",
      "     |  This is just a wrapper around the XMLCorpusReader. See module docstring above for the expected\n",
      "     |  structure of input documents.\n",
      "     |  \n",
      "     |  Method resolution order:\n",
      "     |      RTECorpusReader\n",
      "     |      nltk.corpus.reader.xmldocs.XMLCorpusReader\n",
      "     |      nltk.corpus.reader.api.CorpusReader\n",
      "     |      builtins.object\n",
      "     |  \n",
      "     |  Methods defined here:\n",
      "     |  \n",
      "     |  pairs(self, fileids)\n",
      "     |      Build a list of RTEPairs from a RTE corpus.\n",
      "     |      \n",
      "     |      :param fileids: a list of RTE corpus fileids\n",
      "     |      :type: list\n",
      "     |      :rtype: list(RTEPair)\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Methods inherited from nltk.corpus.reader.xmldocs.XMLCorpusReader:\n",
      "     |  \n",
      "     |  __init__(self, root, fileids, wrap_etree=False)\n",
      "     |      :type root: PathPointer or str\n",
      "     |      :param root: A path pointer identifying the root directory for\n",
      "     |          this corpus.  If a string is specified, then it will be\n",
      "     |          converted to a ``PathPointer`` automatically.\n",
      "     |      :param fileids: A list of the files that make up this corpus.\n",
      "     |          This list can either be specified explicitly, as a list of\n",
      "     |          strings; or implicitly, as a regular expression over file\n",
      "     |          paths.  The absolute path for each file will be constructed\n",
      "     |          by joining the reader's root to each file name.\n",
      "     |      :param encoding: The default unicode encoding for the files\n",
      "     |          that make up the corpus.  The value of ``encoding`` can be any\n",
      "     |          of the following:\n",
      "     |          - A string: ``encoding`` is the encoding name for all files.\n",
      "     |          - A dictionary: ``encoding[file_id]`` is the encoding\n",
      "     |            name for the file whose identifier is ``file_id``.  If\n",
      "     |            ``file_id`` is not in ``encoding``, then the file\n",
      "     |            contents will be processed using non-unicode byte strings.\n",
      "     |          - A list: ``encoding`` should be a list of ``(regexp, encoding)``\n",
      "     |            tuples.  The encoding for a file whose identifier is ``file_id``\n",
      "     |            will be the ``encoding`` value for the first tuple whose\n",
      "     |            ``regexp`` matches the ``file_id``.  If no tuple's ``regexp``\n",
      "     |            matches the ``file_id``, the file contents will be processed\n",
      "     |            using non-unicode byte strings.\n",
      "     |          - None: the file contents of all files will be\n",
      "     |            processed using non-unicode byte strings.\n",
      "     |      :param tagset: The name of the tagset used by this corpus, to be used\n",
      "     |            for normalizing or converting the POS tags returned by the\n",
      "     |            tagged_...() methods.\n",
      "     |  \n",
      "     |  raw(self, fileids=None)\n",
      "     |  \n",
      "     |  words(self, fileid=None)\n",
      "     |      Returns all of the words and punctuation symbols in the specified file\n",
      "     |      that were in text nodes -- ie, tags are ignored. Like the xml() method,\n",
      "     |      fileid can only specify one file.\n",
      "     |      \n",
      "     |      :return: the given file's text nodes as a list of words and punctuation symbols\n",
      "     |      :rtype: list(str)\n",
      "     |  \n",
      "     |  xml(self, fileid=None)\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Methods inherited from nltk.corpus.reader.api.CorpusReader:\n",
      "     |  \n",
      "     |  __repr__(self)\n",
      "     |      Return repr(self).\n",
      "     |  \n",
      "     |  __unicode__ = __str__(self, /)\n",
      "     |  \n",
      "     |  abspath(self, fileid)\n",
      "     |      Return the absolute path for the given file.\n",
      "     |      \n",
      "     |      :type fileid: str\n",
      "     |      :param fileid: The file identifier for the file whose path\n",
      "     |          should be returned.\n",
      "     |      :rtype: PathPointer\n",
      "     |  \n",
      "     |  abspaths(self, fileids=None, include_encoding=False, include_fileid=False)\n",
      "     |      Return a list of the absolute paths for all fileids in this corpus;\n",
      "     |      or for the given list of fileids, if specified.\n",
      "     |      \n",
      "     |      :type fileids: None or str or list\n",
      "     |      :param fileids: Specifies the set of fileids for which paths should\n",
      "     |          be returned.  Can be None, for all fileids; a list of\n",
      "     |          file identifiers, for a specified set of fileids; or a single\n",
      "     |          file identifier, for a single file.  Note that the return\n",
      "     |          value is always a list of paths, even if ``fileids`` is a\n",
      "     |          single file identifier.\n",
      "     |      \n",
      "     |      :param include_encoding: If true, then return a list of\n",
      "     |          ``(path_pointer, encoding)`` tuples.\n",
      "     |      \n",
      "     |      :rtype: list(PathPointer)\n",
      "     |  \n",
      "     |  citation(self)\n",
      "     |      Return the contents of the corpus citation.bib file, if it exists.\n",
      "     |  \n",
      "     |  encoding(self, file)\n",
      "     |      Return the unicode encoding for the given corpus file, if known.\n",
      "     |      If the encoding is unknown, or if the given file should be\n",
      "     |      processed using byte strings (str), then return None.\n",
      "     |  \n",
      "     |  ensure_loaded(self)\n",
      "     |      Load this corpus (if it has not already been loaded).  This is\n",
      "     |      used by LazyCorpusLoader as a simple method that can be used to\n",
      "     |      make sure a corpus is loaded -- e.g., in case a user wants to\n",
      "     |      do help(some_corpus).\n",
      "     |  \n",
      "     |  fileids(self)\n",
      "     |      Return a list of file identifiers for the fileids that make up\n",
      "     |      this corpus.\n",
      "     |  \n",
      "     |  license(self)\n",
      "     |      Return the contents of the corpus LICENSE file, if it exists.\n",
      "     |  \n",
      "     |  open(self, file)\n",
      "     |      Return an open stream that can be used to read the given file.\n",
      "     |      If the file's encoding is not None, then the stream will\n",
      "     |      automatically decode the file's contents into unicode.\n",
      "     |      \n",
      "     |      :param file: The file identifier of the file to read.\n",
      "     |  \n",
      "     |  readme(self)\n",
      "     |      Return the contents of the corpus README file, if it exists.\n",
      "     |  \n",
      "     |  unicode_repr = __repr__(self)\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Data descriptors inherited from nltk.corpus.reader.api.CorpusReader:\n",
      "     |  \n",
      "     |  __dict__\n",
      "     |      dictionary for instance variables (if defined)\n",
      "     |  \n",
      "     |  __weakref__\n",
      "     |      list of weak references to the object (if defined)\n",
      "     |  \n",
      "     |  root\n",
      "     |      The directory where this corpus is stored.\n",
      "     |      \n",
      "     |      :type: PathPointer\n",
      "    \n",
      "    class ReviewsCorpusReader(nltk.corpus.reader.api.CorpusReader)\n",
      "     |  ReviewsCorpusReader(root, fileids, word_tokenizer=WordPunctTokenizer(pattern='\\\\w+|[^\\\\w\\\\s]+', gaps=False, discard_empty=True, flags=<RegexFlag.UNICODE|DOTALL|MULTILINE: 56>), encoding='utf8')\n",
      "     |  \n",
      "     |  Reader for the Customer Review Data dataset by Hu, Liu (2004).\n",
      "     |  Note: we are not applying any sentence tokenization at the moment, just word\n",
      "     |  tokenization.\n",
      "     |  \n",
      "     |      >>> from nltk.corpus import product_reviews_1\n",
      "     |      >>> camera_reviews = product_reviews_1.reviews('Canon_G3.txt')\n",
      "     |      >>> review = camera_reviews[0]\n",
      "     |      >>> review.sents()[0]\n",
      "     |      ['i', 'recently', 'purchased', 'the', 'canon', 'powershot', 'g3', 'and', 'am',\n",
      "     |      'extremely', 'satisfied', 'with', 'the', 'purchase', '.']\n",
      "     |      >>> review.features()\n",
      "     |      [('canon powershot g3', '+3'), ('use', '+2'), ('picture', '+2'),\n",
      "     |      ('picture quality', '+1'), ('picture quality', '+1'), ('camera', '+2'),\n",
      "     |      ('use', '+2'), ('feature', '+1'), ('picture quality', '+3'), ('use', '+1'),\n",
      "     |      ('option', '+1')]\n",
      "     |  \n",
      "     |  We can also reach the same information directly from the stream:\n",
      "     |  \n",
      "     |      >>> product_reviews_1.features('Canon_G3.txt')\n",
      "     |      [('canon powershot g3', '+3'), ('use', '+2'), ...]\n",
      "     |  \n",
      "     |  We can compute stats for specific product features:\n",
      "     |  \n",
      "     |      >>> from __future__ import division\n",
      "     |      >>> n_reviews = len([(feat,score) for (feat,score) in product_reviews_1.features('Canon_G3.txt') if feat=='picture'])\n",
      "     |      >>> tot = sum([int(score) for (feat,score) in product_reviews_1.features('Canon_G3.txt') if feat=='picture'])\n",
      "     |      >>> # We use float for backward compatibility with division in Python2.7\n",
      "     |      >>> mean = tot / n_reviews\n",
      "     |      >>> print(n_reviews, tot, mean)\n",
      "     |      15 24 1.6\n",
      "     |  \n",
      "     |  Method resolution order:\n",
      "     |      ReviewsCorpusReader\n",
      "     |      nltk.corpus.reader.api.CorpusReader\n",
      "     |      builtins.object\n",
      "     |  \n",
      "     |  Methods defined here:\n",
      "     |  \n",
      "     |  __init__(self, root, fileids, word_tokenizer=WordPunctTokenizer(pattern='\\\\w+|[^\\\\w\\\\s]+', gaps=False, discard_empty=True, flags=<RegexFlag.UNICODE|DOTALL|MULTILINE: 56>), encoding='utf8')\n",
      "     |      :param root: The root directory for the corpus.\n",
      "     |      :param fileids: a list or regexp specifying the fileids in the corpus.\n",
      "     |      :param word_tokenizer: a tokenizer for breaking sentences or paragraphs\n",
      "     |          into words. Default: `WordPunctTokenizer`\n",
      "     |      :param encoding: the encoding that should be used to read the corpus.\n",
      "     |  \n",
      "     |  features(self, fileids=None)\n",
      "     |      Return a list of features. Each feature is a tuple made of the specific\n",
      "     |      item feature and the opinion strength about that feature.\n",
      "     |      \n",
      "     |      :param fileids: a list or regexp specifying the ids of the files whose\n",
      "     |          features have to be returned.\n",
      "     |      :return: all features for the item(s) in the given file(s).\n",
      "     |      :rtype: list(tuple)\n",
      "     |  \n",
      "     |  raw(self, fileids=None)\n",
      "     |      :param fileids: a list or regexp specifying the fileids of the files that\n",
      "     |          have to be returned as a raw string.\n",
      "     |      :return: the given file(s) as a single string.\n",
      "     |      :rtype: str\n",
      "     |  \n",
      "     |  readme(self)\n",
      "     |      Return the contents of the corpus README.txt file.\n",
      "     |  \n",
      "     |  reviews(self, fileids=None)\n",
      "     |      Return all the reviews as a list of Review objects. If `fileids` is\n",
      "     |      specified, return all the reviews from each of the specified files.\n",
      "     |      \n",
      "     |      :param fileids: a list or regexp specifying the ids of the files whose\n",
      "     |          reviews have to be returned.\n",
      "     |      :return: the given file(s) as a list of reviews.\n",
      "     |  \n",
      "     |  sents(self, fileids=None)\n",
      "     |      Return all sentences in the corpus or in the specified files.\n",
      "     |      \n",
      "     |      :param fileids: a list or regexp specifying the ids of the files whose\n",
      "     |          sentences have to be returned.\n",
      "     |      :return: the given file(s) as a list of sentences, each encoded as a\n",
      "     |          list of word strings.\n",
      "     |      :rtype: list(list(str))\n",
      "     |  \n",
      "     |  words(self, fileids=None)\n",
      "     |      Return all words and punctuation symbols in the corpus or in the specified\n",
      "     |      files.\n",
      "     |      \n",
      "     |      :param fileids: a list or regexp specifying the ids of the files whose\n",
      "     |          words have to be returned.\n",
      "     |      :return: the given file(s) as a list of words and punctuation symbols.\n",
      "     |      :rtype: list(str)\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Data and other attributes defined here:\n",
      "     |  \n",
      "     |  CorpusView = <class 'nltk.corpus.reader.util.StreamBackedCorpusView'>\n",
      "     |      A 'view' of a corpus file, which acts like a sequence of tokens:\n",
      "     |      it can be accessed by index, iterated over, etc.  However, the\n",
      "     |      tokens are only constructed as-needed -- the entire corpus is\n",
      "     |      never stored in memory at once.\n",
      "     |      \n",
      "     |      The constructor to ``StreamBackedCorpusView`` takes two arguments:\n",
      "     |      a corpus fileid (specified as a string or as a ``PathPointer``);\n",
      "     |      and a block reader.  A \"block reader\" is a function that reads\n",
      "     |      zero or more tokens from a stream, and returns them as a list.  A\n",
      "     |      very simple example of a block reader is:\n",
      "     |      \n",
      "     |          >>> def simple_block_reader(stream):\n",
      "     |          ...     return stream.readline().split()\n",
      "     |      \n",
      "     |      This simple block reader reads a single line at a time, and\n",
      "     |      returns a single token (consisting of a string) for each\n",
      "     |      whitespace-separated substring on the line.\n",
      "     |      \n",
      "     |      When deciding how to define the block reader for a given\n",
      "     |      corpus, careful consideration should be given to the size of\n",
      "     |      blocks handled by the block reader.  Smaller block sizes will\n",
      "     |      increase the memory requirements of the corpus view's internal\n",
      "     |      data structures (by 2 integers per block).  On the other hand,\n",
      "     |      larger block sizes may decrease performance for random access to\n",
      "     |      the corpus.  (But note that larger block sizes will *not*\n",
      "     |      decrease performance for iteration.)\n",
      "     |      \n",
      "     |      Internally, ``CorpusView`` maintains a partial mapping from token\n",
      "     |      index to file position, with one entry per block.  When a token\n",
      "     |      with a given index *i* is requested, the ``CorpusView`` constructs\n",
      "     |      it as follows:\n",
      "     |      \n",
      "     |        1. First, it searches the toknum/filepos mapping for the token\n",
      "     |           index closest to (but less than or equal to) *i*.\n",
      "     |      \n",
      "     |        2. Then, starting at the file position corresponding to that\n",
      "     |           index, it reads one block at a time using the block reader\n",
      "     |           until it reaches the requested token.\n",
      "     |      \n",
      "     |      The toknum/filepos mapping is created lazily: it is initially\n",
      "     |      empty, but every time a new block is read, the block's\n",
      "     |      initial token is added to the mapping.  (Thus, the toknum/filepos\n",
      "     |      map has one entry per block.)\n",
      "     |      \n",
      "     |      In order to increase efficiency for random access patterns that\n",
      "     |      have high degrees of locality, the corpus view may cache one or\n",
      "     |      more blocks.\n",
      "     |      \n",
      "     |      :note: Each ``CorpusView`` object internally maintains an open file\n",
      "     |          object for its underlying corpus file.  This file should be\n",
      "     |          automatically closed when the ``CorpusView`` is garbage collected,\n",
      "     |          but if you wish to close it manually, use the ``close()``\n",
      "     |          method.  If you access a ``CorpusView``'s items after it has been\n",
      "     |          closed, the file object will be automatically re-opened.\n",
      "     |      \n",
      "     |      :warning: If the contents of the file are modified during the\n",
      "     |          lifetime of the ``CorpusView``, then the ``CorpusView``'s behavior\n",
      "     |          is undefined.\n",
      "     |      \n",
      "     |      :warning: If a unicode encoding is specified when constructing a\n",
      "     |          ``CorpusView``, then the block reader may only call\n",
      "     |          ``stream.seek()`` with offsets that have been returned by\n",
      "     |          ``stream.tell()``; in particular, calling ``stream.seek()`` with\n",
      "     |          relative offsets, or with offsets based on string lengths, may\n",
      "     |          lead to incorrect behavior.\n",
      "     |      \n",
      "     |      :ivar _block_reader: The function used to read\n",
      "     |          a single block from the underlying file stream.\n",
      "     |      :ivar _toknum: A list containing the token index of each block\n",
      "     |          that has been processed.  In particular, ``_toknum[i]`` is the\n",
      "     |          token index of the first token in block ``i``.  Together\n",
      "     |          with ``_filepos``, this forms a partial mapping between token\n",
      "     |          indices and file positions.\n",
      "     |      :ivar _filepos: A list containing the file position of each block\n",
      "     |          that has been processed.  In particular, ``_toknum[i]`` is the\n",
      "     |          file position of the first character in block ``i``.  Together\n",
      "     |          with ``_toknum``, this forms a partial mapping between token\n",
      "     |          indices and file positions.\n",
      "     |      :ivar _stream: The stream used to access the underlying corpus file.\n",
      "     |      :ivar _len: The total number of tokens in the corpus, if known;\n",
      "     |          or None, if the number of tokens is not yet known.\n",
      "     |      :ivar _eofpos: The character position of the last character in the\n",
      "     |          file.  This is calculated when the corpus view is initialized,\n",
      "     |          and is used to decide when the end of file has been reached.\n",
      "     |      :ivar _cache: A cache of the most recently read block.  It\n",
      "     |         is encoded as a tuple (start_toknum, end_toknum, tokens), where\n",
      "     |         start_toknum is the token index of the first token in the block;\n",
      "     |         end_toknum is the token index of the first token not in the\n",
      "     |         block; and tokens is a list of the tokens in the block.\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Methods inherited from nltk.corpus.reader.api.CorpusReader:\n",
      "     |  \n",
      "     |  __repr__(self)\n",
      "     |      Return repr(self).\n",
      "     |  \n",
      "     |  __unicode__ = __str__(self, /)\n",
      "     |  \n",
      "     |  abspath(self, fileid)\n",
      "     |      Return the absolute path for the given file.\n",
      "     |      \n",
      "     |      :type fileid: str\n",
      "     |      :param fileid: The file identifier for the file whose path\n",
      "     |          should be returned.\n",
      "     |      :rtype: PathPointer\n",
      "     |  \n",
      "     |  abspaths(self, fileids=None, include_encoding=False, include_fileid=False)\n",
      "     |      Return a list of the absolute paths for all fileids in this corpus;\n",
      "     |      or for the given list of fileids, if specified.\n",
      "     |      \n",
      "     |      :type fileids: None or str or list\n",
      "     |      :param fileids: Specifies the set of fileids for which paths should\n",
      "     |          be returned.  Can be None, for all fileids; a list of\n",
      "     |          file identifiers, for a specified set of fileids; or a single\n",
      "     |          file identifier, for a single file.  Note that the return\n",
      "     |          value is always a list of paths, even if ``fileids`` is a\n",
      "     |          single file identifier.\n",
      "     |      \n",
      "     |      :param include_encoding: If true, then return a list of\n",
      "     |          ``(path_pointer, encoding)`` tuples.\n",
      "     |      \n",
      "     |      :rtype: list(PathPointer)\n",
      "     |  \n",
      "     |  citation(self)\n",
      "     |      Return the contents of the corpus citation.bib file, if it exists.\n",
      "     |  \n",
      "     |  encoding(self, file)\n",
      "     |      Return the unicode encoding for the given corpus file, if known.\n",
      "     |      If the encoding is unknown, or if the given file should be\n",
      "     |      processed using byte strings (str), then return None.\n",
      "     |  \n",
      "     |  ensure_loaded(self)\n",
      "     |      Load this corpus (if it has not already been loaded).  This is\n",
      "     |      used by LazyCorpusLoader as a simple method that can be used to\n",
      "     |      make sure a corpus is loaded -- e.g., in case a user wants to\n",
      "     |      do help(some_corpus).\n",
      "     |  \n",
      "     |  fileids(self)\n",
      "     |      Return a list of file identifiers for the fileids that make up\n",
      "     |      this corpus.\n",
      "     |  \n",
      "     |  license(self)\n",
      "     |      Return the contents of the corpus LICENSE file, if it exists.\n",
      "     |  \n",
      "     |  open(self, file)\n",
      "     |      Return an open stream that can be used to read the given file.\n",
      "     |      If the file's encoding is not None, then the stream will\n",
      "     |      automatically decode the file's contents into unicode.\n",
      "     |      \n",
      "     |      :param file: The file identifier of the file to read.\n",
      "     |  \n",
      "     |  unicode_repr = __repr__(self)\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Data descriptors inherited from nltk.corpus.reader.api.CorpusReader:\n",
      "     |  \n",
      "     |  __dict__\n",
      "     |      dictionary for instance variables (if defined)\n",
      "     |  \n",
      "     |  __weakref__\n",
      "     |      list of weak references to the object (if defined)\n",
      "     |  \n",
      "     |  root\n",
      "     |      The directory where this corpus is stored.\n",
      "     |      \n",
      "     |      :type: PathPointer\n",
      "    \n",
      "    class SemcorCorpusReader(nltk.corpus.reader.xmldocs.XMLCorpusReader)\n",
      "     |  SemcorCorpusReader(root, fileids, wordnet, lazy=True)\n",
      "     |  \n",
      "     |  Corpus reader for the SemCor Corpus.\n",
      "     |  For access to the complete XML data structure, use the ``xml()``\n",
      "     |  method.  For access to simple word lists and tagged word lists, use\n",
      "     |  ``words()``, ``sents()``, ``tagged_words()``, and ``tagged_sents()``.\n",
      "     |  \n",
      "     |  Method resolution order:\n",
      "     |      SemcorCorpusReader\n",
      "     |      nltk.corpus.reader.xmldocs.XMLCorpusReader\n",
      "     |      nltk.corpus.reader.api.CorpusReader\n",
      "     |      builtins.object\n",
      "     |  \n",
      "     |  Methods defined here:\n",
      "     |  \n",
      "     |  __init__(self, root, fileids, wordnet, lazy=True)\n",
      "     |      :type root: PathPointer or str\n",
      "     |      :param root: A path pointer identifying the root directory for\n",
      "     |          this corpus.  If a string is specified, then it will be\n",
      "     |          converted to a ``PathPointer`` automatically.\n",
      "     |      :param fileids: A list of the files that make up this corpus.\n",
      "     |          This list can either be specified explicitly, as a list of\n",
      "     |          strings; or implicitly, as a regular expression over file\n",
      "     |          paths.  The absolute path for each file will be constructed\n",
      "     |          by joining the reader's root to each file name.\n",
      "     |      :param encoding: The default unicode encoding for the files\n",
      "     |          that make up the corpus.  The value of ``encoding`` can be any\n",
      "     |          of the following:\n",
      "     |          - A string: ``encoding`` is the encoding name for all files.\n",
      "     |          - A dictionary: ``encoding[file_id]`` is the encoding\n",
      "     |            name for the file whose identifier is ``file_id``.  If\n",
      "     |            ``file_id`` is not in ``encoding``, then the file\n",
      "     |            contents will be processed using non-unicode byte strings.\n",
      "     |          - A list: ``encoding`` should be a list of ``(regexp, encoding)``\n",
      "     |            tuples.  The encoding for a file whose identifier is ``file_id``\n",
      "     |            will be the ``encoding`` value for the first tuple whose\n",
      "     |            ``regexp`` matches the ``file_id``.  If no tuple's ``regexp``\n",
      "     |            matches the ``file_id``, the file contents will be processed\n",
      "     |            using non-unicode byte strings.\n",
      "     |          - None: the file contents of all files will be\n",
      "     |            processed using non-unicode byte strings.\n",
      "     |      :param tagset: The name of the tagset used by this corpus, to be used\n",
      "     |            for normalizing or converting the POS tags returned by the\n",
      "     |            tagged_...() methods.\n",
      "     |  \n",
      "     |  chunk_sents(self, fileids=None)\n",
      "     |      :return: the given file(s) as a list of sentences, each encoded\n",
      "     |          as a list of chunks.\n",
      "     |      :rtype: list(list(list(str)))\n",
      "     |  \n",
      "     |  chunks(self, fileids=None)\n",
      "     |      :return: the given file(s) as a list of chunks,\n",
      "     |          each of which is a list of words and punctuation symbols\n",
      "     |          that form a unit.\n",
      "     |      :rtype: list(list(str))\n",
      "     |  \n",
      "     |  sents(self, fileids=None)\n",
      "     |      :return: the given file(s) as a list of sentences, each encoded\n",
      "     |          as a list of word strings.\n",
      "     |      :rtype: list(list(str))\n",
      "     |  \n",
      "     |  tagged_chunks(self, fileids=None, tag='pos')\n",
      "     |      :return: the given file(s) as a list of tagged chunks, represented\n",
      "     |          in tree form.\n",
      "     |      :rtype: list(Tree)\n",
      "     |      \n",
      "     |      :param tag: `'pos'` (part of speech), `'sem'` (semantic), or `'both'`\n",
      "     |          to indicate the kind of tags to include.  Semantic tags consist of\n",
      "     |          WordNet lemma IDs, plus an `'NE'` node if the chunk is a named entity\n",
      "     |          without a specific entry in WordNet.  (Named entities of type 'other'\n",
      "     |          have no lemma.  Other chunks not in WordNet have no semantic tag.\n",
      "     |          Punctuation tokens have `None` for their part of speech tag.)\n",
      "     |  \n",
      "     |  tagged_sents(self, fileids=None, tag='pos')\n",
      "     |      :return: the given file(s) as a list of sentences. Each sentence\n",
      "     |          is represented as a list of tagged chunks (in tree form).\n",
      "     |      :rtype: list(list(Tree))\n",
      "     |      \n",
      "     |      :param tag: `'pos'` (part of speech), `'sem'` (semantic), or `'both'`\n",
      "     |          to indicate the kind of tags to include.  Semantic tags consist of\n",
      "     |          WordNet lemma IDs, plus an `'NE'` node if the chunk is a named entity\n",
      "     |          without a specific entry in WordNet.  (Named entities of type 'other'\n",
      "     |          have no lemma.  Other chunks not in WordNet have no semantic tag.\n",
      "     |          Punctuation tokens have `None` for their part of speech tag.)\n",
      "     |  \n",
      "     |  words(self, fileids=None)\n",
      "     |      :return: the given file(s) as a list of words and punctuation symbols.\n",
      "     |      :rtype: list(str)\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Methods inherited from nltk.corpus.reader.xmldocs.XMLCorpusReader:\n",
      "     |  \n",
      "     |  raw(self, fileids=None)\n",
      "     |  \n",
      "     |  xml(self, fileid=None)\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Methods inherited from nltk.corpus.reader.api.CorpusReader:\n",
      "     |  \n",
      "     |  __repr__(self)\n",
      "     |      Return repr(self).\n",
      "     |  \n",
      "     |  __unicode__ = __str__(self, /)\n",
      "     |  \n",
      "     |  abspath(self, fileid)\n",
      "     |      Return the absolute path for the given file.\n",
      "     |      \n",
      "     |      :type fileid: str\n",
      "     |      :param fileid: The file identifier for the file whose path\n",
      "     |          should be returned.\n",
      "     |      :rtype: PathPointer\n",
      "     |  \n",
      "     |  abspaths(self, fileids=None, include_encoding=False, include_fileid=False)\n",
      "     |      Return a list of the absolute paths for all fileids in this corpus;\n",
      "     |      or for the given list of fileids, if specified.\n",
      "     |      \n",
      "     |      :type fileids: None or str or list\n",
      "     |      :param fileids: Specifies the set of fileids for which paths should\n",
      "     |          be returned.  Can be None, for all fileids; a list of\n",
      "     |          file identifiers, for a specified set of fileids; or a single\n",
      "     |          file identifier, for a single file.  Note that the return\n",
      "     |          value is always a list of paths, even if ``fileids`` is a\n",
      "     |          single file identifier.\n",
      "     |      \n",
      "     |      :param include_encoding: If true, then return a list of\n",
      "     |          ``(path_pointer, encoding)`` tuples.\n",
      "     |      \n",
      "     |      :rtype: list(PathPointer)\n",
      "     |  \n",
      "     |  citation(self)\n",
      "     |      Return the contents of the corpus citation.bib file, if it exists.\n",
      "     |  \n",
      "     |  encoding(self, file)\n",
      "     |      Return the unicode encoding for the given corpus file, if known.\n",
      "     |      If the encoding is unknown, or if the given file should be\n",
      "     |      processed using byte strings (str), then return None.\n",
      "     |  \n",
      "     |  ensure_loaded(self)\n",
      "     |      Load this corpus (if it has not already been loaded).  This is\n",
      "     |      used by LazyCorpusLoader as a simple method that can be used to\n",
      "     |      make sure a corpus is loaded -- e.g., in case a user wants to\n",
      "     |      do help(some_corpus).\n",
      "     |  \n",
      "     |  fileids(self)\n",
      "     |      Return a list of file identifiers for the fileids that make up\n",
      "     |      this corpus.\n",
      "     |  \n",
      "     |  license(self)\n",
      "     |      Return the contents of the corpus LICENSE file, if it exists.\n",
      "     |  \n",
      "     |  open(self, file)\n",
      "     |      Return an open stream that can be used to read the given file.\n",
      "     |      If the file's encoding is not None, then the stream will\n",
      "     |      automatically decode the file's contents into unicode.\n",
      "     |      \n",
      "     |      :param file: The file identifier of the file to read.\n",
      "     |  \n",
      "     |  readme(self)\n",
      "     |      Return the contents of the corpus README file, if it exists.\n",
      "     |  \n",
      "     |  unicode_repr = __repr__(self)\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Data descriptors inherited from nltk.corpus.reader.api.CorpusReader:\n",
      "     |  \n",
      "     |  __dict__\n",
      "     |      dictionary for instance variables (if defined)\n",
      "     |  \n",
      "     |  __weakref__\n",
      "     |      list of weak references to the object (if defined)\n",
      "     |  \n",
      "     |  root\n",
      "     |      The directory where this corpus is stored.\n",
      "     |      \n",
      "     |      :type: PathPointer\n",
      "    \n",
      "    class SensevalCorpusReader(nltk.corpus.reader.api.CorpusReader)\n",
      "     |  SensevalCorpusReader(root, fileids, encoding='utf8', tagset=None)\n",
      "     |  \n",
      "     |  A base class for \"corpus reader\" classes, each of which can be\n",
      "     |  used to read a specific corpus format.  Each individual corpus\n",
      "     |  reader instance is used to read a specific corpus, consisting of\n",
      "     |  one or more files under a common root directory.  Each file is\n",
      "     |  identified by its ``file identifier``, which is the relative path\n",
      "     |  to the file from the root directory.\n",
      "     |  \n",
      "     |  A separate subclass is defined for each corpus format.  These\n",
      "     |  subclasses define one or more methods that provide 'views' on the\n",
      "     |  corpus contents, such as ``words()`` (for a list of words) and\n",
      "     |  ``parsed_sents()`` (for a list of parsed sentences).  Called with\n",
      "     |  no arguments, these methods will return the contents of the entire\n",
      "     |  corpus.  For most corpora, these methods define one or more\n",
      "     |  selection arguments, such as ``fileids`` or ``categories``, which can\n",
      "     |  be used to select which portion of the corpus should be returned.\n",
      "     |  \n",
      "     |  Method resolution order:\n",
      "     |      SensevalCorpusReader\n",
      "     |      nltk.corpus.reader.api.CorpusReader\n",
      "     |      builtins.object\n",
      "     |  \n",
      "     |  Methods defined here:\n",
      "     |  \n",
      "     |  instances(self, fileids=None)\n",
      "     |  \n",
      "     |  raw(self, fileids=None)\n",
      "     |      :return: the text contents of the given fileids, as a single string.\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Methods inherited from nltk.corpus.reader.api.CorpusReader:\n",
      "     |  \n",
      "     |  __init__(self, root, fileids, encoding='utf8', tagset=None)\n",
      "     |      :type root: PathPointer or str\n",
      "     |      :param root: A path pointer identifying the root directory for\n",
      "     |          this corpus.  If a string is specified, then it will be\n",
      "     |          converted to a ``PathPointer`` automatically.\n",
      "     |      :param fileids: A list of the files that make up this corpus.\n",
      "     |          This list can either be specified explicitly, as a list of\n",
      "     |          strings; or implicitly, as a regular expression over file\n",
      "     |          paths.  The absolute path for each file will be constructed\n",
      "     |          by joining the reader's root to each file name.\n",
      "     |      :param encoding: The default unicode encoding for the files\n",
      "     |          that make up the corpus.  The value of ``encoding`` can be any\n",
      "     |          of the following:\n",
      "     |          - A string: ``encoding`` is the encoding name for all files.\n",
      "     |          - A dictionary: ``encoding[file_id]`` is the encoding\n",
      "     |            name for the file whose identifier is ``file_id``.  If\n",
      "     |            ``file_id`` is not in ``encoding``, then the file\n",
      "     |            contents will be processed using non-unicode byte strings.\n",
      "     |          - A list: ``encoding`` should be a list of ``(regexp, encoding)``\n",
      "     |            tuples.  The encoding for a file whose identifier is ``file_id``\n",
      "     |            will be the ``encoding`` value for the first tuple whose\n",
      "     |            ``regexp`` matches the ``file_id``.  If no tuple's ``regexp``\n",
      "     |            matches the ``file_id``, the file contents will be processed\n",
      "     |            using non-unicode byte strings.\n",
      "     |          - None: the file contents of all files will be\n",
      "     |            processed using non-unicode byte strings.\n",
      "     |      :param tagset: The name of the tagset used by this corpus, to be used\n",
      "     |            for normalizing or converting the POS tags returned by the\n",
      "     |            tagged_...() methods.\n",
      "     |  \n",
      "     |  __repr__(self)\n",
      "     |      Return repr(self).\n",
      "     |  \n",
      "     |  __unicode__ = __str__(self, /)\n",
      "     |  \n",
      "     |  abspath(self, fileid)\n",
      "     |      Return the absolute path for the given file.\n",
      "     |      \n",
      "     |      :type fileid: str\n",
      "     |      :param fileid: The file identifier for the file whose path\n",
      "     |          should be returned.\n",
      "     |      :rtype: PathPointer\n",
      "     |  \n",
      "     |  abspaths(self, fileids=None, include_encoding=False, include_fileid=False)\n",
      "     |      Return a list of the absolute paths for all fileids in this corpus;\n",
      "     |      or for the given list of fileids, if specified.\n",
      "     |      \n",
      "     |      :type fileids: None or str or list\n",
      "     |      :param fileids: Specifies the set of fileids for which paths should\n",
      "     |          be returned.  Can be None, for all fileids; a list of\n",
      "     |          file identifiers, for a specified set of fileids; or a single\n",
      "     |          file identifier, for a single file.  Note that the return\n",
      "     |          value is always a list of paths, even if ``fileids`` is a\n",
      "     |          single file identifier.\n",
      "     |      \n",
      "     |      :param include_encoding: If true, then return a list of\n",
      "     |          ``(path_pointer, encoding)`` tuples.\n",
      "     |      \n",
      "     |      :rtype: list(PathPointer)\n",
      "     |  \n",
      "     |  citation(self)\n",
      "     |      Return the contents of the corpus citation.bib file, if it exists.\n",
      "     |  \n",
      "     |  encoding(self, file)\n",
      "     |      Return the unicode encoding for the given corpus file, if known.\n",
      "     |      If the encoding is unknown, or if the given file should be\n",
      "     |      processed using byte strings (str), then return None.\n",
      "     |  \n",
      "     |  ensure_loaded(self)\n",
      "     |      Load this corpus (if it has not already been loaded).  This is\n",
      "     |      used by LazyCorpusLoader as a simple method that can be used to\n",
      "     |      make sure a corpus is loaded -- e.g., in case a user wants to\n",
      "     |      do help(some_corpus).\n",
      "     |  \n",
      "     |  fileids(self)\n",
      "     |      Return a list of file identifiers for the fileids that make up\n",
      "     |      this corpus.\n",
      "     |  \n",
      "     |  license(self)\n",
      "     |      Return the contents of the corpus LICENSE file, if it exists.\n",
      "     |  \n",
      "     |  open(self, file)\n",
      "     |      Return an open stream that can be used to read the given file.\n",
      "     |      If the file's encoding is not None, then the stream will\n",
      "     |      automatically decode the file's contents into unicode.\n",
      "     |      \n",
      "     |      :param file: The file identifier of the file to read.\n",
      "     |  \n",
      "     |  readme(self)\n",
      "     |      Return the contents of the corpus README file, if it exists.\n",
      "     |  \n",
      "     |  unicode_repr = __repr__(self)\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Data descriptors inherited from nltk.corpus.reader.api.CorpusReader:\n",
      "     |  \n",
      "     |  __dict__\n",
      "     |      dictionary for instance variables (if defined)\n",
      "     |  \n",
      "     |  __weakref__\n",
      "     |      list of weak references to the object (if defined)\n",
      "     |  \n",
      "     |  root\n",
      "     |      The directory where this corpus is stored.\n",
      "     |      \n",
      "     |      :type: PathPointer\n",
      "    \n",
      "    class SentiSynset(builtins.object)\n",
      "     |  SentiSynset(pos_score, neg_score, synset)\n",
      "     |  \n",
      "     |  Methods defined here:\n",
      "     |  \n",
      "     |  __init__(self, pos_score, neg_score, synset)\n",
      "     |      Initialize self.  See help(type(self)) for accurate signature.\n",
      "     |  \n",
      "     |  __repr__(self)\n",
      "     |      Return repr(self).\n",
      "     |  \n",
      "     |  __str__(self)\n",
      "     |      Prints just the Pos/Neg scores for now.\n",
      "     |  \n",
      "     |  __unicode__ = __str__(self)\n",
      "     |  \n",
      "     |  neg_score(self)\n",
      "     |  \n",
      "     |  obj_score(self)\n",
      "     |  \n",
      "     |  pos_score(self)\n",
      "     |  \n",
      "     |  unicode_repr = __repr__(self)\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Data descriptors defined here:\n",
      "     |  \n",
      "     |  __dict__\n",
      "     |      dictionary for instance variables (if defined)\n",
      "     |  \n",
      "     |  __weakref__\n",
      "     |      list of weak references to the object (if defined)\n",
      "    \n",
      "    class SentiWordNetCorpusReader(nltk.corpus.reader.api.CorpusReader)\n",
      "     |  SentiWordNetCorpusReader(root, fileids, encoding='utf-8')\n",
      "     |  \n",
      "     |  A base class for \"corpus reader\" classes, each of which can be\n",
      "     |  used to read a specific corpus format.  Each individual corpus\n",
      "     |  reader instance is used to read a specific corpus, consisting of\n",
      "     |  one or more files under a common root directory.  Each file is\n",
      "     |  identified by its ``file identifier``, which is the relative path\n",
      "     |  to the file from the root directory.\n",
      "     |  \n",
      "     |  A separate subclass is defined for each corpus format.  These\n",
      "     |  subclasses define one or more methods that provide 'views' on the\n",
      "     |  corpus contents, such as ``words()`` (for a list of words) and\n",
      "     |  ``parsed_sents()`` (for a list of parsed sentences).  Called with\n",
      "     |  no arguments, these methods will return the contents of the entire\n",
      "     |  corpus.  For most corpora, these methods define one or more\n",
      "     |  selection arguments, such as ``fileids`` or ``categories``, which can\n",
      "     |  be used to select which portion of the corpus should be returned.\n",
      "     |  \n",
      "     |  Method resolution order:\n",
      "     |      SentiWordNetCorpusReader\n",
      "     |      nltk.corpus.reader.api.CorpusReader\n",
      "     |      builtins.object\n",
      "     |  \n",
      "     |  Methods defined here:\n",
      "     |  \n",
      "     |  __init__(self, root, fileids, encoding='utf-8')\n",
      "     |      Construct a new SentiWordNet Corpus Reader, using data from\n",
      "     |      the specified file.\n",
      "     |  \n",
      "     |  __unicode__ = __str__(self, /)\n",
      "     |  \n",
      "     |  all_senti_synsets(self)\n",
      "     |  \n",
      "     |  senti_synset(self, *vals)\n",
      "     |  \n",
      "     |  senti_synsets(self, string, pos=None)\n",
      "     |  \n",
      "     |  unicode_repr = __repr__(self)\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Methods inherited from nltk.corpus.reader.api.CorpusReader:\n",
      "     |  \n",
      "     |  __repr__(self)\n",
      "     |      Return repr(self).\n",
      "     |  \n",
      "     |  abspath(self, fileid)\n",
      "     |      Return the absolute path for the given file.\n",
      "     |      \n",
      "     |      :type fileid: str\n",
      "     |      :param fileid: The file identifier for the file whose path\n",
      "     |          should be returned.\n",
      "     |      :rtype: PathPointer\n",
      "     |  \n",
      "     |  abspaths(self, fileids=None, include_encoding=False, include_fileid=False)\n",
      "     |      Return a list of the absolute paths for all fileids in this corpus;\n",
      "     |      or for the given list of fileids, if specified.\n",
      "     |      \n",
      "     |      :type fileids: None or str or list\n",
      "     |      :param fileids: Specifies the set of fileids for which paths should\n",
      "     |          be returned.  Can be None, for all fileids; a list of\n",
      "     |          file identifiers, for a specified set of fileids; or a single\n",
      "     |          file identifier, for a single file.  Note that the return\n",
      "     |          value is always a list of paths, even if ``fileids`` is a\n",
      "     |          single file identifier.\n",
      "     |      \n",
      "     |      :param include_encoding: If true, then return a list of\n",
      "     |          ``(path_pointer, encoding)`` tuples.\n",
      "     |      \n",
      "     |      :rtype: list(PathPointer)\n",
      "     |  \n",
      "     |  citation(self)\n",
      "     |      Return the contents of the corpus citation.bib file, if it exists.\n",
      "     |  \n",
      "     |  encoding(self, file)\n",
      "     |      Return the unicode encoding for the given corpus file, if known.\n",
      "     |      If the encoding is unknown, or if the given file should be\n",
      "     |      processed using byte strings (str), then return None.\n",
      "     |  \n",
      "     |  ensure_loaded(self)\n",
      "     |      Load this corpus (if it has not already been loaded).  This is\n",
      "     |      used by LazyCorpusLoader as a simple method that can be used to\n",
      "     |      make sure a corpus is loaded -- e.g., in case a user wants to\n",
      "     |      do help(some_corpus).\n",
      "     |  \n",
      "     |  fileids(self)\n",
      "     |      Return a list of file identifiers for the fileids that make up\n",
      "     |      this corpus.\n",
      "     |  \n",
      "     |  license(self)\n",
      "     |      Return the contents of the corpus LICENSE file, if it exists.\n",
      "     |  \n",
      "     |  open(self, file)\n",
      "     |      Return an open stream that can be used to read the given file.\n",
      "     |      If the file's encoding is not None, then the stream will\n",
      "     |      automatically decode the file's contents into unicode.\n",
      "     |      \n",
      "     |      :param file: The file identifier of the file to read.\n",
      "     |  \n",
      "     |  readme(self)\n",
      "     |      Return the contents of the corpus README file, if it exists.\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Data descriptors inherited from nltk.corpus.reader.api.CorpusReader:\n",
      "     |  \n",
      "     |  __dict__\n",
      "     |      dictionary for instance variables (if defined)\n",
      "     |  \n",
      "     |  __weakref__\n",
      "     |      list of weak references to the object (if defined)\n",
      "     |  \n",
      "     |  root\n",
      "     |      The directory where this corpus is stored.\n",
      "     |      \n",
      "     |      :type: PathPointer\n",
      "    \n",
      "    class SinicaTreebankCorpusReader(nltk.corpus.reader.api.SyntaxCorpusReader)\n",
      "     |  SinicaTreebankCorpusReader(root, fileids, encoding='utf8', tagset=None)\n",
      "     |  \n",
      "     |  Reader for the sinica treebank.\n",
      "     |  \n",
      "     |  Method resolution order:\n",
      "     |      SinicaTreebankCorpusReader\n",
      "     |      nltk.corpus.reader.api.SyntaxCorpusReader\n",
      "     |      nltk.corpus.reader.api.CorpusReader\n",
      "     |      builtins.object\n",
      "     |  \n",
      "     |  Methods inherited from nltk.corpus.reader.api.SyntaxCorpusReader:\n",
      "     |  \n",
      "     |  parsed_sents(self, fileids=None)\n",
      "     |  \n",
      "     |  raw(self, fileids=None)\n",
      "     |  \n",
      "     |  sents(self, fileids=None)\n",
      "     |  \n",
      "     |  tagged_sents(self, fileids=None, tagset=None)\n",
      "     |  \n",
      "     |  tagged_words(self, fileids=None, tagset=None)\n",
      "     |  \n",
      "     |  words(self, fileids=None)\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Methods inherited from nltk.corpus.reader.api.CorpusReader:\n",
      "     |  \n",
      "     |  __init__(self, root, fileids, encoding='utf8', tagset=None)\n",
      "     |      :type root: PathPointer or str\n",
      "     |      :param root: A path pointer identifying the root directory for\n",
      "     |          this corpus.  If a string is specified, then it will be\n",
      "     |          converted to a ``PathPointer`` automatically.\n",
      "     |      :param fileids: A list of the files that make up this corpus.\n",
      "     |          This list can either be specified explicitly, as a list of\n",
      "     |          strings; or implicitly, as a regular expression over file\n",
      "     |          paths.  The absolute path for each file will be constructed\n",
      "     |          by joining the reader's root to each file name.\n",
      "     |      :param encoding: The default unicode encoding for the files\n",
      "     |          that make up the corpus.  The value of ``encoding`` can be any\n",
      "     |          of the following:\n",
      "     |          - A string: ``encoding`` is the encoding name for all files.\n",
      "     |          - A dictionary: ``encoding[file_id]`` is the encoding\n",
      "     |            name for the file whose identifier is ``file_id``.  If\n",
      "     |            ``file_id`` is not in ``encoding``, then the file\n",
      "     |            contents will be processed using non-unicode byte strings.\n",
      "     |          - A list: ``encoding`` should be a list of ``(regexp, encoding)``\n",
      "     |            tuples.  The encoding for a file whose identifier is ``file_id``\n",
      "     |            will be the ``encoding`` value for the first tuple whose\n",
      "     |            ``regexp`` matches the ``file_id``.  If no tuple's ``regexp``\n",
      "     |            matches the ``file_id``, the file contents will be processed\n",
      "     |            using non-unicode byte strings.\n",
      "     |          - None: the file contents of all files will be\n",
      "     |            processed using non-unicode byte strings.\n",
      "     |      :param tagset: The name of the tagset used by this corpus, to be used\n",
      "     |            for normalizing or converting the POS tags returned by the\n",
      "     |            tagged_...() methods.\n",
      "     |  \n",
      "     |  __repr__(self)\n",
      "     |      Return repr(self).\n",
      "     |  \n",
      "     |  __unicode__ = __str__(self, /)\n",
      "     |  \n",
      "     |  abspath(self, fileid)\n",
      "     |      Return the absolute path for the given file.\n",
      "     |      \n",
      "     |      :type fileid: str\n",
      "     |      :param fileid: The file identifier for the file whose path\n",
      "     |          should be returned.\n",
      "     |      :rtype: PathPointer\n",
      "     |  \n",
      "     |  abspaths(self, fileids=None, include_encoding=False, include_fileid=False)\n",
      "     |      Return a list of the absolute paths for all fileids in this corpus;\n",
      "     |      or for the given list of fileids, if specified.\n",
      "     |      \n",
      "     |      :type fileids: None or str or list\n",
      "     |      :param fileids: Specifies the set of fileids for which paths should\n",
      "     |          be returned.  Can be None, for all fileids; a list of\n",
      "     |          file identifiers, for a specified set of fileids; or a single\n",
      "     |          file identifier, for a single file.  Note that the return\n",
      "     |          value is always a list of paths, even if ``fileids`` is a\n",
      "     |          single file identifier.\n",
      "     |      \n",
      "     |      :param include_encoding: If true, then return a list of\n",
      "     |          ``(path_pointer, encoding)`` tuples.\n",
      "     |      \n",
      "     |      :rtype: list(PathPointer)\n",
      "     |  \n",
      "     |  citation(self)\n",
      "     |      Return the contents of the corpus citation.bib file, if it exists.\n",
      "     |  \n",
      "     |  encoding(self, file)\n",
      "     |      Return the unicode encoding for the given corpus file, if known.\n",
      "     |      If the encoding is unknown, or if the given file should be\n",
      "     |      processed using byte strings (str), then return None.\n",
      "     |  \n",
      "     |  ensure_loaded(self)\n",
      "     |      Load this corpus (if it has not already been loaded).  This is\n",
      "     |      used by LazyCorpusLoader as a simple method that can be used to\n",
      "     |      make sure a corpus is loaded -- e.g., in case a user wants to\n",
      "     |      do help(some_corpus).\n",
      "     |  \n",
      "     |  fileids(self)\n",
      "     |      Return a list of file identifiers for the fileids that make up\n",
      "     |      this corpus.\n",
      "     |  \n",
      "     |  license(self)\n",
      "     |      Return the contents of the corpus LICENSE file, if it exists.\n",
      "     |  \n",
      "     |  open(self, file)\n",
      "     |      Return an open stream that can be used to read the given file.\n",
      "     |      If the file's encoding is not None, then the stream will\n",
      "     |      automatically decode the file's contents into unicode.\n",
      "     |      \n",
      "     |      :param file: The file identifier of the file to read.\n",
      "     |  \n",
      "     |  readme(self)\n",
      "     |      Return the contents of the corpus README file, if it exists.\n",
      "     |  \n",
      "     |  unicode_repr = __repr__(self)\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Data descriptors inherited from nltk.corpus.reader.api.CorpusReader:\n",
      "     |  \n",
      "     |  __dict__\n",
      "     |      dictionary for instance variables (if defined)\n",
      "     |  \n",
      "     |  __weakref__\n",
      "     |      list of weak references to the object (if defined)\n",
      "     |  \n",
      "     |  root\n",
      "     |      The directory where this corpus is stored.\n",
      "     |      \n",
      "     |      :type: PathPointer\n",
      "    \n",
      "    class StringCategoryCorpusReader(nltk.corpus.reader.api.CorpusReader)\n",
      "     |  StringCategoryCorpusReader(root, fileids, delimiter=' ', encoding='utf8')\n",
      "     |  \n",
      "     |  A base class for \"corpus reader\" classes, each of which can be\n",
      "     |  used to read a specific corpus format.  Each individual corpus\n",
      "     |  reader instance is used to read a specific corpus, consisting of\n",
      "     |  one or more files under a common root directory.  Each file is\n",
      "     |  identified by its ``file identifier``, which is the relative path\n",
      "     |  to the file from the root directory.\n",
      "     |  \n",
      "     |  A separate subclass is defined for each corpus format.  These\n",
      "     |  subclasses define one or more methods that provide 'views' on the\n",
      "     |  corpus contents, such as ``words()`` (for a list of words) and\n",
      "     |  ``parsed_sents()`` (for a list of parsed sentences).  Called with\n",
      "     |  no arguments, these methods will return the contents of the entire\n",
      "     |  corpus.  For most corpora, these methods define one or more\n",
      "     |  selection arguments, such as ``fileids`` or ``categories``, which can\n",
      "     |  be used to select which portion of the corpus should be returned.\n",
      "     |  \n",
      "     |  Method resolution order:\n",
      "     |      StringCategoryCorpusReader\n",
      "     |      nltk.corpus.reader.api.CorpusReader\n",
      "     |      builtins.object\n",
      "     |  \n",
      "     |  Methods defined here:\n",
      "     |  \n",
      "     |  __init__(self, root, fileids, delimiter=' ', encoding='utf8')\n",
      "     |      :param root: The root directory for this corpus.\n",
      "     |      :param fileids: A list or regexp specifying the fileids in this corpus.\n",
      "     |      :param delimiter: Field delimiter\n",
      "     |  \n",
      "     |  raw(self, fileids=None)\n",
      "     |      :return: the text contents of the given fileids, as a single string.\n",
      "     |  \n",
      "     |  tuples(self, fileids=None)\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Methods inherited from nltk.corpus.reader.api.CorpusReader:\n",
      "     |  \n",
      "     |  __repr__(self)\n",
      "     |      Return repr(self).\n",
      "     |  \n",
      "     |  __unicode__ = __str__(self, /)\n",
      "     |  \n",
      "     |  abspath(self, fileid)\n",
      "     |      Return the absolute path for the given file.\n",
      "     |      \n",
      "     |      :type fileid: str\n",
      "     |      :param fileid: The file identifier for the file whose path\n",
      "     |          should be returned.\n",
      "     |      :rtype: PathPointer\n",
      "     |  \n",
      "     |  abspaths(self, fileids=None, include_encoding=False, include_fileid=False)\n",
      "     |      Return a list of the absolute paths for all fileids in this corpus;\n",
      "     |      or for the given list of fileids, if specified.\n",
      "     |      \n",
      "     |      :type fileids: None or str or list\n",
      "     |      :param fileids: Specifies the set of fileids for which paths should\n",
      "     |          be returned.  Can be None, for all fileids; a list of\n",
      "     |          file identifiers, for a specified set of fileids; or a single\n",
      "     |          file identifier, for a single file.  Note that the return\n",
      "     |          value is always a list of paths, even if ``fileids`` is a\n",
      "     |          single file identifier.\n",
      "     |      \n",
      "     |      :param include_encoding: If true, then return a list of\n",
      "     |          ``(path_pointer, encoding)`` tuples.\n",
      "     |      \n",
      "     |      :rtype: list(PathPointer)\n",
      "     |  \n",
      "     |  citation(self)\n",
      "     |      Return the contents of the corpus citation.bib file, if it exists.\n",
      "     |  \n",
      "     |  encoding(self, file)\n",
      "     |      Return the unicode encoding for the given corpus file, if known.\n",
      "     |      If the encoding is unknown, or if the given file should be\n",
      "     |      processed using byte strings (str), then return None.\n",
      "     |  \n",
      "     |  ensure_loaded(self)\n",
      "     |      Load this corpus (if it has not already been loaded).  This is\n",
      "     |      used by LazyCorpusLoader as a simple method that can be used to\n",
      "     |      make sure a corpus is loaded -- e.g., in case a user wants to\n",
      "     |      do help(some_corpus).\n",
      "     |  \n",
      "     |  fileids(self)\n",
      "     |      Return a list of file identifiers for the fileids that make up\n",
      "     |      this corpus.\n",
      "     |  \n",
      "     |  license(self)\n",
      "     |      Return the contents of the corpus LICENSE file, if it exists.\n",
      "     |  \n",
      "     |  open(self, file)\n",
      "     |      Return an open stream that can be used to read the given file.\n",
      "     |      If the file's encoding is not None, then the stream will\n",
      "     |      automatically decode the file's contents into unicode.\n",
      "     |      \n",
      "     |      :param file: The file identifier of the file to read.\n",
      "     |  \n",
      "     |  readme(self)\n",
      "     |      Return the contents of the corpus README file, if it exists.\n",
      "     |  \n",
      "     |  unicode_repr = __repr__(self)\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Data descriptors inherited from nltk.corpus.reader.api.CorpusReader:\n",
      "     |  \n",
      "     |  __dict__\n",
      "     |      dictionary for instance variables (if defined)\n",
      "     |  \n",
      "     |  __weakref__\n",
      "     |      list of weak references to the object (if defined)\n",
      "     |  \n",
      "     |  root\n",
      "     |      The directory where this corpus is stored.\n",
      "     |      \n",
      "     |      :type: PathPointer\n",
      "    \n",
      "    class SwadeshCorpusReader(WordListCorpusReader)\n",
      "     |  SwadeshCorpusReader(root, fileids, encoding='utf8', tagset=None)\n",
      "     |  \n",
      "     |  List of words, one per line.  Blank lines are ignored.\n",
      "     |  \n",
      "     |  Method resolution order:\n",
      "     |      SwadeshCorpusReader\n",
      "     |      WordListCorpusReader\n",
      "     |      nltk.corpus.reader.api.CorpusReader\n",
      "     |      builtins.object\n",
      "     |  \n",
      "     |  Methods defined here:\n",
      "     |  \n",
      "     |  entries(self, fileids=None)\n",
      "     |      :return: a tuple of words for the specified fileids.\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Methods inherited from WordListCorpusReader:\n",
      "     |  \n",
      "     |  raw(self, fileids=None)\n",
      "     |  \n",
      "     |  words(self, fileids=None, ignore_lines_startswith='\\n')\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Methods inherited from nltk.corpus.reader.api.CorpusReader:\n",
      "     |  \n",
      "     |  __init__(self, root, fileids, encoding='utf8', tagset=None)\n",
      "     |      :type root: PathPointer or str\n",
      "     |      :param root: A path pointer identifying the root directory for\n",
      "     |          this corpus.  If a string is specified, then it will be\n",
      "     |          converted to a ``PathPointer`` automatically.\n",
      "     |      :param fileids: A list of the files that make up this corpus.\n",
      "     |          This list can either be specified explicitly, as a list of\n",
      "     |          strings; or implicitly, as a regular expression over file\n",
      "     |          paths.  The absolute path for each file will be constructed\n",
      "     |          by joining the reader's root to each file name.\n",
      "     |      :param encoding: The default unicode encoding for the files\n",
      "     |          that make up the corpus.  The value of ``encoding`` can be any\n",
      "     |          of the following:\n",
      "     |          - A string: ``encoding`` is the encoding name for all files.\n",
      "     |          - A dictionary: ``encoding[file_id]`` is the encoding\n",
      "     |            name for the file whose identifier is ``file_id``.  If\n",
      "     |            ``file_id`` is not in ``encoding``, then the file\n",
      "     |            contents will be processed using non-unicode byte strings.\n",
      "     |          - A list: ``encoding`` should be a list of ``(regexp, encoding)``\n",
      "     |            tuples.  The encoding for a file whose identifier is ``file_id``\n",
      "     |            will be the ``encoding`` value for the first tuple whose\n",
      "     |            ``regexp`` matches the ``file_id``.  If no tuple's ``regexp``\n",
      "     |            matches the ``file_id``, the file contents will be processed\n",
      "     |            using non-unicode byte strings.\n",
      "     |          - None: the file contents of all files will be\n",
      "     |            processed using non-unicode byte strings.\n",
      "     |      :param tagset: The name of the tagset used by this corpus, to be used\n",
      "     |            for normalizing or converting the POS tags returned by the\n",
      "     |            tagged_...() methods.\n",
      "     |  \n",
      "     |  __repr__(self)\n",
      "     |      Return repr(self).\n",
      "     |  \n",
      "     |  __unicode__ = __str__(self, /)\n",
      "     |  \n",
      "     |  abspath(self, fileid)\n",
      "     |      Return the absolute path for the given file.\n",
      "     |      \n",
      "     |      :type fileid: str\n",
      "     |      :param fileid: The file identifier for the file whose path\n",
      "     |          should be returned.\n",
      "     |      :rtype: PathPointer\n",
      "     |  \n",
      "     |  abspaths(self, fileids=None, include_encoding=False, include_fileid=False)\n",
      "     |      Return a list of the absolute paths for all fileids in this corpus;\n",
      "     |      or for the given list of fileids, if specified.\n",
      "     |      \n",
      "     |      :type fileids: None or str or list\n",
      "     |      :param fileids: Specifies the set of fileids for which paths should\n",
      "     |          be returned.  Can be None, for all fileids; a list of\n",
      "     |          file identifiers, for a specified set of fileids; or a single\n",
      "     |          file identifier, for a single file.  Note that the return\n",
      "     |          value is always a list of paths, even if ``fileids`` is a\n",
      "     |          single file identifier.\n",
      "     |      \n",
      "     |      :param include_encoding: If true, then return a list of\n",
      "     |          ``(path_pointer, encoding)`` tuples.\n",
      "     |      \n",
      "     |      :rtype: list(PathPointer)\n",
      "     |  \n",
      "     |  citation(self)\n",
      "     |      Return the contents of the corpus citation.bib file, if it exists.\n",
      "     |  \n",
      "     |  encoding(self, file)\n",
      "     |      Return the unicode encoding for the given corpus file, if known.\n",
      "     |      If the encoding is unknown, or if the given file should be\n",
      "     |      processed using byte strings (str), then return None.\n",
      "     |  \n",
      "     |  ensure_loaded(self)\n",
      "     |      Load this corpus (if it has not already been loaded).  This is\n",
      "     |      used by LazyCorpusLoader as a simple method that can be used to\n",
      "     |      make sure a corpus is loaded -- e.g., in case a user wants to\n",
      "     |      do help(some_corpus).\n",
      "     |  \n",
      "     |  fileids(self)\n",
      "     |      Return a list of file identifiers for the fileids that make up\n",
      "     |      this corpus.\n",
      "     |  \n",
      "     |  license(self)\n",
      "     |      Return the contents of the corpus LICENSE file, if it exists.\n",
      "     |  \n",
      "     |  open(self, file)\n",
      "     |      Return an open stream that can be used to read the given file.\n",
      "     |      If the file's encoding is not None, then the stream will\n",
      "     |      automatically decode the file's contents into unicode.\n",
      "     |      \n",
      "     |      :param file: The file identifier of the file to read.\n",
      "     |  \n",
      "     |  readme(self)\n",
      "     |      Return the contents of the corpus README file, if it exists.\n",
      "     |  \n",
      "     |  unicode_repr = __repr__(self)\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Data descriptors inherited from nltk.corpus.reader.api.CorpusReader:\n",
      "     |  \n",
      "     |  __dict__\n",
      "     |      dictionary for instance variables (if defined)\n",
      "     |  \n",
      "     |  __weakref__\n",
      "     |      list of weak references to the object (if defined)\n",
      "     |  \n",
      "     |  root\n",
      "     |      The directory where this corpus is stored.\n",
      "     |      \n",
      "     |      :type: PathPointer\n",
      "    \n",
      "    class SwitchboardCorpusReader(nltk.corpus.reader.api.CorpusReader)\n",
      "     |  SwitchboardCorpusReader(root, tagset=None)\n",
      "     |  \n",
      "     |  A base class for \"corpus reader\" classes, each of which can be\n",
      "     |  used to read a specific corpus format.  Each individual corpus\n",
      "     |  reader instance is used to read a specific corpus, consisting of\n",
      "     |  one or more files under a common root directory.  Each file is\n",
      "     |  identified by its ``file identifier``, which is the relative path\n",
      "     |  to the file from the root directory.\n",
      "     |  \n",
      "     |  A separate subclass is defined for each corpus format.  These\n",
      "     |  subclasses define one or more methods that provide 'views' on the\n",
      "     |  corpus contents, such as ``words()`` (for a list of words) and\n",
      "     |  ``parsed_sents()`` (for a list of parsed sentences).  Called with\n",
      "     |  no arguments, these methods will return the contents of the entire\n",
      "     |  corpus.  For most corpora, these methods define one or more\n",
      "     |  selection arguments, such as ``fileids`` or ``categories``, which can\n",
      "     |  be used to select which portion of the corpus should be returned.\n",
      "     |  \n",
      "     |  Method resolution order:\n",
      "     |      SwitchboardCorpusReader\n",
      "     |      nltk.corpus.reader.api.CorpusReader\n",
      "     |      builtins.object\n",
      "     |  \n",
      "     |  Methods defined here:\n",
      "     |  \n",
      "     |  __init__(self, root, tagset=None)\n",
      "     |      :type root: PathPointer or str\n",
      "     |      :param root: A path pointer identifying the root directory for\n",
      "     |          this corpus.  If a string is specified, then it will be\n",
      "     |          converted to a ``PathPointer`` automatically.\n",
      "     |      :param fileids: A list of the files that make up this corpus.\n",
      "     |          This list can either be specified explicitly, as a list of\n",
      "     |          strings; or implicitly, as a regular expression over file\n",
      "     |          paths.  The absolute path for each file will be constructed\n",
      "     |          by joining the reader's root to each file name.\n",
      "     |      :param encoding: The default unicode encoding for the files\n",
      "     |          that make up the corpus.  The value of ``encoding`` can be any\n",
      "     |          of the following:\n",
      "     |          - A string: ``encoding`` is the encoding name for all files.\n",
      "     |          - A dictionary: ``encoding[file_id]`` is the encoding\n",
      "     |            name for the file whose identifier is ``file_id``.  If\n",
      "     |            ``file_id`` is not in ``encoding``, then the file\n",
      "     |            contents will be processed using non-unicode byte strings.\n",
      "     |          - A list: ``encoding`` should be a list of ``(regexp, encoding)``\n",
      "     |            tuples.  The encoding for a file whose identifier is ``file_id``\n",
      "     |            will be the ``encoding`` value for the first tuple whose\n",
      "     |            ``regexp`` matches the ``file_id``.  If no tuple's ``regexp``\n",
      "     |            matches the ``file_id``, the file contents will be processed\n",
      "     |            using non-unicode byte strings.\n",
      "     |          - None: the file contents of all files will be\n",
      "     |            processed using non-unicode byte strings.\n",
      "     |      :param tagset: The name of the tagset used by this corpus, to be used\n",
      "     |            for normalizing or converting the POS tags returned by the\n",
      "     |            tagged_...() methods.\n",
      "     |  \n",
      "     |  discourses(self)\n",
      "     |  \n",
      "     |  tagged_discourses(self, tagset=False)\n",
      "     |  \n",
      "     |  tagged_turns(self, tagset=None)\n",
      "     |  \n",
      "     |  tagged_words(self, tagset=None)\n",
      "     |  \n",
      "     |  turns(self)\n",
      "     |  \n",
      "     |  words(self)\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Methods inherited from nltk.corpus.reader.api.CorpusReader:\n",
      "     |  \n",
      "     |  __repr__(self)\n",
      "     |      Return repr(self).\n",
      "     |  \n",
      "     |  __unicode__ = __str__(self, /)\n",
      "     |  \n",
      "     |  abspath(self, fileid)\n",
      "     |      Return the absolute path for the given file.\n",
      "     |      \n",
      "     |      :type fileid: str\n",
      "     |      :param fileid: The file identifier for the file whose path\n",
      "     |          should be returned.\n",
      "     |      :rtype: PathPointer\n",
      "     |  \n",
      "     |  abspaths(self, fileids=None, include_encoding=False, include_fileid=False)\n",
      "     |      Return a list of the absolute paths for all fileids in this corpus;\n",
      "     |      or for the given list of fileids, if specified.\n",
      "     |      \n",
      "     |      :type fileids: None or str or list\n",
      "     |      :param fileids: Specifies the set of fileids for which paths should\n",
      "     |          be returned.  Can be None, for all fileids; a list of\n",
      "     |          file identifiers, for a specified set of fileids; or a single\n",
      "     |          file identifier, for a single file.  Note that the return\n",
      "     |          value is always a list of paths, even if ``fileids`` is a\n",
      "     |          single file identifier.\n",
      "     |      \n",
      "     |      :param include_encoding: If true, then return a list of\n",
      "     |          ``(path_pointer, encoding)`` tuples.\n",
      "     |      \n",
      "     |      :rtype: list(PathPointer)\n",
      "     |  \n",
      "     |  citation(self)\n",
      "     |      Return the contents of the corpus citation.bib file, if it exists.\n",
      "     |  \n",
      "     |  encoding(self, file)\n",
      "     |      Return the unicode encoding for the given corpus file, if known.\n",
      "     |      If the encoding is unknown, or if the given file should be\n",
      "     |      processed using byte strings (str), then return None.\n",
      "     |  \n",
      "     |  ensure_loaded(self)\n",
      "     |      Load this corpus (if it has not already been loaded).  This is\n",
      "     |      used by LazyCorpusLoader as a simple method that can be used to\n",
      "     |      make sure a corpus is loaded -- e.g., in case a user wants to\n",
      "     |      do help(some_corpus).\n",
      "     |  \n",
      "     |  fileids(self)\n",
      "     |      Return a list of file identifiers for the fileids that make up\n",
      "     |      this corpus.\n",
      "     |  \n",
      "     |  license(self)\n",
      "     |      Return the contents of the corpus LICENSE file, if it exists.\n",
      "     |  \n",
      "     |  open(self, file)\n",
      "     |      Return an open stream that can be used to read the given file.\n",
      "     |      If the file's encoding is not None, then the stream will\n",
      "     |      automatically decode the file's contents into unicode.\n",
      "     |      \n",
      "     |      :param file: The file identifier of the file to read.\n",
      "     |  \n",
      "     |  readme(self)\n",
      "     |      Return the contents of the corpus README file, if it exists.\n",
      "     |  \n",
      "     |  unicode_repr = __repr__(self)\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Data descriptors inherited from nltk.corpus.reader.api.CorpusReader:\n",
      "     |  \n",
      "     |  __dict__\n",
      "     |      dictionary for instance variables (if defined)\n",
      "     |  \n",
      "     |  __weakref__\n",
      "     |      list of weak references to the object (if defined)\n",
      "     |  \n",
      "     |  root\n",
      "     |      The directory where this corpus is stored.\n",
      "     |      \n",
      "     |      :type: PathPointer\n",
      "    \n",
      "    class SyntaxCorpusReader(CorpusReader)\n",
      "     |  SyntaxCorpusReader(root, fileids, encoding='utf8', tagset=None)\n",
      "     |  \n",
      "     |  An abstract base class for reading corpora consisting of\n",
      "     |  syntactically parsed text.  Subclasses should define:\n",
      "     |  \n",
      "     |    - ``__init__``, which specifies the location of the corpus\n",
      "     |      and a method for detecting the sentence blocks in corpus files.\n",
      "     |    - ``_read_block``, which reads a block from the input stream.\n",
      "     |    - ``_word``, which takes a block and returns a list of list of words.\n",
      "     |    - ``_tag``, which takes a block and returns a list of list of tagged\n",
      "     |      words.\n",
      "     |    - ``_parse``, which takes a block and returns a list of parsed\n",
      "     |      sentences.\n",
      "     |  \n",
      "     |  Method resolution order:\n",
      "     |      SyntaxCorpusReader\n",
      "     |      CorpusReader\n",
      "     |      builtins.object\n",
      "     |  \n",
      "     |  Methods defined here:\n",
      "     |  \n",
      "     |  parsed_sents(self, fileids=None)\n",
      "     |  \n",
      "     |  raw(self, fileids=None)\n",
      "     |  \n",
      "     |  sents(self, fileids=None)\n",
      "     |  \n",
      "     |  tagged_sents(self, fileids=None, tagset=None)\n",
      "     |  \n",
      "     |  tagged_words(self, fileids=None, tagset=None)\n",
      "     |  \n",
      "     |  words(self, fileids=None)\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Methods inherited from CorpusReader:\n",
      "     |  \n",
      "     |  __init__(self, root, fileids, encoding='utf8', tagset=None)\n",
      "     |      :type root: PathPointer or str\n",
      "     |      :param root: A path pointer identifying the root directory for\n",
      "     |          this corpus.  If a string is specified, then it will be\n",
      "     |          converted to a ``PathPointer`` automatically.\n",
      "     |      :param fileids: A list of the files that make up this corpus.\n",
      "     |          This list can either be specified explicitly, as a list of\n",
      "     |          strings; or implicitly, as a regular expression over file\n",
      "     |          paths.  The absolute path for each file will be constructed\n",
      "     |          by joining the reader's root to each file name.\n",
      "     |      :param encoding: The default unicode encoding for the files\n",
      "     |          that make up the corpus.  The value of ``encoding`` can be any\n",
      "     |          of the following:\n",
      "     |          - A string: ``encoding`` is the encoding name for all files.\n",
      "     |          - A dictionary: ``encoding[file_id]`` is the encoding\n",
      "     |            name for the file whose identifier is ``file_id``.  If\n",
      "     |            ``file_id`` is not in ``encoding``, then the file\n",
      "     |            contents will be processed using non-unicode byte strings.\n",
      "     |          - A list: ``encoding`` should be a list of ``(regexp, encoding)``\n",
      "     |            tuples.  The encoding for a file whose identifier is ``file_id``\n",
      "     |            will be the ``encoding`` value for the first tuple whose\n",
      "     |            ``regexp`` matches the ``file_id``.  If no tuple's ``regexp``\n",
      "     |            matches the ``file_id``, the file contents will be processed\n",
      "     |            using non-unicode byte strings.\n",
      "     |          - None: the file contents of all files will be\n",
      "     |            processed using non-unicode byte strings.\n",
      "     |      :param tagset: The name of the tagset used by this corpus, to be used\n",
      "     |            for normalizing or converting the POS tags returned by the\n",
      "     |            tagged_...() methods.\n",
      "     |  \n",
      "     |  __repr__(self)\n",
      "     |      Return repr(self).\n",
      "     |  \n",
      "     |  __unicode__ = __str__(self, /)\n",
      "     |  \n",
      "     |  abspath(self, fileid)\n",
      "     |      Return the absolute path for the given file.\n",
      "     |      \n",
      "     |      :type fileid: str\n",
      "     |      :param fileid: The file identifier for the file whose path\n",
      "     |          should be returned.\n",
      "     |      :rtype: PathPointer\n",
      "     |  \n",
      "     |  abspaths(self, fileids=None, include_encoding=False, include_fileid=False)\n",
      "     |      Return a list of the absolute paths for all fileids in this corpus;\n",
      "     |      or for the given list of fileids, if specified.\n",
      "     |      \n",
      "     |      :type fileids: None or str or list\n",
      "     |      :param fileids: Specifies the set of fileids for which paths should\n",
      "     |          be returned.  Can be None, for all fileids; a list of\n",
      "     |          file identifiers, for a specified set of fileids; or a single\n",
      "     |          file identifier, for a single file.  Note that the return\n",
      "     |          value is always a list of paths, even if ``fileids`` is a\n",
      "     |          single file identifier.\n",
      "     |      \n",
      "     |      :param include_encoding: If true, then return a list of\n",
      "     |          ``(path_pointer, encoding)`` tuples.\n",
      "     |      \n",
      "     |      :rtype: list(PathPointer)\n",
      "     |  \n",
      "     |  citation(self)\n",
      "     |      Return the contents of the corpus citation.bib file, if it exists.\n",
      "     |  \n",
      "     |  encoding(self, file)\n",
      "     |      Return the unicode encoding for the given corpus file, if known.\n",
      "     |      If the encoding is unknown, or if the given file should be\n",
      "     |      processed using byte strings (str), then return None.\n",
      "     |  \n",
      "     |  ensure_loaded(self)\n",
      "     |      Load this corpus (if it has not already been loaded).  This is\n",
      "     |      used by LazyCorpusLoader as a simple method that can be used to\n",
      "     |      make sure a corpus is loaded -- e.g., in case a user wants to\n",
      "     |      do help(some_corpus).\n",
      "     |  \n",
      "     |  fileids(self)\n",
      "     |      Return a list of file identifiers for the fileids that make up\n",
      "     |      this corpus.\n",
      "     |  \n",
      "     |  license(self)\n",
      "     |      Return the contents of the corpus LICENSE file, if it exists.\n",
      "     |  \n",
      "     |  open(self, file)\n",
      "     |      Return an open stream that can be used to read the given file.\n",
      "     |      If the file's encoding is not None, then the stream will\n",
      "     |      automatically decode the file's contents into unicode.\n",
      "     |      \n",
      "     |      :param file: The file identifier of the file to read.\n",
      "     |  \n",
      "     |  readme(self)\n",
      "     |      Return the contents of the corpus README file, if it exists.\n",
      "     |  \n",
      "     |  unicode_repr = __repr__(self)\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Data descriptors inherited from CorpusReader:\n",
      "     |  \n",
      "     |  __dict__\n",
      "     |      dictionary for instance variables (if defined)\n",
      "     |  \n",
      "     |  __weakref__\n",
      "     |      list of weak references to the object (if defined)\n",
      "     |  \n",
      "     |  root\n",
      "     |      The directory where this corpus is stored.\n",
      "     |      \n",
      "     |      :type: PathPointer\n",
      "    \n",
      "    class TEICorpusView(nltk.corpus.reader.util.StreamBackedCorpusView)\n",
      "     |  TEICorpusView(corpus_file, tagged, group_by_sent, group_by_para, tagset=None, head_len=0, textids=None)\n",
      "     |  \n",
      "     |  A 'view' of a corpus file, which acts like a sequence of tokens:\n",
      "     |  it can be accessed by index, iterated over, etc.  However, the\n",
      "     |  tokens are only constructed as-needed -- the entire corpus is\n",
      "     |  never stored in memory at once.\n",
      "     |  \n",
      "     |  The constructor to ``StreamBackedCorpusView`` takes two arguments:\n",
      "     |  a corpus fileid (specified as a string or as a ``PathPointer``);\n",
      "     |  and a block reader.  A \"block reader\" is a function that reads\n",
      "     |  zero or more tokens from a stream, and returns them as a list.  A\n",
      "     |  very simple example of a block reader is:\n",
      "     |  \n",
      "     |      >>> def simple_block_reader(stream):\n",
      "     |      ...     return stream.readline().split()\n",
      "     |  \n",
      "     |  This simple block reader reads a single line at a time, and\n",
      "     |  returns a single token (consisting of a string) for each\n",
      "     |  whitespace-separated substring on the line.\n",
      "     |  \n",
      "     |  When deciding how to define the block reader for a given\n",
      "     |  corpus, careful consideration should be given to the size of\n",
      "     |  blocks handled by the block reader.  Smaller block sizes will\n",
      "     |  increase the memory requirements of the corpus view's internal\n",
      "     |  data structures (by 2 integers per block).  On the other hand,\n",
      "     |  larger block sizes may decrease performance for random access to\n",
      "     |  the corpus.  (But note that larger block sizes will *not*\n",
      "     |  decrease performance for iteration.)\n",
      "     |  \n",
      "     |  Internally, ``CorpusView`` maintains a partial mapping from token\n",
      "     |  index to file position, with one entry per block.  When a token\n",
      "     |  with a given index *i* is requested, the ``CorpusView`` constructs\n",
      "     |  it as follows:\n",
      "     |  \n",
      "     |    1. First, it searches the toknum/filepos mapping for the token\n",
      "     |       index closest to (but less than or equal to) *i*.\n",
      "     |  \n",
      "     |    2. Then, starting at the file position corresponding to that\n",
      "     |       index, it reads one block at a time using the block reader\n",
      "     |       until it reaches the requested token.\n",
      "     |  \n",
      "     |  The toknum/filepos mapping is created lazily: it is initially\n",
      "     |  empty, but every time a new block is read, the block's\n",
      "     |  initial token is added to the mapping.  (Thus, the toknum/filepos\n",
      "     |  map has one entry per block.)\n",
      "     |  \n",
      "     |  In order to increase efficiency for random access patterns that\n",
      "     |  have high degrees of locality, the corpus view may cache one or\n",
      "     |  more blocks.\n",
      "     |  \n",
      "     |  :note: Each ``CorpusView`` object internally maintains an open file\n",
      "     |      object for its underlying corpus file.  This file should be\n",
      "     |      automatically closed when the ``CorpusView`` is garbage collected,\n",
      "     |      but if you wish to close it manually, use the ``close()``\n",
      "     |      method.  If you access a ``CorpusView``'s items after it has been\n",
      "     |      closed, the file object will be automatically re-opened.\n",
      "     |  \n",
      "     |  :warning: If the contents of the file are modified during the\n",
      "     |      lifetime of the ``CorpusView``, then the ``CorpusView``'s behavior\n",
      "     |      is undefined.\n",
      "     |  \n",
      "     |  :warning: If a unicode encoding is specified when constructing a\n",
      "     |      ``CorpusView``, then the block reader may only call\n",
      "     |      ``stream.seek()`` with offsets that have been returned by\n",
      "     |      ``stream.tell()``; in particular, calling ``stream.seek()`` with\n",
      "     |      relative offsets, or with offsets based on string lengths, may\n",
      "     |      lead to incorrect behavior.\n",
      "     |  \n",
      "     |  :ivar _block_reader: The function used to read\n",
      "     |      a single block from the underlying file stream.\n",
      "     |  :ivar _toknum: A list containing the token index of each block\n",
      "     |      that has been processed.  In particular, ``_toknum[i]`` is the\n",
      "     |      token index of the first token in block ``i``.  Together\n",
      "     |      with ``_filepos``, this forms a partial mapping between token\n",
      "     |      indices and file positions.\n",
      "     |  :ivar _filepos: A list containing the file position of each block\n",
      "     |      that has been processed.  In particular, ``_toknum[i]`` is the\n",
      "     |      file position of the first character in block ``i``.  Together\n",
      "     |      with ``_toknum``, this forms a partial mapping between token\n",
      "     |      indices and file positions.\n",
      "     |  :ivar _stream: The stream used to access the underlying corpus file.\n",
      "     |  :ivar _len: The total number of tokens in the corpus, if known;\n",
      "     |      or None, if the number of tokens is not yet known.\n",
      "     |  :ivar _eofpos: The character position of the last character in the\n",
      "     |      file.  This is calculated when the corpus view is initialized,\n",
      "     |      and is used to decide when the end of file has been reached.\n",
      "     |  :ivar _cache: A cache of the most recently read block.  It\n",
      "     |     is encoded as a tuple (start_toknum, end_toknum, tokens), where\n",
      "     |     start_toknum is the token index of the first token in the block;\n",
      "     |     end_toknum is the token index of the first token not in the\n",
      "     |     block; and tokens is a list of the tokens in the block.\n",
      "     |  \n",
      "     |  Method resolution order:\n",
      "     |      TEICorpusView\n",
      "     |      nltk.corpus.reader.util.StreamBackedCorpusView\n",
      "     |      nltk.collections.AbstractLazySequence\n",
      "     |      builtins.object\n",
      "     |  \n",
      "     |  Methods defined here:\n",
      "     |  \n",
      "     |  __init__(self, corpus_file, tagged, group_by_sent, group_by_para, tagset=None, head_len=0, textids=None)\n",
      "     |      Create a new corpus view, based on the file ``fileid``, and\n",
      "     |      read with ``block_reader``.  See the class documentation\n",
      "     |      for more information.\n",
      "     |      \n",
      "     |      :param fileid: The path to the file that is read by this\n",
      "     |          corpus view.  ``fileid`` can either be a string or a\n",
      "     |          ``PathPointer``.\n",
      "     |      \n",
      "     |      :param startpos: The file position at which the view will\n",
      "     |          start reading.  This can be used to skip over preface\n",
      "     |          sections.\n",
      "     |      \n",
      "     |      :param encoding: The unicode encoding that should be used to\n",
      "     |          read the file's contents.  If no encoding is specified,\n",
      "     |          then the file's contents will be read as a non-unicode\n",
      "     |          string (i.e., a str).\n",
      "     |  \n",
      "     |  read_block(self, stream)\n",
      "     |      Read a block from the input stream.\n",
      "     |      \n",
      "     |      :return: a block of tokens from the input stream\n",
      "     |      :rtype: list(any)\n",
      "     |      :param stream: an input stream\n",
      "     |      :type stream: stream\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Methods inherited from nltk.corpus.reader.util.StreamBackedCorpusView:\n",
      "     |  \n",
      "     |  __add__(self, other)\n",
      "     |      Return a list concatenating self with other.\n",
      "     |  \n",
      "     |  __getitem__(self, i)\n",
      "     |      Return the *i* th token in the corpus file underlying this\n",
      "     |      corpus view.  Negative indices and spans are both supported.\n",
      "     |  \n",
      "     |  __len__(self)\n",
      "     |      Return the number of tokens in the corpus file underlying this\n",
      "     |      corpus view.\n",
      "     |  \n",
      "     |  __mul__(self, count)\n",
      "     |      Return a list concatenating self with itself ``count`` times.\n",
      "     |  \n",
      "     |  __radd__(self, other)\n",
      "     |      Return a list concatenating other with self.\n",
      "     |  \n",
      "     |  __rmul__(self, count)\n",
      "     |      Return a list concatenating self with itself ``count`` times.\n",
      "     |  \n",
      "     |  close(self)\n",
      "     |      Close the file stream associated with this corpus view.  This\n",
      "     |      can be useful if you are worried about running out of file\n",
      "     |      handles (although the stream should automatically be closed\n",
      "     |      upon garbage collection of the corpus view).  If the corpus\n",
      "     |      view is accessed after it is closed, it will be automatically\n",
      "     |      re-opened.\n",
      "     |  \n",
      "     |  iterate_from(self, start_tok)\n",
      "     |      Return an iterator that generates the tokens in the corpus\n",
      "     |      file underlying this corpus view, starting at the token number\n",
      "     |      ``start``.  If ``start>=len(self)``, then this iterator will\n",
      "     |      generate no tokens.\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Data descriptors inherited from nltk.corpus.reader.util.StreamBackedCorpusView:\n",
      "     |  \n",
      "     |  fileid\n",
      "     |      The fileid of the file that is accessed by this view.\n",
      "     |      \n",
      "     |      :type: str or PathPointer\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Methods inherited from nltk.collections.AbstractLazySequence:\n",
      "     |  \n",
      "     |  __contains__(self, value)\n",
      "     |      Return true if this list contains ``value``.\n",
      "     |  \n",
      "     |  __eq__(self, other)\n",
      "     |      Return self==value.\n",
      "     |  \n",
      "     |  __ge__(self, other, NotImplemented=NotImplemented)\n",
      "     |      Return a >= b.  Computed by @total_ordering from (not a < b).\n",
      "     |  \n",
      "     |  __gt__(self, other, NotImplemented=NotImplemented)\n",
      "     |      Return a > b.  Computed by @total_ordering from (not a < b) and (a != b).\n",
      "     |  \n",
      "     |  __hash__(self)\n",
      "     |      :raise ValueError: Corpus view objects are unhashable.\n",
      "     |  \n",
      "     |  __iter__(self)\n",
      "     |      Return an iterator that generates the tokens in the corpus\n",
      "     |      file underlying this corpus view.\n",
      "     |  \n",
      "     |  __le__(self, other, NotImplemented=NotImplemented)\n",
      "     |      Return a <= b.  Computed by @total_ordering from (a < b) or (a == b).\n",
      "     |  \n",
      "     |  __lt__(self, other)\n",
      "     |      Return self<value.\n",
      "     |  \n",
      "     |  __ne__(self, other)\n",
      "     |      Return self!=value.\n",
      "     |  \n",
      "     |  __repr__(self)\n",
      "     |      Return a string representation for this corpus view that is\n",
      "     |      similar to a list's representation; but if it would be more\n",
      "     |      than 60 characters long, it is truncated.\n",
      "     |  \n",
      "     |  __unicode__ = __str__(self, /)\n",
      "     |  \n",
      "     |  count(self, value)\n",
      "     |      Return the number of times this list contains ``value``.\n",
      "     |  \n",
      "     |  index(self, value, start=None, stop=None)\n",
      "     |      Return the index of the first occurrence of ``value`` in this\n",
      "     |      list that is greater than or equal to ``start`` and less than\n",
      "     |      ``stop``.  Negative start and stop values are treated like negative\n",
      "     |      slice bounds -- i.e., they count from the end of the list.\n",
      "     |  \n",
      "     |  unicode_repr = __repr__(self)\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Data descriptors inherited from nltk.collections.AbstractLazySequence:\n",
      "     |  \n",
      "     |  __dict__\n",
      "     |      dictionary for instance variables (if defined)\n",
      "     |  \n",
      "     |  __weakref__\n",
      "     |      list of weak references to the object (if defined)\n",
      "    \n",
      "    class TaggedCorpusReader(nltk.corpus.reader.api.CorpusReader)\n",
      "     |  TaggedCorpusReader(root, fileids, sep='/', word_tokenizer=WhitespaceTokenizer(pattern='\\\\s+', gaps=True, discard_empty=True, flags=<RegexFlag.UNICODE|DOTALL|MULTILINE: 56>), sent_tokenizer=RegexpTokenizer(pattern='\\n', gaps=True, discard_empty=True, flags=<RegexFlag.UNICODE|DOTALL|MULTILINE: 56>), para_block_reader=<function read_blankline_block at 0x000001F4CED359D8>, encoding='utf8', tagset=None)\n",
      "     |  \n",
      "     |  Reader for simple part-of-speech tagged corpora.  Paragraphs are\n",
      "     |  assumed to be split using blank lines.  Sentences and words can be\n",
      "     |  tokenized using the default tokenizers, or by custom tokenizers\n",
      "     |  specified as parameters to the constructor.  Words are parsed\n",
      "     |  using ``nltk.tag.str2tuple``.  By default, ``'/'`` is used as the\n",
      "     |  separator.  I.e., words should have the form::\n",
      "     |  \n",
      "     |     word1/tag1 word2/tag2 word3/tag3 ...\n",
      "     |  \n",
      "     |  But custom separators may be specified as parameters to the\n",
      "     |  constructor.  Part of speech tags are case-normalized to upper\n",
      "     |  case.\n",
      "     |  \n",
      "     |  Method resolution order:\n",
      "     |      TaggedCorpusReader\n",
      "     |      nltk.corpus.reader.api.CorpusReader\n",
      "     |      builtins.object\n",
      "     |  \n",
      "     |  Methods defined here:\n",
      "     |  \n",
      "     |  __init__(self, root, fileids, sep='/', word_tokenizer=WhitespaceTokenizer(pattern='\\\\s+', gaps=True, discard_empty=True, flags=<RegexFlag.UNICODE|DOTALL|MULTILINE: 56>), sent_tokenizer=RegexpTokenizer(pattern='\\n', gaps=True, discard_empty=True, flags=<RegexFlag.UNICODE|DOTALL|MULTILINE: 56>), para_block_reader=<function read_blankline_block at 0x000001F4CED359D8>, encoding='utf8', tagset=None)\n",
      "     |      Construct a new Tagged Corpus reader for a set of documents\n",
      "     |      located at the given root directory.  Example usage:\n",
      "     |      \n",
      "     |          >>> root = '/...path to corpus.../'\n",
      "     |          >>> reader = TaggedCorpusReader(root, '.*', '.txt') # doctest: +SKIP\n",
      "     |      \n",
      "     |      :param root: The root directory for this corpus.\n",
      "     |      :param fileids: A list or regexp specifying the fileids in this corpus.\n",
      "     |  \n",
      "     |  paras(self, fileids=None)\n",
      "     |      :return: the given file(s) as a list of\n",
      "     |          paragraphs, each encoded as a list of sentences, which are\n",
      "     |          in turn encoded as lists of word strings.\n",
      "     |      :rtype: list(list(list(str)))\n",
      "     |  \n",
      "     |  raw(self, fileids=None)\n",
      "     |      :return: the given file(s) as a single string.\n",
      "     |      :rtype: str\n",
      "     |  \n",
      "     |  sents(self, fileids=None)\n",
      "     |      :return: the given file(s) as a list of\n",
      "     |          sentences or utterances, each encoded as a list of word\n",
      "     |          strings.\n",
      "     |      :rtype: list(list(str))\n",
      "     |  \n",
      "     |  tagged_paras(self, fileids=None, tagset=None)\n",
      "     |      :return: the given file(s) as a list of\n",
      "     |          paragraphs, each encoded as a list of sentences, which are\n",
      "     |          in turn encoded as lists of ``(word,tag)`` tuples.\n",
      "     |      :rtype: list(list(list(tuple(str,str))))\n",
      "     |  \n",
      "     |  tagged_sents(self, fileids=None, tagset=None)\n",
      "     |      :return: the given file(s) as a list of\n",
      "     |          sentences, each encoded as a list of ``(word,tag)`` tuples.\n",
      "     |      \n",
      "     |      :rtype: list(list(tuple(str,str)))\n",
      "     |  \n",
      "     |  tagged_words(self, fileids=None, tagset=None)\n",
      "     |      :return: the given file(s) as a list of tagged\n",
      "     |          words and punctuation symbols, encoded as tuples\n",
      "     |          ``(word,tag)``.\n",
      "     |      :rtype: list(tuple(str,str))\n",
      "     |  \n",
      "     |  words(self, fileids=None)\n",
      "     |      :return: the given file(s) as a list of words\n",
      "     |          and punctuation symbols.\n",
      "     |      :rtype: list(str)\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Methods inherited from nltk.corpus.reader.api.CorpusReader:\n",
      "     |  \n",
      "     |  __repr__(self)\n",
      "     |      Return repr(self).\n",
      "     |  \n",
      "     |  __unicode__ = __str__(self, /)\n",
      "     |  \n",
      "     |  abspath(self, fileid)\n",
      "     |      Return the absolute path for the given file.\n",
      "     |      \n",
      "     |      :type fileid: str\n",
      "     |      :param fileid: The file identifier for the file whose path\n",
      "     |          should be returned.\n",
      "     |      :rtype: PathPointer\n",
      "     |  \n",
      "     |  abspaths(self, fileids=None, include_encoding=False, include_fileid=False)\n",
      "     |      Return a list of the absolute paths for all fileids in this corpus;\n",
      "     |      or for the given list of fileids, if specified.\n",
      "     |      \n",
      "     |      :type fileids: None or str or list\n",
      "     |      :param fileids: Specifies the set of fileids for which paths should\n",
      "     |          be returned.  Can be None, for all fileids; a list of\n",
      "     |          file identifiers, for a specified set of fileids; or a single\n",
      "     |          file identifier, for a single file.  Note that the return\n",
      "     |          value is always a list of paths, even if ``fileids`` is a\n",
      "     |          single file identifier.\n",
      "     |      \n",
      "     |      :param include_encoding: If true, then return a list of\n",
      "     |          ``(path_pointer, encoding)`` tuples.\n",
      "     |      \n",
      "     |      :rtype: list(PathPointer)\n",
      "     |  \n",
      "     |  citation(self)\n",
      "     |      Return the contents of the corpus citation.bib file, if it exists.\n",
      "     |  \n",
      "     |  encoding(self, file)\n",
      "     |      Return the unicode encoding for the given corpus file, if known.\n",
      "     |      If the encoding is unknown, or if the given file should be\n",
      "     |      processed using byte strings (str), then return None.\n",
      "     |  \n",
      "     |  ensure_loaded(self)\n",
      "     |      Load this corpus (if it has not already been loaded).  This is\n",
      "     |      used by LazyCorpusLoader as a simple method that can be used to\n",
      "     |      make sure a corpus is loaded -- e.g., in case a user wants to\n",
      "     |      do help(some_corpus).\n",
      "     |  \n",
      "     |  fileids(self)\n",
      "     |      Return a list of file identifiers for the fileids that make up\n",
      "     |      this corpus.\n",
      "     |  \n",
      "     |  license(self)\n",
      "     |      Return the contents of the corpus LICENSE file, if it exists.\n",
      "     |  \n",
      "     |  open(self, file)\n",
      "     |      Return an open stream that can be used to read the given file.\n",
      "     |      If the file's encoding is not None, then the stream will\n",
      "     |      automatically decode the file's contents into unicode.\n",
      "     |      \n",
      "     |      :param file: The file identifier of the file to read.\n",
      "     |  \n",
      "     |  readme(self)\n",
      "     |      Return the contents of the corpus README file, if it exists.\n",
      "     |  \n",
      "     |  unicode_repr = __repr__(self)\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Data descriptors inherited from nltk.corpus.reader.api.CorpusReader:\n",
      "     |  \n",
      "     |  __dict__\n",
      "     |      dictionary for instance variables (if defined)\n",
      "     |  \n",
      "     |  __weakref__\n",
      "     |      list of weak references to the object (if defined)\n",
      "     |  \n",
      "     |  root\n",
      "     |      The directory where this corpus is stored.\n",
      "     |      \n",
      "     |      :type: PathPointer\n",
      "    \n",
      "    class TimitCorpusReader(nltk.corpus.reader.api.CorpusReader)\n",
      "     |  TimitCorpusReader(root, encoding='utf8')\n",
      "     |  \n",
      "     |  Reader for the TIMIT corpus (or any other corpus with the same\n",
      "     |  file layout and use of file formats).  The corpus root directory\n",
      "     |  should contain the following files:\n",
      "     |  \n",
      "     |    - timitdic.txt: dictionary of standard transcriptions\n",
      "     |    - spkrinfo.txt: table of speaker information\n",
      "     |  \n",
      "     |  In addition, the root directory should contain one subdirectory\n",
      "     |  for each speaker, containing three files for each utterance:\n",
      "     |  \n",
      "     |    - <utterance-id>.txt: text content of utterances\n",
      "     |    - <utterance-id>.wrd: tokenized text content of utterances\n",
      "     |    - <utterance-id>.phn: phonetic transcription of utterances\n",
      "     |    - <utterance-id>.wav: utterance sound file\n",
      "     |  \n",
      "     |  Method resolution order:\n",
      "     |      TimitCorpusReader\n",
      "     |      nltk.corpus.reader.api.CorpusReader\n",
      "     |      builtins.object\n",
      "     |  \n",
      "     |  Methods defined here:\n",
      "     |  \n",
      "     |  __init__(self, root, encoding='utf8')\n",
      "     |      Construct a new TIMIT corpus reader in the given directory.\n",
      "     |      :param root: The root directory for this corpus.\n",
      "     |  \n",
      "     |  audiodata(self, utterance, start=0, end=None)\n",
      "     |  \n",
      "     |  fileids(self, filetype=None)\n",
      "     |      Return a list of file identifiers for the files that make up\n",
      "     |      this corpus.\n",
      "     |      \n",
      "     |      :param filetype: If specified, then ``filetype`` indicates that\n",
      "     |          only the files that have the given type should be\n",
      "     |          returned.  Accepted values are: ``txt``, ``wrd``, ``phn``,\n",
      "     |          ``wav``, or ``metadata``,\n",
      "     |  \n",
      "     |  phone_times(self, utterances=None)\n",
      "     |      offset is represented as a number of 16kHz samples!\n",
      "     |  \n",
      "     |  phone_trees(self, utterances=None)\n",
      "     |  \n",
      "     |  phones(self, utterances=None)\n",
      "     |  \n",
      "     |  play(self, utterance, start=0, end=None)\n",
      "     |      Play the given audio sample.\n",
      "     |      \n",
      "     |      :param utterance: The utterance id of the sample to play\n",
      "     |  \n",
      "     |  sent_times(self, utterances=None)\n",
      "     |  \n",
      "     |  sentid(self, utterance)\n",
      "     |  \n",
      "     |  sents(self, utterances=None)\n",
      "     |  \n",
      "     |  spkrid(self, utterance)\n",
      "     |  \n",
      "     |  spkrinfo(self, speaker)\n",
      "     |      :return: A dictionary mapping .. something.\n",
      "     |  \n",
      "     |  spkrutteranceids(self, speaker)\n",
      "     |      :return: A list of all utterances associated with a given\n",
      "     |      speaker.\n",
      "     |  \n",
      "     |  transcription_dict(self)\n",
      "     |      :return: A dictionary giving the 'standard' transcription for\n",
      "     |      each word.\n",
      "     |  \n",
      "     |  utterance(self, spkrid, sentid)\n",
      "     |  \n",
      "     |  utteranceids(self, dialect=None, sex=None, spkrid=None, sent_type=None, sentid=None)\n",
      "     |      :return: A list of the utterance identifiers for all\n",
      "     |      utterances in this corpus, or for the given speaker, dialect\n",
      "     |      region, gender, sentence type, or sentence number, if\n",
      "     |      specified.\n",
      "     |  \n",
      "     |  wav(self, utterance, start=0, end=None)\n",
      "     |      # [xx] NOTE: This is currently broken -- we're assuming that the\n",
      "     |      # fileids are WAV fileids (aka RIFF), but they're actually NIST SPHERE\n",
      "     |      # fileids.\n",
      "     |  \n",
      "     |  word_times(self, utterances=None)\n",
      "     |  \n",
      "     |  words(self, utterances=None)\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Methods inherited from nltk.corpus.reader.api.CorpusReader:\n",
      "     |  \n",
      "     |  __repr__(self)\n",
      "     |      Return repr(self).\n",
      "     |  \n",
      "     |  __unicode__ = __str__(self, /)\n",
      "     |  \n",
      "     |  abspath(self, fileid)\n",
      "     |      Return the absolute path for the given file.\n",
      "     |      \n",
      "     |      :type fileid: str\n",
      "     |      :param fileid: The file identifier for the file whose path\n",
      "     |          should be returned.\n",
      "     |      :rtype: PathPointer\n",
      "     |  \n",
      "     |  abspaths(self, fileids=None, include_encoding=False, include_fileid=False)\n",
      "     |      Return a list of the absolute paths for all fileids in this corpus;\n",
      "     |      or for the given list of fileids, if specified.\n",
      "     |      \n",
      "     |      :type fileids: None or str or list\n",
      "     |      :param fileids: Specifies the set of fileids for which paths should\n",
      "     |          be returned.  Can be None, for all fileids; a list of\n",
      "     |          file identifiers, for a specified set of fileids; or a single\n",
      "     |          file identifier, for a single file.  Note that the return\n",
      "     |          value is always a list of paths, even if ``fileids`` is a\n",
      "     |          single file identifier.\n",
      "     |      \n",
      "     |      :param include_encoding: If true, then return a list of\n",
      "     |          ``(path_pointer, encoding)`` tuples.\n",
      "     |      \n",
      "     |      :rtype: list(PathPointer)\n",
      "     |  \n",
      "     |  citation(self)\n",
      "     |      Return the contents of the corpus citation.bib file, if it exists.\n",
      "     |  \n",
      "     |  encoding(self, file)\n",
      "     |      Return the unicode encoding for the given corpus file, if known.\n",
      "     |      If the encoding is unknown, or if the given file should be\n",
      "     |      processed using byte strings (str), then return None.\n",
      "     |  \n",
      "     |  ensure_loaded(self)\n",
      "     |      Load this corpus (if it has not already been loaded).  This is\n",
      "     |      used by LazyCorpusLoader as a simple method that can be used to\n",
      "     |      make sure a corpus is loaded -- e.g., in case a user wants to\n",
      "     |      do help(some_corpus).\n",
      "     |  \n",
      "     |  license(self)\n",
      "     |      Return the contents of the corpus LICENSE file, if it exists.\n",
      "     |  \n",
      "     |  open(self, file)\n",
      "     |      Return an open stream that can be used to read the given file.\n",
      "     |      If the file's encoding is not None, then the stream will\n",
      "     |      automatically decode the file's contents into unicode.\n",
      "     |      \n",
      "     |      :param file: The file identifier of the file to read.\n",
      "     |  \n",
      "     |  readme(self)\n",
      "     |      Return the contents of the corpus README file, if it exists.\n",
      "     |  \n",
      "     |  unicode_repr = __repr__(self)\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Data descriptors inherited from nltk.corpus.reader.api.CorpusReader:\n",
      "     |  \n",
      "     |  __dict__\n",
      "     |      dictionary for instance variables (if defined)\n",
      "     |  \n",
      "     |  __weakref__\n",
      "     |      list of weak references to the object (if defined)\n",
      "     |  \n",
      "     |  root\n",
      "     |      The directory where this corpus is stored.\n",
      "     |      \n",
      "     |      :type: PathPointer\n",
      "    \n",
      "    class TimitTaggedCorpusReader(TaggedCorpusReader)\n",
      "     |  TimitTaggedCorpusReader(*args, **kwargs)\n",
      "     |  \n",
      "     |  A corpus reader for tagged sentences that are included in the TIMIT corpus.\n",
      "     |  \n",
      "     |  Method resolution order:\n",
      "     |      TimitTaggedCorpusReader\n",
      "     |      TaggedCorpusReader\n",
      "     |      nltk.corpus.reader.api.CorpusReader\n",
      "     |      builtins.object\n",
      "     |  \n",
      "     |  Methods defined here:\n",
      "     |  \n",
      "     |  __init__(self, *args, **kwargs)\n",
      "     |      Construct a new Tagged Corpus reader for a set of documents\n",
      "     |      located at the given root directory.  Example usage:\n",
      "     |      \n",
      "     |          >>> root = '/...path to corpus.../'\n",
      "     |          >>> reader = TaggedCorpusReader(root, '.*', '.txt') # doctest: +SKIP\n",
      "     |      \n",
      "     |      :param root: The root directory for this corpus.\n",
      "     |      :param fileids: A list or regexp specifying the fileids in this corpus.\n",
      "     |  \n",
      "     |  paras(self)\n",
      "     |      :return: the given file(s) as a list of\n",
      "     |          paragraphs, each encoded as a list of sentences, which are\n",
      "     |          in turn encoded as lists of word strings.\n",
      "     |      :rtype: list(list(list(str)))\n",
      "     |  \n",
      "     |  tagged_paras(self)\n",
      "     |      :return: the given file(s) as a list of\n",
      "     |          paragraphs, each encoded as a list of sentences, which are\n",
      "     |          in turn encoded as lists of ``(word,tag)`` tuples.\n",
      "     |      :rtype: list(list(list(tuple(str,str))))\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Methods inherited from TaggedCorpusReader:\n",
      "     |  \n",
      "     |  raw(self, fileids=None)\n",
      "     |      :return: the given file(s) as a single string.\n",
      "     |      :rtype: str\n",
      "     |  \n",
      "     |  sents(self, fileids=None)\n",
      "     |      :return: the given file(s) as a list of\n",
      "     |          sentences or utterances, each encoded as a list of word\n",
      "     |          strings.\n",
      "     |      :rtype: list(list(str))\n",
      "     |  \n",
      "     |  tagged_sents(self, fileids=None, tagset=None)\n",
      "     |      :return: the given file(s) as a list of\n",
      "     |          sentences, each encoded as a list of ``(word,tag)`` tuples.\n",
      "     |      \n",
      "     |      :rtype: list(list(tuple(str,str)))\n",
      "     |  \n",
      "     |  tagged_words(self, fileids=None, tagset=None)\n",
      "     |      :return: the given file(s) as a list of tagged\n",
      "     |          words and punctuation symbols, encoded as tuples\n",
      "     |          ``(word,tag)``.\n",
      "     |      :rtype: list(tuple(str,str))\n",
      "     |  \n",
      "     |  words(self, fileids=None)\n",
      "     |      :return: the given file(s) as a list of words\n",
      "     |          and punctuation symbols.\n",
      "     |      :rtype: list(str)\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Methods inherited from nltk.corpus.reader.api.CorpusReader:\n",
      "     |  \n",
      "     |  __repr__(self)\n",
      "     |      Return repr(self).\n",
      "     |  \n",
      "     |  __unicode__ = __str__(self, /)\n",
      "     |  \n",
      "     |  abspath(self, fileid)\n",
      "     |      Return the absolute path for the given file.\n",
      "     |      \n",
      "     |      :type fileid: str\n",
      "     |      :param fileid: The file identifier for the file whose path\n",
      "     |          should be returned.\n",
      "     |      :rtype: PathPointer\n",
      "     |  \n",
      "     |  abspaths(self, fileids=None, include_encoding=False, include_fileid=False)\n",
      "     |      Return a list of the absolute paths for all fileids in this corpus;\n",
      "     |      or for the given list of fileids, if specified.\n",
      "     |      \n",
      "     |      :type fileids: None or str or list\n",
      "     |      :param fileids: Specifies the set of fileids for which paths should\n",
      "     |          be returned.  Can be None, for all fileids; a list of\n",
      "     |          file identifiers, for a specified set of fileids; or a single\n",
      "     |          file identifier, for a single file.  Note that the return\n",
      "     |          value is always a list of paths, even if ``fileids`` is a\n",
      "     |          single file identifier.\n",
      "     |      \n",
      "     |      :param include_encoding: If true, then return a list of\n",
      "     |          ``(path_pointer, encoding)`` tuples.\n",
      "     |      \n",
      "     |      :rtype: list(PathPointer)\n",
      "     |  \n",
      "     |  citation(self)\n",
      "     |      Return the contents of the corpus citation.bib file, if it exists.\n",
      "     |  \n",
      "     |  encoding(self, file)\n",
      "     |      Return the unicode encoding for the given corpus file, if known.\n",
      "     |      If the encoding is unknown, or if the given file should be\n",
      "     |      processed using byte strings (str), then return None.\n",
      "     |  \n",
      "     |  ensure_loaded(self)\n",
      "     |      Load this corpus (if it has not already been loaded).  This is\n",
      "     |      used by LazyCorpusLoader as a simple method that can be used to\n",
      "     |      make sure a corpus is loaded -- e.g., in case a user wants to\n",
      "     |      do help(some_corpus).\n",
      "     |  \n",
      "     |  fileids(self)\n",
      "     |      Return a list of file identifiers for the fileids that make up\n",
      "     |      this corpus.\n",
      "     |  \n",
      "     |  license(self)\n",
      "     |      Return the contents of the corpus LICENSE file, if it exists.\n",
      "     |  \n",
      "     |  open(self, file)\n",
      "     |      Return an open stream that can be used to read the given file.\n",
      "     |      If the file's encoding is not None, then the stream will\n",
      "     |      automatically decode the file's contents into unicode.\n",
      "     |      \n",
      "     |      :param file: The file identifier of the file to read.\n",
      "     |  \n",
      "     |  readme(self)\n",
      "     |      Return the contents of the corpus README file, if it exists.\n",
      "     |  \n",
      "     |  unicode_repr = __repr__(self)\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Data descriptors inherited from nltk.corpus.reader.api.CorpusReader:\n",
      "     |  \n",
      "     |  __dict__\n",
      "     |      dictionary for instance variables (if defined)\n",
      "     |  \n",
      "     |  __weakref__\n",
      "     |      list of weak references to the object (if defined)\n",
      "     |  \n",
      "     |  root\n",
      "     |      The directory where this corpus is stored.\n",
      "     |      \n",
      "     |      :type: PathPointer\n",
      "    \n",
      "    class ToolboxCorpusReader(nltk.corpus.reader.api.CorpusReader)\n",
      "     |  ToolboxCorpusReader(root, fileids, encoding='utf8', tagset=None)\n",
      "     |  \n",
      "     |  A base class for \"corpus reader\" classes, each of which can be\n",
      "     |  used to read a specific corpus format.  Each individual corpus\n",
      "     |  reader instance is used to read a specific corpus, consisting of\n",
      "     |  one or more files under a common root directory.  Each file is\n",
      "     |  identified by its ``file identifier``, which is the relative path\n",
      "     |  to the file from the root directory.\n",
      "     |  \n",
      "     |  A separate subclass is defined for each corpus format.  These\n",
      "     |  subclasses define one or more methods that provide 'views' on the\n",
      "     |  corpus contents, such as ``words()`` (for a list of words) and\n",
      "     |  ``parsed_sents()`` (for a list of parsed sentences).  Called with\n",
      "     |  no arguments, these methods will return the contents of the entire\n",
      "     |  corpus.  For most corpora, these methods define one or more\n",
      "     |  selection arguments, such as ``fileids`` or ``categories``, which can\n",
      "     |  be used to select which portion of the corpus should be returned.\n",
      "     |  \n",
      "     |  Method resolution order:\n",
      "     |      ToolboxCorpusReader\n",
      "     |      nltk.corpus.reader.api.CorpusReader\n",
      "     |      builtins.object\n",
      "     |  \n",
      "     |  Methods defined here:\n",
      "     |  \n",
      "     |  entries(self, fileids, **kwargs)\n",
      "     |      # should probably be done lazily:\n",
      "     |  \n",
      "     |  fields(self, fileids, strip=True, unwrap=True, encoding='utf8', errors='strict', unicode_fields=None)\n",
      "     |  \n",
      "     |  raw(self, fileids)\n",
      "     |  \n",
      "     |  words(self, fileids, key='lx')\n",
      "     |  \n",
      "     |  xml(self, fileids, key=None)\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Methods inherited from nltk.corpus.reader.api.CorpusReader:\n",
      "     |  \n",
      "     |  __init__(self, root, fileids, encoding='utf8', tagset=None)\n",
      "     |      :type root: PathPointer or str\n",
      "     |      :param root: A path pointer identifying the root directory for\n",
      "     |          this corpus.  If a string is specified, then it will be\n",
      "     |          converted to a ``PathPointer`` automatically.\n",
      "     |      :param fileids: A list of the files that make up this corpus.\n",
      "     |          This list can either be specified explicitly, as a list of\n",
      "     |          strings; or implicitly, as a regular expression over file\n",
      "     |          paths.  The absolute path for each file will be constructed\n",
      "     |          by joining the reader's root to each file name.\n",
      "     |      :param encoding: The default unicode encoding for the files\n",
      "     |          that make up the corpus.  The value of ``encoding`` can be any\n",
      "     |          of the following:\n",
      "     |          - A string: ``encoding`` is the encoding name for all files.\n",
      "     |          - A dictionary: ``encoding[file_id]`` is the encoding\n",
      "     |            name for the file whose identifier is ``file_id``.  If\n",
      "     |            ``file_id`` is not in ``encoding``, then the file\n",
      "     |            contents will be processed using non-unicode byte strings.\n",
      "     |          - A list: ``encoding`` should be a list of ``(regexp, encoding)``\n",
      "     |            tuples.  The encoding for a file whose identifier is ``file_id``\n",
      "     |            will be the ``encoding`` value for the first tuple whose\n",
      "     |            ``regexp`` matches the ``file_id``.  If no tuple's ``regexp``\n",
      "     |            matches the ``file_id``, the file contents will be processed\n",
      "     |            using non-unicode byte strings.\n",
      "     |          - None: the file contents of all files will be\n",
      "     |            processed using non-unicode byte strings.\n",
      "     |      :param tagset: The name of the tagset used by this corpus, to be used\n",
      "     |            for normalizing or converting the POS tags returned by the\n",
      "     |            tagged_...() methods.\n",
      "     |  \n",
      "     |  __repr__(self)\n",
      "     |      Return repr(self).\n",
      "     |  \n",
      "     |  __unicode__ = __str__(self, /)\n",
      "     |  \n",
      "     |  abspath(self, fileid)\n",
      "     |      Return the absolute path for the given file.\n",
      "     |      \n",
      "     |      :type fileid: str\n",
      "     |      :param fileid: The file identifier for the file whose path\n",
      "     |          should be returned.\n",
      "     |      :rtype: PathPointer\n",
      "     |  \n",
      "     |  abspaths(self, fileids=None, include_encoding=False, include_fileid=False)\n",
      "     |      Return a list of the absolute paths for all fileids in this corpus;\n",
      "     |      or for the given list of fileids, if specified.\n",
      "     |      \n",
      "     |      :type fileids: None or str or list\n",
      "     |      :param fileids: Specifies the set of fileids for which paths should\n",
      "     |          be returned.  Can be None, for all fileids; a list of\n",
      "     |          file identifiers, for a specified set of fileids; or a single\n",
      "     |          file identifier, for a single file.  Note that the return\n",
      "     |          value is always a list of paths, even if ``fileids`` is a\n",
      "     |          single file identifier.\n",
      "     |      \n",
      "     |      :param include_encoding: If true, then return a list of\n",
      "     |          ``(path_pointer, encoding)`` tuples.\n",
      "     |      \n",
      "     |      :rtype: list(PathPointer)\n",
      "     |  \n",
      "     |  citation(self)\n",
      "     |      Return the contents of the corpus citation.bib file, if it exists.\n",
      "     |  \n",
      "     |  encoding(self, file)\n",
      "     |      Return the unicode encoding for the given corpus file, if known.\n",
      "     |      If the encoding is unknown, or if the given file should be\n",
      "     |      processed using byte strings (str), then return None.\n",
      "     |  \n",
      "     |  ensure_loaded(self)\n",
      "     |      Load this corpus (if it has not already been loaded).  This is\n",
      "     |      used by LazyCorpusLoader as a simple method that can be used to\n",
      "     |      make sure a corpus is loaded -- e.g., in case a user wants to\n",
      "     |      do help(some_corpus).\n",
      "     |  \n",
      "     |  fileids(self)\n",
      "     |      Return a list of file identifiers for the fileids that make up\n",
      "     |      this corpus.\n",
      "     |  \n",
      "     |  license(self)\n",
      "     |      Return the contents of the corpus LICENSE file, if it exists.\n",
      "     |  \n",
      "     |  open(self, file)\n",
      "     |      Return an open stream that can be used to read the given file.\n",
      "     |      If the file's encoding is not None, then the stream will\n",
      "     |      automatically decode the file's contents into unicode.\n",
      "     |      \n",
      "     |      :param file: The file identifier of the file to read.\n",
      "     |  \n",
      "     |  readme(self)\n",
      "     |      Return the contents of the corpus README file, if it exists.\n",
      "     |  \n",
      "     |  unicode_repr = __repr__(self)\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Data descriptors inherited from nltk.corpus.reader.api.CorpusReader:\n",
      "     |  \n",
      "     |  __dict__\n",
      "     |      dictionary for instance variables (if defined)\n",
      "     |  \n",
      "     |  __weakref__\n",
      "     |      list of weak references to the object (if defined)\n",
      "     |  \n",
      "     |  root\n",
      "     |      The directory where this corpus is stored.\n",
      "     |      \n",
      "     |      :type: PathPointer\n",
      "    \n",
      "    class TwitterCorpusReader(nltk.corpus.reader.api.CorpusReader)\n",
      "     |  TwitterCorpusReader(root, fileids=None, word_tokenizer=<nltk.tokenize.casual.TweetTokenizer object at 0x000001F4CEE6F8C8>, encoding='utf8')\n",
      "     |  \n",
      "     |  Reader for corpora that consist of Tweets represented as a list of line-delimited JSON.\n",
      "     |  \n",
      "     |  Individual Tweets can be tokenized using the default tokenizer, or by a\n",
      "     |  custom tokenizer specified as a parameter to the constructor.\n",
      "     |  \n",
      "     |  Construct a new Tweet corpus reader for a set of documents\n",
      "     |  located at the given root directory.\n",
      "     |  \n",
      "     |  If you made your own tweet collection in a directory called\n",
      "     |  `twitter-files`, then you can initialise the reader as::\n",
      "     |  \n",
      "     |      from nltk.corpus import TwitterCorpusReader\n",
      "     |      reader = TwitterCorpusReader(root='/path/to/twitter-files', '.*\\.json')\n",
      "     |  \n",
      "     |  However, the recommended approach is to set the relevant directory as the\n",
      "     |  value of the environmental variable `TWITTER`, and then invoke the reader\n",
      "     |  as follows::\n",
      "     |  \n",
      "     |     root = os.environ['TWITTER']\n",
      "     |     reader = TwitterCorpusReader(root, '.*\\.json')\n",
      "     |  \n",
      "     |  If you want to work directly with the raw Tweets, the `json` library can\n",
      "     |  be used::\n",
      "     |  \n",
      "     |     import json\n",
      "     |     for tweet in reader.docs():\n",
      "     |         print(json.dumps(tweet, indent=1, sort_keys=True))\n",
      "     |  \n",
      "     |  Method resolution order:\n",
      "     |      TwitterCorpusReader\n",
      "     |      nltk.corpus.reader.api.CorpusReader\n",
      "     |      builtins.object\n",
      "     |  \n",
      "     |  Methods defined here:\n",
      "     |  \n",
      "     |  __init__(self, root, fileids=None, word_tokenizer=<nltk.tokenize.casual.TweetTokenizer object at 0x000001F4CEE6F8C8>, encoding='utf8')\n",
      "     |      :param root: The root directory for this corpus.\n",
      "     |      \n",
      "     |      :param fileids: A list or regexp specifying the fileids in this corpus.\n",
      "     |      \n",
      "     |      :param word_tokenizer: Tokenizer for breaking the text of Tweets into\n",
      "     |      smaller units, including but not limited to words.\n",
      "     |  \n",
      "     |  docs(self, fileids=None)\n",
      "     |      Returns the full Tweet objects, as specified by `Twitter\n",
      "     |      documentation on Tweets\n",
      "     |      <https://dev.twitter.com/docs/platform-objects/tweets>`_\n",
      "     |      \n",
      "     |      :return: the given file(s) as a list of dictionaries deserialised\n",
      "     |      from JSON.\n",
      "     |      :rtype: list(dict)\n",
      "     |  \n",
      "     |  raw(self, fileids=None)\n",
      "     |      Return the corpora in their raw form.\n",
      "     |  \n",
      "     |  strings(self, fileids=None)\n",
      "     |      Returns only the text content of Tweets in the file(s)\n",
      "     |      \n",
      "     |      :return: the given file(s) as a list of Tweets.\n",
      "     |      :rtype: list(str)\n",
      "     |  \n",
      "     |  tokenized(self, fileids=None)\n",
      "     |      :return: the given file(s) as a list of the text content of Tweets as\n",
      "     |      as a list of words, screenanames, hashtags, URLs and punctuation symbols.\n",
      "     |      \n",
      "     |      :rtype: list(list(str))\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Data and other attributes defined here:\n",
      "     |  \n",
      "     |  CorpusView = <class 'nltk.corpus.reader.util.StreamBackedCorpusView'>\n",
      "     |      A 'view' of a corpus file, which acts like a sequence of tokens:\n",
      "     |      it can be accessed by index, iterated over, etc.  However, the\n",
      "     |      tokens are only constructed as-needed -- the entire corpus is\n",
      "     |      never stored in memory at once.\n",
      "     |      \n",
      "     |      The constructor to ``StreamBackedCorpusView`` takes two arguments:\n",
      "     |      a corpus fileid (specified as a string or as a ``PathPointer``);\n",
      "     |      and a block reader.  A \"block reader\" is a function that reads\n",
      "     |      zero or more tokens from a stream, and returns them as a list.  A\n",
      "     |      very simple example of a block reader is:\n",
      "     |      \n",
      "     |          >>> def simple_block_reader(stream):\n",
      "     |          ...     return stream.readline().split()\n",
      "     |      \n",
      "     |      This simple block reader reads a single line at a time, and\n",
      "     |      returns a single token (consisting of a string) for each\n",
      "     |      whitespace-separated substring on the line.\n",
      "     |      \n",
      "     |      When deciding how to define the block reader for a given\n",
      "     |      corpus, careful consideration should be given to the size of\n",
      "     |      blocks handled by the block reader.  Smaller block sizes will\n",
      "     |      increase the memory requirements of the corpus view's internal\n",
      "     |      data structures (by 2 integers per block).  On the other hand,\n",
      "     |      larger block sizes may decrease performance for random access to\n",
      "     |      the corpus.  (But note that larger block sizes will *not*\n",
      "     |      decrease performance for iteration.)\n",
      "     |      \n",
      "     |      Internally, ``CorpusView`` maintains a partial mapping from token\n",
      "     |      index to file position, with one entry per block.  When a token\n",
      "     |      with a given index *i* is requested, the ``CorpusView`` constructs\n",
      "     |      it as follows:\n",
      "     |      \n",
      "     |        1. First, it searches the toknum/filepos mapping for the token\n",
      "     |           index closest to (but less than or equal to) *i*.\n",
      "     |      \n",
      "     |        2. Then, starting at the file position corresponding to that\n",
      "     |           index, it reads one block at a time using the block reader\n",
      "     |           until it reaches the requested token.\n",
      "     |      \n",
      "     |      The toknum/filepos mapping is created lazily: it is initially\n",
      "     |      empty, but every time a new block is read, the block's\n",
      "     |      initial token is added to the mapping.  (Thus, the toknum/filepos\n",
      "     |      map has one entry per block.)\n",
      "     |      \n",
      "     |      In order to increase efficiency for random access patterns that\n",
      "     |      have high degrees of locality, the corpus view may cache one or\n",
      "     |      more blocks.\n",
      "     |      \n",
      "     |      :note: Each ``CorpusView`` object internally maintains an open file\n",
      "     |          object for its underlying corpus file.  This file should be\n",
      "     |          automatically closed when the ``CorpusView`` is garbage collected,\n",
      "     |          but if you wish to close it manually, use the ``close()``\n",
      "     |          method.  If you access a ``CorpusView``'s items after it has been\n",
      "     |          closed, the file object will be automatically re-opened.\n",
      "     |      \n",
      "     |      :warning: If the contents of the file are modified during the\n",
      "     |          lifetime of the ``CorpusView``, then the ``CorpusView``'s behavior\n",
      "     |          is undefined.\n",
      "     |      \n",
      "     |      :warning: If a unicode encoding is specified when constructing a\n",
      "     |          ``CorpusView``, then the block reader may only call\n",
      "     |          ``stream.seek()`` with offsets that have been returned by\n",
      "     |          ``stream.tell()``; in particular, calling ``stream.seek()`` with\n",
      "     |          relative offsets, or with offsets based on string lengths, may\n",
      "     |          lead to incorrect behavior.\n",
      "     |      \n",
      "     |      :ivar _block_reader: The function used to read\n",
      "     |          a single block from the underlying file stream.\n",
      "     |      :ivar _toknum: A list containing the token index of each block\n",
      "     |          that has been processed.  In particular, ``_toknum[i]`` is the\n",
      "     |          token index of the first token in block ``i``.  Together\n",
      "     |          with ``_filepos``, this forms a partial mapping between token\n",
      "     |          indices and file positions.\n",
      "     |      :ivar _filepos: A list containing the file position of each block\n",
      "     |          that has been processed.  In particular, ``_toknum[i]`` is the\n",
      "     |          file position of the first character in block ``i``.  Together\n",
      "     |          with ``_toknum``, this forms a partial mapping between token\n",
      "     |          indices and file positions.\n",
      "     |      :ivar _stream: The stream used to access the underlying corpus file.\n",
      "     |      :ivar _len: The total number of tokens in the corpus, if known;\n",
      "     |          or None, if the number of tokens is not yet known.\n",
      "     |      :ivar _eofpos: The character position of the last character in the\n",
      "     |          file.  This is calculated when the corpus view is initialized,\n",
      "     |          and is used to decide when the end of file has been reached.\n",
      "     |      :ivar _cache: A cache of the most recently read block.  It\n",
      "     |         is encoded as a tuple (start_toknum, end_toknum, tokens), where\n",
      "     |         start_toknum is the token index of the first token in the block;\n",
      "     |         end_toknum is the token index of the first token not in the\n",
      "     |         block; and tokens is a list of the tokens in the block.\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Methods inherited from nltk.corpus.reader.api.CorpusReader:\n",
      "     |  \n",
      "     |  __repr__(self)\n",
      "     |      Return repr(self).\n",
      "     |  \n",
      "     |  __unicode__ = __str__(self, /)\n",
      "     |  \n",
      "     |  abspath(self, fileid)\n",
      "     |      Return the absolute path for the given file.\n",
      "     |      \n",
      "     |      :type fileid: str\n",
      "     |      :param fileid: The file identifier for the file whose path\n",
      "     |          should be returned.\n",
      "     |      :rtype: PathPointer\n",
      "     |  \n",
      "     |  abspaths(self, fileids=None, include_encoding=False, include_fileid=False)\n",
      "     |      Return a list of the absolute paths for all fileids in this corpus;\n",
      "     |      or for the given list of fileids, if specified.\n",
      "     |      \n",
      "     |      :type fileids: None or str or list\n",
      "     |      :param fileids: Specifies the set of fileids for which paths should\n",
      "     |          be returned.  Can be None, for all fileids; a list of\n",
      "     |          file identifiers, for a specified set of fileids; or a single\n",
      "     |          file identifier, for a single file.  Note that the return\n",
      "     |          value is always a list of paths, even if ``fileids`` is a\n",
      "     |          single file identifier.\n",
      "     |      \n",
      "     |      :param include_encoding: If true, then return a list of\n",
      "     |          ``(path_pointer, encoding)`` tuples.\n",
      "     |      \n",
      "     |      :rtype: list(PathPointer)\n",
      "     |  \n",
      "     |  citation(self)\n",
      "     |      Return the contents of the corpus citation.bib file, if it exists.\n",
      "     |  \n",
      "     |  encoding(self, file)\n",
      "     |      Return the unicode encoding for the given corpus file, if known.\n",
      "     |      If the encoding is unknown, or if the given file should be\n",
      "     |      processed using byte strings (str), then return None.\n",
      "     |  \n",
      "     |  ensure_loaded(self)\n",
      "     |      Load this corpus (if it has not already been loaded).  This is\n",
      "     |      used by LazyCorpusLoader as a simple method that can be used to\n",
      "     |      make sure a corpus is loaded -- e.g., in case a user wants to\n",
      "     |      do help(some_corpus).\n",
      "     |  \n",
      "     |  fileids(self)\n",
      "     |      Return a list of file identifiers for the fileids that make up\n",
      "     |      this corpus.\n",
      "     |  \n",
      "     |  license(self)\n",
      "     |      Return the contents of the corpus LICENSE file, if it exists.\n",
      "     |  \n",
      "     |  open(self, file)\n",
      "     |      Return an open stream that can be used to read the given file.\n",
      "     |      If the file's encoding is not None, then the stream will\n",
      "     |      automatically decode the file's contents into unicode.\n",
      "     |      \n",
      "     |      :param file: The file identifier of the file to read.\n",
      "     |  \n",
      "     |  readme(self)\n",
      "     |      Return the contents of the corpus README file, if it exists.\n",
      "     |  \n",
      "     |  unicode_repr = __repr__(self)\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Data descriptors inherited from nltk.corpus.reader.api.CorpusReader:\n",
      "     |  \n",
      "     |  __dict__\n",
      "     |      dictionary for instance variables (if defined)\n",
      "     |  \n",
      "     |  __weakref__\n",
      "     |      list of weak references to the object (if defined)\n",
      "     |  \n",
      "     |  root\n",
      "     |      The directory where this corpus is stored.\n",
      "     |      \n",
      "     |      :type: PathPointer\n",
      "    \n",
      "    class UdhrCorpusReader(nltk.corpus.reader.plaintext.PlaintextCorpusReader)\n",
      "     |  UdhrCorpusReader(root='udhr')\n",
      "     |  \n",
      "     |  Reader for corpora that consist of plaintext documents.  Paragraphs\n",
      "     |  are assumed to be split using blank lines.  Sentences and words can\n",
      "     |  be tokenized using the default tokenizers, or by custom tokenizers\n",
      "     |  specificed as parameters to the constructor.\n",
      "     |  \n",
      "     |  This corpus reader can be customized (e.g., to skip preface\n",
      "     |  sections of specific document formats) by creating a subclass and\n",
      "     |  overriding the ``CorpusView`` class variable.\n",
      "     |  \n",
      "     |  Method resolution order:\n",
      "     |      UdhrCorpusReader\n",
      "     |      nltk.corpus.reader.plaintext.PlaintextCorpusReader\n",
      "     |      nltk.corpus.reader.api.CorpusReader\n",
      "     |      builtins.object\n",
      "     |  \n",
      "     |  Methods defined here:\n",
      "     |  \n",
      "     |  __init__(self, root='udhr')\n",
      "     |      Construct a new plaintext corpus reader for a set of documents\n",
      "     |      located at the given root directory.  Example usage:\n",
      "     |      \n",
      "     |          >>> root = '/usr/local/share/nltk_data/corpora/webtext/'\n",
      "     |          >>> reader = PlaintextCorpusReader(root, '.*\\.txt') # doctest: +SKIP\n",
      "     |      \n",
      "     |      :param root: The root directory for this corpus.\n",
      "     |      :param fileids: A list or regexp specifying the fileids in this corpus.\n",
      "     |      :param word_tokenizer: Tokenizer for breaking sentences or\n",
      "     |          paragraphs into words.\n",
      "     |      :param sent_tokenizer: Tokenizer for breaking paragraphs\n",
      "     |          into words.\n",
      "     |      :param para_block_reader: The block reader used to divide the\n",
      "     |          corpus into paragraph blocks.\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Data and other attributes defined here:\n",
      "     |  \n",
      "     |  ENCODINGS = [('.*-Latin1$', 'latin-1'), ('.*-Hebrew$', 'hebrew'), ('.*...\n",
      "     |  \n",
      "     |  SKIP = {'Amharic-Afenegus6..60375', 'Armenian-DallakHelv', 'Azeri_Azer...\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Methods inherited from nltk.corpus.reader.plaintext.PlaintextCorpusReader:\n",
      "     |  \n",
      "     |  paras(self, fileids=None)\n",
      "     |      :return: the given file(s) as a list of\n",
      "     |          paragraphs, each encoded as a list of sentences, which are\n",
      "     |          in turn encoded as lists of word strings.\n",
      "     |      :rtype: list(list(list(str)))\n",
      "     |  \n",
      "     |  raw(self, fileids=None)\n",
      "     |      :return: the given file(s) as a single string.\n",
      "     |      :rtype: str\n",
      "     |  \n",
      "     |  sents(self, fileids=None)\n",
      "     |      :return: the given file(s) as a list of\n",
      "     |          sentences or utterances, each encoded as a list of word\n",
      "     |          strings.\n",
      "     |      :rtype: list(list(str))\n",
      "     |  \n",
      "     |  words(self, fileids=None)\n",
      "     |      :return: the given file(s) as a list of words\n",
      "     |          and punctuation symbols.\n",
      "     |      :rtype: list(str)\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Data and other attributes inherited from nltk.corpus.reader.plaintext.PlaintextCorpusReader:\n",
      "     |  \n",
      "     |  CorpusView = <class 'nltk.corpus.reader.util.StreamBackedCorpusView'>\n",
      "     |      A 'view' of a corpus file, which acts like a sequence of tokens:\n",
      "     |      it can be accessed by index, iterated over, etc.  However, the\n",
      "     |      tokens are only constructed as-needed -- the entire corpus is\n",
      "     |      never stored in memory at once.\n",
      "     |      \n",
      "     |      The constructor to ``StreamBackedCorpusView`` takes two arguments:\n",
      "     |      a corpus fileid (specified as a string or as a ``PathPointer``);\n",
      "     |      and a block reader.  A \"block reader\" is a function that reads\n",
      "     |      zero or more tokens from a stream, and returns them as a list.  A\n",
      "     |      very simple example of a block reader is:\n",
      "     |      \n",
      "     |          >>> def simple_block_reader(stream):\n",
      "     |          ...     return stream.readline().split()\n",
      "     |      \n",
      "     |      This simple block reader reads a single line at a time, and\n",
      "     |      returns a single token (consisting of a string) for each\n",
      "     |      whitespace-separated substring on the line.\n",
      "     |      \n",
      "     |      When deciding how to define the block reader for a given\n",
      "     |      corpus, careful consideration should be given to the size of\n",
      "     |      blocks handled by the block reader.  Smaller block sizes will\n",
      "     |      increase the memory requirements of the corpus view's internal\n",
      "     |      data structures (by 2 integers per block).  On the other hand,\n",
      "     |      larger block sizes may decrease performance for random access to\n",
      "     |      the corpus.  (But note that larger block sizes will *not*\n",
      "     |      decrease performance for iteration.)\n",
      "     |      \n",
      "     |      Internally, ``CorpusView`` maintains a partial mapping from token\n",
      "     |      index to file position, with one entry per block.  When a token\n",
      "     |      with a given index *i* is requested, the ``CorpusView`` constructs\n",
      "     |      it as follows:\n",
      "     |      \n",
      "     |        1. First, it searches the toknum/filepos mapping for the token\n",
      "     |           index closest to (but less than or equal to) *i*.\n",
      "     |      \n",
      "     |        2. Then, starting at the file position corresponding to that\n",
      "     |           index, it reads one block at a time using the block reader\n",
      "     |           until it reaches the requested token.\n",
      "     |      \n",
      "     |      The toknum/filepos mapping is created lazily: it is initially\n",
      "     |      empty, but every time a new block is read, the block's\n",
      "     |      initial token is added to the mapping.  (Thus, the toknum/filepos\n",
      "     |      map has one entry per block.)\n",
      "     |      \n",
      "     |      In order to increase efficiency for random access patterns that\n",
      "     |      have high degrees of locality, the corpus view may cache one or\n",
      "     |      more blocks.\n",
      "     |      \n",
      "     |      :note: Each ``CorpusView`` object internally maintains an open file\n",
      "     |          object for its underlying corpus file.  This file should be\n",
      "     |          automatically closed when the ``CorpusView`` is garbage collected,\n",
      "     |          but if you wish to close it manually, use the ``close()``\n",
      "     |          method.  If you access a ``CorpusView``'s items after it has been\n",
      "     |          closed, the file object will be automatically re-opened.\n",
      "     |      \n",
      "     |      :warning: If the contents of the file are modified during the\n",
      "     |          lifetime of the ``CorpusView``, then the ``CorpusView``'s behavior\n",
      "     |          is undefined.\n",
      "     |      \n",
      "     |      :warning: If a unicode encoding is specified when constructing a\n",
      "     |          ``CorpusView``, then the block reader may only call\n",
      "     |          ``stream.seek()`` with offsets that have been returned by\n",
      "     |          ``stream.tell()``; in particular, calling ``stream.seek()`` with\n",
      "     |          relative offsets, or with offsets based on string lengths, may\n",
      "     |          lead to incorrect behavior.\n",
      "     |      \n",
      "     |      :ivar _block_reader: The function used to read\n",
      "     |          a single block from the underlying file stream.\n",
      "     |      :ivar _toknum: A list containing the token index of each block\n",
      "     |          that has been processed.  In particular, ``_toknum[i]`` is the\n",
      "     |          token index of the first token in block ``i``.  Together\n",
      "     |          with ``_filepos``, this forms a partial mapping between token\n",
      "     |          indices and file positions.\n",
      "     |      :ivar _filepos: A list containing the file position of each block\n",
      "     |          that has been processed.  In particular, ``_toknum[i]`` is the\n",
      "     |          file position of the first character in block ``i``.  Together\n",
      "     |          with ``_toknum``, this forms a partial mapping between token\n",
      "     |          indices and file positions.\n",
      "     |      :ivar _stream: The stream used to access the underlying corpus file.\n",
      "     |      :ivar _len: The total number of tokens in the corpus, if known;\n",
      "     |          or None, if the number of tokens is not yet known.\n",
      "     |      :ivar _eofpos: The character position of the last character in the\n",
      "     |          file.  This is calculated when the corpus view is initialized,\n",
      "     |          and is used to decide when the end of file has been reached.\n",
      "     |      :ivar _cache: A cache of the most recently read block.  It\n",
      "     |         is encoded as a tuple (start_toknum, end_toknum, tokens), where\n",
      "     |         start_toknum is the token index of the first token in the block;\n",
      "     |         end_toknum is the token index of the first token not in the\n",
      "     |         block; and tokens is a list of the tokens in the block.\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Methods inherited from nltk.corpus.reader.api.CorpusReader:\n",
      "     |  \n",
      "     |  __repr__(self)\n",
      "     |      Return repr(self).\n",
      "     |  \n",
      "     |  __unicode__ = __str__(self, /)\n",
      "     |  \n",
      "     |  abspath(self, fileid)\n",
      "     |      Return the absolute path for the given file.\n",
      "     |      \n",
      "     |      :type fileid: str\n",
      "     |      :param fileid: The file identifier for the file whose path\n",
      "     |          should be returned.\n",
      "     |      :rtype: PathPointer\n",
      "     |  \n",
      "     |  abspaths(self, fileids=None, include_encoding=False, include_fileid=False)\n",
      "     |      Return a list of the absolute paths for all fileids in this corpus;\n",
      "     |      or for the given list of fileids, if specified.\n",
      "     |      \n",
      "     |      :type fileids: None or str or list\n",
      "     |      :param fileids: Specifies the set of fileids for which paths should\n",
      "     |          be returned.  Can be None, for all fileids; a list of\n",
      "     |          file identifiers, for a specified set of fileids; or a single\n",
      "     |          file identifier, for a single file.  Note that the return\n",
      "     |          value is always a list of paths, even if ``fileids`` is a\n",
      "     |          single file identifier.\n",
      "     |      \n",
      "     |      :param include_encoding: If true, then return a list of\n",
      "     |          ``(path_pointer, encoding)`` tuples.\n",
      "     |      \n",
      "     |      :rtype: list(PathPointer)\n",
      "     |  \n",
      "     |  citation(self)\n",
      "     |      Return the contents of the corpus citation.bib file, if it exists.\n",
      "     |  \n",
      "     |  encoding(self, file)\n",
      "     |      Return the unicode encoding for the given corpus file, if known.\n",
      "     |      If the encoding is unknown, or if the given file should be\n",
      "     |      processed using byte strings (str), then return None.\n",
      "     |  \n",
      "     |  ensure_loaded(self)\n",
      "     |      Load this corpus (if it has not already been loaded).  This is\n",
      "     |      used by LazyCorpusLoader as a simple method that can be used to\n",
      "     |      make sure a corpus is loaded -- e.g., in case a user wants to\n",
      "     |      do help(some_corpus).\n",
      "     |  \n",
      "     |  fileids(self)\n",
      "     |      Return a list of file identifiers for the fileids that make up\n",
      "     |      this corpus.\n",
      "     |  \n",
      "     |  license(self)\n",
      "     |      Return the contents of the corpus LICENSE file, if it exists.\n",
      "     |  \n",
      "     |  open(self, file)\n",
      "     |      Return an open stream that can be used to read the given file.\n",
      "     |      If the file's encoding is not None, then the stream will\n",
      "     |      automatically decode the file's contents into unicode.\n",
      "     |      \n",
      "     |      :param file: The file identifier of the file to read.\n",
      "     |  \n",
      "     |  readme(self)\n",
      "     |      Return the contents of the corpus README file, if it exists.\n",
      "     |  \n",
      "     |  unicode_repr = __repr__(self)\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Data descriptors inherited from nltk.corpus.reader.api.CorpusReader:\n",
      "     |  \n",
      "     |  __dict__\n",
      "     |      dictionary for instance variables (if defined)\n",
      "     |  \n",
      "     |  __weakref__\n",
      "     |      list of weak references to the object (if defined)\n",
      "     |  \n",
      "     |  root\n",
      "     |      The directory where this corpus is stored.\n",
      "     |      \n",
      "     |      :type: PathPointer\n",
      "    \n",
      "    class UnicharsCorpusReader(WordListCorpusReader)\n",
      "     |  UnicharsCorpusReader(root, fileids, encoding='utf8', tagset=None)\n",
      "     |  \n",
      "     |  This class is used to read lists of characters from the Perl Unicode\n",
      "     |  Properties (see http://perldoc.perl.org/perluniprops.html).\n",
      "     |  The files in the perluniprop.zip are extracted using the Unicode::Tussle\n",
      "     |  module from http://search.cpan.org/~bdfoy/Unicode-Tussle-1.11/lib/Unicode/Tussle.pm\n",
      "     |  \n",
      "     |  Method resolution order:\n",
      "     |      UnicharsCorpusReader\n",
      "     |      WordListCorpusReader\n",
      "     |      nltk.corpus.reader.api.CorpusReader\n",
      "     |      builtins.object\n",
      "     |  \n",
      "     |  Methods defined here:\n",
      "     |  \n",
      "     |  chars(self, category=None, fileids=None)\n",
      "     |      This module returns a list of characters from  the Perl Unicode Properties.\n",
      "     |      They are very useful when porting Perl tokenizers to Python.\n",
      "     |      \n",
      "     |      >>> from nltk.corpus import perluniprops as pup\n",
      "     |      >>> pup.chars('Open_Punctuation')[:5] == [u'(', u'[', u'{', u'༺', u'༼']\n",
      "     |      True\n",
      "     |      >>> pup.chars('Currency_Symbol')[:5] == [u'$', u'¢', u'£', u'¤', u'¥']\n",
      "     |      True\n",
      "     |      >>> pup.available_categories\n",
      "     |      ['Close_Punctuation', 'Currency_Symbol', 'IsAlnum', 'IsAlpha', 'IsLower', 'IsN', 'IsSc', 'IsSo', 'IsUpper', 'Line_Separator', 'Number', 'Open_Punctuation', 'Punctuation', 'Separator', 'Symbol']\n",
      "     |      \n",
      "     |      :return: a list of characters given the specific unicode character category\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Data and other attributes defined here:\n",
      "     |  \n",
      "     |  available_categories = ['Close_Punctuation', 'Currency_Symbol', 'IsAln...\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Methods inherited from WordListCorpusReader:\n",
      "     |  \n",
      "     |  raw(self, fileids=None)\n",
      "     |  \n",
      "     |  words(self, fileids=None, ignore_lines_startswith='\\n')\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Methods inherited from nltk.corpus.reader.api.CorpusReader:\n",
      "     |  \n",
      "     |  __init__(self, root, fileids, encoding='utf8', tagset=None)\n",
      "     |      :type root: PathPointer or str\n",
      "     |      :param root: A path pointer identifying the root directory for\n",
      "     |          this corpus.  If a string is specified, then it will be\n",
      "     |          converted to a ``PathPointer`` automatically.\n",
      "     |      :param fileids: A list of the files that make up this corpus.\n",
      "     |          This list can either be specified explicitly, as a list of\n",
      "     |          strings; or implicitly, as a regular expression over file\n",
      "     |          paths.  The absolute path for each file will be constructed\n",
      "     |          by joining the reader's root to each file name.\n",
      "     |      :param encoding: The default unicode encoding for the files\n",
      "     |          that make up the corpus.  The value of ``encoding`` can be any\n",
      "     |          of the following:\n",
      "     |          - A string: ``encoding`` is the encoding name for all files.\n",
      "     |          - A dictionary: ``encoding[file_id]`` is the encoding\n",
      "     |            name for the file whose identifier is ``file_id``.  If\n",
      "     |            ``file_id`` is not in ``encoding``, then the file\n",
      "     |            contents will be processed using non-unicode byte strings.\n",
      "     |          - A list: ``encoding`` should be a list of ``(regexp, encoding)``\n",
      "     |            tuples.  The encoding for a file whose identifier is ``file_id``\n",
      "     |            will be the ``encoding`` value for the first tuple whose\n",
      "     |            ``regexp`` matches the ``file_id``.  If no tuple's ``regexp``\n",
      "     |            matches the ``file_id``, the file contents will be processed\n",
      "     |            using non-unicode byte strings.\n",
      "     |          - None: the file contents of all files will be\n",
      "     |            processed using non-unicode byte strings.\n",
      "     |      :param tagset: The name of the tagset used by this corpus, to be used\n",
      "     |            for normalizing or converting the POS tags returned by the\n",
      "     |            tagged_...() methods.\n",
      "     |  \n",
      "     |  __repr__(self)\n",
      "     |      Return repr(self).\n",
      "     |  \n",
      "     |  __unicode__ = __str__(self, /)\n",
      "     |  \n",
      "     |  abspath(self, fileid)\n",
      "     |      Return the absolute path for the given file.\n",
      "     |      \n",
      "     |      :type fileid: str\n",
      "     |      :param fileid: The file identifier for the file whose path\n",
      "     |          should be returned.\n",
      "     |      :rtype: PathPointer\n",
      "     |  \n",
      "     |  abspaths(self, fileids=None, include_encoding=False, include_fileid=False)\n",
      "     |      Return a list of the absolute paths for all fileids in this corpus;\n",
      "     |      or for the given list of fileids, if specified.\n",
      "     |      \n",
      "     |      :type fileids: None or str or list\n",
      "     |      :param fileids: Specifies the set of fileids for which paths should\n",
      "     |          be returned.  Can be None, for all fileids; a list of\n",
      "     |          file identifiers, for a specified set of fileids; or a single\n",
      "     |          file identifier, for a single file.  Note that the return\n",
      "     |          value is always a list of paths, even if ``fileids`` is a\n",
      "     |          single file identifier.\n",
      "     |      \n",
      "     |      :param include_encoding: If true, then return a list of\n",
      "     |          ``(path_pointer, encoding)`` tuples.\n",
      "     |      \n",
      "     |      :rtype: list(PathPointer)\n",
      "     |  \n",
      "     |  citation(self)\n",
      "     |      Return the contents of the corpus citation.bib file, if it exists.\n",
      "     |  \n",
      "     |  encoding(self, file)\n",
      "     |      Return the unicode encoding for the given corpus file, if known.\n",
      "     |      If the encoding is unknown, or if the given file should be\n",
      "     |      processed using byte strings (str), then return None.\n",
      "     |  \n",
      "     |  ensure_loaded(self)\n",
      "     |      Load this corpus (if it has not already been loaded).  This is\n",
      "     |      used by LazyCorpusLoader as a simple method that can be used to\n",
      "     |      make sure a corpus is loaded -- e.g., in case a user wants to\n",
      "     |      do help(some_corpus).\n",
      "     |  \n",
      "     |  fileids(self)\n",
      "     |      Return a list of file identifiers for the fileids that make up\n",
      "     |      this corpus.\n",
      "     |  \n",
      "     |  license(self)\n",
      "     |      Return the contents of the corpus LICENSE file, if it exists.\n",
      "     |  \n",
      "     |  open(self, file)\n",
      "     |      Return an open stream that can be used to read the given file.\n",
      "     |      If the file's encoding is not None, then the stream will\n",
      "     |      automatically decode the file's contents into unicode.\n",
      "     |      \n",
      "     |      :param file: The file identifier of the file to read.\n",
      "     |  \n",
      "     |  readme(self)\n",
      "     |      Return the contents of the corpus README file, if it exists.\n",
      "     |  \n",
      "     |  unicode_repr = __repr__(self)\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Data descriptors inherited from nltk.corpus.reader.api.CorpusReader:\n",
      "     |  \n",
      "     |  __dict__\n",
      "     |      dictionary for instance variables (if defined)\n",
      "     |  \n",
      "     |  __weakref__\n",
      "     |      list of weak references to the object (if defined)\n",
      "     |  \n",
      "     |  root\n",
      "     |      The directory where this corpus is stored.\n",
      "     |      \n",
      "     |      :type: PathPointer\n",
      "    \n",
      "    class VerbnetCorpusReader(nltk.corpus.reader.xmldocs.XMLCorpusReader)\n",
      "     |  VerbnetCorpusReader(root, fileids, wrap_etree=False)\n",
      "     |  \n",
      "     |  An NLTK interface to the VerbNet verb lexicon.\n",
      "     |  \n",
      "     |  From the VerbNet site: \"VerbNet (VN) (Kipper-Schuler 2006) is the largest\n",
      "     |  on-line verb lexicon currently available for English. It is a hierarchical\n",
      "     |  domain-independent, broad-coverage verb lexicon with mappings to other\n",
      "     |  lexical resources such as WordNet (Miller, 1990; Fellbaum, 1998), XTAG\n",
      "     |  (XTAG Research Group, 2001), and FrameNet (Baker et al., 1998).\"\n",
      "     |  \n",
      "     |  For details about VerbNet see:\n",
      "     |  https://verbs.colorado.edu/~mpalmer/projects/verbnet.html\n",
      "     |  \n",
      "     |  Method resolution order:\n",
      "     |      VerbnetCorpusReader\n",
      "     |      nltk.corpus.reader.xmldocs.XMLCorpusReader\n",
      "     |      nltk.corpus.reader.api.CorpusReader\n",
      "     |      builtins.object\n",
      "     |  \n",
      "     |  Methods defined here:\n",
      "     |  \n",
      "     |  __init__(self, root, fileids, wrap_etree=False)\n",
      "     |      :type root: PathPointer or str\n",
      "     |      :param root: A path pointer identifying the root directory for\n",
      "     |          this corpus.  If a string is specified, then it will be\n",
      "     |          converted to a ``PathPointer`` automatically.\n",
      "     |      :param fileids: A list of the files that make up this corpus.\n",
      "     |          This list can either be specified explicitly, as a list of\n",
      "     |          strings; or implicitly, as a regular expression over file\n",
      "     |          paths.  The absolute path for each file will be constructed\n",
      "     |          by joining the reader's root to each file name.\n",
      "     |      :param encoding: The default unicode encoding for the files\n",
      "     |          that make up the corpus.  The value of ``encoding`` can be any\n",
      "     |          of the following:\n",
      "     |          - A string: ``encoding`` is the encoding name for all files.\n",
      "     |          - A dictionary: ``encoding[file_id]`` is the encoding\n",
      "     |            name for the file whose identifier is ``file_id``.  If\n",
      "     |            ``file_id`` is not in ``encoding``, then the file\n",
      "     |            contents will be processed using non-unicode byte strings.\n",
      "     |          - A list: ``encoding`` should be a list of ``(regexp, encoding)``\n",
      "     |            tuples.  The encoding for a file whose identifier is ``file_id``\n",
      "     |            will be the ``encoding`` value for the first tuple whose\n",
      "     |            ``regexp`` matches the ``file_id``.  If no tuple's ``regexp``\n",
      "     |            matches the ``file_id``, the file contents will be processed\n",
      "     |            using non-unicode byte strings.\n",
      "     |          - None: the file contents of all files will be\n",
      "     |            processed using non-unicode byte strings.\n",
      "     |      :param tagset: The name of the tagset used by this corpus, to be used\n",
      "     |            for normalizing or converting the POS tags returned by the\n",
      "     |            tagged_...() methods.\n",
      "     |  \n",
      "     |  classids(self, lemma=None, wordnetid=None, fileid=None, classid=None)\n",
      "     |      Return a list of the VerbNet class identifiers.  If a file\n",
      "     |      identifier is specified, then return only the VerbNet class\n",
      "     |      identifiers for classes (and subclasses) defined by that file.\n",
      "     |      If a lemma is specified, then return only VerbNet class\n",
      "     |      identifiers for classes that contain that lemma as a member.\n",
      "     |      If a wordnetid is specified, then return only identifiers for\n",
      "     |      classes that contain that wordnetid as a member.  If a classid\n",
      "     |      is specified, then return only identifiers for subclasses of\n",
      "     |      the specified VerbNet class.\n",
      "     |      If nothing is specified, return all classids within VerbNet\n",
      "     |  \n",
      "     |  fileids(self, vnclass_ids=None)\n",
      "     |      Return a list of fileids that make up this corpus.  If\n",
      "     |      ``vnclass_ids`` is specified, then return the fileids that make\n",
      "     |      up the specified VerbNet class(es).\n",
      "     |  \n",
      "     |  frames(self, vnclass)\n",
      "     |      Given a VerbNet class, this method returns VerbNet frames\n",
      "     |      \n",
      "     |      The members returned are:\n",
      "     |      1) Example\n",
      "     |      2) Description\n",
      "     |      3) Syntax\n",
      "     |      4) Semantics\n",
      "     |      \n",
      "     |      :param vnclass: A VerbNet class identifier; or an ElementTree\n",
      "     |          containing the xml contents of a VerbNet class.\n",
      "     |      :return: frames - a list of frame dictionaries\n",
      "     |  \n",
      "     |  lemmas(self, vnclass=None)\n",
      "     |      Return a list of all verb lemmas that appear in any class, or\n",
      "     |      in the ``classid`` if specified.\n",
      "     |  \n",
      "     |  longid(self, shortid)\n",
      "     |      Returns longid of a VerbNet class\n",
      "     |      \n",
      "     |      Given a short VerbNet class identifier (eg '37.10'), map it\n",
      "     |      to a long id (eg 'confess-37.10').  If ``shortid`` is already a\n",
      "     |      long id, then return it as-is\n",
      "     |  \n",
      "     |  pprint(self, vnclass)\n",
      "     |      Returns pretty printed version of a VerbNet class\n",
      "     |      \n",
      "     |      Return a string containing a pretty-printed representation of\n",
      "     |      the given VerbNet class.\n",
      "     |      \n",
      "     |      :param vnclass: A VerbNet class identifier; or an ElementTree\n",
      "     |      containing the xml contents of a VerbNet class.\n",
      "     |  \n",
      "     |  pprint_frames(self, vnclass, indent='')\n",
      "     |      Returns pretty version of all frames in a VerbNet class\n",
      "     |      \n",
      "     |      Return a string containing a pretty-printed representation of\n",
      "     |      the list of frames within the VerbNet class.\n",
      "     |      \n",
      "     |      :param vnclass: A VerbNet class identifier; or an ElementTree\n",
      "     |          containing the xml contents of a VerbNet class.\n",
      "     |  \n",
      "     |  pprint_members(self, vnclass, indent='')\n",
      "     |      Returns pretty printed version of members in a VerbNet class\n",
      "     |      \n",
      "     |      Return a string containing a pretty-printed representation of\n",
      "     |      the given VerbNet class's member verbs.\n",
      "     |      \n",
      "     |      :param vnclass: A VerbNet class identifier; or an ElementTree\n",
      "     |          containing the xml contents of a VerbNet class.\n",
      "     |  \n",
      "     |  pprint_subclasses(self, vnclass, indent='')\n",
      "     |      Returns pretty printed version of subclasses of VerbNet class\n",
      "     |      \n",
      "     |      Return a string containing a pretty-printed representation of\n",
      "     |      the given VerbNet class's subclasses.\n",
      "     |      \n",
      "     |      :param vnclass: A VerbNet class identifier; or an ElementTree\n",
      "     |          containing the xml contents of a VerbNet class.\n",
      "     |  \n",
      "     |  pprint_themroles(self, vnclass, indent='')\n",
      "     |      Returns pretty printed version of thematic roles in a VerbNet class\n",
      "     |      \n",
      "     |      Return a string containing a pretty-printed representation of\n",
      "     |      the given VerbNet class's thematic roles.\n",
      "     |      \n",
      "     |      :param vnclass: A VerbNet class identifier; or an ElementTree\n",
      "     |          containing the xml contents of a VerbNet class.\n",
      "     |  \n",
      "     |  shortid(self, longid)\n",
      "     |      Returns shortid of a VerbNet class\n",
      "     |      \n",
      "     |      Given a long VerbNet class identifier (eg 'confess-37.10'),\n",
      "     |      map it to a short id (eg '37.10').  If ``longid`` is already a\n",
      "     |      short id, then return it as-is.\n",
      "     |  \n",
      "     |  subclasses(self, vnclass)\n",
      "     |      Returns subclass ids, if any exist\n",
      "     |      \n",
      "     |      Given a VerbNet class, this method returns subclass ids (if they exist)\n",
      "     |      in a list of strings.\n",
      "     |      \n",
      "     |      :param vnclass: A VerbNet class identifier; or an ElementTree\n",
      "     |          containing the xml contents of a VerbNet class.\n",
      "     |      :return: list of subclasses\n",
      "     |  \n",
      "     |  themroles(self, vnclass)\n",
      "     |      Returns thematic roles participating in a VerbNet class\n",
      "     |      \n",
      "     |      Members returned as part of roles are-\n",
      "     |      1) Type\n",
      "     |      2) Modifiers\n",
      "     |      \n",
      "     |      :param vnclass: A VerbNet class identifier; or an ElementTree\n",
      "     |          containing the xml contents of a VerbNet class.\n",
      "     |      :return: themroles: A list of thematic roles in the VerbNet class\n",
      "     |  \n",
      "     |  vnclass(self, fileid_or_classid)\n",
      "     |      Returns VerbNet class ElementTree\n",
      "     |      \n",
      "     |      Return an ElementTree containing the xml for the specified\n",
      "     |      VerbNet class.\n",
      "     |      \n",
      "     |      :param fileid_or_classid: An identifier specifying which class\n",
      "     |          should be returned.  Can be a file identifier (such as\n",
      "     |          ``'put-9.1.xml'``), or a VerbNet class identifier (such as\n",
      "     |          ``'put-9.1'``) or a short VerbNet class identifier (such as\n",
      "     |          ``'9.1'``).\n",
      "     |  \n",
      "     |  wordnetids(self, vnclass=None)\n",
      "     |      Return a list of all wordnet identifiers that appear in any\n",
      "     |      class, or in ``classid`` if specified.\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Methods inherited from nltk.corpus.reader.xmldocs.XMLCorpusReader:\n",
      "     |  \n",
      "     |  raw(self, fileids=None)\n",
      "     |  \n",
      "     |  words(self, fileid=None)\n",
      "     |      Returns all of the words and punctuation symbols in the specified file\n",
      "     |      that were in text nodes -- ie, tags are ignored. Like the xml() method,\n",
      "     |      fileid can only specify one file.\n",
      "     |      \n",
      "     |      :return: the given file's text nodes as a list of words and punctuation symbols\n",
      "     |      :rtype: list(str)\n",
      "     |  \n",
      "     |  xml(self, fileid=None)\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Methods inherited from nltk.corpus.reader.api.CorpusReader:\n",
      "     |  \n",
      "     |  __repr__(self)\n",
      "     |      Return repr(self).\n",
      "     |  \n",
      "     |  __unicode__ = __str__(self, /)\n",
      "     |  \n",
      "     |  abspath(self, fileid)\n",
      "     |      Return the absolute path for the given file.\n",
      "     |      \n",
      "     |      :type fileid: str\n",
      "     |      :param fileid: The file identifier for the file whose path\n",
      "     |          should be returned.\n",
      "     |      :rtype: PathPointer\n",
      "     |  \n",
      "     |  abspaths(self, fileids=None, include_encoding=False, include_fileid=False)\n",
      "     |      Return a list of the absolute paths for all fileids in this corpus;\n",
      "     |      or for the given list of fileids, if specified.\n",
      "     |      \n",
      "     |      :type fileids: None or str or list\n",
      "     |      :param fileids: Specifies the set of fileids for which paths should\n",
      "     |          be returned.  Can be None, for all fileids; a list of\n",
      "     |          file identifiers, for a specified set of fileids; or a single\n",
      "     |          file identifier, for a single file.  Note that the return\n",
      "     |          value is always a list of paths, even if ``fileids`` is a\n",
      "     |          single file identifier.\n",
      "     |      \n",
      "     |      :param include_encoding: If true, then return a list of\n",
      "     |          ``(path_pointer, encoding)`` tuples.\n",
      "     |      \n",
      "     |      :rtype: list(PathPointer)\n",
      "     |  \n",
      "     |  citation(self)\n",
      "     |      Return the contents of the corpus citation.bib file, if it exists.\n",
      "     |  \n",
      "     |  encoding(self, file)\n",
      "     |      Return the unicode encoding for the given corpus file, if known.\n",
      "     |      If the encoding is unknown, or if the given file should be\n",
      "     |      processed using byte strings (str), then return None.\n",
      "     |  \n",
      "     |  ensure_loaded(self)\n",
      "     |      Load this corpus (if it has not already been loaded).  This is\n",
      "     |      used by LazyCorpusLoader as a simple method that can be used to\n",
      "     |      make sure a corpus is loaded -- e.g., in case a user wants to\n",
      "     |      do help(some_corpus).\n",
      "     |  \n",
      "     |  license(self)\n",
      "     |      Return the contents of the corpus LICENSE file, if it exists.\n",
      "     |  \n",
      "     |  open(self, file)\n",
      "     |      Return an open stream that can be used to read the given file.\n",
      "     |      If the file's encoding is not None, then the stream will\n",
      "     |      automatically decode the file's contents into unicode.\n",
      "     |      \n",
      "     |      :param file: The file identifier of the file to read.\n",
      "     |  \n",
      "     |  readme(self)\n",
      "     |      Return the contents of the corpus README file, if it exists.\n",
      "     |  \n",
      "     |  unicode_repr = __repr__(self)\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Data descriptors inherited from nltk.corpus.reader.api.CorpusReader:\n",
      "     |  \n",
      "     |  __dict__\n",
      "     |      dictionary for instance variables (if defined)\n",
      "     |  \n",
      "     |  __weakref__\n",
      "     |      list of weak references to the object (if defined)\n",
      "     |  \n",
      "     |  root\n",
      "     |      The directory where this corpus is stored.\n",
      "     |      \n",
      "     |      :type: PathPointer\n",
      "    \n",
      "    class WordListCorpusReader(nltk.corpus.reader.api.CorpusReader)\n",
      "     |  WordListCorpusReader(root, fileids, encoding='utf8', tagset=None)\n",
      "     |  \n",
      "     |  List of words, one per line.  Blank lines are ignored.\n",
      "     |  \n",
      "     |  Method resolution order:\n",
      "     |      WordListCorpusReader\n",
      "     |      nltk.corpus.reader.api.CorpusReader\n",
      "     |      builtins.object\n",
      "     |  \n",
      "     |  Methods defined here:\n",
      "     |  \n",
      "     |  raw(self, fileids=None)\n",
      "     |  \n",
      "     |  words(self, fileids=None, ignore_lines_startswith='\\n')\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Methods inherited from nltk.corpus.reader.api.CorpusReader:\n",
      "     |  \n",
      "     |  __init__(self, root, fileids, encoding='utf8', tagset=None)\n",
      "     |      :type root: PathPointer or str\n",
      "     |      :param root: A path pointer identifying the root directory for\n",
      "     |          this corpus.  If a string is specified, then it will be\n",
      "     |          converted to a ``PathPointer`` automatically.\n",
      "     |      :param fileids: A list of the files that make up this corpus.\n",
      "     |          This list can either be specified explicitly, as a list of\n",
      "     |          strings; or implicitly, as a regular expression over file\n",
      "     |          paths.  The absolute path for each file will be constructed\n",
      "     |          by joining the reader's root to each file name.\n",
      "     |      :param encoding: The default unicode encoding for the files\n",
      "     |          that make up the corpus.  The value of ``encoding`` can be any\n",
      "     |          of the following:\n",
      "     |          - A string: ``encoding`` is the encoding name for all files.\n",
      "     |          - A dictionary: ``encoding[file_id]`` is the encoding\n",
      "     |            name for the file whose identifier is ``file_id``.  If\n",
      "     |            ``file_id`` is not in ``encoding``, then the file\n",
      "     |            contents will be processed using non-unicode byte strings.\n",
      "     |          - A list: ``encoding`` should be a list of ``(regexp, encoding)``\n",
      "     |            tuples.  The encoding for a file whose identifier is ``file_id``\n",
      "     |            will be the ``encoding`` value for the first tuple whose\n",
      "     |            ``regexp`` matches the ``file_id``.  If no tuple's ``regexp``\n",
      "     |            matches the ``file_id``, the file contents will be processed\n",
      "     |            using non-unicode byte strings.\n",
      "     |          - None: the file contents of all files will be\n",
      "     |            processed using non-unicode byte strings.\n",
      "     |      :param tagset: The name of the tagset used by this corpus, to be used\n",
      "     |            for normalizing or converting the POS tags returned by the\n",
      "     |            tagged_...() methods.\n",
      "     |  \n",
      "     |  __repr__(self)\n",
      "     |      Return repr(self).\n",
      "     |  \n",
      "     |  __unicode__ = __str__(self, /)\n",
      "     |  \n",
      "     |  abspath(self, fileid)\n",
      "     |      Return the absolute path for the given file.\n",
      "     |      \n",
      "     |      :type fileid: str\n",
      "     |      :param fileid: The file identifier for the file whose path\n",
      "     |          should be returned.\n",
      "     |      :rtype: PathPointer\n",
      "     |  \n",
      "     |  abspaths(self, fileids=None, include_encoding=False, include_fileid=False)\n",
      "     |      Return a list of the absolute paths for all fileids in this corpus;\n",
      "     |      or for the given list of fileids, if specified.\n",
      "     |      \n",
      "     |      :type fileids: None or str or list\n",
      "     |      :param fileids: Specifies the set of fileids for which paths should\n",
      "     |          be returned.  Can be None, for all fileids; a list of\n",
      "     |          file identifiers, for a specified set of fileids; or a single\n",
      "     |          file identifier, for a single file.  Note that the return\n",
      "     |          value is always a list of paths, even if ``fileids`` is a\n",
      "     |          single file identifier.\n",
      "     |      \n",
      "     |      :param include_encoding: If true, then return a list of\n",
      "     |          ``(path_pointer, encoding)`` tuples.\n",
      "     |      \n",
      "     |      :rtype: list(PathPointer)\n",
      "     |  \n",
      "     |  citation(self)\n",
      "     |      Return the contents of the corpus citation.bib file, if it exists.\n",
      "     |  \n",
      "     |  encoding(self, file)\n",
      "     |      Return the unicode encoding for the given corpus file, if known.\n",
      "     |      If the encoding is unknown, or if the given file should be\n",
      "     |      processed using byte strings (str), then return None.\n",
      "     |  \n",
      "     |  ensure_loaded(self)\n",
      "     |      Load this corpus (if it has not already been loaded).  This is\n",
      "     |      used by LazyCorpusLoader as a simple method that can be used to\n",
      "     |      make sure a corpus is loaded -- e.g., in case a user wants to\n",
      "     |      do help(some_corpus).\n",
      "     |  \n",
      "     |  fileids(self)\n",
      "     |      Return a list of file identifiers for the fileids that make up\n",
      "     |      this corpus.\n",
      "     |  \n",
      "     |  license(self)\n",
      "     |      Return the contents of the corpus LICENSE file, if it exists.\n",
      "     |  \n",
      "     |  open(self, file)\n",
      "     |      Return an open stream that can be used to read the given file.\n",
      "     |      If the file's encoding is not None, then the stream will\n",
      "     |      automatically decode the file's contents into unicode.\n",
      "     |      \n",
      "     |      :param file: The file identifier of the file to read.\n",
      "     |  \n",
      "     |  readme(self)\n",
      "     |      Return the contents of the corpus README file, if it exists.\n",
      "     |  \n",
      "     |  unicode_repr = __repr__(self)\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Data descriptors inherited from nltk.corpus.reader.api.CorpusReader:\n",
      "     |  \n",
      "     |  __dict__\n",
      "     |      dictionary for instance variables (if defined)\n",
      "     |  \n",
      "     |  __weakref__\n",
      "     |      list of weak references to the object (if defined)\n",
      "     |  \n",
      "     |  root\n",
      "     |      The directory where this corpus is stored.\n",
      "     |      \n",
      "     |      :type: PathPointer\n",
      "    \n",
      "    class WordNetCorpusReader(nltk.corpus.reader.api.CorpusReader)\n",
      "     |  WordNetCorpusReader(root, omw_reader)\n",
      "     |  \n",
      "     |  A corpus reader used to access wordnet or its variants.\n",
      "     |  \n",
      "     |  Method resolution order:\n",
      "     |      WordNetCorpusReader\n",
      "     |      nltk.corpus.reader.api.CorpusReader\n",
      "     |      builtins.object\n",
      "     |  \n",
      "     |  Methods defined here:\n",
      "     |  \n",
      "     |  __init__(self, root, omw_reader)\n",
      "     |      Construct a new wordnet corpus reader, with the given root\n",
      "     |      directory.\n",
      "     |  \n",
      "     |  all_lemma_names(self, pos=None, lang='eng')\n",
      "     |      Return all lemma names for all synsets for the given\n",
      "     |      part of speech tag and language or languages. If pos is\n",
      "     |      not specified, all synsets for all parts of speech will\n",
      "     |      be used.\n",
      "     |  \n",
      "     |  all_synsets(self, pos=None)\n",
      "     |      Iterate over all synsets with a given part of speech tag.\n",
      "     |      If no pos is specified, all synsets for all parts of speech\n",
      "     |      will be loaded.\n",
      "     |  \n",
      "     |  citation(self, lang='omw')\n",
      "     |      Return the contents of citation.bib file (for omw)\n",
      "     |      use lang=lang to get the citation for an individual language\n",
      "     |  \n",
      "     |  custom_lemmas(self, tab_file, lang)\n",
      "     |      Reads a custom tab file containing mappings of lemmas in the given\n",
      "     |      language to Princeton WordNet 3.0 synset offsets, allowing NLTK's\n",
      "     |      WordNet functions to then be used with that language.\n",
      "     |      \n",
      "     |      See the \"Tab files\" section at http://compling.hss.ntu.edu.sg/omw/ for\n",
      "     |      documentation on the Multilingual WordNet tab file format.\n",
      "     |      \n",
      "     |      :param tab_file: Tab file as a file or file-like object\n",
      "     |      :type  lang str\n",
      "     |      :param lang ISO 639-3 code of the language of the tab file\n",
      "     |  \n",
      "     |  get_version(self)\n",
      "     |  \n",
      "     |  ic(self, corpus, weight_senses_equally=False, smoothing=1.0)\n",
      "     |      Creates an information content lookup dictionary from a corpus.\n",
      "     |      \n",
      "     |      :type corpus: CorpusReader\n",
      "     |      :param corpus: The corpus from which we create an information\n",
      "     |      content dictionary.\n",
      "     |      :type weight_senses_equally: bool\n",
      "     |      :param weight_senses_equally: If this is True, gives all\n",
      "     |      possible senses equal weight rather than dividing by the\n",
      "     |      number of possible senses.  (If a word has 3 synses, each\n",
      "     |      sense gets 0.3333 per appearance when this is False, 1.0 when\n",
      "     |      it is true.)\n",
      "     |      :param smoothing: How much do we smooth synset counts (default is 1.0)\n",
      "     |      :type smoothing: float\n",
      "     |      :return: An information content dictionary\n",
      "     |  \n",
      "     |  jcn_similarity(self, synset1, synset2, ic, verbose=False)\n",
      "     |      Jiang-Conrath Similarity:\n",
      "     |      Return a score denoting how similar two word senses are, based on the\n",
      "     |      Information Content (IC) of the Least Common Subsumer (most specific\n",
      "     |      ancestor node) and that of the two input Synsets. The relationship is\n",
      "     |      given by the equation 1 / (IC(s1) + IC(s2) - 2 * IC(lcs)).\n",
      "     |      \n",
      "     |      :type  other: Synset\n",
      "     |      :param other: The ``Synset`` that this ``Synset`` is being compared to.\n",
      "     |      :type  ic: dict\n",
      "     |      :param ic: an information content object (as returned by\n",
      "     |          ``nltk.corpus.wordnet_ic.ic()``).\n",
      "     |      :return: A float score denoting the similarity of the two ``Synset``\n",
      "     |          objects.\n",
      "     |  \n",
      "     |  langs(self)\n",
      "     |      return a list of languages supported by Multilingual Wordnet\n",
      "     |  \n",
      "     |  lch_similarity(self, synset1, synset2, verbose=False, simulate_root=True)\n",
      "     |      Leacock Chodorow Similarity:\n",
      "     |      Return a score denoting how similar two word senses are, based on the\n",
      "     |      shortest path that connects the senses (as above) and the maximum depth\n",
      "     |      of the taxonomy in which the senses occur. The relationship is given as\n",
      "     |      -log(p/2d) where p is the shortest path length and d is the taxonomy\n",
      "     |      depth.\n",
      "     |      \n",
      "     |      :type  other: Synset\n",
      "     |      :param other: The ``Synset`` that this ``Synset`` is being compared to.\n",
      "     |      :type simulate_root: bool\n",
      "     |      :param simulate_root: The various verb taxonomies do not\n",
      "     |          share a single root which disallows this metric from working for\n",
      "     |          synsets that are not connected. This flag (True by default)\n",
      "     |          creates a fake root that connects all the taxonomies. Set it\n",
      "     |          to false to disable this behavior. For the noun taxonomy,\n",
      "     |          there is usually a default root except for WordNet version 1.6.\n",
      "     |          If you are using wordnet 1.6, a fake root will be added for nouns\n",
      "     |          as well.\n",
      "     |      :return: A score denoting the similarity of the two ``Synset`` objects,\n",
      "     |          normally greater than 0. None is returned if no connecting path\n",
      "     |          could be found. If a ``Synset`` is compared with itself, the\n",
      "     |          maximum score is returned, which varies depending on the taxonomy\n",
      "     |          depth.\n",
      "     |  \n",
      "     |  lemma(self, name, lang='eng')\n",
      "     |      Return lemma object that matches the name\n",
      "     |  \n",
      "     |  lemma_count(self, lemma)\n",
      "     |      Return the frequency count for this Lemma\n",
      "     |  \n",
      "     |  lemma_from_key(self, key)\n",
      "     |  \n",
      "     |  lemmas(self, lemma, pos=None, lang='eng')\n",
      "     |      Return all Lemma objects with a name matching the specified lemma\n",
      "     |      name and part of speech tag. Matches any part of speech tag if none is\n",
      "     |      specified.\n",
      "     |  \n",
      "     |  license(self, lang='eng')\n",
      "     |      Return the contents of LICENSE (for omw)\n",
      "     |      use lang=lang to get the license for an individual language\n",
      "     |  \n",
      "     |  lin_similarity(self, synset1, synset2, ic, verbose=False)\n",
      "     |      Lin Similarity:\n",
      "     |      Return a score denoting how similar two word senses are, based on the\n",
      "     |      Information Content (IC) of the Least Common Subsumer (most specific\n",
      "     |      ancestor node) and that of the two input Synsets. The relationship is\n",
      "     |      given by the equation 2 * IC(lcs) / (IC(s1) + IC(s2)).\n",
      "     |      \n",
      "     |      :type other: Synset\n",
      "     |      :param other: The ``Synset`` that this ``Synset`` is being compared to.\n",
      "     |      :type ic: dict\n",
      "     |      :param ic: an information content object (as returned by\n",
      "     |          ``nltk.corpus.wordnet_ic.ic()``).\n",
      "     |      :return: A float score denoting the similarity of the two ``Synset``\n",
      "     |          objects, in the range 0 to 1.\n",
      "     |  \n",
      "     |  morphy(self, form, pos=None, check_exceptions=True)\n",
      "     |      Find a possible base form for the given form, with the given\n",
      "     |      part of speech, by checking WordNet's list of exceptional\n",
      "     |      forms, and by recursively stripping affixes for this part of\n",
      "     |      speech until a form in WordNet is found.\n",
      "     |      \n",
      "     |      >>> from nltk.corpus import wordnet as wn\n",
      "     |      >>> print(wn.morphy('dogs'))\n",
      "     |      dog\n",
      "     |      >>> print(wn.morphy('churches'))\n",
      "     |      church\n",
      "     |      >>> print(wn.morphy('aardwolves'))\n",
      "     |      aardwolf\n",
      "     |      >>> print(wn.morphy('abaci'))\n",
      "     |      abacus\n",
      "     |      >>> wn.morphy('hardrock', wn.ADV)\n",
      "     |      >>> print(wn.morphy('book', wn.NOUN))\n",
      "     |      book\n",
      "     |      >>> wn.morphy('book', wn.ADJ)\n",
      "     |  \n",
      "     |  of2ss(self, of)\n",
      "     |      take an id and return the synsets\n",
      "     |  \n",
      "     |  path_similarity(self, synset1, synset2, verbose=False, simulate_root=True)\n",
      "     |      Path Distance Similarity:\n",
      "     |      Return a score denoting how similar two word senses are, based on the\n",
      "     |      shortest path that connects the senses in the is-a (hypernym/hypnoym)\n",
      "     |      taxonomy. The score is in the range 0 to 1, except in those cases where\n",
      "     |      a path cannot be found (will only be true for verbs as there are many\n",
      "     |      distinct verb taxonomies), in which case None is returned. A score of\n",
      "     |      1 represents identity i.e. comparing a sense with itself will return 1.\n",
      "     |      \n",
      "     |      :type other: Synset\n",
      "     |      :param other: The ``Synset`` that this ``Synset`` is being compared to.\n",
      "     |      :type simulate_root: bool\n",
      "     |      :param simulate_root: The various verb taxonomies do not\n",
      "     |          share a single root which disallows this metric from working for\n",
      "     |          synsets that are not connected. This flag (True by default)\n",
      "     |          creates a fake root that connects all the taxonomies. Set it\n",
      "     |          to false to disable this behavior. For the noun taxonomy,\n",
      "     |          there is usually a default root except for WordNet version 1.6.\n",
      "     |          If you are using wordnet 1.6, a fake root will be added for nouns\n",
      "     |          as well.\n",
      "     |      :return: A score denoting the similarity of the two ``Synset`` objects,\n",
      "     |          normally between 0 and 1. None is returned if no connecting path\n",
      "     |          could be found. 1 is returned if a ``Synset`` is compared with\n",
      "     |          itself.\n",
      "     |  \n",
      "     |  readme(self, lang='omw')\n",
      "     |      Return the contents of README (for omw)\n",
      "     |      use lang=lang to get the readme for an individual language\n",
      "     |  \n",
      "     |  res_similarity(self, synset1, synset2, ic, verbose=False)\n",
      "     |      Resnik Similarity:\n",
      "     |      Return a score denoting how similar two word senses are, based on the\n",
      "     |      Information Content (IC) of the Least Common Subsumer (most specific\n",
      "     |      ancestor node).\n",
      "     |      \n",
      "     |      :type  other: Synset\n",
      "     |      :param other: The ``Synset`` that this ``Synset`` is being compared to.\n",
      "     |      :type ic: dict\n",
      "     |      :param ic: an information content object (as returned by\n",
      "     |          ``nltk.corpus.wordnet_ic.ic()``).\n",
      "     |      :return: A float score denoting the similarity of the two ``Synset``\n",
      "     |          objects. Synsets whose LCS is the root node of the taxonomy will\n",
      "     |          have a score of 0 (e.g. N['dog'][0] and N['table'][0]).\n",
      "     |  \n",
      "     |  ss2of(self, ss, lang=None)\n",
      "     |      return the ID of the synset\n",
      "     |  \n",
      "     |  synset(self, name)\n",
      "     |      #############################################################\n",
      "     |      # Loading Synsets\n",
      "     |      #############################################################\n",
      "     |  \n",
      "     |  synset_from_pos_and_offset(self, pos, offset)\n",
      "     |  \n",
      "     |  synset_from_sense_key(self, sense_key)\n",
      "     |      Retrieves synset based on a given sense_key. Sense keys can be\n",
      "     |      obtained from lemma.key()\n",
      "     |      \n",
      "     |      From https://wordnet.princeton.edu/documentation/senseidx5wn:\n",
      "     |      A sense_key is represented as:\n",
      "     |          lemma % lex_sense (e.g. 'dog%1:18:01::')\n",
      "     |      where lex_sense is encoded as:\n",
      "     |          ss_type:lex_filenum:lex_id:head_word:head_id\n",
      "     |      \n",
      "     |      lemma:       ASCII text of word/collocation, in lower case\n",
      "     |      ss_type:     synset type for the sense (1 digit int)\n",
      "     |                   The synset type is encoded as follows:\n",
      "     |                   1    NOUN\n",
      "     |                   2    VERB\n",
      "     |                   3    ADJECTIVE\n",
      "     |                   4    ADVERB\n",
      "     |                   5    ADJECTIVE SATELLITE\n",
      "     |      lex_filenum: name of lexicographer file containing the synset for the sense (2 digit int)\n",
      "     |      lex_id:      when paired with lemma, uniquely identifies a sense in the lexicographer file (2 digit int)\n",
      "     |      head_word:   lemma of the first word in satellite's head synset\n",
      "     |                   Only used if sense is in an adjective satellite synset\n",
      "     |      head_id:     uniquely identifies sense in a lexicographer file when paired with head_word\n",
      "     |                   Only used if head_word is present (2 digit int)\n",
      "     |  \n",
      "     |  synsets(self, lemma, pos=None, lang='eng', check_exceptions=True)\n",
      "     |      Load all synsets with a given lemma and part of speech tag.\n",
      "     |      If no pos is specified, all synsets for all parts of speech\n",
      "     |      will be loaded.\n",
      "     |      If lang is specified, all the synsets associated with the lemma name\n",
      "     |      of that language will be returned.\n",
      "     |  \n",
      "     |  words(self, lang='eng')\n",
      "     |      return lemmas of the given language as list of words\n",
      "     |  \n",
      "     |  wup_similarity(self, synset1, synset2, verbose=False, simulate_root=True)\n",
      "     |      Wu-Palmer Similarity:\n",
      "     |      Return a score denoting how similar two word senses are, based on the\n",
      "     |      depth of the two senses in the taxonomy and that of their Least Common\n",
      "     |      Subsumer (most specific ancestor node). Previously, the scores computed\n",
      "     |      by this implementation did _not_ always agree with those given by\n",
      "     |      Pedersen's Perl implementation of WordNet Similarity. However, with\n",
      "     |      the addition of the simulate_root flag (see below), the score for\n",
      "     |      verbs now almost always agree but not always for nouns.\n",
      "     |      \n",
      "     |      The LCS does not necessarily feature in the shortest path connecting\n",
      "     |      the two senses, as it is by definition the common ancestor deepest in\n",
      "     |      the taxonomy, not closest to the two senses. Typically, however, it\n",
      "     |      will so feature. Where multiple candidates for the LCS exist, that\n",
      "     |      whose shortest path to the root node is the longest will be selected.\n",
      "     |      Where the LCS has multiple paths to the root, the longer path is used\n",
      "     |      for the purposes of the calculation.\n",
      "     |      \n",
      "     |      :type  other: Synset\n",
      "     |      :param other: The ``Synset`` that this ``Synset`` is being compared to.\n",
      "     |      :type simulate_root: bool\n",
      "     |      :param simulate_root: The various verb taxonomies do not\n",
      "     |          share a single root which disallows this metric from working for\n",
      "     |          synsets that are not connected. This flag (True by default)\n",
      "     |          creates a fake root that connects all the taxonomies. Set it\n",
      "     |          to false to disable this behavior. For the noun taxonomy,\n",
      "     |          there is usually a default root except for WordNet version 1.6.\n",
      "     |          If you are using wordnet 1.6, a fake root will be added for nouns\n",
      "     |          as well.\n",
      "     |      :return: A float score denoting the similarity of the two ``Synset``\n",
      "     |          objects, normally greater than zero. If no connecting path between\n",
      "     |          the two senses can be found, None is returned.\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Data and other attributes defined here:\n",
      "     |  \n",
      "     |  ADJ = 'a'\n",
      "     |  \n",
      "     |  ADJ_SAT = 's'\n",
      "     |  \n",
      "     |  ADV = 'r'\n",
      "     |  \n",
      "     |  MORPHOLOGICAL_SUBSTITUTIONS = {'a': [('er', ''), ('est', ''), ('er', '...\n",
      "     |  \n",
      "     |  NOUN = 'n'\n",
      "     |  \n",
      "     |  VERB = 'v'\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Methods inherited from nltk.corpus.reader.api.CorpusReader:\n",
      "     |  \n",
      "     |  __repr__(self)\n",
      "     |      Return repr(self).\n",
      "     |  \n",
      "     |  __unicode__ = __str__(self, /)\n",
      "     |  \n",
      "     |  abspath(self, fileid)\n",
      "     |      Return the absolute path for the given file.\n",
      "     |      \n",
      "     |      :type fileid: str\n",
      "     |      :param fileid: The file identifier for the file whose path\n",
      "     |          should be returned.\n",
      "     |      :rtype: PathPointer\n",
      "     |  \n",
      "     |  abspaths(self, fileids=None, include_encoding=False, include_fileid=False)\n",
      "     |      Return a list of the absolute paths for all fileids in this corpus;\n",
      "     |      or for the given list of fileids, if specified.\n",
      "     |      \n",
      "     |      :type fileids: None or str or list\n",
      "     |      :param fileids: Specifies the set of fileids for which paths should\n",
      "     |          be returned.  Can be None, for all fileids; a list of\n",
      "     |          file identifiers, for a specified set of fileids; or a single\n",
      "     |          file identifier, for a single file.  Note that the return\n",
      "     |          value is always a list of paths, even if ``fileids`` is a\n",
      "     |          single file identifier.\n",
      "     |      \n",
      "     |      :param include_encoding: If true, then return a list of\n",
      "     |          ``(path_pointer, encoding)`` tuples.\n",
      "     |      \n",
      "     |      :rtype: list(PathPointer)\n",
      "     |  \n",
      "     |  encoding(self, file)\n",
      "     |      Return the unicode encoding for the given corpus file, if known.\n",
      "     |      If the encoding is unknown, or if the given file should be\n",
      "     |      processed using byte strings (str), then return None.\n",
      "     |  \n",
      "     |  ensure_loaded(self)\n",
      "     |      Load this corpus (if it has not already been loaded).  This is\n",
      "     |      used by LazyCorpusLoader as a simple method that can be used to\n",
      "     |      make sure a corpus is loaded -- e.g., in case a user wants to\n",
      "     |      do help(some_corpus).\n",
      "     |  \n",
      "     |  fileids(self)\n",
      "     |      Return a list of file identifiers for the fileids that make up\n",
      "     |      this corpus.\n",
      "     |  \n",
      "     |  open(self, file)\n",
      "     |      Return an open stream that can be used to read the given file.\n",
      "     |      If the file's encoding is not None, then the stream will\n",
      "     |      automatically decode the file's contents into unicode.\n",
      "     |      \n",
      "     |      :param file: The file identifier of the file to read.\n",
      "     |  \n",
      "     |  unicode_repr = __repr__(self)\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Data descriptors inherited from nltk.corpus.reader.api.CorpusReader:\n",
      "     |  \n",
      "     |  __dict__\n",
      "     |      dictionary for instance variables (if defined)\n",
      "     |  \n",
      "     |  __weakref__\n",
      "     |      list of weak references to the object (if defined)\n",
      "     |  \n",
      "     |  root\n",
      "     |      The directory where this corpus is stored.\n",
      "     |      \n",
      "     |      :type: PathPointer\n",
      "    \n",
      "    class WordNetICCorpusReader(nltk.corpus.reader.api.CorpusReader)\n",
      "     |  WordNetICCorpusReader(root, fileids)\n",
      "     |  \n",
      "     |  A corpus reader for the WordNet information content corpus.\n",
      "     |  \n",
      "     |  Method resolution order:\n",
      "     |      WordNetICCorpusReader\n",
      "     |      nltk.corpus.reader.api.CorpusReader\n",
      "     |      builtins.object\n",
      "     |  \n",
      "     |  Methods defined here:\n",
      "     |  \n",
      "     |  __init__(self, root, fileids)\n",
      "     |      :type root: PathPointer or str\n",
      "     |      :param root: A path pointer identifying the root directory for\n",
      "     |          this corpus.  If a string is specified, then it will be\n",
      "     |          converted to a ``PathPointer`` automatically.\n",
      "     |      :param fileids: A list of the files that make up this corpus.\n",
      "     |          This list can either be specified explicitly, as a list of\n",
      "     |          strings; or implicitly, as a regular expression over file\n",
      "     |          paths.  The absolute path for each file will be constructed\n",
      "     |          by joining the reader's root to each file name.\n",
      "     |      :param encoding: The default unicode encoding for the files\n",
      "     |          that make up the corpus.  The value of ``encoding`` can be any\n",
      "     |          of the following:\n",
      "     |          - A string: ``encoding`` is the encoding name for all files.\n",
      "     |          - A dictionary: ``encoding[file_id]`` is the encoding\n",
      "     |            name for the file whose identifier is ``file_id``.  If\n",
      "     |            ``file_id`` is not in ``encoding``, then the file\n",
      "     |            contents will be processed using non-unicode byte strings.\n",
      "     |          - A list: ``encoding`` should be a list of ``(regexp, encoding)``\n",
      "     |            tuples.  The encoding for a file whose identifier is ``file_id``\n",
      "     |            will be the ``encoding`` value for the first tuple whose\n",
      "     |            ``regexp`` matches the ``file_id``.  If no tuple's ``regexp``\n",
      "     |            matches the ``file_id``, the file contents will be processed\n",
      "     |            using non-unicode byte strings.\n",
      "     |          - None: the file contents of all files will be\n",
      "     |            processed using non-unicode byte strings.\n",
      "     |      :param tagset: The name of the tagset used by this corpus, to be used\n",
      "     |            for normalizing or converting the POS tags returned by the\n",
      "     |            tagged_...() methods.\n",
      "     |  \n",
      "     |  ic(self, icfile)\n",
      "     |      Load an information content file from the wordnet_ic corpus\n",
      "     |      and return a dictionary.  This dictionary has just two keys,\n",
      "     |      NOUN and VERB, whose values are dictionaries that map from\n",
      "     |      synsets to information content values.\n",
      "     |      \n",
      "     |      :type icfile: str\n",
      "     |      :param icfile: The name of the wordnet_ic file (e.g. \"ic-brown.dat\")\n",
      "     |      :return: An information content dictionary\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Methods inherited from nltk.corpus.reader.api.CorpusReader:\n",
      "     |  \n",
      "     |  __repr__(self)\n",
      "     |      Return repr(self).\n",
      "     |  \n",
      "     |  __unicode__ = __str__(self, /)\n",
      "     |  \n",
      "     |  abspath(self, fileid)\n",
      "     |      Return the absolute path for the given file.\n",
      "     |      \n",
      "     |      :type fileid: str\n",
      "     |      :param fileid: The file identifier for the file whose path\n",
      "     |          should be returned.\n",
      "     |      :rtype: PathPointer\n",
      "     |  \n",
      "     |  abspaths(self, fileids=None, include_encoding=False, include_fileid=False)\n",
      "     |      Return a list of the absolute paths for all fileids in this corpus;\n",
      "     |      or for the given list of fileids, if specified.\n",
      "     |      \n",
      "     |      :type fileids: None or str or list\n",
      "     |      :param fileids: Specifies the set of fileids for which paths should\n",
      "     |          be returned.  Can be None, for all fileids; a list of\n",
      "     |          file identifiers, for a specified set of fileids; or a single\n",
      "     |          file identifier, for a single file.  Note that the return\n",
      "     |          value is always a list of paths, even if ``fileids`` is a\n",
      "     |          single file identifier.\n",
      "     |      \n",
      "     |      :param include_encoding: If true, then return a list of\n",
      "     |          ``(path_pointer, encoding)`` tuples.\n",
      "     |      \n",
      "     |      :rtype: list(PathPointer)\n",
      "     |  \n",
      "     |  citation(self)\n",
      "     |      Return the contents of the corpus citation.bib file, if it exists.\n",
      "     |  \n",
      "     |  encoding(self, file)\n",
      "     |      Return the unicode encoding for the given corpus file, if known.\n",
      "     |      If the encoding is unknown, or if the given file should be\n",
      "     |      processed using byte strings (str), then return None.\n",
      "     |  \n",
      "     |  ensure_loaded(self)\n",
      "     |      Load this corpus (if it has not already been loaded).  This is\n",
      "     |      used by LazyCorpusLoader as a simple method that can be used to\n",
      "     |      make sure a corpus is loaded -- e.g., in case a user wants to\n",
      "     |      do help(some_corpus).\n",
      "     |  \n",
      "     |  fileids(self)\n",
      "     |      Return a list of file identifiers for the fileids that make up\n",
      "     |      this corpus.\n",
      "     |  \n",
      "     |  license(self)\n",
      "     |      Return the contents of the corpus LICENSE file, if it exists.\n",
      "     |  \n",
      "     |  open(self, file)\n",
      "     |      Return an open stream that can be used to read the given file.\n",
      "     |      If the file's encoding is not None, then the stream will\n",
      "     |      automatically decode the file's contents into unicode.\n",
      "     |      \n",
      "     |      :param file: The file identifier of the file to read.\n",
      "     |  \n",
      "     |  readme(self)\n",
      "     |      Return the contents of the corpus README file, if it exists.\n",
      "     |  \n",
      "     |  unicode_repr = __repr__(self)\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Data descriptors inherited from nltk.corpus.reader.api.CorpusReader:\n",
      "     |  \n",
      "     |  __dict__\n",
      "     |      dictionary for instance variables (if defined)\n",
      "     |  \n",
      "     |  __weakref__\n",
      "     |      list of weak references to the object (if defined)\n",
      "     |  \n",
      "     |  root\n",
      "     |      The directory where this corpus is stored.\n",
      "     |      \n",
      "     |      :type: PathPointer\n",
      "    \n",
      "    class XMLCorpusReader(nltk.corpus.reader.api.CorpusReader)\n",
      "     |  XMLCorpusReader(root, fileids, wrap_etree=False)\n",
      "     |  \n",
      "     |  Corpus reader for corpora whose documents are xml files.\n",
      "     |  \n",
      "     |  Note that the ``XMLCorpusReader`` constructor does not take an\n",
      "     |  ``encoding`` argument, because the unicode encoding is specified by\n",
      "     |  the XML files themselves.  See the XML specs for more info.\n",
      "     |  \n",
      "     |  Method resolution order:\n",
      "     |      XMLCorpusReader\n",
      "     |      nltk.corpus.reader.api.CorpusReader\n",
      "     |      builtins.object\n",
      "     |  \n",
      "     |  Methods defined here:\n",
      "     |  \n",
      "     |  __init__(self, root, fileids, wrap_etree=False)\n",
      "     |      :type root: PathPointer or str\n",
      "     |      :param root: A path pointer identifying the root directory for\n",
      "     |          this corpus.  If a string is specified, then it will be\n",
      "     |          converted to a ``PathPointer`` automatically.\n",
      "     |      :param fileids: A list of the files that make up this corpus.\n",
      "     |          This list can either be specified explicitly, as a list of\n",
      "     |          strings; or implicitly, as a regular expression over file\n",
      "     |          paths.  The absolute path for each file will be constructed\n",
      "     |          by joining the reader's root to each file name.\n",
      "     |      :param encoding: The default unicode encoding for the files\n",
      "     |          that make up the corpus.  The value of ``encoding`` can be any\n",
      "     |          of the following:\n",
      "     |          - A string: ``encoding`` is the encoding name for all files.\n",
      "     |          - A dictionary: ``encoding[file_id]`` is the encoding\n",
      "     |            name for the file whose identifier is ``file_id``.  If\n",
      "     |            ``file_id`` is not in ``encoding``, then the file\n",
      "     |            contents will be processed using non-unicode byte strings.\n",
      "     |          - A list: ``encoding`` should be a list of ``(regexp, encoding)``\n",
      "     |            tuples.  The encoding for a file whose identifier is ``file_id``\n",
      "     |            will be the ``encoding`` value for the first tuple whose\n",
      "     |            ``regexp`` matches the ``file_id``.  If no tuple's ``regexp``\n",
      "     |            matches the ``file_id``, the file contents will be processed\n",
      "     |            using non-unicode byte strings.\n",
      "     |          - None: the file contents of all files will be\n",
      "     |            processed using non-unicode byte strings.\n",
      "     |      :param tagset: The name of the tagset used by this corpus, to be used\n",
      "     |            for normalizing or converting the POS tags returned by the\n",
      "     |            tagged_...() methods.\n",
      "     |  \n",
      "     |  raw(self, fileids=None)\n",
      "     |  \n",
      "     |  words(self, fileid=None)\n",
      "     |      Returns all of the words and punctuation symbols in the specified file\n",
      "     |      that were in text nodes -- ie, tags are ignored. Like the xml() method,\n",
      "     |      fileid can only specify one file.\n",
      "     |      \n",
      "     |      :return: the given file's text nodes as a list of words and punctuation symbols\n",
      "     |      :rtype: list(str)\n",
      "     |  \n",
      "     |  xml(self, fileid=None)\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Methods inherited from nltk.corpus.reader.api.CorpusReader:\n",
      "     |  \n",
      "     |  __repr__(self)\n",
      "     |      Return repr(self).\n",
      "     |  \n",
      "     |  __unicode__ = __str__(self, /)\n",
      "     |  \n",
      "     |  abspath(self, fileid)\n",
      "     |      Return the absolute path for the given file.\n",
      "     |      \n",
      "     |      :type fileid: str\n",
      "     |      :param fileid: The file identifier for the file whose path\n",
      "     |          should be returned.\n",
      "     |      :rtype: PathPointer\n",
      "     |  \n",
      "     |  abspaths(self, fileids=None, include_encoding=False, include_fileid=False)\n",
      "     |      Return a list of the absolute paths for all fileids in this corpus;\n",
      "     |      or for the given list of fileids, if specified.\n",
      "     |      \n",
      "     |      :type fileids: None or str or list\n",
      "     |      :param fileids: Specifies the set of fileids for which paths should\n",
      "     |          be returned.  Can be None, for all fileids; a list of\n",
      "     |          file identifiers, for a specified set of fileids; or a single\n",
      "     |          file identifier, for a single file.  Note that the return\n",
      "     |          value is always a list of paths, even if ``fileids`` is a\n",
      "     |          single file identifier.\n",
      "     |      \n",
      "     |      :param include_encoding: If true, then return a list of\n",
      "     |          ``(path_pointer, encoding)`` tuples.\n",
      "     |      \n",
      "     |      :rtype: list(PathPointer)\n",
      "     |  \n",
      "     |  citation(self)\n",
      "     |      Return the contents of the corpus citation.bib file, if it exists.\n",
      "     |  \n",
      "     |  encoding(self, file)\n",
      "     |      Return the unicode encoding for the given corpus file, if known.\n",
      "     |      If the encoding is unknown, or if the given file should be\n",
      "     |      processed using byte strings (str), then return None.\n",
      "     |  \n",
      "     |  ensure_loaded(self)\n",
      "     |      Load this corpus (if it has not already been loaded).  This is\n",
      "     |      used by LazyCorpusLoader as a simple method that can be used to\n",
      "     |      make sure a corpus is loaded -- e.g., in case a user wants to\n",
      "     |      do help(some_corpus).\n",
      "     |  \n",
      "     |  fileids(self)\n",
      "     |      Return a list of file identifiers for the fileids that make up\n",
      "     |      this corpus.\n",
      "     |  \n",
      "     |  license(self)\n",
      "     |      Return the contents of the corpus LICENSE file, if it exists.\n",
      "     |  \n",
      "     |  open(self, file)\n",
      "     |      Return an open stream that can be used to read the given file.\n",
      "     |      If the file's encoding is not None, then the stream will\n",
      "     |      automatically decode the file's contents into unicode.\n",
      "     |      \n",
      "     |      :param file: The file identifier of the file to read.\n",
      "     |  \n",
      "     |  readme(self)\n",
      "     |      Return the contents of the corpus README file, if it exists.\n",
      "     |  \n",
      "     |  unicode_repr = __repr__(self)\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Data descriptors inherited from nltk.corpus.reader.api.CorpusReader:\n",
      "     |  \n",
      "     |  __dict__\n",
      "     |      dictionary for instance variables (if defined)\n",
      "     |  \n",
      "     |  __weakref__\n",
      "     |      list of weak references to the object (if defined)\n",
      "     |  \n",
      "     |  root\n",
      "     |      The directory where this corpus is stored.\n",
      "     |      \n",
      "     |      :type: PathPointer\n",
      "    \n",
      "    class YCOECorpusReader(nltk.corpus.reader.api.CorpusReader)\n",
      "     |  YCOECorpusReader(root, encoding='utf8')\n",
      "     |  \n",
      "     |  Corpus reader for the York-Toronto-Helsinki Parsed Corpus of Old\n",
      "     |  English Prose (YCOE), a 1.5 million word syntactically-annotated\n",
      "     |  corpus of Old English prose texts.\n",
      "     |  \n",
      "     |  Method resolution order:\n",
      "     |      YCOECorpusReader\n",
      "     |      nltk.corpus.reader.api.CorpusReader\n",
      "     |      builtins.object\n",
      "     |  \n",
      "     |  Methods defined here:\n",
      "     |  \n",
      "     |  __init__(self, root, encoding='utf8')\n",
      "     |      :type root: PathPointer or str\n",
      "     |      :param root: A path pointer identifying the root directory for\n",
      "     |          this corpus.  If a string is specified, then it will be\n",
      "     |          converted to a ``PathPointer`` automatically.\n",
      "     |      :param fileids: A list of the files that make up this corpus.\n",
      "     |          This list can either be specified explicitly, as a list of\n",
      "     |          strings; or implicitly, as a regular expression over file\n",
      "     |          paths.  The absolute path for each file will be constructed\n",
      "     |          by joining the reader's root to each file name.\n",
      "     |      :param encoding: The default unicode encoding for the files\n",
      "     |          that make up the corpus.  The value of ``encoding`` can be any\n",
      "     |          of the following:\n",
      "     |          - A string: ``encoding`` is the encoding name for all files.\n",
      "     |          - A dictionary: ``encoding[file_id]`` is the encoding\n",
      "     |            name for the file whose identifier is ``file_id``.  If\n",
      "     |            ``file_id`` is not in ``encoding``, then the file\n",
      "     |            contents will be processed using non-unicode byte strings.\n",
      "     |          - A list: ``encoding`` should be a list of ``(regexp, encoding)``\n",
      "     |            tuples.  The encoding for a file whose identifier is ``file_id``\n",
      "     |            will be the ``encoding`` value for the first tuple whose\n",
      "     |            ``regexp`` matches the ``file_id``.  If no tuple's ``regexp``\n",
      "     |            matches the ``file_id``, the file contents will be processed\n",
      "     |            using non-unicode byte strings.\n",
      "     |          - None: the file contents of all files will be\n",
      "     |            processed using non-unicode byte strings.\n",
      "     |      :param tagset: The name of the tagset used by this corpus, to be used\n",
      "     |            for normalizing or converting the POS tags returned by the\n",
      "     |            tagged_...() methods.\n",
      "     |  \n",
      "     |  documents(self, fileids=None)\n",
      "     |      Return a list of document identifiers for all documents in\n",
      "     |      this corpus, or for the documents with the given file(s) if\n",
      "     |      specified.\n",
      "     |  \n",
      "     |  fileids(self, documents=None)\n",
      "     |      Return a list of file identifiers for the files that make up\n",
      "     |      this corpus, or that store the given document(s) if specified.\n",
      "     |  \n",
      "     |  paras(self, documents=None)\n",
      "     |  \n",
      "     |  parsed_sents(self, documents=None)\n",
      "     |  \n",
      "     |  sents(self, documents=None)\n",
      "     |  \n",
      "     |  tagged_paras(self, documents=None)\n",
      "     |  \n",
      "     |  tagged_sents(self, documents=None)\n",
      "     |  \n",
      "     |  tagged_words(self, documents=None)\n",
      "     |  \n",
      "     |  words(self, documents=None)\n",
      "     |      # Delegate to one of our two sub-readers:\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Methods inherited from nltk.corpus.reader.api.CorpusReader:\n",
      "     |  \n",
      "     |  __repr__(self)\n",
      "     |      Return repr(self).\n",
      "     |  \n",
      "     |  __unicode__ = __str__(self, /)\n",
      "     |  \n",
      "     |  abspath(self, fileid)\n",
      "     |      Return the absolute path for the given file.\n",
      "     |      \n",
      "     |      :type fileid: str\n",
      "     |      :param fileid: The file identifier for the file whose path\n",
      "     |          should be returned.\n",
      "     |      :rtype: PathPointer\n",
      "     |  \n",
      "     |  abspaths(self, fileids=None, include_encoding=False, include_fileid=False)\n",
      "     |      Return a list of the absolute paths for all fileids in this corpus;\n",
      "     |      or for the given list of fileids, if specified.\n",
      "     |      \n",
      "     |      :type fileids: None or str or list\n",
      "     |      :param fileids: Specifies the set of fileids for which paths should\n",
      "     |          be returned.  Can be None, for all fileids; a list of\n",
      "     |          file identifiers, for a specified set of fileids; or a single\n",
      "     |          file identifier, for a single file.  Note that the return\n",
      "     |          value is always a list of paths, even if ``fileids`` is a\n",
      "     |          single file identifier.\n",
      "     |      \n",
      "     |      :param include_encoding: If true, then return a list of\n",
      "     |          ``(path_pointer, encoding)`` tuples.\n",
      "     |      \n",
      "     |      :rtype: list(PathPointer)\n",
      "     |  \n",
      "     |  citation(self)\n",
      "     |      Return the contents of the corpus citation.bib file, if it exists.\n",
      "     |  \n",
      "     |  encoding(self, file)\n",
      "     |      Return the unicode encoding for the given corpus file, if known.\n",
      "     |      If the encoding is unknown, or if the given file should be\n",
      "     |      processed using byte strings (str), then return None.\n",
      "     |  \n",
      "     |  ensure_loaded(self)\n",
      "     |      Load this corpus (if it has not already been loaded).  This is\n",
      "     |      used by LazyCorpusLoader as a simple method that can be used to\n",
      "     |      make sure a corpus is loaded -- e.g., in case a user wants to\n",
      "     |      do help(some_corpus).\n",
      "     |  \n",
      "     |  license(self)\n",
      "     |      Return the contents of the corpus LICENSE file, if it exists.\n",
      "     |  \n",
      "     |  open(self, file)\n",
      "     |      Return an open stream that can be used to read the given file.\n",
      "     |      If the file's encoding is not None, then the stream will\n",
      "     |      automatically decode the file's contents into unicode.\n",
      "     |      \n",
      "     |      :param file: The file identifier of the file to read.\n",
      "     |  \n",
      "     |  readme(self)\n",
      "     |      Return the contents of the corpus README file, if it exists.\n",
      "     |  \n",
      "     |  unicode_repr = __repr__(self)\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Data descriptors inherited from nltk.corpus.reader.api.CorpusReader:\n",
      "     |  \n",
      "     |  __dict__\n",
      "     |      dictionary for instance variables (if defined)\n",
      "     |  \n",
      "     |  __weakref__\n",
      "     |      list of weak references to the object (if defined)\n",
      "     |  \n",
      "     |  root\n",
      "     |      The directory where this corpus is stored.\n",
      "     |      \n",
      "     |      :type: PathPointer\n",
      "\n",
      "FUNCTIONS\n",
      "    find_corpus_fileids(root, regexp)\n",
      "    \n",
      "    tagged_treebank_para_block_reader(stream)\n",
      "\n",
      "DATA\n",
      "    __all__ = ['CorpusReader', 'CategorizedCorpusReader', 'PlaintextCorpus...\n",
      "\n",
      "FILE\n",
      "    c:\\users\\34677\\anaconda3\\lib\\site-packages\\nltk\\corpus\\reader\\__init__.py\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "help(nltk.corpus.reader)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " http://nltk.org/howto\n",
    "\n",
    "Example \t                      Description\n",
    "\n",
    "fileids()        \t        the files of the corpus\n",
    "\n",
    "fileids([categories]) \t    the files of the corpus corresponding to these categories\n",
    "\n",
    "categories() \t            the categories of the corpus\n",
    "\n",
    "categories([fileids]) \t    the categories of the corpus corresponding to these files\n",
    "\n",
    "raw() \t                    the raw content of the corpus\n",
    "\n",
    "raw(fileids=[f1,f2,f3]) \tthe raw content of the specified files\n",
    "\n",
    "raw(categories=[c1,c2]) \tthe raw content of the specified categories\n",
    "\n",
    "words() \t                the words of the whole corpus\n",
    "\n",
    "words(fileids=[f1,f2,f3]) \tthe words of the specified fileids\n",
    "\n",
    "words(categories=[c1,c2]) \tthe words of the specified categories\n",
    "\n",
    "sents() \t                the sentences of the whole corpus\n",
    "\n",
    "sents(fileids=[f1,f2,f3]) \tthe sentences of the specified fileids\n",
    "\n",
    "sents(categories=[c1,c2]) \tthe sentences of the specified categories\n",
    "\n",
    "abspath(fileid) \t        the location of the given file on disk\n",
    "\n",
    "encoding(fileid) \t        the encoding of the file (if known)\n",
    "\n",
    "open(fileid) \t            open a stream for reading the given corpus file\n",
    "\n",
    "root \t                    if the path to the root of locally installed corpus\n",
    "\n",
    "readme() \t                the contents of the README file of the corpus   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'The Adventures of B'"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "raw = gutenberg.raw(\"burgess-busterbrown.txt\")\n",
    "raw[1:20]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['The',\n",
       " 'Adventures',\n",
       " 'of',\n",
       " 'Buster',\n",
       " 'Bear',\n",
       " 'by',\n",
       " 'Thornton',\n",
       " 'W',\n",
       " '.',\n",
       " 'Burgess',\n",
       " '1920',\n",
       " ']',\n",
       " 'I',\n",
       " 'BUSTER',\n",
       " 'BEAR',\n",
       " 'GOES',\n",
       " 'FISHING',\n",
       " 'Buster',\n",
       " 'Bear']"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "words = gutenberg.words(\"burgess-busterbrown.txt\")\n",
    "words[1:20]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[['I'],\n",
       " ['BUSTER', 'BEAR', 'GOES', 'FISHING'],\n",
       " ['Buster',\n",
       "  'Bear',\n",
       "  'yawned',\n",
       "  'as',\n",
       "  'he',\n",
       "  'lay',\n",
       "  'on',\n",
       "  'his',\n",
       "  'comfortable',\n",
       "  'bed',\n",
       "  'of',\n",
       "  'leaves',\n",
       "  'and',\n",
       "  'watched',\n",
       "  'the',\n",
       "  'first',\n",
       "  'early',\n",
       "  'morning',\n",
       "  'sunbeams',\n",
       "  'creeping',\n",
       "  'through',\n",
       "  'the',\n",
       "  'Green',\n",
       "  'Forest',\n",
       "  'to',\n",
       "  'chase',\n",
       "  'out',\n",
       "  'the',\n",
       "  'Black',\n",
       "  'Shadows',\n",
       "  '.'],\n",
       " ['Once',\n",
       "  'more',\n",
       "  'he',\n",
       "  'yawned',\n",
       "  ',',\n",
       "  'and',\n",
       "  'slowly',\n",
       "  'got',\n",
       "  'to',\n",
       "  'his',\n",
       "  'feet',\n",
       "  'and',\n",
       "  'shook',\n",
       "  'himself',\n",
       "  '.'],\n",
       " ['Then',\n",
       "  'he',\n",
       "  'walked',\n",
       "  'over',\n",
       "  'to',\n",
       "  'a',\n",
       "  'big',\n",
       "  'pine',\n",
       "  '-',\n",
       "  'tree',\n",
       "  ',',\n",
       "  'stood',\n",
       "  'up',\n",
       "  'on',\n",
       "  'his',\n",
       "  'hind',\n",
       "  'legs',\n",
       "  ',',\n",
       "  'reached',\n",
       "  'as',\n",
       "  'high',\n",
       "  'up',\n",
       "  'on',\n",
       "  'the',\n",
       "  'trunk',\n",
       "  'of',\n",
       "  'the',\n",
       "  'tree',\n",
       "  'as',\n",
       "  'he',\n",
       "  'could',\n",
       "  ',',\n",
       "  'and',\n",
       "  'scratched',\n",
       "  'the',\n",
       "  'bark',\n",
       "  'with',\n",
       "  'his',\n",
       "  'great',\n",
       "  'claws',\n",
       "  '.'],\n",
       " ['After',\n",
       "  'that',\n",
       "  'he',\n",
       "  'yawned',\n",
       "  'until',\n",
       "  'it',\n",
       "  'seemed',\n",
       "  'as',\n",
       "  'if',\n",
       "  'his',\n",
       "  'jaws',\n",
       "  'would',\n",
       "  'crack',\n",
       "  ',',\n",
       "  'and',\n",
       "  'then',\n",
       "  'sat',\n",
       "  'down',\n",
       "  'to',\n",
       "  'think',\n",
       "  'what',\n",
       "  'he',\n",
       "  'wanted',\n",
       "  'for',\n",
       "  'breakfast',\n",
       "  '.'],\n",
       " ['While',\n",
       "  'he',\n",
       "  'sat',\n",
       "  'there',\n",
       "  ',',\n",
       "  'trying',\n",
       "  'to',\n",
       "  'make',\n",
       "  'up',\n",
       "  'his',\n",
       "  'mind',\n",
       "  'what',\n",
       "  'would',\n",
       "  'taste',\n",
       "  'best',\n",
       "  ',',\n",
       "  'he',\n",
       "  'was',\n",
       "  'listening',\n",
       "  'to',\n",
       "  'the',\n",
       "  'sounds',\n",
       "  'that',\n",
       "  'told',\n",
       "  'of',\n",
       "  'the',\n",
       "  'waking',\n",
       "  'of',\n",
       "  'all',\n",
       "  'the',\n",
       "  'little',\n",
       "  'people',\n",
       "  'who',\n",
       "  'live',\n",
       "  'in',\n",
       "  'the',\n",
       "  'Green',\n",
       "  'Forest',\n",
       "  '.'],\n",
       " ['He',\n",
       "  'heard',\n",
       "  'Sammy',\n",
       "  'Jay',\n",
       "  'way',\n",
       "  'off',\n",
       "  'in',\n",
       "  'the',\n",
       "  'distance',\n",
       "  'screaming',\n",
       "  ',',\n",
       "  '\"',\n",
       "  'Thief',\n",
       "  '!'],\n",
       " ['Thief', '!\"'],\n",
       " ['and', 'grinned', '.'],\n",
       " ['\"',\n",
       "  'I',\n",
       "  'wonder',\n",
       "  ',\"',\n",
       "  'thought',\n",
       "  'Buster',\n",
       "  ',',\n",
       "  '\"',\n",
       "  'if',\n",
       "  'some',\n",
       "  'one',\n",
       "  'has',\n",
       "  'stolen',\n",
       "  'Sammy',\n",
       "  \"'\",\n",
       "  's',\n",
       "  'breakfast',\n",
       "  ',',\n",
       "  'or',\n",
       "  'if',\n",
       "  'he',\n",
       "  'has',\n",
       "  'stolen',\n",
       "  'the',\n",
       "  'breakfast',\n",
       "  'of',\n",
       "  'some',\n",
       "  'one',\n",
       "  'else',\n",
       "  '.'],\n",
       " ['Probably', 'he', 'is', 'the', 'thief', 'himself', '.\"'],\n",
       " ['He',\n",
       "  'heard',\n",
       "  'Chatterer',\n",
       "  'the',\n",
       "  'Red',\n",
       "  'Squirrel',\n",
       "  'scolding',\n",
       "  'as',\n",
       "  'fast',\n",
       "  'as',\n",
       "  'he',\n",
       "  'could',\n",
       "  'make',\n",
       "  'his',\n",
       "  'tongue',\n",
       "  'go',\n",
       "  'and',\n",
       "  'working',\n",
       "  'himself',\n",
       "  'into',\n",
       "  'a',\n",
       "  'terrible',\n",
       "  'rage',\n",
       "  '.'],\n",
       " ['\"',\n",
       "  'Must',\n",
       "  'be',\n",
       "  'that',\n",
       "  'Chatterer',\n",
       "  'got',\n",
       "  'out',\n",
       "  'of',\n",
       "  'bed',\n",
       "  'the',\n",
       "  'wrong',\n",
       "  'way',\n",
       "  'this',\n",
       "  'morning',\n",
       "  ',\"',\n",
       "  'thought',\n",
       "  'he',\n",
       "  '.'],\n",
       " ['He',\n",
       "  'heard',\n",
       "  'Blacky',\n",
       "  'the',\n",
       "  'Crow',\n",
       "  'cawing',\n",
       "  'at',\n",
       "  'the',\n",
       "  'top',\n",
       "  'of',\n",
       "  'his',\n",
       "  'lungs',\n",
       "  ',',\n",
       "  'and',\n",
       "  'he',\n",
       "  'knew',\n",
       "  'by',\n",
       "  'the',\n",
       "  'sound',\n",
       "  'that',\n",
       "  'Blacky',\n",
       "  'was',\n",
       "  'getting',\n",
       "  'into',\n",
       "  'mischief',\n",
       "  'of',\n",
       "  'some',\n",
       "  'kind',\n",
       "  '.'],\n",
       " ['He',\n",
       "  'heard',\n",
       "  'the',\n",
       "  'sweet',\n",
       "  'voices',\n",
       "  'of',\n",
       "  'happy',\n",
       "  'little',\n",
       "  'singers',\n",
       "  ',',\n",
       "  'and',\n",
       "  'they',\n",
       "  'were',\n",
       "  'good',\n",
       "  'to',\n",
       "  'hear',\n",
       "  '.'],\n",
       " ['But',\n",
       "  'most',\n",
       "  'of',\n",
       "  'all',\n",
       "  'he',\n",
       "  'listened',\n",
       "  'to',\n",
       "  'a',\n",
       "  'merry',\n",
       "  ',',\n",
       "  'low',\n",
       "  ',',\n",
       "  'silvery',\n",
       "  'laugh',\n",
       "  'that',\n",
       "  'never',\n",
       "  'stopped',\n",
       "  'but',\n",
       "  'went',\n",
       "  'on',\n",
       "  'and',\n",
       "  'on',\n",
       "  ',',\n",
       "  'until',\n",
       "  'he',\n",
       "  'just',\n",
       "  'felt',\n",
       "  'as',\n",
       "  'if',\n",
       "  'he',\n",
       "  'must',\n",
       "  'laugh',\n",
       "  'too',\n",
       "  '.'],\n",
       " ['It', 'was', 'the', 'voice', 'of', 'the', 'Laughing', 'Brook', '.'],\n",
       " ['And',\n",
       "  'as',\n",
       "  'Buster',\n",
       "  'listened',\n",
       "  'it',\n",
       "  'suddenly',\n",
       "  'came',\n",
       "  'to',\n",
       "  'him',\n",
       "  'just',\n",
       "  'what',\n",
       "  'he',\n",
       "  'wanted',\n",
       "  'for',\n",
       "  'breakfast',\n",
       "  '.']]"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sents = gutenberg.sents(\"burgess-busterbrown.txt\")\n",
    "sents[1:20]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.9   Loading your own Corpus"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from nltk.corpus import PlaintextCorpusReader\n",
    "corpus_root = '/usr/share/dict'\n",
    "wordlists = PlaintextCorpusReader(corpus_root, '.*')\n",
    "wordlists.fileids()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "wordlists.words('connectives')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2   Conditional Frequency Distributions\n",
    "\n",
    "### 2.1   Conditions and Events\n",
    "\n",
    "### 2.2   Counting Words by Genre"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "from nltk.corpus import brown\n",
    "cfd = nltk.ConditionalFreqDist(\n",
    "    (genre, word)\n",
    "    for genre in brown.categories()\n",
    "    for word in brown.words(categories=genre))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "170576"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "genre_word = [(genre, word)\n",
    "              for genre in ['news', 'romance'] \n",
    "              for word in brown.words(categories=genre)]\n",
    "len(genre_word)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('news', 'The'), ('news', 'Fulton'), ('news', 'County'), ('news', 'Grand')]"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "genre_word[:4]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('romance', 'afraid'),\n",
       " ('romance', 'not'),\n",
       " ('romance', \"''\"),\n",
       " ('romance', '.')]"
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "genre_word[-4:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<ConditionalFreqDist with 2 conditions>"
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cfd = nltk.ConditionalFreqDist(genre_word)\n",
    "cfd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['news', 'romance']"
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cfd.conditions()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<FreqDist with 14394 samples and 100554 outcomes>\n"
     ]
    }
   ],
   "source": [
    "print(cfd['news'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<FreqDist with 8452 samples and 70022 outcomes>\n"
     ]
    }
   ],
   "source": [
    "print(cfd['romance'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(',', 3899),\n",
       " ('.', 3736),\n",
       " ('the', 2758),\n",
       " ('and', 1776),\n",
       " ('to', 1502),\n",
       " ('a', 1335),\n",
       " ('of', 1186),\n",
       " ('``', 1045),\n",
       " (\"''\", 1044),\n",
       " ('was', 993),\n",
       " ('I', 951),\n",
       " ('in', 875),\n",
       " ('he', 702),\n",
       " ('had', 692),\n",
       " ('?', 690),\n",
       " ('her', 651),\n",
       " ('that', 583),\n",
       " ('it', 573),\n",
       " ('his', 559),\n",
       " ('she', 496)]"
      ]
     },
     "execution_count": 58,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cfd['romance'].most_common(20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "193"
      ]
     },
     "execution_count": 59,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cfd['romance']['could']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.3   Plotting and Tabulating Distributions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [],
   "source": [
    "from nltk.corpus import inaugural\n",
    "cfd = nltk.ConditionalFreqDist(\n",
    "    (target, fileid[:4])\n",
    "    for fileid in inaugural.fileids()\n",
    "    for w in inaugural.words(fileid)\n",
    "    for target in ['america', 'citizen']\n",
    "    if w.lower().startswith(target))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [],
   "source": [
    "from nltk.corpus import udhr\n",
    "languages = ['Chickasaw', 'English', 'German_Deutsch', 'Greenlandic_Inuktikut', 'Hungarian_Magyar', 'Ibibio_Efik']\n",
    "cfd = nltk.ConditionalFreqDist(\n",
    "    (lang, len(word))\n",
    "    for lang in languages\n",
    "    for word in udhr.words(lang + '-Latin1'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                  0    1    2    3    4    5    6    7    8    9 \n",
      "       English    0  185  525  883  997 1166 1283 1440 1558 1638 \n",
      "German_Deutsch    0  171  263  614  717  894 1013 1110 1213 1275 \n",
      "       Spanish    0    0    0    0    0    0    0    0    0    0 \n"
     ]
    }
   ],
   "source": [
    "cfd.tabulate(conditions=['English', 'German_Deutsch', 'Spanish'], samples=range(10), cumulative=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.4   Generating Random Text with Bigrams"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('In', 'the'),\n",
       " ('the', 'beginning'),\n",
       " ('beginning', 'God'),\n",
       " ('God', 'created'),\n",
       " ('created', 'the'),\n",
       " ('the', 'heaven'),\n",
       " ('heaven', 'and'),\n",
       " ('and', 'the'),\n",
       " ('the', 'earth'),\n",
       " ('earth', '.')]"
      ]
     },
     "execution_count": 64,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sent = ['In', 'the', 'beginning', 'God', 'created', 'the', 'heaven', 'and', 'the', 'earth', '.']\n",
    "list(nltk.bigrams(sent))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_model(cfdist, word, num=15):\n",
    "    for i in range(num):\n",
    "        print(word, end=' ')\n",
    "        word = cfdist[word].max()\n",
    "\n",
    "text = nltk.corpus.genesis.words('english-kjv.txt')\n",
    "bigrams = nltk.bigrams(text)\n",
    "cfd = nltk.ConditionalFreqDist(bigrams)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "FreqDist({'creature': 7, 'thing': 4, 'substance': 2, 'soul': 1, '.': 1, ',': 1})"
      ]
     },
     "execution_count": 67,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cfd['living']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "living creature that he said , and the land of the land of the land "
     ]
    }
   ],
   "source": [
    "generate_model(cfd, 'living')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**NLTK's Conditional Frequency Distributions:** commonly-used methods and idioms for defining, accessing, and visualizing a conditional frequency distribution of counters.\n",
    "\n",
    "Example \t                              Description\n",
    "cfdist = ConditionalFreqDist(pairs) \tcreate a conditional frequency distribution from a list of pairs\n",
    "cfdist.conditions() \t                the conditions\n",
    "cfdist[condition] \t                    the frequency distribution for this condition\n",
    "cfdist[condition][sample] \t            frequency for the given sample for this condition\n",
    "cfdist.tabulate() \t                    tabulate the conditional frequency distribution\n",
    "cfdist.tabulate(samples, conditions) \ttabulation limited to the specified samples and conditions\n",
    "cfdist.plot() \t                        graphical plot of the conditional frequency distribution\n",
    "cfdist.plot(samples, conditions) \t    graphical plot limited to the specified samples and conditions\n",
    "cfdist1 < cfdist2 \t                    test if samples in cfdist1 occur less frequently than in cfdist2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3   More Python: Reusing Code\n",
    "\n",
    "### 3.1   Creating Programs with a Text Editor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Monty Python\n"
     ]
    }
   ],
   "source": [
    "print('Monty Python')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.2 Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [],
   "source": [
    "from __future__ import division\n",
    "def lexical_diversity(text):\n",
    "    return len(text) / len(set(text))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [],
   "source": [
    "def  lexical_diversity (my_text_data):\n",
    "    word_count = len (my_text_data)\n",
    "    vocab_size = len (set (my_text_data))\n",
    "    diversity_score = vocab_size / word_count\n",
    "    return diversity_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.06230453042623537"
      ]
     },
     "execution_count": 74,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from nltk.corpus import genesis\n",
    "kjv = genesis.words('english-kjv.txt')\n",
    "lexical_diversity(kjv)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "44764"
      ]
     },
     "execution_count": 76,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "word_count = len(kjv)\n",
    "word_count"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2789"
      ]
     },
     "execution_count": 78,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vocab_size = len (set (kjv))\n",
    "vocab_size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [],
   "source": [
    "#  this function tries to work out the plural form of any English noun:\n",
    "def plural(word):\n",
    "    if word.endswith('y'):\n",
    "        return word[:-1] + 'ies'\n",
    "    elif word[-1] in 'sx' or word[-2:] in ['sh', 'ch']:\n",
    "        return word + 'es'\n",
    "    elif word.endswith('an'):\n",
    "        return word[:-2] + 'en'\n",
    "    else:\n",
    "        return word + 's'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'fairies'"
      ]
     },
     "execution_count": 80,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "plural('fairy')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'women'"
      ]
     },
     "execution_count": 81,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "plural('woman')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.3   Modules"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4   Lexical Resources\n",
    "\n",
    "### 4.1   Wordlist Corpora"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [],
   "source": [
    "def unusual_words(text):\n",
    "    text_vocab = set(w.lower() for w in text if w.isalpha())\n",
    "    english_vocab = set(w.lower() for w in nltk.corpus.words.words())\n",
    "    unusual = text_vocab - english_vocab\n",
    "    return sorted(unusual)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['abbeyland',\n",
       " 'abhorred',\n",
       " 'abilities',\n",
       " 'abounded',\n",
       " 'abridgement',\n",
       " 'abused',\n",
       " 'abuses',\n",
       " 'accents',\n",
       " 'accepting',\n",
       " 'accommodations',\n",
       " 'accompanied',\n",
       " 'accounted',\n",
       " 'accounts',\n",
       " 'accustomary',\n",
       " 'aches',\n",
       " 'acknowledging',\n",
       " 'acknowledgment',\n",
       " 'acknowledgments',\n",
       " 'acquaintances',\n",
       " 'acquiesced',\n",
       " 'acquitted',\n",
       " 'acquitting',\n",
       " 'acted',\n",
       " 'actions',\n",
       " 'adapted',\n",
       " 'adding',\n",
       " 'additions',\n",
       " 'addressed',\n",
       " 'addresses',\n",
       " 'addressing',\n",
       " 'adhering',\n",
       " 'adieus',\n",
       " 'adjusting',\n",
       " 'administering',\n",
       " 'admirers',\n",
       " 'admires',\n",
       " 'admitting',\n",
       " 'adorned',\n",
       " 'advances',\n",
       " 'advantages',\n",
       " 'affairs',\n",
       " 'affections',\n",
       " 'affects',\n",
       " 'affixed',\n",
       " 'afflictions',\n",
       " 'afforded',\n",
       " 'affording',\n",
       " 'ages',\n",
       " 'agitated',\n",
       " 'agonies',\n",
       " 'ailments',\n",
       " 'aimed',\n",
       " 'alarms',\n",
       " 'alienated',\n",
       " 'alighted',\n",
       " 'alleged',\n",
       " 'allenham',\n",
       " 'allowances',\n",
       " 'allowed',\n",
       " 'allowing',\n",
       " 'alluded',\n",
       " 'alterations',\n",
       " 'altered',\n",
       " 'altering',\n",
       " 'amended',\n",
       " 'amounted',\n",
       " 'amusements',\n",
       " 'ankles',\n",
       " 'annamaria',\n",
       " 'annexed',\n",
       " 'announced',\n",
       " 'announcing',\n",
       " 'annuities',\n",
       " 'annum',\n",
       " 'answered',\n",
       " 'answering',\n",
       " 'answers',\n",
       " 'anticipated',\n",
       " 'anticipating',\n",
       " 'anticipations',\n",
       " 'anymore',\n",
       " 'apartments',\n",
       " 'apologies',\n",
       " 'apologising',\n",
       " 'apologized',\n",
       " 'appearances',\n",
       " 'appeared',\n",
       " 'appearing',\n",
       " 'appeased',\n",
       " 'appetites',\n",
       " 'applauded',\n",
       " 'applying',\n",
       " 'appointed',\n",
       " 'apprehended',\n",
       " 'apprehensions',\n",
       " 'approached',\n",
       " 'approved',\n",
       " 'arbour',\n",
       " 'ardour',\n",
       " 'arguments',\n",
       " 'arranged',\n",
       " 'arrangements',\n",
       " 'arranging',\n",
       " 'arrived',\n",
       " 'arrives',\n",
       " 'arriving',\n",
       " 'ascended',\n",
       " 'ascertained',\n",
       " 'asked',\n",
       " 'asking',\n",
       " 'assembled',\n",
       " 'assemblies',\n",
       " 'asserted',\n",
       " 'assertions',\n",
       " 'assiduities',\n",
       " 'assisted',\n",
       " 'assisting',\n",
       " 'associating',\n",
       " 'assurances',\n",
       " 'astonished',\n",
       " 'atoned',\n",
       " 'atoning',\n",
       " 'attaching',\n",
       " 'attachments',\n",
       " 'attacked',\n",
       " 'attacks',\n",
       " 'attained',\n",
       " 'attempted',\n",
       " 'attempting',\n",
       " 'attempts',\n",
       " 'attendants',\n",
       " 'attended',\n",
       " 'attending',\n",
       " 'attentions',\n",
       " 'attracted',\n",
       " 'attractions',\n",
       " 'attributed',\n",
       " 'attributing',\n",
       " 'auditors',\n",
       " 'augmenting',\n",
       " 'austen',\n",
       " 'authorised',\n",
       " 'authors',\n",
       " 'availed',\n",
       " 'avignon',\n",
       " 'avoided',\n",
       " 'avoiding',\n",
       " 'awaited',\n",
       " 'awakened',\n",
       " 'awaking',\n",
       " 'bags',\n",
       " 'balls',\n",
       " 'banished',\n",
       " 'barouches',\n",
       " 'bathed',\n",
       " 'bears',\n",
       " 'beasts',\n",
       " 'beauties',\n",
       " 'became',\n",
       " 'bedrooms',\n",
       " 'beds',\n",
       " 'befallen',\n",
       " 'befalls',\n",
       " 'befell',\n",
       " 'began',\n",
       " 'begged',\n",
       " 'begins',\n",
       " 'behaved',\n",
       " 'beings',\n",
       " 'believed',\n",
       " 'believes',\n",
       " 'belonged',\n",
       " 'belongs',\n",
       " 'benefited',\n",
       " 'bequeathed',\n",
       " 'berkeley',\n",
       " 'bestowed',\n",
       " 'betrayed',\n",
       " 'betraying',\n",
       " 'biased',\n",
       " 'blackest',\n",
       " 'blameable',\n",
       " 'blessings',\n",
       " 'blights',\n",
       " 'blossoms',\n",
       " 'blundered',\n",
       " 'blushed',\n",
       " 'blushes',\n",
       " 'bolder',\n",
       " 'bones',\n",
       " 'bonomi',\n",
       " 'books',\n",
       " 'booksellers',\n",
       " 'borrowed',\n",
       " 'bottoms',\n",
       " 'boys',\n",
       " 'breakfasting',\n",
       " 'bribing',\n",
       " 'brightened',\n",
       " 'brighter',\n",
       " 'bringing',\n",
       " 'brings',\n",
       " 'broader',\n",
       " 'brothers',\n",
       " 'bruised',\n",
       " 'buildings',\n",
       " 'bursts',\n",
       " 'buying',\n",
       " 'called',\n",
       " 'calls',\n",
       " 'calming',\n",
       " 'candles',\n",
       " 'candour',\n",
       " 'canvassing',\n",
       " 'cards',\n",
       " 'cares',\n",
       " 'caresses',\n",
       " 'careys',\n",
       " 'carriages',\n",
       " 'carries',\n",
       " 'cases',\n",
       " 'casts',\n",
       " 'cats',\n",
       " 'caused',\n",
       " 'ceased',\n",
       " 'ceasing',\n",
       " 'censured',\n",
       " 'centre',\n",
       " 'certainties',\n",
       " 'chagrined',\n",
       " 'chairs',\n",
       " 'chambers',\n",
       " 'chanced',\n",
       " 'changed',\n",
       " 'changes',\n",
       " 'changing',\n",
       " 'characters',\n",
       " 'charged',\n",
       " 'charmed',\n",
       " 'charms',\n",
       " 'cheated',\n",
       " 'checking',\n",
       " 'cheeks',\n",
       " 'cheerfuller',\n",
       " 'cherished',\n",
       " 'cherries',\n",
       " 'children',\n",
       " 'choked',\n",
       " 'chuse',\n",
       " 'chusing',\n",
       " 'circles',\n",
       " 'circumstances',\n",
       " 'civilities',\n",
       " 'claimed',\n",
       " 'claiming',\n",
       " 'claims',\n",
       " 'clarke',\n",
       " 'cleared',\n",
       " 'cleveland',\n",
       " 'clogged',\n",
       " 'closing',\n",
       " 'clouds',\n",
       " 'coats',\n",
       " 'collecting',\n",
       " 'coloured',\n",
       " 'colouring',\n",
       " 'combe',\n",
       " 'comforted',\n",
       " 'comforts',\n",
       " 'comings',\n",
       " 'commanded',\n",
       " 'commands',\n",
       " 'commended',\n",
       " 'comments',\n",
       " 'commissioned',\n",
       " 'commonest',\n",
       " 'communicated',\n",
       " 'companions',\n",
       " 'compared',\n",
       " 'compares',\n",
       " 'comparisons',\n",
       " 'complained',\n",
       " 'complaining',\n",
       " 'complaints',\n",
       " 'completed',\n",
       " 'compliments',\n",
       " 'comprehended',\n",
       " 'concealing',\n",
       " 'concerns',\n",
       " 'concessions',\n",
       " 'concluded',\n",
       " 'conclusions',\n",
       " 'conditions',\n",
       " 'conducted',\n",
       " 'confessed',\n",
       " 'confidante',\n",
       " 'conforming',\n",
       " 'congratulated',\n",
       " 'congratulating',\n",
       " 'congratulations',\n",
       " 'conjectured',\n",
       " 'conjectures',\n",
       " 'conjecturing',\n",
       " 'connections',\n",
       " 'conquests',\n",
       " 'consented',\n",
       " 'consequences',\n",
       " 'considerations',\n",
       " 'considers',\n",
       " 'consisted',\n",
       " 'consists',\n",
       " 'consoled',\n",
       " 'conspired',\n",
       " 'constantia',\n",
       " 'consulted',\n",
       " 'contained',\n",
       " 'containing',\n",
       " 'contend',\n",
       " 'contenting',\n",
       " 'continuing',\n",
       " 'contradicted',\n",
       " 'contrasted',\n",
       " 'contributed',\n",
       " 'contributing',\n",
       " 'contrived',\n",
       " 'contrives',\n",
       " 'contriving',\n",
       " 'controlled',\n",
       " 'conveniences',\n",
       " 'conversations',\n",
       " 'conversed',\n",
       " 'conversing',\n",
       " 'conveyed',\n",
       " 'conveying',\n",
       " 'copying',\n",
       " 'cordials',\n",
       " 'cottages',\n",
       " 'counsellor',\n",
       " 'counteracted',\n",
       " 'couples',\n",
       " 'courted',\n",
       " 'courting',\n",
       " 'courtland',\n",
       " 'cousins',\n",
       " 'cowper',\n",
       " 'cows',\n",
       " 'coxcombs',\n",
       " 'cramps',\n",
       " 'created',\n",
       " 'creating',\n",
       " 'creatures',\n",
       " 'cries',\n",
       " 'crimsoned',\n",
       " 'curtsying',\n",
       " 'cutlets',\n",
       " 'danced',\n",
       " 'dances',\n",
       " 'dared',\n",
       " 'darker',\n",
       " 'dartford',\n",
       " 'dashwood',\n",
       " 'dashwoods',\n",
       " 'daughters',\n",
       " 'davies',\n",
       " 'dawdled',\n",
       " 'dawlish',\n",
       " 'dawned',\n",
       " 'dearer',\n",
       " 'dearest',\n",
       " 'debated',\n",
       " 'debts',\n",
       " 'deceived',\n",
       " 'deciding',\n",
       " 'decisions',\n",
       " 'declares',\n",
       " 'declaring',\n",
       " 'declining',\n",
       " 'deemed',\n",
       " 'deeper',\n",
       " 'deepest',\n",
       " 'defects',\n",
       " 'defended',\n",
       " 'deficiencies',\n",
       " 'degrees',\n",
       " 'delaford',\n",
       " 'delayed',\n",
       " 'delays',\n",
       " 'deliberating',\n",
       " 'delicacies',\n",
       " 'delighful',\n",
       " 'delineated',\n",
       " 'delivered',\n",
       " 'demanded',\n",
       " 'demands',\n",
       " 'demonstrations',\n",
       " 'demur',\n",
       " 'denied',\n",
       " 'dennison',\n",
       " 'denoted',\n",
       " 'denoting',\n",
       " 'departing',\n",
       " 'depended',\n",
       " 'depends',\n",
       " 'deprived',\n",
       " 'described',\n",
       " 'describing',\n",
       " 'deserts',\n",
       " 'deserves',\n",
       " 'designs',\n",
       " 'desiring',\n",
       " 'despatch',\n",
       " 'despatching',\n",
       " 'despised',\n",
       " 'despising',\n",
       " 'destroyed',\n",
       " 'destroys',\n",
       " 'detaining',\n",
       " 'detected',\n",
       " 'detecting',\n",
       " 'determining',\n",
       " 'deterred',\n",
       " 'detested',\n",
       " 'devolved',\n",
       " 'died',\n",
       " 'dies',\n",
       " 'differed',\n",
       " 'differing',\n",
       " 'difficulties',\n",
       " 'dimensions',\n",
       " 'diminished',\n",
       " 'dined',\n",
       " 'dinners',\n",
       " 'directing',\n",
       " 'directions',\n",
       " 'disagreements',\n",
       " 'disappeared',\n",
       " 'disappointments',\n",
       " 'disapproved',\n",
       " 'disapproves',\n",
       " 'disapproving',\n",
       " 'discarded',\n",
       " 'discharged',\n",
       " 'disclaiming',\n",
       " 'disclosing',\n",
       " 'discontents',\n",
       " 'discovering',\n",
       " 'discussions',\n",
       " 'disgraced',\n",
       " 'disinherited',\n",
       " 'disliked',\n",
       " 'dismissed',\n",
       " 'dismounted',\n",
       " 'dispatched',\n",
       " 'dispatches',\n",
       " 'dispersing',\n",
       " 'disposing',\n",
       " 'disputes',\n",
       " 'disqualifications',\n",
       " 'disregarded',\n",
       " 'dissembling',\n",
       " 'dissented',\n",
       " 'distresses',\n",
       " 'distrusts',\n",
       " 'diverted',\n",
       " 'doatingly',\n",
       " 'donavan',\n",
       " 'doomed',\n",
       " 'dooming',\n",
       " 'doors',\n",
       " 'dorsetshire',\n",
       " 'doubted',\n",
       " 'doubts',\n",
       " 'douceur',\n",
       " 'downs',\n",
       " 'dr',\n",
       " 'drains',\n",
       " 'drawings',\n",
       " 'draws',\n",
       " 'dreaded',\n",
       " 'dreading',\n",
       " 'dreaming',\n",
       " 'dresses',\n",
       " 'drives',\n",
       " 'dropped',\n",
       " 'drops',\n",
       " 'drury',\n",
       " 'duets',\n",
       " 'duties',\n",
       " 'earlier',\n",
       " 'earliest',\n",
       " 'earned',\n",
       " 'ears',\n",
       " 'echoed',\n",
       " 'editions',\n",
       " 'edtions',\n",
       " 'effected',\n",
       " 'effecting',\n",
       " 'effusions',\n",
       " 'ellison',\n",
       " 'ellisons',\n",
       " 'eloping',\n",
       " 'eluded',\n",
       " 'embellishments',\n",
       " 'embraced',\n",
       " 'embraces',\n",
       " 'employments',\n",
       " 'enabled',\n",
       " 'enamoured',\n",
       " 'encouraged',\n",
       " 'encouragements',\n",
       " 'encroachments',\n",
       " 'encumbered',\n",
       " 'endeavoring',\n",
       " 'endeavors',\n",
       " 'endeavour',\n",
       " 'endeavoured',\n",
       " 'endeavouring',\n",
       " 'endeavours',\n",
       " 'endowed',\n",
       " 'ends',\n",
       " 'endured',\n",
       " 'enfeebled',\n",
       " 'enforcing',\n",
       " 'engagements',\n",
       " 'england',\n",
       " 'enjoyed',\n",
       " 'enjoyments',\n",
       " 'enquired',\n",
       " 'enquiries',\n",
       " 'enquiring',\n",
       " 'ensued',\n",
       " 'ensured',\n",
       " 'entered',\n",
       " 'entertained',\n",
       " 'entitled',\n",
       " 'entreated',\n",
       " 'entreaties',\n",
       " 'entrusted',\n",
       " 'equalled',\n",
       " 'equals',\n",
       " 'erred',\n",
       " 'errors',\n",
       " 'escaped',\n",
       " 'esq',\n",
       " 'establishing',\n",
       " 'esteemed',\n",
       " 'esteeming',\n",
       " 'esteems',\n",
       " 'estimating',\n",
       " 'estranged',\n",
       " 'evenings',\n",
       " 'events',\n",
       " 'evils',\n",
       " 'examined',\n",
       " 'exceeded',\n",
       " 'excellencies',\n",
       " 'exchanged',\n",
       " 'exclaimed',\n",
       " 'exclamations',\n",
       " 'excused',\n",
       " 'excuses',\n",
       " 'exercised',\n",
       " 'exercising',\n",
       " 'exerted',\n",
       " 'exertions',\n",
       " 'exeter',\n",
       " 'exhilarated',\n",
       " 'existed',\n",
       " 'expectations',\n",
       " 'expected',\n",
       " 'expecting',\n",
       " 'expects',\n",
       " 'expenses',\n",
       " 'experiencing',\n",
       " 'explained',\n",
       " 'explanations',\n",
       " 'expressing',\n",
       " 'expressions',\n",
       " 'extolling',\n",
       " 'extorted',\n",
       " 'extorting',\n",
       " 'extremest',\n",
       " 'eyeing',\n",
       " 'eyes',\n",
       " 'faces',\n",
       " 'facts',\n",
       " 'failed',\n",
       " 'falls',\n",
       " 'familiarized',\n",
       " 'families',\n",
       " 'fancying',\n",
       " 'fates',\n",
       " 'fatigued',\n",
       " 'fatigues',\n",
       " 'faults',\n",
       " 'favour',\n",
       " 'favourable',\n",
       " 'favourite',\n",
       " 'favourites',\n",
       " 'fearing',\n",
       " 'fears',\n",
       " 'features',\n",
       " 'feelings',\n",
       " 'feels',\n",
       " 'feet',\n",
       " 'felicitations',\n",
       " 'females',\n",
       " 'ferrars',\n",
       " 'fetches',\n",
       " 'fettered',\n",
       " 'finds',\n",
       " 'finest',\n",
       " 'fingers',\n",
       " 'flattered',\n",
       " 'flatteries',\n",
       " 'flowed',\n",
       " 'fluctuating',\n",
       " 'flushed',\n",
       " 'foibles',\n",
       " 'followed',\n",
       " 'follows',\n",
       " 'fond',\n",
       " 'footsteps',\n",
       " 'forebodings',\n",
       " 'foreplanned',\n",
       " 'foresaw',\n",
       " 'foreseeing',\n",
       " 'foreseen',\n",
       " 'forfeited',\n",
       " 'forfeiting',\n",
       " 'forgave',\n",
       " 'forgiven',\n",
       " 'forms',\n",
       " 'forsaking',\n",
       " 'fortunes',\n",
       " 'forwarded',\n",
       " 'foundations',\n",
       " 'founded',\n",
       " 'fowls',\n",
       " 'friendliest',\n",
       " 'friends',\n",
       " 'frightens',\n",
       " 'froid',\n",
       " 'frosts',\n",
       " 'fulfil',\n",
       " 'fulfilled',\n",
       " 'fullest',\n",
       " 'gained',\n",
       " 'gales',\n",
       " 'gardens',\n",
       " 'garrets',\n",
       " 'gates',\n",
       " 'gathered',\n",
       " 'generations',\n",
       " 'gentlemen',\n",
       " 'gigs',\n",
       " 'gilberts',\n",
       " 'girls',\n",
       " 'gives',\n",
       " 'glances',\n",
       " 'gloried',\n",
       " 'gloves',\n",
       " 'godby',\n",
       " 'goings',\n",
       " 'goodby',\n",
       " 'governed',\n",
       " 'gowns',\n",
       " 'graces',\n",
       " 'grandmothers',\n",
       " 'granted',\n",
       " 'greatest',\n",
       " 'grieves',\n",
       " 'grows',\n",
       " 'guardians',\n",
       " 'guessed',\n",
       " 'guests',\n",
       " 'guided',\n",
       " 'guineas',\n",
       " 'habits',\n",
       " 'hallooing',\n",
       " 'hands',\n",
       " 'handsomer',\n",
       " 'handsomest',\n",
       " 'hang',\n",
       " 'hanover',\n",
       " 'happened',\n",
       " 'happens',\n",
       " 'hardened',\n",
       " 'hardships',\n",
       " 'harley',\n",
       " 'has',\n",
       " 'hastened',\n",
       " 'hastening',\n",
       " 'hated',\n",
       " 'hates',\n",
       " 'hating',\n",
       " 'having',\n",
       " 'hazarded',\n",
       " 'hazarding',\n",
       " 'heads',\n",
       " 'heard',\n",
       " 'hears',\n",
       " 'heightened',\n",
       " 'heightening',\n",
       " 'heights',\n",
       " 'heirs',\n",
       " 'held',\n",
       " 'hens',\n",
       " 'henshawe',\n",
       " 'hesitated',\n",
       " 'hiding',\n",
       " 'hills',\n",
       " 'hinted',\n",
       " 'hints',\n",
       " 'hoarded',\n",
       " 'holborn',\n",
       " 'holburn',\n",
       " 'holds',\n",
       " 'holidays',\n",
       " 'homes',\n",
       " 'honeysuckles',\n",
       " 'honiton',\n",
       " 'honour',\n",
       " 'honourable',\n",
       " 'honourably',\n",
       " 'honoured',\n",
       " 'honours',\n",
       " 'hopes',\n",
       " 'hoping',\n",
       " 'horrors',\n",
       " 'horses',\n",
       " 'hours',\n",
       " 'houses',\n",
       " 'howsever',\n",
       " 'humbled',\n",
       " 'humiliations',\n",
       " 'humored',\n",
       " 'humoured',\n",
       " 'humouring',\n",
       " 'hunted',\n",
       " 'hunters',\n",
       " 'hunts',\n",
       " 'hurrying',\n",
       " 'husbands',\n",
       " 'huswifes',\n",
       " 'ideas',\n",
       " 'idled',\n",
       " 'idolized',\n",
       " 'ii',\n",
       " 'imaginations',\n",
       " 'imagined',\n",
       " 'imagining',\n",
       " 'imbibed',\n",
       " 'immoveable',\n",
       " 'imparted',\n",
       " 'imperfections',\n",
       " 'implied',\n",
       " 'implies',\n",
       " 'impoverished',\n",
       " 'impoverishing',\n",
       " 'improved',\n",
       " 'improvements',\n",
       " 'imputed',\n",
       " 'inclinations',\n",
       " 'inclined',\n",
       " 'inclosing',\n",
       " 'including',\n",
       " 'incommoded',\n",
       " 'inconveniences',\n",
       " 'increased',\n",
       " 'incurred',\n",
       " 'incurring',\n",
       " 'indulged',\n",
       " 'infants',\n",
       " 'inflicted',\n",
       " 'inflicting',\n",
       " 'influenced',\n",
       " 'inforce',\n",
       " 'inforced',\n",
       " 'informing',\n",
       " 'inhabitants',\n",
       " 'inhabiting',\n",
       " 'inheriting',\n",
       " 'injuries',\n",
       " 'inquired',\n",
       " 'inquiries',\n",
       " 'insinuations',\n",
       " 'insisted',\n",
       " 'installed',\n",
       " 'instigated',\n",
       " 'instructions',\n",
       " 'insulted',\n",
       " 'intends',\n",
       " 'intentions',\n",
       " 'intents',\n",
       " 'interests',\n",
       " 'interposed',\n",
       " 'interspersed',\n",
       " 'intervals',\n",
       " 'interviews',\n",
       " 'intimated',\n",
       " 'introduced',\n",
       " 'introducing',\n",
       " 'intruded',\n",
       " 'invented',\n",
       " 'inventing',\n",
       " 'invitations',\n",
       " 'invited',\n",
       " 'irritated',\n",
       " 'irritates',\n",
       " 'issued',\n",
       " 'jealousies',\n",
       " 'jenning',\n",
       " 'jennings',\n",
       " 'jewels',\n",
       " 'jilting',\n",
       " 'joined',\n",
       " 'joked',\n",
       " 'jokes',\n",
       " 'joking',\n",
       " 'joys',\n",
       " 'judged',\n",
       " 'judging',\n",
       " 'judgments',\n",
       " 'jumbled',\n",
       " 'justified',\n",
       " 'keeps',\n",
       " 'keys',\n",
       " 'kicked',\n",
       " 'kinder',\n",
       " 'kindest',\n",
       " 'kingham',\n",
       " 'kissed',\n",
       " 'kisses',\n",
       " 'knees',\n",
       " 'knives',\n",
       " 'knows',\n",
       " 'laboured',\n",
       " 'lamentations',\n",
       " 'lamps',\n",
       " 'lanes',\n",
       " 'languages',\n",
       " 'larger',\n",
       " 'largest',\n",
       " 'lasted',\n",
       " 'laughed',\n",
       " 'laughs',\n",
       " 'leagued',\n",
       " 'legacies',\n",
       " 'lengthened',\n",
       " 'lengths',\n",
       " 'lessened',\n",
       " 'lessening',\n",
       " 'letters',\n",
       " 'letting',\n",
       " 'lies',\n",
       " 'lifted',\n",
       " 'lightened',\n",
       " 'liked',\n",
       " 'likes',\n",
       " 'limbs',\n",
       " 'limits',\n",
       " 'lines',\n",
       " 'lingered',\n",
       " 'lingering',\n",
       " 'lips',\n",
       " 'listened',\n",
       " 'lives',\n",
       " 'livings',\n",
       " 'll',\n",
       " 'lodges',\n",
       " 'loitered',\n",
       " 'lombardy',\n",
       " 'london',\n",
       " 'longed',\n",
       " 'longest',\n",
       " 'longstaple',\n",
       " 'looked',\n",
       " 'looks',\n",
       " 'loved',\n",
       " 'lovers',\n",
       " 'loves',\n",
       " 'lowered',\n",
       " 'lurking',\n",
       " 'magna',\n",
       " 'maids',\n",
       " 'maintained',\n",
       " 'makes',\n",
       " 'mama',\n",
       " 'managed',\n",
       " 'marlborough',\n",
       " 'marriages',\n",
       " 'marries',\n",
       " 'matters',\n",
       " 'maxims',\n",
       " 'meadows',\n",
       " 'meals',\n",
       " 'means',\n",
       " 'meantime',\n",
       " 'measures',\n",
       " 'medicines',\n",
       " 'meditated',\n",
       " 'meditations',\n",
       " 'meetings',\n",
       " 'mentioned',\n",
       " 'mentioning',\n",
       " 'merest',\n",
       " 'merits',\n",
       " 'merrier',\n",
       " 'messages',\n",
       " 'middleton',\n",
       " 'middletons',\n",
       " 'militated',\n",
       " 'minds',\n",
       " 'minutes',\n",
       " 'misapplied',\n",
       " 'misinformed',\n",
       " 'missed',\n",
       " 'misses',\n",
       " 'mistakes',\n",
       " 'mixing',\n",
       " 'modestest',\n",
       " 'mohrs',\n",
       " 'moments',\n",
       " 'months',\n",
       " 'mosquitoes',\n",
       " 'mothers',\n",
       " 'motives',\n",
       " 'moved',\n",
       " 'murmurings',\n",
       " 'muttered',\n",
       " 'nabobs',\n",
       " 'named',\n",
       " 'names',\n",
       " 'natured',\n",
       " 'nearer',\n",
       " 'needed',\n",
       " 'neglected',\n",
       " 'neighbour',\n",
       " 'neighbourhood',\n",
       " 'neighbouring',\n",
       " 'neighbourly',\n",
       " 'neighbours',\n",
       " 'nerves',\n",
       " 'nests',\n",
       " 'nettles',\n",
       " 'newer',\n",
       " 'newspapers',\n",
       " 'nicest',\n",
       " 'nieces',\n",
       " 'nipped',\n",
       " 'nodded',\n",
       " 'nods',\n",
       " 'noisier',\n",
       " 'notes',\n",
       " 'noticed',\n",
       " 'noticing',\n",
       " 'notions',\n",
       " 'nt',\n",
       " 'nurses',\n",
       " 'obeyed',\n",
       " 'objected',\n",
       " 'objections',\n",
       " 'objects',\n",
       " 'obligations',\n",
       " 'observations',\n",
       " 'observed',\n",
       " 'obstacles',\n",
       " 'obstructed',\n",
       " 'obtained',\n",
       " 'obtaining',\n",
       " 'obviated',\n",
       " 'obviating',\n",
       " 'occasioned',\n",
       " 'occasions',\n",
       " 'occupations',\n",
       " 'occupied',\n",
       " 'occurred',\n",
       " 'oddest',\n",
       " 'offence',\n",
       " 'offences',\n",
       " 'offending',\n",
       " 'offered',\n",
       " 'offices',\n",
       " 'oftener',\n",
       " 'oftenest',\n",
       " 'oldest',\n",
       " 'olives',\n",
       " 'omitted',\n",
       " 'ones',\n",
       " 'opened',\n",
       " 'opinions',\n",
       " 'opportunities',\n",
       " 'ordained',\n",
       " 'orders',\n",
       " 'originated',\n",
       " 'ornamented',\n",
       " 'ornaments',\n",
       " 'others',\n",
       " 'outdone',\n",
       " ...]"
      ]
     },
     "execution_count": 84,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "unusual_words(nltk.corpus.gutenberg.words('austen-sense.txt'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['aaaaaaaaaaaaaaaaa',\n",
       " 'aaahhhh',\n",
       " 'abortions',\n",
       " 'abou',\n",
       " 'abourted',\n",
       " 'abs',\n",
       " 'ack',\n",
       " 'acros',\n",
       " 'actualy',\n",
       " 'adams',\n",
       " 'adds',\n",
       " 'adduser',\n",
       " 'adjusts',\n",
       " 'adoted',\n",
       " 'adreniline',\n",
       " 'ads',\n",
       " 'adults',\n",
       " 'afe',\n",
       " 'affairs',\n",
       " 'affari',\n",
       " 'affects',\n",
       " 'afk',\n",
       " 'agaibn',\n",
       " 'ages',\n",
       " 'aggravated',\n",
       " 'agurlwithbigguns',\n",
       " 'ahah',\n",
       " 'ahahah',\n",
       " 'ahahh',\n",
       " 'ahahha',\n",
       " 'ahh',\n",
       " 'ahhah',\n",
       " 'ahhahahaha',\n",
       " 'ahhh',\n",
       " 'ahhhh',\n",
       " 'ahhhhhh',\n",
       " 'ahhhhhhhhhhhhhh',\n",
       " 'aiiiiiiiiiiiiiiiiiiiiiiii',\n",
       " 'aiken',\n",
       " 'aime',\n",
       " 'akdt',\n",
       " 'akon',\n",
       " 'akron',\n",
       " 'akst',\n",
       " 'aligator',\n",
       " 'allergies',\n",
       " 'allo',\n",
       " 'allowed',\n",
       " 'aloha',\n",
       " 'alohaaa',\n",
       " 'alohas',\n",
       " 'alot',\n",
       " 'alotta',\n",
       " 'alternatives',\n",
       " 'alterz',\n",
       " 'alwys',\n",
       " 'alzheimers',\n",
       " 'amazingness',\n",
       " 'americans',\n",
       " 'anithing',\n",
       " 'ans',\n",
       " 'answering',\n",
       " 'answers',\n",
       " 'antidepressants',\n",
       " 'anygirl',\n",
       " 'anymore',\n",
       " 'anythin',\n",
       " 'anytime',\n",
       " 'anyyyyyyyyyyyyyyyyy',\n",
       " 'aok',\n",
       " 'apoligize',\n",
       " 'appearently',\n",
       " 'appears',\n",
       " 'applaudes',\n",
       " 'appleton',\n",
       " 'appologise',\n",
       " 'appologize',\n",
       " 'aqwesome',\n",
       " 'arggghhh',\n",
       " 'argh',\n",
       " 'armtnpeat',\n",
       " 'arrested',\n",
       " 'arrived',\n",
       " 'arround',\n",
       " 'asked',\n",
       " 'askin',\n",
       " 'asking',\n",
       " 'asks',\n",
       " 'asl',\n",
       " 'asnwer',\n",
       " 'asses',\n",
       " 'asshole',\n",
       " 'assholes',\n",
       " 'asss',\n",
       " 'assumes',\n",
       " 'aterry',\n",
       " 'atl',\n",
       " 'attempted',\n",
       " 'attracted',\n",
       " 'aussies',\n",
       " 'awesomee',\n",
       " 'awesomes',\n",
       " 'awrighty',\n",
       " 'awsome',\n",
       " 'aww',\n",
       " 'awww',\n",
       " 'awwww',\n",
       " 'awwwwww',\n",
       " 'awwwwwww',\n",
       " 'awwwwwwwwww',\n",
       " 'aynawy',\n",
       " 'az',\n",
       " 'azerbaijan',\n",
       " 'baaaaalllllllliiiiiiinnnnnnnnnnn',\n",
       " 'babay',\n",
       " 'babblein',\n",
       " 'babes',\n",
       " 'babies',\n",
       " 'babiess',\n",
       " 'babycakeses',\n",
       " 'bachelorette',\n",
       " 'backatchya',\n",
       " 'backfrontsidewaysandallaroundtheworld',\n",
       " 'backroom',\n",
       " 'bacl',\n",
       " 'bagels',\n",
       " 'bahahahaa',\n",
       " 'bak',\n",
       " 'balad',\n",
       " 'balck',\n",
       " 'ballin',\n",
       " 'balls',\n",
       " 'bandito',\n",
       " 'bandsaw',\n",
       " 'banjoes',\n",
       " 'banned',\n",
       " 'baord',\n",
       " 'barbie',\n",
       " 'barbieee',\n",
       " 'bares',\n",
       " 'barfights',\n",
       " 'barks',\n",
       " 'bbbbbyyyyyyyeeeeeeeee',\n",
       " 'bbiam',\n",
       " 'bbl',\n",
       " 'bbs',\n",
       " 'bc',\n",
       " 'beachhhh',\n",
       " 'beams',\n",
       " 'beans',\n",
       " 'bears',\n",
       " 'beatles',\n",
       " 'beats',\n",
       " 'beattles',\n",
       " 'beckley',\n",
       " 'beeeeehave',\n",
       " 'beeehave',\n",
       " 'bein',\n",
       " 'beleive',\n",
       " 'belongings',\n",
       " 'benz',\n",
       " 'beuty',\n",
       " 'bf',\n",
       " 'bi',\n",
       " 'biatch',\n",
       " 'biebsa',\n",
       " 'bied',\n",
       " 'bigest',\n",
       " 'biiiatch',\n",
       " 'biiiiiitch',\n",
       " 'bikes',\n",
       " 'bio',\n",
       " 'biographys',\n",
       " 'birdgang',\n",
       " 'birfday',\n",
       " 'bishes',\n",
       " 'bitches',\n",
       " 'bitdh',\n",
       " 'bites',\n",
       " 'biyatch',\n",
       " 'bj',\n",
       " 'blankie',\n",
       " 'blazed',\n",
       " 'blech',\n",
       " 'blessings',\n",
       " 'blew',\n",
       " 'bloe',\n",
       " 'blondes',\n",
       " 'bloooooooood',\n",
       " 'bloooooooooood',\n",
       " 'bloooooooooooood',\n",
       " 'blowjob',\n",
       " 'bodies',\n",
       " 'boed',\n",
       " 'boght',\n",
       " 'boi',\n",
       " 'boing',\n",
       " 'boinked',\n",
       " 'bones',\n",
       " 'boning',\n",
       " 'booboo',\n",
       " 'boobs',\n",
       " 'books',\n",
       " 'boooooooooooglyyyyyy',\n",
       " 'bootay',\n",
       " 'booyah',\n",
       " 'borat',\n",
       " 'bored',\n",
       " 'bothering',\n",
       " 'bounced',\n",
       " 'bouncers',\n",
       " 'bouts',\n",
       " 'boyfriend',\n",
       " 'boys',\n",
       " 'boyz',\n",
       " 'brady',\n",
       " 'brakes',\n",
       " 'brb',\n",
       " 'brbbb',\n",
       " 'breaks',\n",
       " 'brightened',\n",
       " 'brings',\n",
       " 'bro',\n",
       " 'brooklyn',\n",
       " 'brothers',\n",
       " 'brrrrrrr',\n",
       " 'bruises',\n",
       " 'brwn',\n",
       " 'btw',\n",
       " 'bucks',\n",
       " 'buddyyyyyy',\n",
       " 'bugs',\n",
       " 'buh',\n",
       " 'builds',\n",
       " 'bulls',\n",
       " 'bumber',\n",
       " 'bumped',\n",
       " 'burger',\n",
       " 'burito',\n",
       " 'burns',\n",
       " 'burpin',\n",
       " 'burps',\n",
       " 'burried',\n",
       " 'burryed',\n",
       " 'buses',\n",
       " 'buying',\n",
       " 'bwahahahahahahahahahaha',\n",
       " 'bwhaha',\n",
       " 'byb',\n",
       " 'byeee',\n",
       " 'byeeee',\n",
       " 'byeeeeeeee',\n",
       " 'byeeeeeeeeeeeee',\n",
       " 'byes',\n",
       " 'caan',\n",
       " 'caint',\n",
       " 'caiuse',\n",
       " 'cakes',\n",
       " 'cali',\n",
       " 'called',\n",
       " 'callifornia',\n",
       " 'calls',\n",
       " 'cams',\n",
       " 'canadaian',\n",
       " 'canadain',\n",
       " 'canehda',\n",
       " 'caps',\n",
       " 'cardinals',\n",
       " 'cardnials',\n",
       " 'cards',\n",
       " 'cares',\n",
       " 'cars',\n",
       " 'casts',\n",
       " 'catches',\n",
       " 'categories',\n",
       " 'catterick',\n",
       " 'caused',\n",
       " 'cdt',\n",
       " 'cepn',\n",
       " 'cereals',\n",
       " 'chamillionaire',\n",
       " 'changed',\n",
       " 'changing',\n",
       " 'chanop',\n",
       " 'chanowner',\n",
       " 'chathide',\n",
       " 'chatland',\n",
       " 'chatr',\n",
       " 'chatroom',\n",
       " 'chats',\n",
       " 'chatt',\n",
       " 'chatted',\n",
       " 'chattin',\n",
       " 'chcken',\n",
       " 'cheaking',\n",
       " 'checkin',\n",
       " 'checking',\n",
       " 'checks',\n",
       " 'cheeeez',\n",
       " 'cheers',\n",
       " 'cheking',\n",
       " 'chews',\n",
       " 'chica',\n",
       " 'chickens',\n",
       " 'chics',\n",
       " 'chik',\n",
       " 'children',\n",
       " 'chineese',\n",
       " 'chingy',\n",
       " 'choc',\n",
       " 'chocha',\n",
       " 'chococake',\n",
       " 'choices',\n",
       " 'chokes',\n",
       " 'chops',\n",
       " 'chp',\n",
       " 'chuckles',\n",
       " 'chunks',\n",
       " 'churches',\n",
       " 'ciao',\n",
       " 'ciara',\n",
       " 'cigars',\n",
       " 'ciggareets',\n",
       " 'ck',\n",
       " 'claws',\n",
       " 'cleared',\n",
       " 'cleveland',\n",
       " 'clicked',\n",
       " 'clients',\n",
       " 'clinicals',\n",
       " 'clooney',\n",
       " 'closes',\n",
       " 'clubs',\n",
       " 'cmon',\n",
       " 'cnnecticut',\n",
       " 'co',\n",
       " 'coconuts',\n",
       " 'coem',\n",
       " 'coffe',\n",
       " 'coggieeee',\n",
       " 'com',\n",
       " 'combo',\n",
       " 'comenting',\n",
       " 'comin',\n",
       " 'commanded',\n",
       " 'comments',\n",
       " 'comon',\n",
       " 'comp',\n",
       " 'complains',\n",
       " 'completly',\n",
       " 'compliments',\n",
       " 'compoud',\n",
       " 'comprende',\n",
       " 'comps',\n",
       " 'computers',\n",
       " 'computor',\n",
       " 'concernin',\n",
       " 'confessed',\n",
       " 'confusing',\n",
       " 'confusting',\n",
       " 'congrat',\n",
       " 'congrats',\n",
       " 'connecticutt',\n",
       " 'constituents',\n",
       " 'contast',\n",
       " 'contemplating',\n",
       " 'controll',\n",
       " 'controllers',\n",
       " 'controllin',\n",
       " 'controlling',\n",
       " 'convo',\n",
       " 'conway',\n",
       " 'cookie',\n",
       " 'cookies',\n",
       " 'coolcat',\n",
       " 'coonarsee',\n",
       " 'cooooooooookiiiiiiiiiiiieeeeeeeeeeee',\n",
       " 'copone',\n",
       " 'cops',\n",
       " 'costumes',\n",
       " 'cottons',\n",
       " 'coudl',\n",
       " 'coughed',\n",
       " 'coughs',\n",
       " 'cougs',\n",
       " 'couldnt',\n",
       " 'counts',\n",
       " 'coupons',\n",
       " 'courst',\n",
       " 'covers',\n",
       " 'coworkers',\n",
       " 'cpr',\n",
       " 'cramps',\n",
       " 'crashed',\n",
       " 'creme',\n",
       " 'cries',\n",
       " 'cripos',\n",
       " 'crosses',\n",
       " 'csi',\n",
       " 'cst',\n",
       " 'ct',\n",
       " 'ctrl',\n",
       " 'cuddlicious',\n",
       " 'cuffed',\n",
       " 'cums',\n",
       " 'cuppers',\n",
       " 'curls',\n",
       " 'currious',\n",
       " 'cus',\n",
       " 'cusion',\n",
       " 'cutes',\n",
       " 'cuz',\n",
       " 'cya',\n",
       " 'cyas',\n",
       " 'cyber',\n",
       " 'czeching',\n",
       " 'daamn',\n",
       " 'dahlin',\n",
       " 'damnit',\n",
       " 'dances',\n",
       " 'danes',\n",
       " 'dangit',\n",
       " 'darlin',\n",
       " 'darlings',\n",
       " 'darwin',\n",
       " 'dat',\n",
       " 'dated',\n",
       " 'daughters',\n",
       " 'daveeee',\n",
       " 'davis',\n",
       " 'dawg',\n",
       " 'dawnstar',\n",
       " 'dayum',\n",
       " 'dd',\n",
       " 'deals',\n",
       " 'deaths',\n",
       " 'decades',\n",
       " 'deceived',\n",
       " 'deciding',\n",
       " 'declaw',\n",
       " 'declawed',\n",
       " 'deeper',\n",
       " 'definately',\n",
       " 'definitley',\n",
       " 'defragging',\n",
       " 'defrags',\n",
       " 'degrees',\n",
       " 'deleware',\n",
       " 'delivers',\n",
       " 'dem',\n",
       " 'democrats',\n",
       " 'denver',\n",
       " 'denzel',\n",
       " 'deop',\n",
       " 'depeche',\n",
       " 'depends',\n",
       " 'descriminate',\n",
       " 'despie',\n",
       " 'despises',\n",
       " 'detroit',\n",
       " 'didnts',\n",
       " 'died',\n",
       " 'dies',\n",
       " 'diggin',\n",
       " 'dik',\n",
       " 'dipset',\n",
       " 'dirrrrty',\n",
       " 'diseast',\n",
       " 'disocvered',\n",
       " 'dissing',\n",
       " 'divorced',\n",
       " 'dj',\n",
       " 'dl',\n",
       " 'dman',\n",
       " 'docs',\n",
       " 'doggies',\n",
       " 'doin',\n",
       " 'dojn',\n",
       " 'dokey',\n",
       " 'dokken',\n",
       " 'dollars',\n",
       " 'dolls',\n",
       " 'donno',\n",
       " 'dontcha',\n",
       " 'donuts',\n",
       " 'dood',\n",
       " 'doody',\n",
       " 'doors',\n",
       " 'dork',\n",
       " 'dotn',\n",
       " 'doublewide',\n",
       " 'douchebag',\n",
       " 'doupt',\n",
       " 'downloaded',\n",
       " 'downloading',\n",
       " 'downnnnnn',\n",
       " 'downs',\n",
       " 'dr',\n",
       " 'drags',\n",
       " 'dratts',\n",
       " 'dreaded',\n",
       " 'dreammm',\n",
       " 'dreams',\n",
       " 'drinks',\n",
       " 'driveby',\n",
       " 'drivers',\n",
       " 'drivin',\n",
       " 'drools',\n",
       " 'dropped',\n",
       " 'drops',\n",
       " 'drugs',\n",
       " 'dryer',\n",
       " 'dsklgjsdk',\n",
       " 'du',\n",
       " 'duh',\n",
       " 'dumbass',\n",
       " 'dummmm',\n",
       " 'dunkin',\n",
       " 'dunno',\n",
       " 'dvd',\n",
       " 'dya',\n",
       " 'dyed',\n",
       " 'dyslexic',\n",
       " 'earplugs',\n",
       " 'earrings',\n",
       " 'ears',\n",
       " 'eay',\n",
       " 'ebay',\n",
       " 'edgewood',\n",
       " 'edmonton',\n",
       " 'eeeeeeeeewwwwwwww',\n",
       " 'eeeek',\n",
       " 'eeek',\n",
       " 'eeekk',\n",
       " 'eeewww',\n",
       " 'eeewwwwww',\n",
       " 'eeww',\n",
       " 'eggs',\n",
       " 'ehh',\n",
       " 'eitther',\n",
       " 'elbows',\n",
       " 'elected',\n",
       " 'elections',\n",
       " 'elev',\n",
       " 'ello',\n",
       " 'elo',\n",
       " 'email',\n",
       " 'eng',\n",
       " 'england',\n",
       " 'enjoys',\n",
       " 'enters',\n",
       " 'entitled',\n",
       " 'enuf',\n",
       " 'enuff',\n",
       " 'ep',\n",
       " 'erics',\n",
       " 'erm',\n",
       " 'eroticaust',\n",
       " 'errrrr',\n",
       " 'escaped',\n",
       " 'est',\n",
       " 'este',\n",
       " 'estefan',\n",
       " 'estra',\n",
       " 'eticket',\n",
       " 'euphamisms',\n",
       " 'evah',\n",
       " 'everbody',\n",
       " 'everone',\n",
       " 'evertonr',\n",
       " 'everytime',\n",
       " 'ewedding',\n",
       " 'eww',\n",
       " 'ewww',\n",
       " 'ewwww',\n",
       " 'ewwwww',\n",
       " 'ewwwwww',\n",
       " 'ewwwwwww',\n",
       " 'exchanged',\n",
       " 'exchanging',\n",
       " 'excitin',\n",
       " 'excuuuuuuse',\n",
       " 'experimenting',\n",
       " 'extensions',\n",
       " 'extras',\n",
       " 'exwife',\n",
       " 'eyes',\n",
       " 'facilitated',\n",
       " 'fails',\n",
       " 'fairbanks',\n",
       " 'fallout',\n",
       " 'falls',\n",
       " 'fallz',\n",
       " 'farms',\n",
       " 'fart',\n",
       " 'farting',\n",
       " 'farts',\n",
       " 'fav',\n",
       " 'fawk',\n",
       " 'fawked',\n",
       " 'fawker',\n",
       " 'fck',\n",
       " 'febe',\n",
       " 'feeds',\n",
       " 'feelings',\n",
       " 'feels',\n",
       " 'feet',\n",
       " 'fella',\n",
       " 'fellows',\n",
       " 'females',\n",
       " 'femine',\n",
       " 'fer',\n",
       " 'fergalicious',\n",
       " 'fergie',\n",
       " 'fetterline',\n",
       " 'fettish',\n",
       " 'ff',\n",
       " 'fiddles',\n",
       " 'files',\n",
       " 'fillin',\n",
       " 'finds',\n",
       " 'finers',\n",
       " 'fingers',\n",
       " 'firs',\n",
       " 'fishercat',\n",
       " 'fishercats',\n",
       " 'fishers',\n",
       " 'fishin',\n",
       " 'fits',\n",
       " 'fkajslf',\n",
       " 'fl',\n",
       " 'flames',\n",
       " 'flashed',\n",
       " 'flattered',\n",
       " 'flatts',\n",
       " 'flavors',\n",
       " 'flippin',\n",
       " 'flirts',\n",
       " 'fliuds',\n",
       " 'flops',\n",
       " 'fluids',\n",
       " 'fock',\n",
       " 'foley',\n",
       " 'folks',\n",
       " 'fongul',\n",
       " 'foothills',\n",
       " 'footprints',\n",
       " 'foreplay',\n",
       " 'forgets',\n",
       " 'forwads',\n",
       " 'foxes',\n",
       " 'foxwoods',\n",
       " 'fractured',\n",
       " 'fragged',\n",
       " 'fraggle',\n",
       " 'frags',\n",
       " 'freaing',\n",
       " 'freaked',\n",
       " 'freakin',\n",
       " 'freaking',\n",
       " 'freaks',\n",
       " 'freeeezinggg',\n",
       " 'freeezinggggg',\n",
       " 'freesbee',\n",
       " 'freind',\n",
       " 'frenchkiss',\n",
       " 'friends',\n",
       " 'fries',\n",
       " 'frm',\n",
       " 'froogle',\n",
       " 'frst',\n",
       " 'frustrating',\n",
       " 'ft',\n",
       " 'fuck',\n",
       " 'fucker',\n",
       " 'fuckin',\n",
       " 'fucking',\n",
       " 'fucks',\n",
       " 'fuddahnut',\n",
       " 'fuked',\n",
       " 'fulfilling',\n",
       " 'futurama',\n",
       " 'fwd',\n",
       " 'gaaaaaaay',\n",
       " 'gagas',\n",
       " 'gags',\n",
       " 'gained',\n",
       " 'gals',\n",
       " 'gamefly',\n",
       " 'games',\n",
       " 'garciae',\n",
       " 'gaspppp',\n",
       " 'gawd',\n",
       " 'gayoholic',\n",
       " 'gays',\n",
       " 'geeks',\n",
       " 'gees',\n",
       " 'geesh',\n",
       " 'geeshh',\n",
       " 'geeshhh',\n",
       " 'geessh',\n",
       " 'geeze',\n",
       " 'gente',\n",
       " 'gentlemen',\n",
       " 'gets',\n",
       " 'gettign',\n",
       " 'gettin',\n",
       " 'gettysburg',\n",
       " 'gezzz',\n",
       " 'gf',\n",
       " 'gguyyyzzzz',\n",
       " 'ghet',\n",
       " 'giggles',\n",
       " 'girlfriend',\n",
       " 'girls',\n",
       " 'giva',\n",
       " 'gives',\n",
       " 'givs',\n",
       " 'glitches',\n",
       " 'gm',\n",
       " 'gn',\n",
       " 'gng',\n",
       " 'goddamn',\n",
       " 'goin',\n",
       " 'goneee',\n",
       " 'gonna',\n",
       " 'goodbye',\n",
       " 'goodie',\n",
       " 'goodnight',\n",
       " 'goodnite',\n",
       " 'google',\n",
       " 'gooo',\n",
       " 'goooooo',\n",
       " 'gorda',\n",
       " 'gotaa',\n",
       " 'goths',\n",
       " 'gotta',\n",
       " 'gottsa',\n",
       " 'grabs',\n",
       " 'gracemont',\n",
       " 'grea',\n",
       " 'greetings',\n",
       " 'gret',\n",
       " 'grettings',\n",
       " 'grilfriend',\n",
       " 'grins',\n",
       " 'gritt',\n",
       " 'grlz',\n",
       " 'groups',\n",
       " 'grrl',\n",
       " 'grrr',\n",
       " 'grrrrrring',\n",
       " 'grrrrrrrr',\n",
       " 'grrrrrrrrr',\n",
       " 'grrrrrrrrrrrrrrrrr',\n",
       " 'gs',\n",
       " 'gtg',\n",
       " 'guns',\n",
       " 'gurlie',\n",
       " 'gurls',\n",
       " 'gurrrrl',\n",
       " 'guts',\n",
       " 'guys',\n",
       " 'guyz',\n",
       " 'guyzz',\n",
       " 'haaa',\n",
       " 'hafta',\n",
       " 'haha',\n",
       " 'hahaaa',\n",
       " 'hahaaaa',\n",
       " 'hahah',\n",
       " 'hahaha',\n",
       " 'hahahaa',\n",
       " 'hahahah',\n",
       " 'hahahaha',\n",
       " 'hahahahaaa',\n",
       " 'hahahahahaha',\n",
       " 'hahahahahahaha',\n",
       " 'hahahahahahahahahahahahahahahaha',\n",
       " 'hahahhahah',\n",
       " 'hahhaa',\n",
       " 'hahhahahaha',\n",
       " 'hairs',\n",
       " 'halfa',\n",
       " 'hallo',\n",
       " 'handheld',\n",
       " 'handing',\n",
       " 'hands',\n",
       " 'handyman',\n",
       " 'hang',\n",
       " 'hangin',\n",
       " 'hangs',\n",
       " 'happend',\n",
       " 'happened',\n",
       " 'happens',\n",
       " 'happpy',\n",
       " 'harley',\n",
       " 'hartford',\n",
       " 'has',\n",
       " 'haters',\n",
       " 'hates',\n",
       " 'hav',\n",
       " 'havin',\n",
       " 'having',\n",
       " 'hawaii',\n",
       " 'hawt',\n",
       " 'hb',\n",
       " 'headach',\n",
       " 'headlights',\n",
       " 'heads',\n",
       " 'heard',\n",
       " 'hearin',\n",
       " 'hearthechatters',\n",
       " 'heee',\n",
       " 'heeee',\n",
       " 'heeeey',\n",
       " 'heeheeheeheeheehee',\n",
       " 'heh',\n",
       " 'heheh',\n",
       " 'hehehe',\n",
       " 'hehehee',\n",
       " 'hehehehe',\n",
       " 'hel',\n",
       " 'helloooo',\n",
       " 'hellos',\n",
       " 'helped',\n",
       " 'hendrix',\n",
       " 'heroes',\n",
       " 'hertory',\n",
       " 'hes',\n",
       " 'heya',\n",
       " 'heyheyhey',\n",
       " 'heys',\n",
       " 'heyy',\n",
       " 'heyyy',\n",
       " 'heyyyy',\n",
       " 'heyyyyy',\n",
       " 'heyyyyyy',\n",
       " 'heyyyyyyy',\n",
       " 'heyyyyyyyy',\n",
       " 'heyyyyyyyyy',\n",
       " 'heyyyyyyyyyy',\n",
       " 'heyyyyyyyyyyyyyy',\n",
       " 'hfglhs',\n",
       " 'hgey',\n",
       " 'hgfhgfjgf',\n",
       " 'hhaaaaatttee',\n",
       " 'hheeyy',\n",
       " 'hheeyyy',\n",
       " 'hheeyyyyyyyyyyyyyyyyyyyyyyyyyyyyyyyyyyyyyyyyyyyyyyy',\n",
       " 'hhehe',\n",
       " 'hiding',\n",
       " 'hih',\n",
       " 'hii',\n",
       " 'hiii',\n",
       " 'hiiii',\n",
       " 'hio',\n",
       " 'hiom',\n",
       " 'hissy',\n",
       " 'hits',\n",
       " 'hitting',\n",
       " 'hix',\n",
       " 'hiy',\n",
       " 'hiya',\n",
       " 'hiyas',\n",
       " 'hm',\n",
       " 'hmm',\n",
       " 'hmmm',\n",
       " 'hmmmm',\n",
       " 'hmmmmm',\n",
       " 'hmmmmmmm',\n",
       " 'hmmmmmmmm',\n",
       " 'hmmmmmmmmmm',\n",
       " 'hmph',\n",
       " 'hogs',\n",
       " 'hohohohhohhoo',\n",
       " 'hola',\n",
       " 'holdin',\n",
       " 'holds',\n",
       " 'holocaustyourmom',\n",
       " 'hom',\n",
       " 'homeade',\n",
       " 'homeboys',\n",
       " 'homes',\n",
       " 'homies',\n",
       " 'homophobic',\n",
       " 'hoo',\n",
       " 'hooo',\n",
       " 'hooooo',\n",
       " 'hopin',\n",
       " 'hoping',\n",
       " 'horace',\n",
       " 'horriable',\n",
       " 'horrified',\n",
       " 'hots',\n",
       " 'hott',\n",
       " 'hottie',\n",
       " 'hotties',\n",
       " 'hours',\n",
       " 'houses',\n",
       " 'hows',\n",
       " 'howz',\n",
       " 'hpa',\n",
       " 'hr',\n",
       " 'hrs',\n",
       " 'http',\n",
       " 'hubbys',\n",
       " 'hugggs',\n",
       " 'huggs',\n",
       " 'huggss',\n",
       " 'hugs',\n",
       " 'hugss',\n",
       " 'hugsss',\n",
       " 'hugsssss',\n",
       " 'hugsssssssss',\n",
       " 'hugzzzzzzz',\n",
       " 'humm',\n",
       " 'hummmm',\n",
       " 'humple',\n",
       " 'hunters',\n",
       " 'huskers',\n",
       " 'husteling',\n",
       " 'huuuuuuuuuuuuuuuuuuuuuuuuuuuuuuuuuuugz',\n",
       " 'hx',\n",
       " 'hyy',\n",
       " 'iamahotnip',\n",
       " 'iamahotniplickme',\n",
       " 'iamahotnipwithhotnippics',\n",
       " 'iamahotnipwithpics',\n",
       " 'icky',\n",
       " 'ico',\n",
       " 'idiots',\n",
       " 'idnt',\n",
       " 'ifr',\n",
       " 'ignored',\n",
       " 'ignoring',\n",
       " 'ihavehotnips',\n",
       " 'ii',\n",
       " 'il',\n",
       " 'illin',\n",
       " 'im',\n",
       " 'images',\n",
       " 'imhave',\n",
       " 'imma',\n",
       " 'immersed',\n",
       " 'impaired',\n",
       " 'impared',\n",
       " 'impressed',\n",
       " 'indiantown',\n",
       " 'infor',\n",
       " 'inhales',\n",
       " 'injureis',\n",
       " 'innit',\n",
       " 'innocense',\n",
       " 'insuklting',\n",
       " 'internet',\n",
       " 'intersting',\n",
       " 'invisiable',\n",
       " 'involves',\n",
       " 'irc',\n",
       " 'irl',\n",
       " 'isnt',\n",
       " 'issues',\n",
       " 'italians',\n",
       " 'italy',\n",
       " 'itches',\n",
       " 'items',\n",
       " 'itz',\n",
       " 'ive',\n",
       " 'iz',\n",
       " 'ja',\n",
       " 'jackie',\n",
       " 'jacking',\n",
       " 'jajajaaa',\n",
       " 'jammed',\n",
       " 'jammers',\n",
       " 'jammies',\n",
       " 'jayse',\n",
       " 'jerimiah',\n",
       " 'jerkettes',\n",
       " 'jerketts',\n",
       " 'jerks',\n",
       " 'jeter',\n",
       " 'jk',\n",
       " 'johnson',\n",
       " 'johny',\n",
       " 'joined',\n",
       " 'jokes',\n",
       " 'joking',\n",
       " 'jonesboro',\n",
       " 'jordison',\n",
       " 'joshy',\n",
       " 'jr',\n",
       " 'jrz',\n",
       " 'jto',\n",
       " 'jucilicious',\n",
       " 'judges',\n",
       " 'jujubees',\n",
       " 'jumpin',\n",
       " 'jumps',\n",
       " ...]"
      ]
     },
     "execution_count": 85,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "unusual_words(nltk.corpus.nps_chat.words())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['i',\n",
       " 'me',\n",
       " 'my',\n",
       " 'myself',\n",
       " 'we',\n",
       " 'our',\n",
       " 'ours',\n",
       " 'ourselves',\n",
       " 'you',\n",
       " \"you're\",\n",
       " \"you've\",\n",
       " \"you'll\",\n",
       " \"you'd\",\n",
       " 'your',\n",
       " 'yours',\n",
       " 'yourself',\n",
       " 'yourselves',\n",
       " 'he',\n",
       " 'him',\n",
       " 'his',\n",
       " 'himself',\n",
       " 'she',\n",
       " \"she's\",\n",
       " 'her',\n",
       " 'hers',\n",
       " 'herself',\n",
       " 'it',\n",
       " \"it's\",\n",
       " 'its',\n",
       " 'itself',\n",
       " 'they',\n",
       " 'them',\n",
       " 'their',\n",
       " 'theirs',\n",
       " 'themselves',\n",
       " 'what',\n",
       " 'which',\n",
       " 'who',\n",
       " 'whom',\n",
       " 'this',\n",
       " 'that',\n",
       " \"that'll\",\n",
       " 'these',\n",
       " 'those',\n",
       " 'am',\n",
       " 'is',\n",
       " 'are',\n",
       " 'was',\n",
       " 'were',\n",
       " 'be',\n",
       " 'been',\n",
       " 'being',\n",
       " 'have',\n",
       " 'has',\n",
       " 'had',\n",
       " 'having',\n",
       " 'do',\n",
       " 'does',\n",
       " 'did',\n",
       " 'doing',\n",
       " 'a',\n",
       " 'an',\n",
       " 'the',\n",
       " 'and',\n",
       " 'but',\n",
       " 'if',\n",
       " 'or',\n",
       " 'because',\n",
       " 'as',\n",
       " 'until',\n",
       " 'while',\n",
       " 'of',\n",
       " 'at',\n",
       " 'by',\n",
       " 'for',\n",
       " 'with',\n",
       " 'about',\n",
       " 'against',\n",
       " 'between',\n",
       " 'into',\n",
       " 'through',\n",
       " 'during',\n",
       " 'before',\n",
       " 'after',\n",
       " 'above',\n",
       " 'below',\n",
       " 'to',\n",
       " 'from',\n",
       " 'up',\n",
       " 'down',\n",
       " 'in',\n",
       " 'out',\n",
       " 'on',\n",
       " 'off',\n",
       " 'over',\n",
       " 'under',\n",
       " 'again',\n",
       " 'further',\n",
       " 'then',\n",
       " 'once',\n",
       " 'here',\n",
       " 'there',\n",
       " 'when',\n",
       " 'where',\n",
       " 'why',\n",
       " 'how',\n",
       " 'all',\n",
       " 'any',\n",
       " 'both',\n",
       " 'each',\n",
       " 'few',\n",
       " 'more',\n",
       " 'most',\n",
       " 'other',\n",
       " 'some',\n",
       " 'such',\n",
       " 'no',\n",
       " 'nor',\n",
       " 'not',\n",
       " 'only',\n",
       " 'own',\n",
       " 'same',\n",
       " 'so',\n",
       " 'than',\n",
       " 'too',\n",
       " 'very',\n",
       " 's',\n",
       " 't',\n",
       " 'can',\n",
       " 'will',\n",
       " 'just',\n",
       " 'don',\n",
       " \"don't\",\n",
       " 'should',\n",
       " \"should've\",\n",
       " 'now',\n",
       " 'd',\n",
       " 'll',\n",
       " 'm',\n",
       " 'o',\n",
       " 're',\n",
       " 've',\n",
       " 'y',\n",
       " 'ain',\n",
       " 'aren',\n",
       " \"aren't\",\n",
       " 'couldn',\n",
       " \"couldn't\",\n",
       " 'didn',\n",
       " \"didn't\",\n",
       " 'doesn',\n",
       " \"doesn't\",\n",
       " 'hadn',\n",
       " \"hadn't\",\n",
       " 'hasn',\n",
       " \"hasn't\",\n",
       " 'haven',\n",
       " \"haven't\",\n",
       " 'isn',\n",
       " \"isn't\",\n",
       " 'ma',\n",
       " 'mightn',\n",
       " \"mightn't\",\n",
       " 'mustn',\n",
       " \"mustn't\",\n",
       " 'needn',\n",
       " \"needn't\",\n",
       " 'shan',\n",
       " \"shan't\",\n",
       " 'shouldn',\n",
       " \"shouldn't\",\n",
       " 'wasn',\n",
       " \"wasn't\",\n",
       " 'weren',\n",
       " \"weren't\",\n",
       " 'won',\n",
       " \"won't\",\n",
       " 'wouldn',\n",
       " \"wouldn't\"]"
      ]
     },
     "execution_count": 86,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from nltk.corpus import stopwords\n",
    "## Stopwords usually have little lexical content, and their presence in a text fails to distinguish it from other texts.\n",
    "stopwords.words('english')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.735240435097661"
      ]
     },
     "execution_count": 87,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# a function to compute what fraction of words in a text are not in the stopwords list:\n",
    "def content_fraction(text):\n",
    "    stopwords = nltk.corpus.stopwords.words('english')\n",
    "    content = [w for w in text if w.lower() not in stopwords]\n",
    "    return len(content) / len(text)\n",
    "\n",
    "content_fraction(nltk.corpus.reuters.words())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['glover',\n",
       " 'gorlin',\n",
       " 'govern',\n",
       " 'grovel',\n",
       " 'ignore',\n",
       " 'involver',\n",
       " 'lienor',\n",
       " 'linger',\n",
       " 'longer',\n",
       " 'lovering',\n",
       " 'noiler',\n",
       " 'overling',\n",
       " 'region',\n",
       " 'renvoi',\n",
       " 'revolving',\n",
       " 'ringle',\n",
       " 'roving',\n",
       " 'violer',\n",
       " 'virole']"
      ]
     },
     "execution_count": 88,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# How many words of 4 lettters or more can you make from 'egivrvonl'? \n",
    "# Each letter may be used once per word.\n",
    "# Each word must contain the letter 'r' and there must be at least one 6-letter word.\n",
    "# No plurals ending in 's'; no foreign words; no proper names.\n",
    "puzzle_letters = nltk.FreqDist('egivrvonl')\n",
    "obligatory = 'r'\n",
    "wordlist = nltk.corpus.words.words()\n",
    "[w for w in wordlist if len(w) >= 6\n",
    " and obligatory in w \n",
    " and nltk.FreqDist(w) <= puzzle_letters] "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['female.txt', 'male.txt']"
      ]
     },
     "execution_count": 89,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "names = nltk.corpus.names\n",
    "names.fileids()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Abbey',\n",
       " 'Abbie',\n",
       " 'Abby',\n",
       " 'Addie',\n",
       " 'Adrian',\n",
       " 'Adrien',\n",
       " 'Ajay',\n",
       " 'Alex',\n",
       " 'Alexis',\n",
       " 'Alfie',\n",
       " 'Ali',\n",
       " 'Alix',\n",
       " 'Allie',\n",
       " 'Allyn',\n",
       " 'Andie',\n",
       " 'Andrea',\n",
       " 'Andy',\n",
       " 'Angel',\n",
       " 'Angie',\n",
       " 'Ariel',\n",
       " 'Ashley',\n",
       " 'Aubrey',\n",
       " 'Augustine',\n",
       " 'Austin',\n",
       " 'Averil',\n",
       " 'Barrie',\n",
       " 'Barry',\n",
       " 'Beau',\n",
       " 'Bennie',\n",
       " 'Benny',\n",
       " 'Bernie',\n",
       " 'Bert',\n",
       " 'Bertie',\n",
       " 'Bill',\n",
       " 'Billie',\n",
       " 'Billy',\n",
       " 'Blair',\n",
       " 'Blake',\n",
       " 'Bo',\n",
       " 'Bobbie',\n",
       " 'Bobby',\n",
       " 'Brandy',\n",
       " 'Brett',\n",
       " 'Britt',\n",
       " 'Brook',\n",
       " 'Brooke',\n",
       " 'Brooks',\n",
       " 'Bryn',\n",
       " 'Cal',\n",
       " 'Cam',\n",
       " 'Cammy',\n",
       " 'Carey',\n",
       " 'Carlie',\n",
       " 'Carlin',\n",
       " 'Carmine',\n",
       " 'Carroll',\n",
       " 'Cary',\n",
       " 'Caryl',\n",
       " 'Casey',\n",
       " 'Cass',\n",
       " 'Cat',\n",
       " 'Cecil',\n",
       " 'Chad',\n",
       " 'Chris',\n",
       " 'Chrissy',\n",
       " 'Christian',\n",
       " 'Christie',\n",
       " 'Christy',\n",
       " 'Clair',\n",
       " 'Claire',\n",
       " 'Clare',\n",
       " 'Claude',\n",
       " 'Clem',\n",
       " 'Clemmie',\n",
       " 'Cody',\n",
       " 'Connie',\n",
       " 'Constantine',\n",
       " 'Corey',\n",
       " 'Corrie',\n",
       " 'Cory',\n",
       " 'Courtney',\n",
       " 'Cris',\n",
       " 'Daffy',\n",
       " 'Dale',\n",
       " 'Dallas',\n",
       " 'Dana',\n",
       " 'Dani',\n",
       " 'Daniel',\n",
       " 'Dannie',\n",
       " 'Danny',\n",
       " 'Darby',\n",
       " 'Darcy',\n",
       " 'Darryl',\n",
       " 'Daryl',\n",
       " 'Deane',\n",
       " 'Del',\n",
       " 'Dell',\n",
       " 'Demetris',\n",
       " 'Dennie',\n",
       " 'Denny',\n",
       " 'Devin',\n",
       " 'Devon',\n",
       " 'Dion',\n",
       " 'Dionis',\n",
       " 'Dominique',\n",
       " 'Donnie',\n",
       " 'Donny',\n",
       " 'Dorian',\n",
       " 'Dory',\n",
       " 'Drew',\n",
       " 'Eddie',\n",
       " 'Eddy',\n",
       " 'Edie',\n",
       " 'Elisha',\n",
       " 'Emmy',\n",
       " 'Erin',\n",
       " 'Esme',\n",
       " 'Evelyn',\n",
       " 'Felice',\n",
       " 'Fran',\n",
       " 'Francis',\n",
       " 'Frank',\n",
       " 'Frankie',\n",
       " 'Franky',\n",
       " 'Fred',\n",
       " 'Freddie',\n",
       " 'Freddy',\n",
       " 'Gabriel',\n",
       " 'Gabriell',\n",
       " 'Gail',\n",
       " 'Gale',\n",
       " 'Gay',\n",
       " 'Gayle',\n",
       " 'Gene',\n",
       " 'George',\n",
       " 'Georgia',\n",
       " 'Georgie',\n",
       " 'Geri',\n",
       " 'Germaine',\n",
       " 'Gerri',\n",
       " 'Gerry',\n",
       " 'Gill',\n",
       " 'Ginger',\n",
       " 'Glen',\n",
       " 'Glenn',\n",
       " 'Grace',\n",
       " 'Gretchen',\n",
       " 'Gus',\n",
       " 'Haleigh',\n",
       " 'Haley',\n",
       " 'Hannibal',\n",
       " 'Harley',\n",
       " 'Hazel',\n",
       " 'Heath',\n",
       " 'Henrie',\n",
       " 'Hilary',\n",
       " 'Hillary',\n",
       " 'Holly',\n",
       " 'Ike',\n",
       " 'Ikey',\n",
       " 'Ira',\n",
       " 'Isa',\n",
       " 'Isador',\n",
       " 'Isadore',\n",
       " 'Jackie',\n",
       " 'Jaime',\n",
       " 'Jamie',\n",
       " 'Jan',\n",
       " 'Jean',\n",
       " 'Jere',\n",
       " 'Jermaine',\n",
       " 'Jerrie',\n",
       " 'Jerry',\n",
       " 'Jess',\n",
       " 'Jesse',\n",
       " 'Jessie',\n",
       " 'Jo',\n",
       " 'Jodi',\n",
       " 'Jodie',\n",
       " 'Jody',\n",
       " 'Joey',\n",
       " 'Jordan',\n",
       " 'Juanita',\n",
       " 'Jude',\n",
       " 'Judith',\n",
       " 'Judy',\n",
       " 'Julie',\n",
       " 'Justin',\n",
       " 'Karel',\n",
       " 'Kellen',\n",
       " 'Kelley',\n",
       " 'Kelly',\n",
       " 'Kelsey',\n",
       " 'Kerry',\n",
       " 'Kim',\n",
       " 'Kip',\n",
       " 'Kirby',\n",
       " 'Kit',\n",
       " 'Kris',\n",
       " 'Kyle',\n",
       " 'Lane',\n",
       " 'Lanny',\n",
       " 'Lauren',\n",
       " 'Laurie',\n",
       " 'Lee',\n",
       " 'Leigh',\n",
       " 'Leland',\n",
       " 'Lesley',\n",
       " 'Leslie',\n",
       " 'Lin',\n",
       " 'Lind',\n",
       " 'Lindsay',\n",
       " 'Lindsey',\n",
       " 'Lindy',\n",
       " 'Lonnie',\n",
       " 'Loren',\n",
       " 'Lorne',\n",
       " 'Lorrie',\n",
       " 'Lou',\n",
       " 'Luce',\n",
       " 'Lyn',\n",
       " 'Lynn',\n",
       " 'Maddie',\n",
       " 'Maddy',\n",
       " 'Marietta',\n",
       " 'Marion',\n",
       " 'Marlo',\n",
       " 'Martie',\n",
       " 'Marty',\n",
       " 'Mattie',\n",
       " 'Matty',\n",
       " 'Maurise',\n",
       " 'Max',\n",
       " 'Maxie',\n",
       " 'Mead',\n",
       " 'Meade',\n",
       " 'Mel',\n",
       " 'Meredith',\n",
       " 'Merle',\n",
       " 'Merrill',\n",
       " 'Merry',\n",
       " 'Meryl',\n",
       " 'Michal',\n",
       " 'Michel',\n",
       " 'Michele',\n",
       " 'Mickie',\n",
       " 'Micky',\n",
       " 'Millicent',\n",
       " 'Morgan',\n",
       " 'Morlee',\n",
       " 'Muffin',\n",
       " 'Nat',\n",
       " 'Nichole',\n",
       " 'Nickie',\n",
       " 'Nicky',\n",
       " 'Niki',\n",
       " 'Nikki',\n",
       " 'Noel',\n",
       " 'Ollie',\n",
       " 'Page',\n",
       " 'Paige',\n",
       " 'Pat',\n",
       " 'Patrice',\n",
       " 'Patsy',\n",
       " 'Pattie',\n",
       " 'Patty',\n",
       " 'Pen',\n",
       " 'Pennie',\n",
       " 'Penny',\n",
       " 'Perry',\n",
       " 'Phil',\n",
       " 'Pooh',\n",
       " 'Quentin',\n",
       " 'Quinn',\n",
       " 'Randi',\n",
       " 'Randie',\n",
       " 'Randy',\n",
       " 'Ray',\n",
       " 'Regan',\n",
       " 'Reggie',\n",
       " 'Rene',\n",
       " 'Rey',\n",
       " 'Ricki',\n",
       " 'Rickie',\n",
       " 'Ricky',\n",
       " 'Rikki',\n",
       " 'Robbie',\n",
       " 'Robin',\n",
       " 'Ronnie',\n",
       " 'Ronny',\n",
       " 'Rory',\n",
       " 'Ruby',\n",
       " 'Sal',\n",
       " 'Sam',\n",
       " 'Sammy',\n",
       " 'Sandy',\n",
       " 'Sascha',\n",
       " 'Sasha',\n",
       " 'Saundra',\n",
       " 'Sayre',\n",
       " 'Scotty',\n",
       " 'Sean',\n",
       " 'Shaine',\n",
       " 'Shane',\n",
       " 'Shannon',\n",
       " 'Shaun',\n",
       " 'Shawn',\n",
       " 'Shay',\n",
       " 'Shayne',\n",
       " 'Shea',\n",
       " 'Shelby',\n",
       " 'Shell',\n",
       " 'Shelley',\n",
       " 'Sibyl',\n",
       " 'Simone',\n",
       " 'Sonnie',\n",
       " 'Sonny',\n",
       " 'Stacy',\n",
       " 'Sunny',\n",
       " 'Sydney',\n",
       " 'Tabbie',\n",
       " 'Tabby',\n",
       " 'Tallie',\n",
       " 'Tally',\n",
       " 'Tammie',\n",
       " 'Tammy',\n",
       " 'Tate',\n",
       " 'Ted',\n",
       " 'Teddie',\n",
       " 'Teddy',\n",
       " 'Terri',\n",
       " 'Terry',\n",
       " 'Theo',\n",
       " 'Tim',\n",
       " 'Timmie',\n",
       " 'Timmy',\n",
       " 'Tobe',\n",
       " 'Tobie',\n",
       " 'Toby',\n",
       " 'Tommie',\n",
       " 'Tommy',\n",
       " 'Tony',\n",
       " 'Torey',\n",
       " 'Trace',\n",
       " 'Tracey',\n",
       " 'Tracie',\n",
       " 'Tracy',\n",
       " 'Val',\n",
       " 'Vale',\n",
       " 'Valentine',\n",
       " 'Van',\n",
       " 'Vin',\n",
       " 'Vinnie',\n",
       " 'Vinny',\n",
       " 'Virgie',\n",
       " 'Wallie',\n",
       " 'Wallis',\n",
       " 'Wally',\n",
       " 'Whitney',\n",
       " 'Willi',\n",
       " 'Willie',\n",
       " 'Willy',\n",
       " 'Winnie',\n",
       " 'Winny',\n",
       " 'Wynn']"
      ]
     },
     "execution_count": 90,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "male_names = names.words('male.txt')\n",
    "female_names = names.words('female.txt')\n",
    "[w for w in male_names if w in female_names]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<matplotlib.axes._subplots.AxesSubplot at 0x1f4d749cb08>"
      ]
     },
     "execution_count": 91,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cfd = nltk.ConditionalFreqDist(\n",
    "    (fileid, name[-1])\n",
    "    for fileid in names.fileids()\n",
    "    for name in names.words(fileid))\n",
    "cfd.plot()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4.2   A Pronouncing Dictionary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "133737"
      ]
     },
     "execution_count": 92,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "entries = nltk.corpus.cmudict.entries()\n",
    "len(entries)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "('fir', ['F', 'ER1'])\n",
      "('fire', ['F', 'AY1', 'ER0'])\n",
      "('fire', ['F', 'AY1', 'R'])\n",
      "('firearm', ['F', 'AY1', 'ER0', 'AA2', 'R', 'M'])\n",
      "('firearm', ['F', 'AY1', 'R', 'AA2', 'R', 'M'])\n",
      "('firearms', ['F', 'AY1', 'ER0', 'AA2', 'R', 'M', 'Z'])\n",
      "('firearms', ['F', 'AY1', 'R', 'AA2', 'R', 'M', 'Z'])\n",
      "('fireball', ['F', 'AY1', 'ER0', 'B', 'AO2', 'L'])\n"
     ]
    }
   ],
   "source": [
    "for entry in entries[42371:42379]:\n",
    "    print(entry)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "pait EY1 pat AE1 pate EY1 patt AE1 peart ER1 peat IY1 peet IY1 peete IY1 pert ER1 pet EH1 pete IY1 pett EH1 piet IY1 piette IY1 pit IH1 pitt IH1 pot AA1 pote OW1 pott AA1 pout AW1 puett UW1 purt ER1 put UH1 putt AH1 "
     ]
    }
   ],
   "source": [
    "for word, pron in entries: \n",
    "    if len(pron) == 3: \n",
    "        ph1, ph2, ph3 = pron \n",
    "        if ph1 == 'P' and ph3 == 'T':\n",
    "            print(word, ph2, end=' ')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[\"atlantic's\",\n",
       " 'audiotronics',\n",
       " 'avionics',\n",
       " 'beatniks',\n",
       " 'calisthenics',\n",
       " 'centronics',\n",
       " 'chamonix',\n",
       " 'chetniks',\n",
       " \"clinic's\",\n",
       " 'clinics',\n",
       " 'conics',\n",
       " 'conics',\n",
       " 'cryogenics',\n",
       " 'cynics',\n",
       " 'diasonics',\n",
       " \"dominic's\",\n",
       " 'ebonics',\n",
       " 'electronics',\n",
       " \"electronics'\",\n",
       " \"endotronics'\",\n",
       " 'endotronics',\n",
       " 'enix',\n",
       " 'environics',\n",
       " 'ethnics',\n",
       " 'eugenics',\n",
       " 'fibronics',\n",
       " 'flextronics',\n",
       " 'harmonics',\n",
       " 'hispanics',\n",
       " 'histrionics',\n",
       " 'identics',\n",
       " 'ionics',\n",
       " 'kibbutzniks',\n",
       " 'lasersonics',\n",
       " 'lumonics',\n",
       " 'mannix',\n",
       " 'mechanics',\n",
       " \"mechanics'\",\n",
       " 'microelectronics',\n",
       " 'minix',\n",
       " 'minnix',\n",
       " 'mnemonics',\n",
       " 'mnemonics',\n",
       " 'molonicks',\n",
       " 'mullenix',\n",
       " 'mullenix',\n",
       " 'mullinix',\n",
       " 'mulnix',\n",
       " \"munich's\",\n",
       " 'nucleonics',\n",
       " 'onyx',\n",
       " 'organics',\n",
       " \"panic's\",\n",
       " 'panics',\n",
       " 'penix',\n",
       " 'pennix',\n",
       " 'personics',\n",
       " 'phenix',\n",
       " \"philharmonic's\",\n",
       " 'phoenix',\n",
       " 'phonics',\n",
       " 'photronics',\n",
       " 'pinnix',\n",
       " 'plantronics',\n",
       " 'pyrotechnics',\n",
       " 'refuseniks',\n",
       " \"resnick's\",\n",
       " 'respironics',\n",
       " 'sconnix',\n",
       " 'siliconix',\n",
       " 'skolniks',\n",
       " 'sonics',\n",
       " 'sputniks',\n",
       " 'technics',\n",
       " 'tectonics',\n",
       " 'tektronix',\n",
       " 'telectronics',\n",
       " 'telephonics',\n",
       " 'tonics',\n",
       " 'unix',\n",
       " \"vinick's\",\n",
       " \"vinnick's\",\n",
       " 'vitronics']"
      ]
     },
     "execution_count": 95,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "syllable = ['N', 'IH0', 'K', 'S']\n",
    "[word for word, pron in entries if pron[-4:] == syllable]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['autumn', 'column', 'condemn', 'damn', 'goddamn', 'hymn', 'solemn']"
      ]
     },
     "execution_count": 96,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "[w for w, pron in entries if pron[-1] == 'M' and w[-1] == 'n']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['gn', 'kn', 'mn', 'pn']"
      ]
     },
     "execution_count": 97,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sorted(set(w[:2] for w, pron in entries if pron[0] == 'N' and w[0] != 'n'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['abbreviated',\n",
       " 'abbreviated',\n",
       " 'abbreviating',\n",
       " 'accelerated',\n",
       " 'accelerating',\n",
       " 'accelerator',\n",
       " 'accelerators',\n",
       " 'accentuated',\n",
       " 'accentuating',\n",
       " 'accommodated',\n",
       " 'accommodating',\n",
       " 'accommodative',\n",
       " 'accumulated',\n",
       " 'accumulating',\n",
       " 'accumulative',\n",
       " 'accumulator',\n",
       " 'accumulators',\n",
       " 'accusatory',\n",
       " 'adenovirus',\n",
       " 'adjudicated',\n",
       " 'adjudicating',\n",
       " 'administrating',\n",
       " 'administrative',\n",
       " 'administrator',\n",
       " \"administrators'\",\n",
       " \"administrator's\",\n",
       " 'administrators',\n",
       " 'adulterated',\n",
       " 'adventurism',\n",
       " 'adventurism',\n",
       " 'affiliated',\n",
       " 'affiliated',\n",
       " \"affiliated's\",\n",
       " 'affiliating',\n",
       " 'alleviated',\n",
       " 'alleviated',\n",
       " 'alleviating',\n",
       " 'alliteration',\n",
       " 'alliterative',\n",
       " 'amalgamated',\n",
       " \"amalgamated's\",\n",
       " 'amalgamating',\n",
       " 'ameliorated',\n",
       " 'ameridata',\n",
       " 'amoxicillin',\n",
       " 'anachronism',\n",
       " 'anachronisms',\n",
       " 'annihilated',\n",
       " 'annihilating',\n",
       " 'antagonism',\n",
       " 'antagonisms',\n",
       " 'antagonizing',\n",
       " 'anticipated',\n",
       " 'anticipated',\n",
       " 'anticipating',\n",
       " 'apologizes',\n",
       " 'apologizing',\n",
       " 'apothecary',\n",
       " 'appreciated',\n",
       " 'appreciating',\n",
       " 'appreciative',\n",
       " 'appropriated',\n",
       " 'appropriating',\n",
       " 'appropriator',\n",
       " 'appropriators',\n",
       " 'approximated',\n",
       " 'approximating',\n",
       " 'articulated',\n",
       " 'articulating',\n",
       " 'asphyxiated',\n",
       " 'asphyxiating',\n",
       " 'assassinated',\n",
       " 'assassinating',\n",
       " 'assemblywoman',\n",
       " 'assimilated',\n",
       " 'assimilating',\n",
       " 'associated',\n",
       " 'associated',\n",
       " 'associating',\n",
       " 'astigmatism',\n",
       " 'attenuated',\n",
       " 'authenticated',\n",
       " 'authenticating',\n",
       " 'authoritative',\n",
       " 'bicentenary',\n",
       " 'bilingualism',\n",
       " 'biosciences',\n",
       " 'buchananism',\n",
       " 'cadiddlehopper',\n",
       " 'capitulated',\n",
       " 'catholicism',\n",
       " 'celebratory',\n",
       " 'coagulating',\n",
       " 'cogenerator',\n",
       " 'cogenerators',\n",
       " 'collaborated',\n",
       " 'collaborated',\n",
       " 'collaborating',\n",
       " 'collaborative',\n",
       " 'collaborator',\n",
       " 'collaborators',\n",
       " 'collectivism',\n",
       " 'commemorated',\n",
       " 'commemorating',\n",
       " 'commemorative',\n",
       " 'commercialism',\n",
       " 'commercializing',\n",
       " 'communicated',\n",
       " 'communicating',\n",
       " 'communicator',\n",
       " 'compensatory',\n",
       " 'computerizing',\n",
       " 'computervision',\n",
       " 'concatenated',\n",
       " 'concatenating',\n",
       " 'concessionary',\n",
       " 'conciliator',\n",
       " \"conciliator's\",\n",
       " 'conciliatory',\n",
       " 'confectionaries',\n",
       " 'confectionary',\n",
       " 'confectionery',\n",
       " 'confirmatory',\n",
       " 'confiscatory',\n",
       " 'confucianism',\n",
       " 'congratulated',\n",
       " 'congratulating',\n",
       " 'conservatism',\n",
       " 'conservatories',\n",
       " 'consolidated',\n",
       " \"consolidated's\",\n",
       " 'consolidating',\n",
       " 'consolidator',\n",
       " 'consolidators',\n",
       " 'constabulary',\n",
       " 'construcciones',\n",
       " 'consumerism',\n",
       " 'contaminated',\n",
       " 'contaminated',\n",
       " 'contaminating',\n",
       " 'contemporaries',\n",
       " 'contemporary',\n",
       " 'contributory',\n",
       " 'cooperated',\n",
       " 'cooperating',\n",
       " 'cooperative',\n",
       " 'coordinating',\n",
       " 'coordinator',\n",
       " 'coordinators',\n",
       " 'corroborated',\n",
       " 'corroborating',\n",
       " 'creationism',\n",
       " 'debilitated',\n",
       " 'debilitating',\n",
       " 'decaffeinated',\n",
       " 'decaffeinating',\n",
       " 'decapitated',\n",
       " 'decelerated',\n",
       " 'decelerating',\n",
       " 'decentralizing',\n",
       " 'decisionmaker',\n",
       " 'decisionmaking',\n",
       " 'declaratory',\n",
       " 'deemphasizing',\n",
       " 'defamatory',\n",
       " 'defibrillator',\n",
       " 'defibrillators',\n",
       " 'deflationary',\n",
       " 'degenerated',\n",
       " 'degenerating',\n",
       " 'dehumanizing',\n",
       " 'deliberated',\n",
       " 'deliberating',\n",
       " 'deliberative',\n",
       " 'delineated',\n",
       " 'delineating',\n",
       " 'demobilizes',\n",
       " 'demobilizing',\n",
       " 'democratizes',\n",
       " 'democratizing',\n",
       " 'demoralizing',\n",
       " 'denominated',\n",
       " 'denominator',\n",
       " 'depilatory',\n",
       " 'depositary',\n",
       " 'depositary',\n",
       " 'depository',\n",
       " 'depreciated',\n",
       " 'depreciating',\n",
       " 'depressurizes',\n",
       " 'depressurizing',\n",
       " 'deregulating',\n",
       " 'derogatory',\n",
       " 'desegregated',\n",
       " 'desensitizing',\n",
       " 'destabilizing',\n",
       " 'determinism',\n",
       " 'devaluated',\n",
       " 'diastrophism',\n",
       " 'dilapidated',\n",
       " 'discretionary',\n",
       " 'discriminated',\n",
       " 'discriminated',\n",
       " 'discriminating',\n",
       " 'disintegrated',\n",
       " 'disintegrating',\n",
       " 'disoriented',\n",
       " 'disorienting',\n",
       " 'disqualifying',\n",
       " 'disseminated',\n",
       " 'disseminating',\n",
       " 'diversifying',\n",
       " 'diversifying',\n",
       " 'diversionary',\n",
       " 'diversionary',\n",
       " 'domesticated',\n",
       " 'domesticating',\n",
       " 'economizes',\n",
       " 'economizes',\n",
       " 'economizing',\n",
       " 'economizing',\n",
       " 'elaborating',\n",
       " 'electrifying',\n",
       " 'electrocuted',\n",
       " 'electroplating',\n",
       " 'eliminated',\n",
       " 'eliminated',\n",
       " 'eliminating',\n",
       " 'elucidated',\n",
       " 'elucidative',\n",
       " 'emaciated',\n",
       " 'emaciating',\n",
       " 'emancipated',\n",
       " 'emancipating',\n",
       " 'emasculated',\n",
       " 'empiricism',\n",
       " 'emulsifier',\n",
       " 'encapsulated',\n",
       " 'encapsulating',\n",
       " 'enthusiasm',\n",
       " 'enthusiasms',\n",
       " 'enumerated',\n",
       " 'enunciated',\n",
       " 'enunciating',\n",
       " 'epistolary',\n",
       " 'epitomizes',\n",
       " 'equivocating',\n",
       " 'eradicated',\n",
       " 'eradicating',\n",
       " 'eroticism',\n",
       " 'evacuated',\n",
       " 'evacuated',\n",
       " 'evacuating',\n",
       " 'evacuating',\n",
       " 'evaluated',\n",
       " 'evaluated',\n",
       " 'evaluating',\n",
       " 'evaluating',\n",
       " 'evangelism',\n",
       " 'evangelism',\n",
       " 'evaporated',\n",
       " 'evaporated',\n",
       " 'evaporated',\n",
       " 'evaporated',\n",
       " 'evaporating',\n",
       " 'evaporating',\n",
       " 'evaporator',\n",
       " 'evaporator',\n",
       " 'eviscerated',\n",
       " 'exacerbated',\n",
       " 'exacerbated',\n",
       " 'exacerbating',\n",
       " 'exaggerated',\n",
       " 'exaggerated',\n",
       " 'exaggerating',\n",
       " 'exasperated',\n",
       " 'exasperating',\n",
       " 'exclusionary',\n",
       " 'excoriated',\n",
       " 'excoriating',\n",
       " 'excoriation',\n",
       " 'excruciating',\n",
       " 'exemplifying',\n",
       " 'exhilarated',\n",
       " 'exhilarating',\n",
       " 'exonerated',\n",
       " 'exonerating',\n",
       " 'expansionary',\n",
       " 'expansionary',\n",
       " 'expansionism',\n",
       " 'expansionism',\n",
       " 'experimenter',\n",
       " 'experimenters',\n",
       " 'experimenting',\n",
       " 'expiratory',\n",
       " 'explanatory',\n",
       " 'exploratory',\n",
       " 'exploravision',\n",
       " 'expressionism',\n",
       " 'expropriated',\n",
       " 'extenuating',\n",
       " 'exterminated',\n",
       " 'exterminating',\n",
       " 'exterminator',\n",
       " 'exterminators',\n",
       " 'extraordinary',\n",
       " 'extrapolated',\n",
       " 'extrapolating',\n",
       " 'facilitated',\n",
       " 'facilitating',\n",
       " 'facilitator',\n",
       " \"facilitator's\",\n",
       " 'facilitators',\n",
       " 'fanaticism',\n",
       " 'fiduciares',\n",
       " 'fiduciaries',\n",
       " 'fiduciary',\n",
       " 'ganatieuganauf',\n",
       " 'geotropism',\n",
       " 'hereditary',\n",
       " 'humidifier',\n",
       " 'humidifiers',\n",
       " 'humiliated',\n",
       " 'humiliating',\n",
       " 'hydrogenated',\n",
       " 'identifier',\n",
       " 'identifier',\n",
       " 'identifying',\n",
       " 'identifying',\n",
       " 'illuminated',\n",
       " 'illuminating',\n",
       " 'illuminator',\n",
       " 'illusionary',\n",
       " 'illusionism',\n",
       " 'imaginary',\n",
       " 'immeasurable',\n",
       " 'immeasurably',\n",
       " 'immobilizing',\n",
       " 'impersonated',\n",
       " 'impersonating',\n",
       " 'impersonators',\n",
       " 'impressionism',\n",
       " 'inaccuracies',\n",
       " 'inactivated',\n",
       " 'inaugurated',\n",
       " 'inaugurated',\n",
       " 'inaugurating',\n",
       " 'incantatory',\n",
       " 'incarcerated',\n",
       " 'incarcerating',\n",
       " 'incinerated',\n",
       " 'incinerating',\n",
       " 'incineration',\n",
       " 'incinerator',\n",
       " 'incinerators',\n",
       " 'inconsistencies',\n",
       " 'incorporated',\n",
       " 'incorporated',\n",
       " \"incorporated's\",\n",
       " 'incorporating',\n",
       " 'incriminating',\n",
       " 'indisputably',\n",
       " 'indoctrinated',\n",
       " 'inebriated',\n",
       " 'inebriating',\n",
       " 'infatuated',\n",
       " 'infatuating',\n",
       " 'inflammatory',\n",
       " 'inflationary',\n",
       " 'infuriated',\n",
       " 'infuriated',\n",
       " 'infuriating',\n",
       " 'ingratiating',\n",
       " 'inhibitory',\n",
       " 'initiated',\n",
       " 'initiated',\n",
       " 'initiating',\n",
       " 'innoculated',\n",
       " 'innoculating',\n",
       " 'inoculated',\n",
       " 'instantiated',\n",
       " 'instantiating',\n",
       " 'intensifying',\n",
       " 'interrogated',\n",
       " 'interrogating',\n",
       " 'intimidated',\n",
       " 'intimidating',\n",
       " 'intoxicated',\n",
       " 'intoxicated',\n",
       " 'intoxicating',\n",
       " 'invalidated',\n",
       " 'invalidated',\n",
       " 'invalidating',\n",
       " 'investigated',\n",
       " 'investigated',\n",
       " 'investigating',\n",
       " 'investigative',\n",
       " 'investigator',\n",
       " \"investigator's\",\n",
       " 'investigators',\n",
       " \"investigators'\",\n",
       " 'invigorated',\n",
       " 'invigorating',\n",
       " 'involuntary',\n",
       " 'irradiated',\n",
       " 'itineraries',\n",
       " 'itinerary',\n",
       " 'judiciary',\n",
       " 'legitimizes',\n",
       " 'legitimizing',\n",
       " 'manipulated',\n",
       " 'manipulating',\n",
       " 'manipulative',\n",
       " 'manipulator',\n",
       " 'manipulators',\n",
       " 'mercantilism',\n",
       " 'metabolism',\n",
       " 'metabolisms',\n",
       " 'misallocated',\n",
       " 'misallocating',\n",
       " 'miscalculated',\n",
       " 'misrecognizes',\n",
       " 'misrecognizing',\n",
       " 'monasticism',\n",
       " 'monopolizes',\n",
       " 'monopolizing',\n",
       " 'necessitated',\n",
       " 'necessitating',\n",
       " 'negotiated',\n",
       " 'negotiated',\n",
       " 'negotiating',\n",
       " 'negotiator',\n",
       " 'negotiator',\n",
       " \"negotiators'\",\n",
       " \"negotiator's\",\n",
       " 'negotiators',\n",
       " 'nonmilitary',\n",
       " 'nonregulated',\n",
       " 'obituaries',\n",
       " 'obituary',\n",
       " 'obligatory',\n",
       " 'obliterated',\n",
       " 'obliterating',\n",
       " 'observatories',\n",
       " 'observatory',\n",
       " \"observatory's\",\n",
       " 'obstructionism',\n",
       " 'officiated',\n",
       " 'officiating',\n",
       " 'opinionated',\n",
       " 'originated',\n",
       " 'originated',\n",
       " 'originating',\n",
       " 'originator',\n",
       " 'originators',\n",
       " 'participated',\n",
       " 'participated',\n",
       " 'participating',\n",
       " 'paternalism',\n",
       " 'pecuniary',\n",
       " 'perfectionism',\n",
       " 'perpetuated',\n",
       " 'perpetuating',\n",
       " 'personifying',\n",
       " 'pituitary',\n",
       " 'pituitary',\n",
       " 'politicizing',\n",
       " 'pontificated',\n",
       " 'pontificater',\n",
       " 'pontificaters',\n",
       " 'pontificating',\n",
       " 'precipitated',\n",
       " 'precipitating',\n",
       " 'predominated',\n",
       " 'predominating',\n",
       " 'prefabricated',\n",
       " 'prekindergarten',\n",
       " 'preliminaries',\n",
       " 'preliminaries',\n",
       " 'preliminary',\n",
       " 'preliminary',\n",
       " 'premeditated',\n",
       " 'preparatory',\n",
       " 'prioritizes',\n",
       " 'prioritizing',\n",
       " 'probationary',\n",
       " 'procrastinated',\n",
       " 'procrastinating',\n",
       " 'procrastinator',\n",
       " 'procrastinators',\n",
       " 'prohibitory',\n",
       " 'proliferated',\n",
       " 'proliferating',\n",
       " 'proprietaries',\n",
       " 'proprietary',\n",
       " 'protectionism',\n",
       " 'protectionism',\n",
       " 'provincialism',\n",
       " 'reactionaries',\n",
       " 'reactionary',\n",
       " 'reallocating',\n",
       " 'reanalyses',\n",
       " 'reanalysing',\n",
       " 'reauthorizing',\n",
       " 'recalculated',\n",
       " 'recalculating',\n",
       " 'recessionary',\n",
       " 'recidivism',\n",
       " 'reciprocated',\n",
       " 'reciprocating',\n",
       " 'reclassifying',\n",
       " 'reconstituted',\n",
       " 'reconstituting',\n",
       " 'recuperated',\n",
       " 'recuperater',\n",
       " 'recuperating',\n",
       " 'recuperating',\n",
       " 'redecorated',\n",
       " 'redecorating',\n",
       " 'reformatories',\n",
       " 'reformatory',\n",
       " 'reformulated',\n",
       " 'refrigerated',\n",
       " 'refrigerator',\n",
       " 'refrigerator',\n",
       " 'refrigerators',\n",
       " 'regenerated',\n",
       " 'regenerating',\n",
       " 'reinstituting',\n",
       " 'reintegrated',\n",
       " 'reintegration',\n",
       " 'reiterated',\n",
       " 'reiterating',\n",
       " 'rejuvenated',\n",
       " 'rejuvenating',\n",
       " 'renominated',\n",
       " 'reorganizes',\n",
       " 'reorganizing',\n",
       " 'repatriated',\n",
       " 'repatriating',\n",
       " 'repositories',\n",
       " 'repository',\n",
       " 'repudiated',\n",
       " 'repudiating',\n",
       " 'resuscitated',\n",
       " 'resuscitating',\n",
       " 'retaliated',\n",
       " 'retaliated',\n",
       " 'retaliating',\n",
       " 'retaliatory',\n",
       " 'revelatory',\n",
       " 'reverberated',\n",
       " 'reverberated',\n",
       " 'reverberated',\n",
       " 'reverberating',\n",
       " 'reverberating',\n",
       " 'revisionism',\n",
       " 'revitalizing',\n",
       " 'romanticism',\n",
       " 'romanticizing',\n",
       " 'securitizing',\n",
       " 'solidifying',\n",
       " 'sophisticated',\n",
       " 'sophisticated',\n",
       " 'subordinated',\n",
       " 'subordinating',\n",
       " 'subsidiaries',\n",
       " \"subsidiaries'\",\n",
       " 'subsidiary',\n",
       " \"subsidiary's\",\n",
       " 'substantiated',\n",
       " 'substantiated',\n",
       " 'surrealism',\n",
       " \"surrealism's\",\n",
       " 'surrealisms',\n",
       " 'unallocated',\n",
       " 'uncompensated',\n",
       " 'uncomplicated',\n",
       " 'uneducated',\n",
       " 'unmitigated',\n",
       " 'unnecessary',\n",
       " 'unprecedented',\n",
       " 'unregulated',\n",
       " 'unsanitary',\n",
       " 'unsatisfying',\n",
       " 'unsaturated',\n",
       " 'velociraptor',\n",
       " 'vocabulary',\n",
       " 'voluntarism']"
      ]
     },
     "execution_count": 99,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def stress(pron):\n",
    "    return [char for phone in pron for char in phone if char.isdigit()]\n",
    "[w for w, pron in entries if stress(pron) == ['0', '1', '0', '2', '0']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['abbreviation',\n",
       " 'abbreviations',\n",
       " 'abomination',\n",
       " 'abortifacient',\n",
       " 'abortifacients',\n",
       " 'academicians',\n",
       " 'accommodation',\n",
       " 'accommodations',\n",
       " 'accreditation',\n",
       " 'accreditations',\n",
       " 'accumulation',\n",
       " 'accumulations',\n",
       " 'acetylcholine',\n",
       " 'acetylcholine',\n",
       " 'adjudication',\n",
       " 'administration',\n",
       " \"administration's\",\n",
       " 'administrations',\n",
       " \"administrations'\",\n",
       " 'aduliadae',\n",
       " 'adulteration',\n",
       " 'affiliation',\n",
       " 'affiliations',\n",
       " 'aficionados',\n",
       " 'agglomeration',\n",
       " 'ahasuerus',\n",
       " 'ajinomoto',\n",
       " 'alleviation',\n",
       " 'amalgamation',\n",
       " 'ambrosiano',\n",
       " 'amelioration',\n",
       " 'americana',\n",
       " \"americana's\",\n",
       " 'americanas',\n",
       " 'americano',\n",
       " 'americanos',\n",
       " 'anachronistic',\n",
       " 'anencephalic',\n",
       " 'annihilation',\n",
       " 'antagonistic',\n",
       " 'anticipation',\n",
       " 'anticipations',\n",
       " 'apocalyptic',\n",
       " 'apologetic',\n",
       " 'apotheosis',\n",
       " 'appreciation',\n",
       " 'appropriation',\n",
       " 'appropriations',\n",
       " 'approximation',\n",
       " 'approximations',\n",
       " 'aristocratic',\n",
       " 'arunachalam',\n",
       " 'assassination',\n",
       " 'assassinations',\n",
       " 'assimilation',\n",
       " 'association',\n",
       " 'association',\n",
       " 'associations',\n",
       " \"association's\",\n",
       " 'associations',\n",
       " 'authentication',\n",
       " 'authentications',\n",
       " 'bancoklahoma',\n",
       " 'biagioni',\n",
       " 'boguslavskaya',\n",
       " 'bollapragada',\n",
       " 'bollettieri',\n",
       " 'burkina-faso',\n",
       " \"burkina-faso's\",\n",
       " 'canariensis',\n",
       " 'capitulation',\n",
       " 'cartusciello',\n",
       " 'catacosinos',\n",
       " 'cohabitation',\n",
       " 'coincidental',\n",
       " 'collaboration',\n",
       " 'commemoration',\n",
       " 'commemorations',\n",
       " 'communication',\n",
       " 'communications',\n",
       " \"communications'\",\n",
       " \"communication's\",\n",
       " 'concatenation',\n",
       " 'conciliation',\n",
       " 'confabulation',\n",
       " 'confederation',\n",
       " 'configuration',\n",
       " 'configurations',\n",
       " 'conglomeration',\n",
       " 'congratulation',\n",
       " 'congratulations',\n",
       " 'conigliaro',\n",
       " 'consideration',\n",
       " 'considerations',\n",
       " 'consolidation',\n",
       " 'consolidations',\n",
       " 'contamination',\n",
       " 'continuation',\n",
       " 'controladora',\n",
       " 'cooperation',\n",
       " 'cooperations',\n",
       " 'coordination',\n",
       " 'corroboration',\n",
       " 'decaffeination',\n",
       " 'decapitation',\n",
       " 'decapitations',\n",
       " 'deceleration',\n",
       " 'deforestation',\n",
       " 'degeneration',\n",
       " 'deliberation',\n",
       " 'deliberations',\n",
       " 'delineation',\n",
       " 'denomination',\n",
       " \"denomination's\",\n",
       " 'denominations',\n",
       " 'denunciation',\n",
       " 'denunciations',\n",
       " 'depopulation',\n",
       " 'depreciation',\n",
       " 'depreciations',\n",
       " 'deregulation',\n",
       " 'desalination',\n",
       " 'desegregation',\n",
       " 'determination',\n",
       " \"determination's\",\n",
       " 'determinations',\n",
       " 'deterministic',\n",
       " 'detoxication',\n",
       " 'devaluation',\n",
       " 'developmental',\n",
       " 'developmental',\n",
       " 'diguglielmo',\n",
       " 'dilophosaurus',\n",
       " 'discoloration',\n",
       " 'discolorations',\n",
       " 'discrimination',\n",
       " 'disembarkation',\n",
       " 'disinformation',\n",
       " 'disintegration',\n",
       " 'disintegration',\n",
       " 'dissemination',\n",
       " 'dissociation',\n",
       " 'domeniconi',\n",
       " 'domestication',\n",
       " 'dominicana',\n",
       " 'dominicana',\n",
       " 'ecclesiastic',\n",
       " 'econometric',\n",
       " 'econometrics',\n",
       " 'economico',\n",
       " 'edizione',\n",
       " 'ejaculation',\n",
       " 'elaboration',\n",
       " 'electioneering',\n",
       " 'electrocution',\n",
       " 'electrocutions',\n",
       " 'electrolytic',\n",
       " 'electromagnet',\n",
       " 'electromagnets',\n",
       " 'electromedics',\n",
       " 'electrostatic',\n",
       " 'elimination',\n",
       " 'eliminations',\n",
       " 'emancipation',\n",
       " 'emancipations',\n",
       " 'embarcadero',\n",
       " 'encephalitis',\n",
       " 'encyclopedic',\n",
       " 'encyclopedic',\n",
       " 'encyclopedist',\n",
       " 'encyclopedist',\n",
       " 'enthusiastic',\n",
       " 'enumeration',\n",
       " 'environmental',\n",
       " 'environmental',\n",
       " 'episcopalian',\n",
       " 'episcopalians',\n",
       " 'eradication',\n",
       " 'erythropoietin',\n",
       " 'evacuation',\n",
       " 'evacuations',\n",
       " 'evaluation',\n",
       " 'evaluation',\n",
       " 'evaluations',\n",
       " 'evaluations',\n",
       " 'evaporation',\n",
       " 'evaporation',\n",
       " 'exacerbation',\n",
       " 'exacerbations',\n",
       " 'exaggeration',\n",
       " 'exaggerations',\n",
       " 'examination',\n",
       " 'examinations',\n",
       " 'exfoliation',\n",
       " 'exhilaration',\n",
       " 'expatriation',\n",
       " 'experiential',\n",
       " 'experimental',\n",
       " 'experimental',\n",
       " 'expressionistic',\n",
       " 'extermination',\n",
       " 'extrapolation',\n",
       " 'extravaganza',\n",
       " 'extravaganzas',\n",
       " 'facilitation',\n",
       " 'famiglietti',\n",
       " 'fedeccredito',\n",
       " 'financiera',\n",
       " 'financiero',\n",
       " 'garagiola',\n",
       " 'giovanniello',\n",
       " 'hallucination',\n",
       " 'hallucinations',\n",
       " 'hermaphroditic',\n",
       " 'humiliation',\n",
       " 'iacobelli',\n",
       " 'iacobellis',\n",
       " 'iacovelli',\n",
       " 'iannaccone',\n",
       " 'iannacone',\n",
       " 'iannamico',\n",
       " 'ianniello',\n",
       " 'iavarone',\n",
       " 'idealistic',\n",
       " 'illumination',\n",
       " 'imagination',\n",
       " 'imaginations',\n",
       " 'imagineering',\n",
       " 'impressionistic',\n",
       " 'inactivation',\n",
       " 'inauguration',\n",
       " 'inaugurations',\n",
       " 'incarceration',\n",
       " 'inconsequential',\n",
       " 'incorporation',\n",
       " \"incorporation's\",\n",
       " 'incorporations',\n",
       " 'incrimination',\n",
       " 'indemnifying',\n",
       " 'indoctrination',\n",
       " 'industriali',\n",
       " 'infatuation',\n",
       " 'inhabitation',\n",
       " 'initiation',\n",
       " 'innoculation',\n",
       " 'inoculation',\n",
       " 'inoculations',\n",
       " 'insemination',\n",
       " 'insinuation',\n",
       " 'insinuations',\n",
       " 'instantiation',\n",
       " 'interpretation',\n",
       " 'interpretations',\n",
       " 'interrogation',\n",
       " 'interrogations',\n",
       " 'intimidation',\n",
       " 'intoxication',\n",
       " 'invalidation',\n",
       " 'investigation',\n",
       " 'investigations',\n",
       " 'investimento',\n",
       " 'ionospheric',\n",
       " 'irimajiri',\n",
       " 'irradiation',\n",
       " 'italiana',\n",
       " 'kartasasmita',\n",
       " 'kilimanjaro',\n",
       " 'kolodziejski',\n",
       " 'korzeniewski',\n",
       " 'kumaratunga',\n",
       " 'kumarisami',\n",
       " 'lagomarsino',\n",
       " 'louisiana',\n",
       " \"louisiana's\",\n",
       " 'manipulation',\n",
       " 'manipulations',\n",
       " 'maquiladoras',\n",
       " 'marielito',\n",
       " 'marielitos',\n",
       " 'mazowiecki',\n",
       " 'mcalexander',\n",
       " 'mediobanca',\n",
       " 'mericantante',\n",
       " 'mezhdumarodnom',\n",
       " 'misallocation',\n",
       " 'misapplication',\n",
       " 'misapprehension',\n",
       " 'misdiagnoses',\n",
       " 'misdiagnoses',\n",
       " 'misdiagnosis',\n",
       " 'misrecognition',\n",
       " 'misrepresenting',\n",
       " 'misrepresenting',\n",
       " 'modigliani',\n",
       " 'modigliani',\n",
       " 'modiliani',\n",
       " 'monongahela',\n",
       " 'monopolistic',\n",
       " 'monticciolo',\n",
       " 'napoleonic',\n",
       " 'navratilova',\n",
       " \"navratilova's\",\n",
       " 'negotiation',\n",
       " 'negotiations',\n",
       " 'negotiations',\n",
       " 'nomenklatura',\n",
       " 'nonacademic',\n",
       " 'noncontroversial',\n",
       " 'nongovernmental',\n",
       " 'obliteration',\n",
       " 'okoniewski',\n",
       " 'origination',\n",
       " 'originations',\n",
       " 'participation',\n",
       " 'participations',\n",
       " 'paternalistic',\n",
       " 'perpetuation',\n",
       " 'pontification',\n",
       " 'pontifications',\n",
       " 'popieluszko',\n",
       " 'precipitation',\n",
       " 'premeditation',\n",
       " 'preoccupation',\n",
       " 'preoccupations',\n",
       " 'prevarication',\n",
       " 'procrastination',\n",
       " 'prognostication',\n",
       " 'prognostications',\n",
       " 'pronunciation',\n",
       " 'pronunciation',\n",
       " 'pronunciations',\n",
       " 'pronunciations',\n",
       " 'prudentialbache',\n",
       " 'psychosomatic',\n",
       " 'reallocation',\n",
       " 'recalculation',\n",
       " 'recrimination',\n",
       " 'recriminations',\n",
       " 'recuperation',\n",
       " 'rededication',\n",
       " 'redefinition',\n",
       " 'redeposition',\n",
       " 'reengineering',\n",
       " 'refrigeration',\n",
       " 'reiteration',\n",
       " 'rejuvenation',\n",
       " 'religione',\n",
       " 'remediation',\n",
       " 'remuneration',\n",
       " 'renunciation',\n",
       " 'repatriation',\n",
       " 'repudiation',\n",
       " 'resuscitation',\n",
       " 'retaliation',\n",
       " 'reverberation',\n",
       " 'reverberations',\n",
       " 'ricigliano',\n",
       " 'rovaniemi',\n",
       " 'sebastiana',\n",
       " 'sebastiani',\n",
       " 'sebastianis',\n",
       " 'solicitation',\n",
       " 'solicitations',\n",
       " 'sophistication',\n",
       " 'subordination',\n",
       " 'substantiation',\n",
       " 'substantiation',\n",
       " 'sundararajan',\n",
       " 'surrealistic',\n",
       " 'tabacalera',\n",
       " 'ticonderoga',\n",
       " \"ticonderoga's\",\n",
       " 'triangulation',\n",
       " 'tuberculosis',\n",
       " 'tuberculosis',\n",
       " 'tuberculosis',\n",
       " 'uenohara',\n",
       " 'undiplomatic',\n",
       " 'uneconomic',\n",
       " 'unpatriotic',\n",
       " 'unrepresented',\n",
       " 'unscientific',\n",
       " 'unsentimental',\n",
       " 'unsympathetic',\n",
       " 'wakabayashi',\n",
       " 'yekaterinburg']"
      ]
     },
     "execution_count": 100,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "[w for w, pron in entries if stress(pron) == ['0', '2', '0', '1', '0']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "P-CH patch pautsch peach perch petsch petsche piche piech pietsch pitch pit...\n",
      "P-K pac pack paek paik pak pake paque peak peake pech peck peek perc perk ...\n",
      "P-L pahl pail paille pal pale pall paul paule paull peal peale pearl pearl...\n",
      "P-N paign pain paine pan pane pawn payne peine pen penh penn pin pine pinn...\n",
      "P-P paap paape pap pape papp paup peep pep pip pipe pipp poop pop pope pop...\n",
      "P-R paar pair par pare parr pear peer pier poor poore por pore porr pour...\n",
      "P-S pace pass pasts peace pearse pease perce pers perse pesce piece piss p...\n",
      "P-T pait pat pate patt peart peat peet peete pert pet pete pett piet piett...\n",
      "P-UW1 peru peugh pew plew plue prew pru prue prugh pshew pugh...\n",
      "P-Z p's p.'s p.s pais paiz pao's pas pause paws pays paz peas pease pei's ...\n"
     ]
    }
   ],
   "source": [
    "p3 = [(pron[0]+'-'+pron[2], word) \n",
    "      for (word, pron) in entries\n",
    "      if pron[0] == 'P' and len(pron) == 3]\n",
    "\n",
    "cfd = nltk.ConditionalFreqDist(p3)\n",
    "\n",
    "for template in sorted(cfd.conditions()):\n",
    "    if len(cfd[template]) > 10:\n",
    "        words = sorted(cfd[template])\n",
    "        wordstring = ' '.join(words)\n",
    "        print(template, wordstring[:70] + \"...\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[['F', 'AY1', 'ER0'], ['F', 'AY1', 'R']]"
      ]
     },
     "execution_count": 102,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "prondict = nltk.corpus.cmudict.dict()\n",
    "prondict['fire']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyError",
     "evalue": "'blog'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-103-4b851fde5ef1>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mprondict\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'blog'\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;31mKeyError\u001b[0m: 'blog'"
     ]
    }
   ],
   "source": [
    "prondict['blog']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[['B', 'L', 'AA1', 'G']]"
      ]
     },
     "execution_count": 105,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "prondict['blog'] = [['B', 'L', 'AA1', 'G']]\n",
    "prondict['blog']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['N',\n",
       " 'AE1',\n",
       " 'CH',\n",
       " 'ER0',\n",
       " 'AH0',\n",
       " 'L',\n",
       " 'L',\n",
       " 'AE1',\n",
       " 'NG',\n",
       " 'G',\n",
       " 'W',\n",
       " 'AH0',\n",
       " 'JH',\n",
       " 'P',\n",
       " 'R',\n",
       " 'AA1',\n",
       " 'S',\n",
       " 'EH0',\n",
       " 'S',\n",
       " 'IH0',\n",
       " 'NG']"
      ]
     },
     "execution_count": 106,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "text = ['natural', 'language', 'processing']\n",
    "[ph for w in text for ph in prondict[w][0]]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4.3   Comparative Wordlists"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['be',\n",
       " 'bg',\n",
       " 'bs',\n",
       " 'ca',\n",
       " 'cs',\n",
       " 'cu',\n",
       " 'de',\n",
       " 'en',\n",
       " 'es',\n",
       " 'fr',\n",
       " 'hr',\n",
       " 'it',\n",
       " 'la',\n",
       " 'mk',\n",
       " 'nl',\n",
       " 'pl',\n",
       " 'pt',\n",
       " 'ro',\n",
       " 'ru',\n",
       " 'sk',\n",
       " 'sl',\n",
       " 'sr',\n",
       " 'sw',\n",
       " 'uk']"
      ]
     },
     "execution_count": 107,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from nltk.corpus import swadesh\n",
    "swadesh.fileids()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['I',\n",
       " 'you (singular), thou',\n",
       " 'he',\n",
       " 'we',\n",
       " 'you (plural)',\n",
       " 'they',\n",
       " 'this',\n",
       " 'that',\n",
       " 'here',\n",
       " 'there',\n",
       " 'who',\n",
       " 'what',\n",
       " 'where',\n",
       " 'when',\n",
       " 'how',\n",
       " 'not',\n",
       " 'all',\n",
       " 'many',\n",
       " 'some',\n",
       " 'few',\n",
       " 'other',\n",
       " 'one',\n",
       " 'two',\n",
       " 'three',\n",
       " 'four',\n",
       " 'five',\n",
       " 'big',\n",
       " 'long',\n",
       " 'wide',\n",
       " 'thick',\n",
       " 'heavy',\n",
       " 'small',\n",
       " 'short',\n",
       " 'narrow',\n",
       " 'thin',\n",
       " 'woman',\n",
       " 'man (adult male)',\n",
       " 'man (human being)',\n",
       " 'child',\n",
       " 'wife',\n",
       " 'husband',\n",
       " 'mother',\n",
       " 'father',\n",
       " 'animal',\n",
       " 'fish',\n",
       " 'bird',\n",
       " 'dog',\n",
       " 'louse',\n",
       " 'snake',\n",
       " 'worm',\n",
       " 'tree',\n",
       " 'forest',\n",
       " 'stick',\n",
       " 'fruit',\n",
       " 'seed',\n",
       " 'leaf',\n",
       " 'root',\n",
       " 'bark (from tree)',\n",
       " 'flower',\n",
       " 'grass',\n",
       " 'rope',\n",
       " 'skin',\n",
       " 'meat',\n",
       " 'blood',\n",
       " 'bone',\n",
       " 'fat (noun)',\n",
       " 'egg',\n",
       " 'horn',\n",
       " 'tail',\n",
       " 'feather',\n",
       " 'hair',\n",
       " 'head',\n",
       " 'ear',\n",
       " 'eye',\n",
       " 'nose',\n",
       " 'mouth',\n",
       " 'tooth',\n",
       " 'tongue',\n",
       " 'fingernail',\n",
       " 'foot',\n",
       " 'leg',\n",
       " 'knee',\n",
       " 'hand',\n",
       " 'wing',\n",
       " 'belly',\n",
       " 'guts',\n",
       " 'neck',\n",
       " 'back',\n",
       " 'breast',\n",
       " 'heart',\n",
       " 'liver',\n",
       " 'drink',\n",
       " 'eat',\n",
       " 'bite',\n",
       " 'suck',\n",
       " 'spit',\n",
       " 'vomit',\n",
       " 'blow',\n",
       " 'breathe',\n",
       " 'laugh',\n",
       " 'see',\n",
       " 'hear',\n",
       " 'know (a fact)',\n",
       " 'think',\n",
       " 'smell',\n",
       " 'fear',\n",
       " 'sleep',\n",
       " 'live',\n",
       " 'die',\n",
       " 'kill',\n",
       " 'fight',\n",
       " 'hunt',\n",
       " 'hit',\n",
       " 'cut',\n",
       " 'split',\n",
       " 'stab',\n",
       " 'scratch',\n",
       " 'dig',\n",
       " 'swim',\n",
       " 'fly (verb)',\n",
       " 'walk',\n",
       " 'come',\n",
       " 'lie',\n",
       " 'sit',\n",
       " 'stand',\n",
       " 'turn',\n",
       " 'fall',\n",
       " 'give',\n",
       " 'hold',\n",
       " 'squeeze',\n",
       " 'rub',\n",
       " 'wash',\n",
       " 'wipe',\n",
       " 'pull',\n",
       " 'push',\n",
       " 'throw',\n",
       " 'tie',\n",
       " 'sew',\n",
       " 'count',\n",
       " 'say',\n",
       " 'sing',\n",
       " 'play',\n",
       " 'float',\n",
       " 'flow',\n",
       " 'freeze',\n",
       " 'swell',\n",
       " 'sun',\n",
       " 'moon',\n",
       " 'star',\n",
       " 'water',\n",
       " 'rain',\n",
       " 'river',\n",
       " 'lake',\n",
       " 'sea',\n",
       " 'salt',\n",
       " 'stone',\n",
       " 'sand',\n",
       " 'dust',\n",
       " 'earth',\n",
       " 'cloud',\n",
       " 'fog',\n",
       " 'sky',\n",
       " 'wind',\n",
       " 'snow',\n",
       " 'ice',\n",
       " 'smoke',\n",
       " 'fire',\n",
       " 'ashes',\n",
       " 'burn',\n",
       " 'road',\n",
       " 'mountain',\n",
       " 'red',\n",
       " 'green',\n",
       " 'yellow',\n",
       " 'white',\n",
       " 'black',\n",
       " 'night',\n",
       " 'day',\n",
       " 'year',\n",
       " 'warm',\n",
       " 'cold',\n",
       " 'full',\n",
       " 'new',\n",
       " 'old',\n",
       " 'good',\n",
       " 'bad',\n",
       " 'rotten',\n",
       " 'dirty',\n",
       " 'straight',\n",
       " 'round',\n",
       " 'sharp',\n",
       " 'dull',\n",
       " 'smooth',\n",
       " 'wet',\n",
       " 'dry',\n",
       " 'correct',\n",
       " 'near',\n",
       " 'far',\n",
       " 'right',\n",
       " 'left',\n",
       " 'at',\n",
       " 'in',\n",
       " 'with',\n",
       " 'and',\n",
       " 'if',\n",
       " 'because',\n",
       " 'name']"
      ]
     },
     "execution_count": 108,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "swadesh.words('en')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['yo',\n",
       " 'tú, usted',\n",
       " 'él',\n",
       " 'nosotros',\n",
       " 'vosotros, ustedes',\n",
       " 'ellos, ellas',\n",
       " 'este',\n",
       " 'ese, aquel',\n",
       " 'aquí, acá',\n",
       " 'ahí, allí, allá',\n",
       " 'quien',\n",
       " 'que',\n",
       " 'donde',\n",
       " 'cuando',\n",
       " 'como',\n",
       " 'no',\n",
       " 'todo',\n",
       " 'muchos',\n",
       " 'algunos, unos',\n",
       " 'poco',\n",
       " 'otro',\n",
       " 'uno',\n",
       " 'dos',\n",
       " 'tres',\n",
       " 'cuatro',\n",
       " 'cinco',\n",
       " 'grande',\n",
       " 'largo',\n",
       " 'ancho',\n",
       " 'gordo',\n",
       " 'pesado',\n",
       " 'pequeño',\n",
       " 'corto',\n",
       " 'estrecho, angosto',\n",
       " 'delgado, flaco',\n",
       " 'mujer',\n",
       " 'hombre',\n",
       " 'hombre',\n",
       " 'niño',\n",
       " 'esposa, mujer',\n",
       " 'esposo, marido',\n",
       " 'madre',\n",
       " 'padre',\n",
       " 'animal',\n",
       " 'pez, pescado',\n",
       " 'ave, pájaro',\n",
       " 'perro',\n",
       " 'piojo',\n",
       " 'serpiente, culebra',\n",
       " 'gusano',\n",
       " 'árbol',\n",
       " 'bosque',\n",
       " 'palo',\n",
       " 'fruta',\n",
       " 'semilla',\n",
       " 'hoja',\n",
       " 'raíz',\n",
       " 'corteza',\n",
       " 'flor',\n",
       " 'hierba, pasto',\n",
       " 'cuerda',\n",
       " 'piel',\n",
       " 'carne',\n",
       " 'sangre',\n",
       " 'hueso',\n",
       " 'grasa',\n",
       " 'huevo',\n",
       " 'cuerno',\n",
       " 'cola',\n",
       " 'pluma',\n",
       " 'cabello, pelo',\n",
       " 'cabeza',\n",
       " 'oreja',\n",
       " 'ojo',\n",
       " 'nariz',\n",
       " 'boca',\n",
       " 'diente',\n",
       " 'lengua',\n",
       " 'uña',\n",
       " 'pie',\n",
       " 'pierna',\n",
       " 'rodilla',\n",
       " 'mano',\n",
       " 'ala',\n",
       " 'barriga, vientre, panza',\n",
       " 'entrañas, tripas',\n",
       " 'cuello',\n",
       " 'espalda',\n",
       " 'pecho, seno',\n",
       " 'corazón',\n",
       " 'hígado',\n",
       " 'beber, tomar',\n",
       " 'comer',\n",
       " 'morder',\n",
       " 'chupar',\n",
       " 'escupir',\n",
       " 'vomitar',\n",
       " 'soplar',\n",
       " 'respirar',\n",
       " 'reír',\n",
       " 'ver',\n",
       " 'oír',\n",
       " 'saber',\n",
       " 'pensar',\n",
       " 'oler',\n",
       " 'temer',\n",
       " 'dormir',\n",
       " 'vivir',\n",
       " 'morir',\n",
       " 'matar',\n",
       " 'pelear',\n",
       " 'cazar',\n",
       " 'golpear',\n",
       " 'cortar',\n",
       " 'partir',\n",
       " 'apuñalar',\n",
       " 'arañar, rascar',\n",
       " 'cavar',\n",
       " 'nadar',\n",
       " 'volar',\n",
       " 'caminar',\n",
       " 'venir',\n",
       " 'echarse, acostarse, tenderse',\n",
       " 'sentarse',\n",
       " 'estar de pie',\n",
       " 'voltear',\n",
       " 'caer',\n",
       " 'dar',\n",
       " 'sostener',\n",
       " 'apretar',\n",
       " 'frotar',\n",
       " 'lavar',\n",
       " 'limpiar',\n",
       " 'tirar',\n",
       " 'empujar',\n",
       " 'tirar',\n",
       " 'atar',\n",
       " 'coser',\n",
       " 'contar',\n",
       " 'decir',\n",
       " 'cantar',\n",
       " 'jugar',\n",
       " 'flotar',\n",
       " 'fluir',\n",
       " 'helar',\n",
       " 'hincharse',\n",
       " 'sol',\n",
       " 'luna',\n",
       " 'estrella',\n",
       " 'agua',\n",
       " 'lluvia',\n",
       " 'río',\n",
       " 'lago',\n",
       " 'mar',\n",
       " 'sal',\n",
       " 'piedra',\n",
       " 'arena',\n",
       " 'polvo',\n",
       " 'tierra',\n",
       " 'nube',\n",
       " 'niebla',\n",
       " 'cielo',\n",
       " 'viento',\n",
       " 'nieve',\n",
       " 'hielo',\n",
       " 'humo',\n",
       " 'fuego',\n",
       " 'cenizas',\n",
       " 'quemar',\n",
       " 'camino',\n",
       " 'montaña',\n",
       " 'rojo',\n",
       " 'verde',\n",
       " 'amarillo',\n",
       " 'blanco',\n",
       " 'negro',\n",
       " 'noche',\n",
       " 'día',\n",
       " 'año',\n",
       " 'cálido, tibio',\n",
       " 'frío',\n",
       " 'lleno',\n",
       " 'nuevo',\n",
       " 'viejo',\n",
       " 'bueno',\n",
       " 'malo',\n",
       " 'podrido',\n",
       " 'sucio',\n",
       " 'recto',\n",
       " 'redondo',\n",
       " 'afilado',\n",
       " 'desafilado',\n",
       " 'suave, liso',\n",
       " 'mojado',\n",
       " 'seco',\n",
       " 'correcto',\n",
       " 'cerca',\n",
       " 'lejos',\n",
       " 'derecha',\n",
       " 'izquierda',\n",
       " 'a, en, ante',\n",
       " 'en',\n",
       " 'con',\n",
       " 'y',\n",
       " 'si',\n",
       " 'porque',\n",
       " 'nombre']"
      ]
     },
     "execution_count": 109,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "swadesh.words('es')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('je', 'I'),\n",
       " ('tu, vous', 'you (singular), thou'),\n",
       " ('il', 'he'),\n",
       " ('nous', 'we'),\n",
       " ('vous', 'you (plural)'),\n",
       " ('ils, elles', 'they'),\n",
       " ('ceci', 'this'),\n",
       " ('cela', 'that'),\n",
       " ('ici', 'here'),\n",
       " ('là', 'there'),\n",
       " ('qui', 'who'),\n",
       " ('quoi', 'what'),\n",
       " ('où', 'where'),\n",
       " ('quand', 'when'),\n",
       " ('comment', 'how'),\n",
       " ('ne...pas', 'not'),\n",
       " ('tout', 'all'),\n",
       " ('plusieurs', 'many'),\n",
       " ('quelques', 'some'),\n",
       " ('peu', 'few'),\n",
       " ('autre', 'other'),\n",
       " ('un', 'one'),\n",
       " ('deux', 'two'),\n",
       " ('trois', 'three'),\n",
       " ('quatre', 'four'),\n",
       " ('cinq', 'five'),\n",
       " ('grand', 'big'),\n",
       " ('long', 'long'),\n",
       " ('large', 'wide'),\n",
       " ('épais', 'thick'),\n",
       " ('lourd', 'heavy'),\n",
       " ('petit', 'small'),\n",
       " ('court', 'short'),\n",
       " ('étroit', 'narrow'),\n",
       " ('mince', 'thin'),\n",
       " ('femme', 'woman'),\n",
       " ('homme', 'man (adult male)'),\n",
       " ('homme', 'man (human being)'),\n",
       " ('enfant', 'child'),\n",
       " ('femme, épouse', 'wife'),\n",
       " ('mari, époux', 'husband'),\n",
       " ('mère', 'mother'),\n",
       " ('père', 'father'),\n",
       " ('animal', 'animal'),\n",
       " ('poisson', 'fish'),\n",
       " ('oiseau', 'bird'),\n",
       " ('chien', 'dog'),\n",
       " ('pou', 'louse'),\n",
       " ('serpent', 'snake'),\n",
       " ('ver', 'worm'),\n",
       " ('arbre', 'tree'),\n",
       " ('forêt', 'forest'),\n",
       " ('bâton', 'stick'),\n",
       " ('fruit', 'fruit'),\n",
       " ('graine', 'seed'),\n",
       " ('feuille', 'leaf'),\n",
       " ('racine', 'root'),\n",
       " ('écorce', 'bark (from tree)'),\n",
       " ('fleur', 'flower'),\n",
       " ('herbe', 'grass'),\n",
       " ('corde', 'rope'),\n",
       " ('peau', 'skin'),\n",
       " ('viande', 'meat'),\n",
       " ('sang', 'blood'),\n",
       " ('os', 'bone'),\n",
       " ('graisse', 'fat (noun)'),\n",
       " ('œuf', 'egg'),\n",
       " ('corne', 'horn'),\n",
       " ('queue', 'tail'),\n",
       " ('plume', 'feather'),\n",
       " ('cheveu', 'hair'),\n",
       " ('tête', 'head'),\n",
       " ('oreille', 'ear'),\n",
       " ('œil', 'eye'),\n",
       " ('nez', 'nose'),\n",
       " ('bouche', 'mouth'),\n",
       " ('dent', 'tooth'),\n",
       " ('langue', 'tongue'),\n",
       " ('ongle', 'fingernail'),\n",
       " ('pied', 'foot'),\n",
       " ('jambe', 'leg'),\n",
       " ('genou', 'knee'),\n",
       " ('main', 'hand'),\n",
       " ('aile', 'wing'),\n",
       " ('ventre', 'belly'),\n",
       " ('entrailles', 'guts'),\n",
       " ('cou', 'neck'),\n",
       " ('dos', 'back'),\n",
       " ('sein, poitrine', 'breast'),\n",
       " ('cœur', 'heart'),\n",
       " ('foie', 'liver'),\n",
       " ('boire', 'drink'),\n",
       " ('manger', 'eat'),\n",
       " ('mordre', 'bite'),\n",
       " ('sucer', 'suck'),\n",
       " ('cracher', 'spit'),\n",
       " ('vomir', 'vomit'),\n",
       " ('souffler', 'blow'),\n",
       " ('respirer', 'breathe'),\n",
       " ('rire', 'laugh'),\n",
       " ('voir', 'see'),\n",
       " ('entendre', 'hear'),\n",
       " ('savoir', 'know (a fact)'),\n",
       " ('penser', 'think'),\n",
       " ('sentir', 'smell'),\n",
       " ('craindre, avoir peur', 'fear'),\n",
       " ('dormir', 'sleep'),\n",
       " ('vivre', 'live'),\n",
       " ('mourir', 'die'),\n",
       " ('tuer', 'kill'),\n",
       " ('se battre', 'fight'),\n",
       " ('chasser', 'hunt'),\n",
       " ('frapper', 'hit'),\n",
       " ('couper', 'cut'),\n",
       " ('fendre', 'split'),\n",
       " ('poignarder', 'stab'),\n",
       " ('gratter', 'scratch'),\n",
       " ('creuser', 'dig'),\n",
       " ('nager', 'swim'),\n",
       " ('voler', 'fly (verb)'),\n",
       " ('marcher', 'walk'),\n",
       " ('venir', 'come'),\n",
       " (\"s'étendre\", 'lie'),\n",
       " (\"s'asseoir\", 'sit'),\n",
       " ('se lever', 'stand'),\n",
       " ('tourner', 'turn'),\n",
       " ('tomber', 'fall'),\n",
       " ('donner', 'give'),\n",
       " ('tenir', 'hold'),\n",
       " ('serrer', 'squeeze'),\n",
       " ('frotter', 'rub'),\n",
       " ('laver', 'wash'),\n",
       " ('essuyer', 'wipe'),\n",
       " ('tirer', 'pull'),\n",
       " ('pousser', 'push'),\n",
       " ('jeter', 'throw'),\n",
       " ('lier', 'tie'),\n",
       " ('coudre', 'sew'),\n",
       " ('compter', 'count'),\n",
       " ('dire', 'say'),\n",
       " ('chanter', 'sing'),\n",
       " ('jouer', 'play'),\n",
       " ('flotter', 'float'),\n",
       " ('couler', 'flow'),\n",
       " ('geler', 'freeze'),\n",
       " ('gonfler', 'swell'),\n",
       " ('soleil', 'sun'),\n",
       " ('lune', 'moon'),\n",
       " ('étoile', 'star'),\n",
       " ('eau', 'water'),\n",
       " ('pluie', 'rain'),\n",
       " ('rivière', 'river'),\n",
       " ('lac', 'lake'),\n",
       " ('mer', 'sea'),\n",
       " ('sel', 'salt'),\n",
       " ('pierre', 'stone'),\n",
       " ('sable', 'sand'),\n",
       " ('poussière', 'dust'),\n",
       " ('terre', 'earth'),\n",
       " ('nuage', 'cloud'),\n",
       " ('brouillard', 'fog'),\n",
       " ('ciel', 'sky'),\n",
       " ('vent', 'wind'),\n",
       " ('neige', 'snow'),\n",
       " ('glace', 'ice'),\n",
       " ('fumée', 'smoke'),\n",
       " ('feu', 'fire'),\n",
       " ('cendres', 'ashes'),\n",
       " ('brûler', 'burn'),\n",
       " ('route', 'road'),\n",
       " ('montagne', 'mountain'),\n",
       " ('rouge', 'red'),\n",
       " ('vert', 'green'),\n",
       " ('jaune', 'yellow'),\n",
       " ('blanc', 'white'),\n",
       " ('noir', 'black'),\n",
       " ('nuit', 'night'),\n",
       " ('jour', 'day'),\n",
       " ('an, année', 'year'),\n",
       " ('chaud', 'warm'),\n",
       " ('froid', 'cold'),\n",
       " ('plein', 'full'),\n",
       " ('nouveau', 'new'),\n",
       " ('vieux', 'old'),\n",
       " ('bon', 'good'),\n",
       " ('mauvais', 'bad'),\n",
       " ('pourri', 'rotten'),\n",
       " ('sale', 'dirty'),\n",
       " ('droit', 'straight'),\n",
       " ('rond', 'round'),\n",
       " ('tranchant, pointu, aigu', 'sharp'),\n",
       " ('émoussé', 'dull'),\n",
       " ('lisse', 'smooth'),\n",
       " ('mouillé', 'wet'),\n",
       " ('sec', 'dry'),\n",
       " ('juste, correct', 'correct'),\n",
       " ('proche', 'near'),\n",
       " ('loin', 'far'),\n",
       " ('à droite', 'right'),\n",
       " ('à gauche', 'left'),\n",
       " ('à', 'at'),\n",
       " ('dans', 'in'),\n",
       " ('avec', 'with'),\n",
       " ('et', 'and'),\n",
       " ('si', 'if'),\n",
       " ('parce que', 'because'),\n",
       " ('nom', 'name')]"
      ]
     },
     "execution_count": 110,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "fr2en = swadesh.entries(['fr', 'en'])\n",
    "fr2en"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'dog'"
      ]
     },
     "execution_count": 111,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "translate = dict(fr2en)\n",
    "translate['chien']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'throw'"
      ]
     },
     "execution_count": 112,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "translate['jeter']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'perro'"
      ]
     },
     "execution_count": 115,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "fralen = swadesh.entries(['fr', 'es'])\n",
    "traducir = dict(fralen)\n",
    "traducir['chien']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'dog'"
      ]
     },
     "execution_count": 116,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "de2en = swadesh.entries(['de', 'en'])    # German-English\n",
    "es2en = swadesh.entries(['es', 'en'])    # Spanish-English\n",
    "translate.update(dict(de2en))\n",
    "translate.update(dict(es2en))\n",
    "translate['Hund']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'dog'"
      ]
     },
     "execution_count": 117,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "translate['perro']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "('say', 'sagen', 'zeggen', 'decir', 'dire', 'dizer', 'dicere')\n",
      "('sing', 'singen', 'zingen', 'cantar', 'chanter', 'cantar', 'canere')\n",
      "('play', 'spielen', 'spelen', 'jugar', 'jouer', 'jogar, brincar', 'ludere')\n",
      "('float', 'schweben', 'zweven', 'flotar', 'flotter', 'flutuar, boiar', 'fluctuare')\n"
     ]
    }
   ],
   "source": [
    "languages = ['en', 'de', 'nl', 'es', 'fr', 'pt', 'la']\n",
    "for i in [139, 140, 141, 142]:\n",
    "    print(swadesh.entries(languages)[i])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4.4   Shoebox and Toolbox Lexicons"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('kaa',\n",
       "  [('ps', 'V'),\n",
       "   ('pt', 'A'),\n",
       "   ('ge', 'gag'),\n",
       "   ('tkp', 'nek i pas'),\n",
       "   ('dcsv', 'true'),\n",
       "   ('vx', '1'),\n",
       "   ('sc', '???'),\n",
       "   ('dt', '29/Oct/2005'),\n",
       "   ('ex', 'Apoka ira kaaroi aioa-ia reoreopaoro.'),\n",
       "   ('xp', 'Kaikai i pas long nek bilong Apoka bikos em i kaikai na toktok.'),\n",
       "   ('xe', 'Apoka is gagging from food while talking.')]),\n",
       " ('kaa',\n",
       "  [('ps', 'V'),\n",
       "   ('pt', 'B'),\n",
       "   ('ge', 'strangle'),\n",
       "   ('tkp', 'pasim nek'),\n",
       "   ('arg', 'O'),\n",
       "   ('vx', '2'),\n",
       "   ('dt', '07/Oct/2006'),\n",
       "   ('ex', 'Rera rauroro rera kaarevoi.'),\n",
       "   ('xp', 'Em i holim pas em na nekim em.'),\n",
       "   ('xe', 'He is holding him and strangling him.'),\n",
       "   ('ex', 'Iroiro-ia oirato okoearo kaaivoi uvare rirovira kaureoparoveira.'),\n",
       "   ('xp', 'Ol i pasim nek bilong man long rop bikos em i save bikhet tumas.'),\n",
       "   ('xe',\n",
       "    \"They strangled the man's neck with rope because he was very stubborn and arrogant.\"),\n",
       "   ('ex',\n",
       "    'Oirato okoearo kaaivoi iroiro-ia. Uva viapau uvuiparoi ra vovouparo uva kopiiroi.'),\n",
       "   ('xp',\n",
       "    'Ol i pasim nek bilong man long rop. Olsem na em i no pulim win olsem na em i dai.'),\n",
       "   ('xe',\n",
       "    \"They strangled the man's neck with a rope. And he couldn't breathe and he died.\")]),\n",
       " ('kaa',\n",
       "  [('ps', 'N'),\n",
       "   ('pt', 'MASC'),\n",
       "   ('cl', 'isi'),\n",
       "   ('ge', 'cooking banana'),\n",
       "   ('tkp', 'banana bilong kukim'),\n",
       "   ('pt', 'itoo'),\n",
       "   ('sf', 'FLORA'),\n",
       "   ('dt', '12/Aug/2005'),\n",
       "   ('ex', 'Taeavi iria kaa isi kovopaueva kaparapasia.'),\n",
       "   ('xp', 'Taeavi i bin planim gaden banana bilong kukim tasol long paia.'),\n",
       "   ('xe', 'Taeavi planted banana in order to cook it.')]),\n",
       " ('kaakaaro',\n",
       "  [('ps', 'N'),\n",
       "   ('pt', 'NT'),\n",
       "   ('ge', 'mixture'),\n",
       "   ('tkp', '???'),\n",
       "   ('eng', 'mixtures'),\n",
       "   ('eng', 'charm used to keep married men and women youthful and attractive'),\n",
       "   ('cmt',\n",
       "    'Check vowel length. Is it kaakaaro or kaakaro? Does lexeme have suffix, -aro or -ro?'),\n",
       "   ('dt', '20/Nov/2006'),\n",
       "   ('ex',\n",
       "    'Kaakaroto ira purapaiveira aue iava opita, voeao-pa airepa oraouirara, ra va aiopaive.'),\n",
       "   ('xp',\n",
       "    'Kokonas ol i save wokim long ol kain samting bilong ol nupela marit, bai ol i ken kaikai.'),\n",
       "   ('xe', 'Mixtures are made from coconut for newlyweds, who eat them.')]),\n",
       " ('kaakaaviko',\n",
       "  [('ps', 'N'),\n",
       "   ('pt', 'FEM'),\n",
       "   ('ge', 'type of beetle'),\n",
       "   ('tkp', '???'),\n",
       "   ('nt', 'round beetle like Mexican bean beetle'),\n",
       "   ('dt', '10/Feb/2005'),\n",
       "   ('sf', 'FAUNA.INSECT'),\n",
       "   ('ex', 'Kaakaaviko kare oea binara touaveira vara tapo piupaiveira.'),\n",
       "   ('xp',\n",
       "    'Kaakaaviko em i wanpela kain insect em i save istap long ol bin or na long kain lip.'),\n",
       "   ('xe', '???'),\n",
       "   ('ex', 'Kaakaaviko kare oea raviriro kouro piupaiveira.'),\n",
       "   ('xp', 'Em i wanpela kain weevil i save bagarapim ol bin.'),\n",
       "   ('xe', '??? damages up beans.')]),\n",
       " ('kaakaavo',\n",
       "  [('rt', 'kaavo'),\n",
       "   ('ps', '???'),\n",
       "   ('rdp', 'partial'),\n",
       "   ('ge', 'white'),\n",
       "   ('tkp', 'wait'),\n",
       "   ('sc', '???'),\n",
       "   ('cmt', \"What's the part of speech?\"),\n",
       "   ('dt', '29/Oct/2005'),\n",
       "   ('ex',\n",
       "    'Kaakaaro oa purapaiveira varauraro tokipasia aue iava opita ora vegoara iava oirara iava ora riakova kaakaaro.'),\n",
       "   ('xp',\n",
       "    'Ol i save wokim out long kokonas coconut na ol lip na skin blong ol diwai.'),\n",
       "   ('xe', '???'),\n",
       "   ('ex', 'Varoa kaakaavopa popotepa ragai varo.'),\n",
       "   ('xp', 'Em white lap lap blong mi.'),\n",
       "   ('xe', \"That's my white laplap.\"),\n",
       "   ('ex', 'Vaoia evaova kaakaavopaova.'),\n",
       "   ('xp', 'Dispela diwai em i waitpela.'),\n",
       "   ('xe', 'This tree is white.'),\n",
       "   ('ex',\n",
       "    'Rarasoria kaakaavoto ira Amerika iava urioroera vo kovosia rupairara voaro.'),\n",
       "   ('xp',\n",
       "    'Rarason em i wait man em i bin kam long Amerika na kam wok long hap bilong ol bilak man.'),\n",
       "   ('xe', 'Rarason is a white man who came from America ???.')]),\n",
       " ('kaakaoko',\n",
       "  [('ps', 'N'),\n",
       "   ('pt', '???'),\n",
       "   ('ge', 'type of beetle'),\n",
       "   ('tkp', 'binatang'),\n",
       "   ('sf', 'FAUNA.INSECT'),\n",
       "   ('cmt', 'Is it kaakaoko or kaakauko?'),\n",
       "   ('dt', '08/Feb/2005'),\n",
       "   ('ex', 'Kaakaoko vuri gesito./Kaakauko vurisi gesiva.'),\n",
       "   ('xp', '???'),\n",
       "   ('xe', 'Kaakauko em i wanpela binatang.')]),\n",
       " ('kaakasi',\n",
       "  [('rt', '???'),\n",
       "   ('ps', 'V'),\n",
       "   ('pt', 'A'),\n",
       "   ('ge', 'hot'),\n",
       "   ('tkp', 'hot'),\n",
       "   ('vx', '1'),\n",
       "   ('sc', '???'),\n",
       "   ('cmt',\n",
       "    \"Vowel length can't possibly be right. Or is the vowel of kaasi long?\"),\n",
       "   ('dt', '29/Oct/2005'),\n",
       "   ('ex', 'Upiriko pitoka kaakasipai.'),\n",
       "   ('xp', 'Sospen kaukau em i hot tru.'),\n",
       "   ('xe', 'The saucepan of sweet potatos is really hot.'),\n",
       "   ('ex',\n",
       "    'Kaukau pitoka rirovira rutu kaakasipai uvare riro kasia tuitui kasi oripiro.'),\n",
       "   ('xp', 'Sospen kaukau em i hot tru bikos em i tan long bikpela paia.'),\n",
       "   ('xe', '???')]),\n",
       " ('kaakau',\n",
       "  [('ps', 'N'),\n",
       "   ('pt', 'FEM'),\n",
       "   ('ge', 'dog'),\n",
       "   ('tkp', 'dok'),\n",
       "   ('dt', '17/Jul/2005'),\n",
       "   ('ex', 'Kaakau voresiurava toupa aue kokoto ora kokopi.'),\n",
       "   ('xp', 'Dog i gat fopela lek bilong em na em i teleblonge.'),\n",
       "   ('xe', 'Dogs are four-footed ???.'),\n",
       "   ('ex', 'Revisa riro kaakau raguito.'),\n",
       "   ('xp', 'Revisa em i man bilong lukautim dok.'),\n",
       "   ('xe', 'Revisa is a big dog lover.'),\n",
       "   ('ex', 'Rake ora Jon kaakau kare ousia avasie.'),\n",
       "   ('xp', 'Rake wantaim Jon ol i go kisim ol wail dok.'),\n",
       "   ('xe', 'Rake and John went to get wild dogs.')]),\n",
       " ('kaakauko',\n",
       "  [('ps', 'N'),\n",
       "   ('pt', 'MASC'),\n",
       "   ('ge', 'gray weevil'),\n",
       "   ('tkp', 'wanpela kain binatang'),\n",
       "   ('sf', 'FAUNA.INSECT'),\n",
       "   ('nt', 'pictured on PNG postage stamp'),\n",
       "   ('dt', '29/Oct/2005'),\n",
       "   ('ex', 'Kaakauko ira toupareveira aue-ia niugini stemp.'),\n",
       "   ('xp', 'Kaakauko em insect em i istap long niugini.'),\n",
       "   ('xe', 'The gray weevil is found on the PNG stamp.'),\n",
       "   ('ex', 'Kaakauko iria toupaeveira niugini stamia.'),\n",
       "   ('xp', 'Weevil i stap long niguini stamp.'),\n",
       "   ('xe', 'The gray weevil is on the New Guinea stamp.'),\n",
       "   ('ex',\n",
       "    'Kaakauko korekare iava oira iria iava varaua vurivurivira ora kaapovira toupaiveira.'),\n",
       "   ('xp',\n",
       "    'Kaakavuko em i wanpela kain binatang skin bilong em i braun na wait.'),\n",
       "   ('xe', 'Kaakavuko is an insect whose body is brown and white.')]),\n",
       " ('kaakito',\n",
       "  [('rt', 'kaaki'),\n",
       "   ('ps', 'N'),\n",
       "   ('pt', 'HUM'),\n",
       "   ('ge', 'person blind with cataracts'),\n",
       "   ('tkp', 'man i gat wanpela ei'),\n",
       "   ('nt', 'nickname when used to describe one-eyed person'),\n",
       "   ('dt', '11/Feb/2005'),\n",
       "   ('ex', 'Rarasirea kakito eisiva rera Tavusiva uruiia.'),\n",
       "   ('xp', 'Rarasirea em i wan ai man bilong ples Tavusiova.'),\n",
       "   ('xe', 'Rarasirea is a one-eyed man from Tavusiova village.'),\n",
       "   ('ex', 'Kaakito kataitoa iava osireito vurapare.'),\n",
       "   ('xp', 'Man i gat wanpela ei na i lukluk.'),\n",
       "   ('xe', 'A one-eyed man looks out of one eye.')]),\n",
       " ('kaakuupato',\n",
       "  [('ps', 'N'),\n",
       "   ('pt', 'PN'),\n",
       "   ('ge', 'spring of hot mineral water near Togarao.'),\n",
       "   ('tkp', '???'),\n",
       "   ('nt',\n",
       "    'It is located in gulley above the shorter waterfall and is most likely ???.'),\n",
       "   ('dt', '08/Feb/2005'),\n",
       "   ('ex',\n",
       "    'Kasiraopato kaakuupato uicoto ira vusivusipareveira vova rasito vo toupare togarao-ia sisiupaveira vosa upiapave ora ruvapasa.'),\n",
       "   ('xp',\n",
       "    'Kaakuupato em i spirins hot water em i stap long Togavao taim husat i sik bai ol waswas long bai sick br pinis .'),\n",
       "   ('xe', '???'),\n",
       "   ('ex',\n",
       "    'Kaakuupato kasiraopato ukoto ira toupare eisi Rureva Togaraoia ruvaraia.'),\n",
       "   ('xp', 'Hot wara kaakuupato i stap long Rureva klostu long Togarao.'),\n",
       "   ('xe', 'The hot spring Kaakuupato is in Rureva near Togarao.')]),\n",
       " ('kaaova',\n",
       "  [('ps', 'N'),\n",
       "   ('pt', 'FEM'),\n",
       "   ('ge', 'aunt'),\n",
       "   ('tkp', '???'),\n",
       "   ('nt', 'FaSi'),\n",
       "   ('sf', 'KIN'),\n",
       "   ('dt', '19/Jul/2004')]),\n",
       " ('kaapa',\n",
       "  [('ps', 'N'),\n",
       "   ('pt', '???'),\n",
       "   ('ge', 'copper metal'),\n",
       "   ('tkp', 'retpela ain'),\n",
       "   ('dt', '12/Feb/2005'),\n",
       "   ('cmt', 'What is paupara doing in the second example?'),\n",
       "   ('ex', 'Kaapa vao oa-ia kepa paupaviei.'),\n",
       "   ('xp', 'Kaapa em i roof yumi save wokim haus long em.'),\n",
       "   ('xe', 'Copper we make houses from.'),\n",
       "   ('ex', 'Kaapara kepa paupara oara purapaiveira eisi Astararia.'),\n",
       "   ('xp', 'Kapa bilong wokim haus ol i save wokim long Australia.'),\n",
       "   ('xe', 'Copper rooves, they make them in Australia.')]),\n",
       " ('kaapea',\n",
       "  [('ps', '???'),\n",
       "   ('ge', 'weak'),\n",
       "   ('ge', 'loose'),\n",
       "   ('ge', 'easy'),\n",
       "   ('tkp', '???'),\n",
       "   ('cmt', 'Check spelling. Is it kaapea or kapea?'),\n",
       "   ('dt', '03/Jun/2005'),\n",
       "   ('ex', 'Kaapeta virago vao paupa.'),\n",
       "   ('xp', 'Dispela chair i no strong bilong sindaun.'),\n",
       "   ('xe', '???')]),\n",
       " ('kaapie',\n",
       "  [('rt', 'kaa'),\n",
       "   ('ps', 'N'),\n",
       "   ('pt', 'MASC'),\n",
       "   ('ge', 'hook'),\n",
       "   ('ge', 'fishhook'),\n",
       "   ('tkp', 'huk'),\n",
       "   ('dt', '15/Feb/2004')]),\n",
       " ('kaapie',\n",
       "  [('rt', 'kaa'),\n",
       "   ('ps', 'V'),\n",
       "   ('pt', 'B'),\n",
       "   ('ge', 'hook'),\n",
       "   ('eng', 'choke'),\n",
       "   ('eng', 'snag'),\n",
       "   ('eng', 'hook'),\n",
       "   ('ge', 'capture'),\n",
       "   ('tkp', 'hukim'),\n",
       "   ('tkp', 'pasim long huk'),\n",
       "   ('arg', 'O'),\n",
       "   ('vx', '2'),\n",
       "   ('dt', '15/Nov/2005'),\n",
       "   ('cmt',\n",
       "    \"Double-check vowel length of kaa. First example doesn't make sense. Is it two sentences?\"),\n",
       "   ('ex', 'Aiopaoro karoi kakaeto kaapierivoi aioa-ia.'),\n",
       "   ('xp', 'Kaikai pas long nek bilong mi kaikai i pas long pikinini.'),\n",
       "   ('xe', '???'),\n",
       "   ('ex',\n",
       "    'Koie kaapierevo Ririre ovare oira gisipoaro iare karuveraisi vikirevo.'),\n",
       "   ('xp', 'Ririre i tromoem singapo insait long maus bilong pik na i pas.'),\n",
       "   ('xe', 'Ririre ???.'),\n",
       "   ('ex', 'Aakova kakaeto kapieevoi aioa-ia.'),\n",
       "   ('xp',\n",
       "    'Mama i givim kaikai long pikinini na hap kaikai i pas long nek bilong em.'),\n",
       "   ('xe', 'Mother made the boy choke with some food.'),\n",
       "   ('ex',\n",
       "    'Aakova kakaeto kaapievoi aioa-ia uvare viapau vearovira va orievo.'),\n",
       "   ('xp', 'Mama em i mekim pas kaikai long pikinini bikos em i no kukim gut.'),\n",
       "   ('xe',\n",
       "    \"Mother made the boy choke from the food because she didn't cook it well.\"),\n",
       "   ('ex', 'Avuka kakaeto aiopiepaoro rera kaapieevo.'),\n",
       "   ('xp', 'Lapun wok long givim kaikai long bebe na kaikai i pas long nek.'),\n",
       "   ('xe', 'The old person fed the boy and made it choke.')]),\n",
       " ('kaapiepato',\n",
       "  [('rt', 'kaapie'),\n",
       "   ('ps', 'N'),\n",
       "   ('pt', 'HUM'),\n",
       "   ('ge', 'fisher'),\n",
       "   ('tkp', 'man bilong hukim pis'),\n",
       "   ('dt', '12/Feb/2005'),\n",
       "   ('ex', 'Aveatoa atari kapiepato vokiara rutu.'),\n",
       "   ('xp', 'Aveato em i man bilong hukim pis olgeta de.'),\n",
       "   ('xe', 'Aveato works as a fisherman every day.')]),\n",
       " ('kaapisi',\n",
       "  [('ps', 'V'),\n",
       "   ('pt', 'B'),\n",
       "   ('ge', 'pinch together'),\n",
       "   ('ge', 'grip with pincers'),\n",
       "   ('tkp', 'holim'),\n",
       "   ('arg', 'O'),\n",
       "   ('vx', '2'),\n",
       "   ('dt', '08/Jun/2005'),\n",
       "   ('ex',\n",
       "    'Kaapisi ava eva ra avekeara kasiraopa ra kaekaepiea. Ra varao vera oara kasiraopai.'),\n",
       "   ('xp',\n",
       "    'Yu mas kam wantam sisis pinvh bar mi ya rausim ol dispela pela stow ol bai mi rausim ol dispela i hot.'),\n",
       "   ('xe', '???'),\n",
       "   ('ex', 'Avekeara kaapisi evara kasiraopara.'),\n",
       "   ('xp', 'Yu rausim ol ton i hot long pansa.'),\n",
       "   ('xe', '???')]),\n",
       " ('kaapisivira',\n",
       "  [('rt', 'kaapisi'),\n",
       "   ('ps', 'ADV'),\n",
       "   ('pt', 'MANNER'),\n",
       "   ('ge', 'linked'),\n",
       "   ('ge', 'pinched'),\n",
       "   ('tkp', '???'),\n",
       "   ('dt', '29/Oct/2005'),\n",
       "   ('ex', 'Auea eva oa kaapisivira toupaivoi.'),\n",
       "   ('xp', 'Samting i stap olsem pansa.'),\n",
       "   ('xe', '???'),\n",
       "   ('ex', 'Pariearei tapokovira toupai uva kaapisivira kekepapiroi.'),\n",
       "   ('xp', 'Hap mambu i pas wantaim na i luk olsem sises.'),\n",
       "   ('xe', '???')]),\n",
       " ('kaapo',\n",
       "  [('ps', '???'),\n",
       "   ('ge', 'white'),\n",
       "   ('tkp', 'wait'),\n",
       "   ('cmt', 'Not a sentence, I think.'),\n",
       "   ('dt', '29/Oct/2005'),\n",
       "   ('ex', 'Kaapoa varoa ragai vaaro.'),\n",
       "   ('xp', 'Waitpela laplap bilong mi.'),\n",
       "   ('xe', 'My white clothes.'),\n",
       "   ('ex',\n",
       "    'Naomi aakova tavievo oisio kaakau ragai vaaro ivaraia vokaevo varoa kaapopa uva vuri keke rutu.'),\n",
       "   ('xp',\n",
       "    'Naomi tokim mama bilong em olsem, dok i wokabaut antap long waitpela laplap bilong mi na i luk nogut tru.'),\n",
       "   ('xe', '???')]),\n",
       " ('kaapopato',\n",
       "  [('rt', 'kaapo'),\n",
       "   ('ps', 'N'),\n",
       "   ('pt', 'HUM'),\n",
       "   ('ge', 'white man'),\n",
       "   ('tkp', 'waitskin'),\n",
       "   ('cmt', 'One example is kaapoto, not kaapopato.'),\n",
       "   ('dt', '29/Oct/2005'),\n",
       "   ('ex', 'Rarasoria kaapoto oirato.'),\n",
       "   ('xp', 'Rarason em i waitman.'),\n",
       "   ('xe', 'Rarason is a white man.'),\n",
       "   ('ex', 'Rarasoria kaapopato ira rupairara vo reoaro poreparevo.'),\n",
       "   ('xp',\n",
       "    'Rarason em i waitpela man em i wok long tanim tok ples bilong ol bilak man.'),\n",
       "   ('xe',\n",
       "    'Robinson is a white man who is translating the language of black men.')]),\n",
       " ('kaara',\n",
       "  [('ps', 'N'),\n",
       "   ('pt', 'FEM'),\n",
       "   ('ge', 'car'),\n",
       "   ('tkp', 'ka'),\n",
       "   ('nt', 'Tok Pisin loan'),\n",
       "   ('dt', '11/Feb/2005'),\n",
       "   ('ex', 'Kaara avaoe eisi-re Araua.'),\n",
       "   ('xp', 'Ka i bin go long Arawa.'),\n",
       "   ('xe', 'The car went to Arawa.'),\n",
       "   ('ex', 'Moto kaara eira ragai oiraaro garevari.'),\n",
       "   ('xp', 'Moto ka em bilong mi em liklik.'),\n",
       "   ('xe', 'My car is small.')]),\n",
       " ('kaare',\n",
       "  [('ps', '???'),\n",
       "   ('ge', 'white'),\n",
       "   ('tkp', 'wait'),\n",
       "   ('dt', '29/Oct/2005'),\n",
       "   ('ex', 'Eira kaare riakova koie.'),\n",
       "   ('xp', 'Em waitpela pik meri.'),\n",
       "   ('xe', \"That's a white female pig.\"),\n",
       "   ('ex', 'Kaare reoreoa raga oaravu reoara vearo kekepiepasia.'),\n",
       "   ('xp', '???'),\n",
       "   ('xe', '???')]),\n",
       " ('kaareko',\n",
       "  [('ps', 'V'),\n",
       "   ('pt', 'B'),\n",
       "   ('ge', 'scour'),\n",
       "   ('tkp', 'skrapim'),\n",
       "   ('eng', 'scour'),\n",
       "   ('eng', 'clean by scraping'),\n",
       "   ('arg', 'O'),\n",
       "   ('vx', '2'),\n",
       "   ('dcsv', 'true'),\n",
       "   ('dt', '08/Jun/2005'),\n",
       "   ('ex', 'Avukava iria opokuio kaarekoevo va oriorioro.'),\n",
       "   ('xp', 'Lapun meri i skirapim taro wait tru.'),\n",
       "   ('xe', 'The old woman cleaned the taro by scouring it.')]),\n",
       " ('kaarekopie',\n",
       "  [('rt', 'kaareko'),\n",
       "   ('ps', 'V'),\n",
       "   ('pt', 'B'),\n",
       "   ('ge', 'scrub'),\n",
       "   ('eng', 'scrape'),\n",
       "   ('eng', 'scour'),\n",
       "   ('eng', 'scrub'),\n",
       "   ('eng', 'clean by scraping or scrubbing'),\n",
       "   ('tkp', 'skirapim gut'),\n",
       "   ('arg', 'O'),\n",
       "   ('vx', '2'),\n",
       "   ('dt', '15/Nov/2005'),\n",
       "   ('ex', 'Vao opoa kaarekopierivoi rutu va oriorioro.'),\n",
       "   ('xp', 'Yo sikirapim gut tru dispela taro na em wait dseta.'),\n",
       "   ('xe', 'You scraped clean the taro by scouring it.'),\n",
       "   ('ex',\n",
       "    'Sera kaarekopievira opoara oriorievoi uva viapau katokatoara ivaraia.'),\n",
       "   ('xp',\n",
       "    'Sera em i sikirapim gut tru ol taro na ol taro i no gat bilakpela hap long em.'),\n",
       "   ('xe',\n",
       "    'Sera cooked the taro, cleaning it by scraping it, and there are no spots on it.'),\n",
       "   ('ex', 'Sera pitokava kaarokopievo eisi uukovi.'),\n",
       "   ('xp', 'Sera em i klinim gut sospen long wara.'),\n",
       "   ('xe', 'Sera scrubbed the sauce pan in the water.')]),\n",
       " ('kaareto',\n",
       "  [('rt', 'kaare'),\n",
       "   ('ps', 'N'),\n",
       "   ('pt', 'MASC'),\n",
       "   ('ge', 'white male object'),\n",
       "   ('tkp', '???'),\n",
       "   ('cmt',\n",
       "    \"Is the gloss right? What exactly does this mean? Example isn't sentences.\"),\n",
       "   ('nt', 'Used to describe a white male pig.'),\n",
       "   ('dt', '29/Oct/2005'),\n",
       "   ('ex', 'Ragai reraaro kaareto koieto.'),\n",
       "   ('xp', 'Waitpela pik man bilong mi.'),\n",
       "   ('xe', 'My white pig.'),\n",
       "   ('ex',\n",
       "    'Oirato kaareto varuere kare iava ora korekare oisio osia koieto o kookopuoto.'),\n",
       "   ('xp', 'Waitpela man animal ol insek olsem pik man o bataplai man.'),\n",
       "   ('xe', '???')]),\n",
       " ('Kaareva',\n",
       "  [('ps', 'N'),\n",
       "   ('pt', 'PN'),\n",
       "   ('ge', 'Mapiaro'),\n",
       "   ('tkp', 'ples nem'),\n",
       "   ('nt', 'altenate name for this village'),\n",
       "   ('sf', 'TOP'),\n",
       "   ('dt', '08/Feb/2005'),\n",
       "   ('ex', 'Uruia vaisiaro vao Kaareva.'),\n",
       "   ('xp', 'Em name blong wanpela ples Kaareva.'),\n",
       "   ('xe', 'Kaareva is the name of a village.')]),\n",
       " ('kaava',\n",
       "  [('ps', 'V'),\n",
       "   ('pt', 'A'),\n",
       "   ('ge', 'feint with bow and arrow'),\n",
       "   ('tkp', '???'),\n",
       "   ('vx', '1'),\n",
       "   ('dt', '03/Jun/2005'),\n",
       "   ('cmt', 'Is there a better translation. Double check.'),\n",
       "   ('ex', 'Kaavapauei viapau uvuipaupei iasia.'),\n",
       "   ('xp', 'Skin blong yu i no strong tumas long sut.'),\n",
       "   ('xe', \"You feint but you can't shoot.\"),\n",
       "   ('ex', 'Kaavapauei viapau uvuipau iasia eira-ia koetava.'),\n",
       "   ('xp', 'Yu no i nap sut long dispela bonara.'),\n",
       "   ('xe', \"You feint but you can't shoot with a bow.\")]),\n",
       " ('kaavaaua',\n",
       "  [('ps', 'N'),\n",
       "   ('pt', 'NT'),\n",
       "   ('ge', 'plant'),\n",
       "   ('tkp', '???'),\n",
       "   ('sf', 'FLORA'),\n",
       "   ('nt', 'salt flavor is derived by burning it to ash, it grows ???'),\n",
       "   ('cmt', 'Is it kaavaaua or kaavaua?'),\n",
       "   ('dt', '27/Feb/2005'),\n",
       "   ('ex',\n",
       "    'Kaavaua votoupai uuko vagaparo-ia ora vo uuko gaero sivova. Va kasiupa auero sait.'),\n",
       "   ('xp',\n",
       "    'Kaavaua em i save i stap long ol watertool na long arere bilong ol wara. Ol i save kukim bilong sait.'),\n",
       "   ('xe', '???'),\n",
       "   ('ex', 'Kaavaua okouroa purapapiroveira vo vagapapara kovuaro-ia.'),\n",
       "   ('xp', 'Kaavaua i save i stap namel long waterfall.'),\n",
       "   ('xe', 'The kaavaaaua plant shows up in the middle of waterfalls.')]),\n",
       " ('kaaveaka',\n",
       "  [('ps', 'V'),\n",
       "   ('pt', 'B'),\n",
       "   ('ge', 'clear up'),\n",
       "   ('ge', 'make available'),\n",
       "   ('tkp', '???'),\n",
       "   ('arg', '???'),\n",
       "   ('vx', '2'),\n",
       "   ('dcsv', 'true'),\n",
       "   ('dt', '08/Jun/2005'),\n",
       "   ('cmt', 'The syntax of this is interesting and should be investigated.'),\n",
       "   ('ex', 'Kaaveaka vao-ia uvuipai va purasia.'),\n",
       "   ('xp', 'Em isi long mi long mekim.'),\n",
       "   ('xe', \"That's easy for me to do.\")]),\n",
       " ('kaaveakapie',\n",
       "  [('rt', 'kaaveaka'),\n",
       "   ('ps', 'V'),\n",
       "   ('pt', 'B'),\n",
       "   ('ge', '???'),\n",
       "   ('tkp', '???'),\n",
       "   ('arg', 'O'),\n",
       "   ('vx', '2'),\n",
       "   ('dt', '08/Jun/2005'),\n",
       "   ('ex', 'Vearovira uvare va kaveakapieri ragai-pa.'),\n",
       "   ('xp', 'Tenkyu bikos yu mekim isi long mi.'),\n",
       "   ('xe', 'Thank you because you make it easy for me.')]),\n",
       " ('kaaveakapievira',\n",
       "  [('rt', 'kaaveakapie'),\n",
       "   ('ps', 'ADV'),\n",
       "   ('pt', 'MANNER'),\n",
       "   ('ge', '???'),\n",
       "   ('tkp', 'i no putim gut samting'),\n",
       "   ('dt', '15/Nov/2005'),\n",
       "   ('ex', 'Kaveakapievira aveke tovoivo uva koveoe.'),\n",
       "   ('xp', 'Ol i no putim gut ston bihain em i pundaun.'),\n",
       "   ('xe', 'They placed the stone insecurely and it fell down.')]),\n",
       " ('kaaveakavira',\n",
       "  [('rt', 'kaaveaka'),\n",
       "   ('ps', 'ADV'),\n",
       "   ('pt', 'MANNER'),\n",
       "   ('ge', 'easy'),\n",
       "   ('tkp', 'isi'),\n",
       "   ('eng', 'revealed'),\n",
       "   ('eng', 'out in the open'),\n",
       "   ('eng', 'freely'),\n",
       "   ('eng', 'available'),\n",
       "   ('eng', 'easy'),\n",
       "   ('eng', 'clearly'),\n",
       "   ('dt', '11/Feb/2005'),\n",
       "   ('ex', 'Kaaveakavira toupaivo ra va purape. Viapau riro gorupai.'),\n",
       "   ('xp', 'Em i isi long mekim i no hat tumas long yumi long mekmekim.'),\n",
       "   ('xe',\n",
       "    \"It is easy and it can't be done. It's not hard (literally: strong).\"),\n",
       "   ('ex', 'Kaveakavira rutu toupai veigei-pa ra va purape.'),\n",
       "   ('xp', 'Em i isi tru long yumi wokim.'),\n",
       "   ('xe', 'It is easy for us to do it.')]),\n",
       " ('kae',\n",
       "  [('ps', 'V'),\n",
       "   ('pt', 'B'),\n",
       "   ('ge', 'carry'),\n",
       "   ('tkp', 'karim'),\n",
       "   ('arg', 'O'),\n",
       "   ('vx', '2'),\n",
       "   ('dcsv', 'true'),\n",
       "   ('dt', '08/Jun/2005'),\n",
       "   ('ex', 'Vao kae paupava tovosia vo.'),\n",
       "   ('xp', 'Yu karim dispela chair na kam putim long hia.'),\n",
       "   ('xe', 'Carrying this chia and put it here.'),\n",
       "   ('ex', 'Viruata atari keesi kaerevoi eisi-re atoia.'),\n",
       "   ('xp', 'Viruata i karim katen pis i go long ples.'),\n",
       "   ('xe', 'Viruata is carrying a case of fish to the village.')]),\n",
       " ('kae',\n",
       "  [('ps', 'V'),\n",
       "   ('pt', 'A'),\n",
       "   ('ge', 'blow'),\n",
       "   ('tkp', '???'),\n",
       "   ('vx', '1'),\n",
       "   ('cmt', 'double-check gloss'),\n",
       "   ('dt', '06/Dec/2006')]),\n",
       " ('kaekae',\n",
       "  [('rt', 'kae'),\n",
       "   ('ps', '???'),\n",
       "   ('ge', 'long'),\n",
       "   ('tkp', 'long'),\n",
       "   ('am', 'true'),\n",
       "   ('dcsv', '???'),\n",
       "   ('dt', '29/Oct/2005'),\n",
       "   ('ex', 'Tovasi vokepaaro-ia riro kaekaea toupaivoi paupaa.'),\n",
       "   ('xp', 'Long haus bilong Tomas i go longpela bet bilong sindaun.'),\n",
       "   ('xe', \"In Thomas' house there is a long bed.\"),\n",
       "   ('ex',\n",
       "    'Buka-ia riro kaekae tapi rutu viapau uvuipai ra katai voki raga-ia voa-re avau.'),\n",
       "   ('xp', 'Buka i long we tru, yu no inap i go long hap wanpela dei tasol.'),\n",
       "   ('xe', \"Buka is a faraway place, you can't go there in just one day.\")]),\n",
       " ('kaekae',\n",
       "  [('rt', 'kae'),\n",
       "   ('ps', 'V'),\n",
       "   ('pt', 'B'),\n",
       "   ('rdp', 'full'),\n",
       "   ('ge', 'tempt'),\n",
       "   ('tkp', 'traim'),\n",
       "   ('arg', '???'),\n",
       "   ('vx', '???'),\n",
       "   ('dt', '08/Dec/2005'),\n",
       "   ('ex',\n",
       "    'Ragai kaekaeparevo reoreopaoro oisio ra kasipura ra ragai uporeve.'),\n",
       "   ('xp',\n",
       "    'Em i wok long traim mi long toktok olsem na bai mi koros na bai em i paitim mi.'),\n",
       "   ('xe', '???')]),\n",
       " ('kaekaearo',\n",
       "  [('rt', 'kae'),\n",
       "   ('ps', 'N'),\n",
       "   ('pt', 'NT'),\n",
       "   ('ge', 'length of'),\n",
       "   ('tkp', 'long bilong en'),\n",
       "   ('dt', '29/Oct/2005'),\n",
       "   ('ex', 'Va kaekaearo vao-ia oiso uvuipai.'),\n",
       "   ('xp', 'Longpela em em i nap olsem.'),\n",
       "   ('xe', 'Its length is enough.'),\n",
       "   ('ex', 'E vo kepa kaekaearo rutua vao-ia.'),\n",
       "   ('xp', 'Em longpela bilong dispela haus.'),\n",
       "   ('xe', \"That's the length of the house.\"),\n",
       "   ('ex', 'E vo kepa kaekaearo ourivo.'),\n",
       "   ('xp', 'Yu kisim longpela bilong haus.'),\n",
       "   ('xe', 'Get the length of the house.'),\n",
       "   ('ex',\n",
       "    'Buka raiva kaekaearo riro kaekaea rutu Arawa raiva-pa oa tutupievira toupaivoi.'),\n",
       "   ('xp',\n",
       "    'Buka rot em i longpela rot moa yet long rot bilong Arawa em i stap klostu tasol.'),\n",
       "   ('xe', '???')]),\n",
       " ('kaekaeo',\n",
       "  [('ps', 'N'),\n",
       "   ('pt', 'NT'),\n",
       "   ('ge', 'type of fern'),\n",
       "   ('tkp', '???'),\n",
       "   ('nt', 'grows on the ground and has leaves used in medicine and in coded'),\n",
       "   ('dt', '11/Feb/2005'),\n",
       "   ('sf', 'FLORA'),\n",
       "   ('ex',\n",
       "    'Kaekaeo okouro riropai vo vegoaro vara gururaroia ruvaropaveira aue upiaara ora okovorovu toupaivoi.'),\n",
       "   ('xp',\n",
       "    'Kaekaeo em i save grom lans buch ol, save usim lit blons em loag nakim manas bloms sick.'),\n",
       "   ('xe', '???'),\n",
       "   ('ex', 'Kaekaeo kouro oara kovapapeira vo uva kovopaiveira.'),\n",
       "   ('xp', 'Kaekaeo i save kamap long ol hap ol i save wokim gaden.'),\n",
       "   ('xe', 'This type of fern usually appears wherever they garden.')]),\n",
       " ('kaekaesoto',\n",
       "  [('rt', 'kaekae'),\n",
       "   ('ps', 'N'),\n",
       "   ('pt', 'HUM'),\n",
       "   ('ge', 'tall person'),\n",
       "   ('tkp', '???'),\n",
       "   ('dt', '11/Sep/2004'),\n",
       "   ('ex', 'Mak iro kaekaesoto.'),\n",
       "   ('xp', 'Mak em i longpela man.'),\n",
       "   ('xe', 'Mark is tall.'),\n",
       "   ('ex', 'Itasito kaekaesoto eisiva rera Ivu.'),\n",
       "   ('xp', 'Itasito em i longpela man bilong Ibu.'),\n",
       "   ('xe', 'Itasito is a tall man from Ibu.')]),\n",
       " ('kaekaevira',\n",
       "  [('alt', 'kaekaepavira'),\n",
       "   ('rt', 'kaekae'),\n",
       "   ('ps', 'ADV'),\n",
       "   ('pt', 'MANNER'),\n",
       "   ('ge', 'long'),\n",
       "   ('eng', 'long awy'),\n",
       "   ('eng', 'far away'),\n",
       "   ('tkp', 'long we'),\n",
       "   ('dt', '29/Oct/2005'),\n",
       "   ('ex', 'Rarasori riro kaekaevira rutu-va urioroera vigei vo tokoaro iare.'),\n",
       "   ('xp', 'Rarason i bin kam long we tru na kam long ailan bilong yumi.'),\n",
       "   ('xe', 'Robinson came from far away to our island.')]),\n",
       " ('kaekeru',\n",
       "  [('ps', 'N'),\n",
       "   ('pt', '???'),\n",
       "   ('ge', 'clavicle'),\n",
       "   ('tkp', 'bun bilong sol'),\n",
       "   ('dt', '02/Sep/2005'),\n",
       "   ('ex', 'Kaekeru keru upiaei ragai-re voea vao kaepaavoi.'),\n",
       "   ('xp', 'Klavikol bun em i pain taim mi kalim dispela.'),\n",
       "   ('xe', 'The collar bone hurts me ???.'),\n",
       "   ('ex', 'Kaekeru oaia ogata tuupaveira riakora ora oirara evao kaepaveira.'),\n",
       "   ('xp',\n",
       "    'Klavikol bun ol meri i save karim woksak na tu ol man i save karim diwai.'),\n",
       "   ('xe', 'On their shoulders women carry bags and men carry trees.')]),\n",
       " ('kaepaa',\n",
       "  [('rt', 'kae'),\n",
       "   ('ps', 'N'),\n",
       "   ('pt', 'NT'),\n",
       "   ('ge', 'wheelbarrow'),\n",
       "   ('ge', 'basket'),\n",
       "   ('tkp', '???'),\n",
       "   ('nt', 'anything used for carrying things'),\n",
       "   ('dt', '12/Feb/2005'),\n",
       "   ('ex', 'Kiaie kouro kaesia kaepa va-ia.'),\n",
       "   ('xp', 'Yu go karim ol pipia long wilbaro.'),\n",
       "   ('xe', 'Carry the trash in the wheelbarrow.')]),\n",
       " ('kaepie',\n",
       "  [('rt', 'kae'),\n",
       "   ('ps', 'V'),\n",
       "   ('pt', 'B'),\n",
       "   ('sn', '1'),\n",
       "   ('ge', 'hoist'),\n",
       "   ('ge', 'lift'),\n",
       "   ('ge', 'raise'),\n",
       "   ('tkp', 'apim'),\n",
       "   ('tkp', 'antapim'),\n",
       "   ('tkp', 'putim antap'),\n",
       "   ('arg', 'O'),\n",
       "   ('vx', '2'),\n",
       "   ('dt', '15/Nov/2005'),\n",
       "   ('ex', 'Pita, sigoa kaepieoro uriou eva evoa rasiuaro.'),\n",
       "   ('xp', 'Pita, yu kisim naip i kam em i stap long graun.'),\n",
       "   ('xe', \"Pita, come pick up the knife that's on the ground.\"),\n",
       "   ('ex', 'Aiteto rirova aveke kaepierevo aruvea.'),\n",
       "   ('xp', 'Papa i hapim traipela ston asde.'),\n",
       "   ('xe', 'Dad lifted a large stone yesterday.')]),\n",
       " ('kaepie',\n",
       "  [('rt', 'kae'),\n",
       "   ('ps', 'V'),\n",
       "   ('pt', 'B'),\n",
       "   ('sn', '2'),\n",
       "   ('ge', '???'),\n",
       "   ('tkp', 'kisim bik nem'),\n",
       "   ('arg', 'O'),\n",
       "   ('vx', '2'),\n",
       "   ('dt', '11/Feb/2007'),\n",
       "   ('ex',\n",
       "    'Rarasori vaisiaro kaepieivoi uvare vearo kovo rutu purare voea Rotokasi taere-ia'),\n",
       "   ('xp',\n",
       "    'Ol i putim nem bilong Rarason i go hantap bikos em i wokim gutpela wok long Rotokas.'),\n",
       "   ('xe',\n",
       "    \"They've put Robinson's name up there because he is doing good work among the Rotokas.\"),\n",
       "   ('ex', 'Rarasori riro vaisi ourevoi rera varo-ia vearo kovo.'),\n",
       "   ('xp', 'Rarason em i kisim bik nem long gutpela work bilong em.'),\n",
       "   ('xe', 'Robinson is getting a big name for his work.')]),\n",
       " ('kaepievira',\n",
       "  [('rt', 'kaepie'),\n",
       "   ('ps', 'ADV'),\n",
       "   ('pt', 'MANNER'),\n",
       "   ('ge', 'high'),\n",
       "   ('tkp', 'antap hai'),\n",
       "   ('dt', '11/Feb/2005'),\n",
       "   ('ex', 'Vaoepa kaepievira toupai viraia rutu.'),\n",
       "   ('xp', 'Dispela em i stap antap tru.'),\n",
       "   ('xe', 'This is really high up.'),\n",
       "   ('ex', 'Tutue pukui kaepievira toupaivoi.'),\n",
       "   ('xp', 'Maunten Balbi em i stap antap tru.'),\n",
       "   ('xe', 'Mount Balbi is up high.')]),\n",
       " ('kaereasi',\n",
       "  [('ps', '???'),\n",
       "   ('ge', 'type of weave that is slanted (X-like)'),\n",
       "   ('tkp', 'wankain samap'),\n",
       "   ('cmt', 'Second ex. sentence needs to be edited'),\n",
       "   ('dt', '11/Feb/2007'),\n",
       "   ('ex', 'Touro ira kaereasi take raga turupareveira.'),\n",
       "   ('xp', 'Touru i save wokim tasol kaereasi wol.'),\n",
       "   ('xe', 'Touro only knows how to make slant-weave walls.'),\n",
       "   ('ex',\n",
       "    'Viapau uvuipai ra oiratoavai o kaereve takei iria vaisipaiveira oisio kaereasi uvare kovekove paoveira osia oira kaepaive.'),\n",
       "   ('xp',\n",
       "    'Nogat wanpela man karim dispela wuol ol i kolim olsem kaereasi bikos em i save pundaon nating taim ol i karim.'),\n",
       "   ('xe', 'No man can ???.')]),\n",
       " ('kaereasivira',\n",
       "  [('rt', 'kaereasi'),\n",
       "   ('ps', 'ADV'),\n",
       "   ('pt', 'MANNER'),\n",
       "   ('ge', 'slanted'),\n",
       "   ('ge', 'crooked'),\n",
       "   ('tkp', 'i no stret i go'),\n",
       "   ('dt', '11/Feb/2005'),\n",
       "   ('cmt', 'What does regorepa mean?'),\n",
       "   ('ex', 'Kaereasivira vao toupai regorepanisivi.'),\n",
       "   ('xp', 'Dispela em i stap krut liklik.'),\n",
       "   ('xe', 'This is slightly crooked.'),\n",
       "   ('ex', 'Vao evaoa kaereasivira toupai regorepa.'),\n",
       "   ('xp', 'Dispela diwai i no gutpela long karim bikos em i krunkut.'),\n",
       "   ('xe', 'This tree is crooked and ???.')]),\n",
       " ('kaetu',\n",
       "  [('ps', '???'),\n",
       "   ('ge', 'tight'),\n",
       "   ('ge', 'stiff'),\n",
       "   ('ge', 'taut'),\n",
       "   ('tkp', 'tait'),\n",
       "   ('dcsv', 'true'),\n",
       "   ('am', 'false'),\n",
       "   ('cmt', 'Is it kaitu or kaetu?'),\n",
       "   ('dt', '07/Jun/2005'),\n",
       "   ('ex', 'Iroiro vao kaitu vara toupaivoi.'),\n",
       "   ('xp', 'Dispela rop i tait tru.'),\n",
       "   ('xe', 'This rope is tight.')]),\n",
       " ('kaetupie',\n",
       "  [('rt', 'kaetu'),\n",
       "   ('ps', 'V'),\n",
       "   ('pt', 'B'),\n",
       "   ('ge', 'tighten'),\n",
       "   ('tkp', 'taitim'),\n",
       "   ('arg', 'O'),\n",
       "   ('vx', '2'),\n",
       "   ('cmt', 'It is kaetupie or kaitupie?'),\n",
       "   ('dt', '08/Jun/2005'),\n",
       "   ('ex', 'Iroiro kaetupieta, ra vara ivupe.'),\n",
       "   ('xp', 'Yu taitim dispela rop na XXX pulim.'),\n",
       "   ('xe', \"Tighten the rope and we'll pull them.\"),\n",
       "   ('ex', 'Iroiro vao kaetupieri rutu ra kaetupe rutu.'),\n",
       "   ('xp', 'Yu taitim tru dispela rop. Bai em i tait tru.'),\n",
       "   ('xe', 'Tighten this rope good and it will be tight.'),\n",
       "   ('ex', 'Iroiro vao kaitupieri ra kaitupe rutu.'),\n",
       "   ('xp', 'Yu taitim strong rop bai tai tru.'),\n",
       "   ('xe', 'Tighten the rope and it will be tight.')]),\n",
       " ('kaetuvira',\n",
       "  [('ps', 'ADV'),\n",
       "   ('pt', 'MANNER'),\n",
       "   ('ge', 'tight'),\n",
       "   ('ge', 'stiff'),\n",
       "   ('ge', 'taut'),\n",
       "   ('tkp', 'tait'),\n",
       "   ('cmt', 'Is it kaitu or kaetu?'),\n",
       "   ('dt', '03/Jun/2005'),\n",
       "   ('ex', 'Iroiro vao kaetuvira toupai.'),\n",
       "   ('xp', 'Dispela rop em tait tumas.'),\n",
       "   ('xe', 'This rope is too tight.')]),\n",
       " ('kaeviro',\n",
       "  [('ps', 'V'),\n",
       "   ('pt', 'A'),\n",
       "   ('ge', 'lift off'),\n",
       "   ('ge', 'take off'),\n",
       "   ('tkp', 'go antap'),\n",
       "   ('sc', 'MOTION'),\n",
       "   ('vx', '1'),\n",
       "   ('nt', 'used to describe action of plane'),\n",
       "   ('dt', '03/Jun/2005'),\n",
       "   ('ex', 'Pita kaeviroroe kepa kekesia oa vuripierevo kiuvu.'),\n",
       "   ('xp', 'Pita i go antap na lukim haus win i bagarapim.'),\n",
       "   ('xe', 'Peter went to look at the house that the wind destroyed.')]),\n",
       " ('kagave',\n",
       "  [('ps', 'N'),\n",
       "   ('pt', 'FEM'),\n",
       "   ('ge', 'forehead'),\n",
       "   ('tkp', 'poret pes'),\n",
       "   ('sf', 'BP'),\n",
       "   ('dt', '29/Oct/2005'),\n",
       "   ('ex', 'Kukue-ia toupaevoi kakave.'),\n",
       "   ('xp', 'Peis em i stap long het.'),\n",
       "   ('xe', 'The forehead is on the head.'),\n",
       "   ('ex',\n",
       "    'Riakova resipaivo oiratoa iare vuri kagaveto uva rera-pa reasipaoro torievo ouruivu iare.'),\n",
       "   ('xp',\n",
       "    'Ol i mekim meri long wanpela pes nogut man na meri i les long em na em i ranawe i go long narapela ples.'),\n",
       "   ('xe',\n",
       "    'They made the woman go to the man with a bad forehead and, not wanting him, she ran away to another village.')]),\n",
       " ('kaie',\n",
       "  [('ps', 'V'),\n",
       "   ('pt', 'A'),\n",
       "   ('ge', 'make trash'),\n",
       "   ('ge', 'create a mess'),\n",
       "   ('tkp', 'pipia'),\n",
       "   ('vx', '1'),\n",
       "   ('cmt', 'What does panat mean?'),\n",
       "   ('sc', '???'),\n",
       "   ('dt', '03/Jun/2005'),\n",
       "   ('ex', 'Kaiepauei.'),\n",
       "   ('xp', 'Yu mekim panat pipia.'),\n",
       "   ('xe', 'You are creating a mess with the rubbish.'),\n",
       "   ('ex', 'Riroara rutu kaiepaue voia.'),\n",
       "   ('xp', 'Yu mekim panat pipia tumas.'),\n",
       "   ('xe', \"You're making a lot of garbage.\")]),\n",
       " ('kaiea',\n",
       "  [('rt', 'kaie'),\n",
       "   ('ps', 'N'),\n",
       "   ('pt', 'NT'),\n",
       "   ('ge', 'rubbish'),\n",
       "   ('ge', 'trash'),\n",
       "   ('ge', 'garbage'),\n",
       "   ('tkp', '???'),\n",
       "   ('dt', '12/Feb/2005'),\n",
       "   ('cmt', 'Is the second sentence a command or a sentence fragment?'),\n",
       "   ('ex', 'Kaiea vao voia kepa-ia.'),\n",
       "   ('xp', 'Pipia em istap long house.'),\n",
       "   ('xe', 'The trash is in the house.'),\n",
       "   ('ex', 'Kaieara vikisia eisi rikui.'),\n",
       "   ('xp', 'Go tromoe ol pipia long hol.'),\n",
       "   ('xe', 'throw trash in the hole.')]),\n",
       " ('kaikaio',\n",
       "  [('ps', 'N'),\n",
       "   ('pt', 'NT'),\n",
       "   ('ge', 'type of vine'),\n",
       "   ('tkp', '???'),\n",
       "   ('nt', \"Sometimes mistaken for the black vine called `varuru iro'.\"),\n",
       "   ('dt', '12/Feb/2005'),\n",
       "   ('ex',\n",
       "    'Kaikaio vo kovapapeira vo uva kovoive rovovovira va-ia ruvarupavei vosia ira upiaparo.'),\n",
       "   ('xp',\n",
       "    'Kaikaio em i save grow long ples o hap ol isave wokim grondew long em.'),\n",
       "   ('xe', 'The kaikaio vine grows here and ???.'),\n",
       "   ('ex', 'Kaikaio iria vo karekepaoveira uva kovopaiveira.'),\n",
       "   ('xp', 'Kaikaio i save kamap long hap ol i save wokim gaden.'),\n",
       "   ('xe', 'This type of vine appears where they garden.')]),\n",
       " ('Kaio',\n",
       "  [('ps', 'N'),\n",
       "   ('pt', 'PN'),\n",
       "   ('ge', 'name'),\n",
       "   ('eng', 'name'),\n",
       "   ('ig', 'yes'),\n",
       "   ('dt', '17/May/2004')]),\n",
       " ('kaipori',\n",
       "  [('ps', 'V'),\n",
       "   ('pt', 'A'),\n",
       "   ('ge', 'alert'),\n",
       "   ('tkp', 'alert'),\n",
       "   ('eng', 'perky'),\n",
       "   ('eng', 'alert'),\n",
       "   ('vx', '1'),\n",
       "   ('sc', '???'),\n",
       "   ('dt', '29/Oct/2005'),\n",
       "   ('ex', 'Kaiporiparoi.'),\n",
       "   ('xp', '???'),\n",
       "   ('xe', 'He is very alert.'),\n",
       "   ('ex', 'Kaekaeto kaiporivira vuravurarevo osia aakova rera kavauevo.'),\n",
       "   ('xp', 'Pikinini em i lukluk orait taim mama em i karim em.'),\n",
       "   ('xe',\n",
       "    'The boy looked around alertly when his mother gave birth to him.')]),\n",
       " ('kaiporipie',\n",
       "  [('rt', 'kaipori'),\n",
       "   ('ps', 'V'),\n",
       "   ('pt', 'B'),\n",
       "   ('dx', 'Central'),\n",
       "   ('ge', 'arouse'),\n",
       "   ('eng', 'arouse'),\n",
       "   ('eng', 'perk up'),\n",
       "   ('tkp', 'kirapim'),\n",
       "   ('tkp', 'mekim orait'),\n",
       "   ('vx', '2'),\n",
       "   ('arg', 'O'),\n",
       "   ('dt', '22/Nov/2005'),\n",
       "   ('ex',\n",
       "    'Perapera kaiporipierevo Aata uvare rera-va avaroe ruvarupa kepa iare.'),\n",
       "   ('xp',\n",
       "    'Aata em i mekim orait Perapera taim em i kisim em i go long haus sik.'),\n",
       "   ('xe',\n",
       "    'Aata made Perapera perk up because he went to the medical station with him.')]),\n",
       " ('kaiporivira',\n",
       "  [('rt', 'kaipori'),\n",
       "   ('ps', 'ADV'),\n",
       "   ('pt', 'MANNER'),\n",
       "   ('ge', 'alertly'),\n",
       "   ('tkp', '???'),\n",
       "   ('dt', '29/Oct/2005'),\n",
       "   ('ex', 'Kaiporivira vuravurarevoi.'),\n",
       "   ('xp', '???'),\n",
       "   ('xe', 'He is looking around in an alert way.'),\n",
       "   ('ex', 'Luke kaiporivira toreroi uusi tapi-va.'),\n",
       "   ('xp', 'Luke em i kirap gut long slip.'),\n",
       "   ('xe', 'Luke got up alert from bed.'),\n",
       "   ('ex', 'Timoti kaiporivira toupare viapau ruraparevoi.'),\n",
       "   ('xp', 'Timoti i no ai slip em i stap gut.'),\n",
       "   ('xe', \"Timothy is alert, he's not ???.\"),\n",
       "   ('ex', 'Pita kaiporivira vokaparevo uvare upia opesie.'),\n",
       "   ('xp', 'Pita em i wokabaut olsem em i orait bikos sik bilong i pinis.'),\n",
       "   ('xe', 'Peter walked about alert because his sickness finished.')]),\n",
       " ('kairi',\n",
       "  [('ps', 'N'),\n",
       "   ('pt', 'NT'),\n",
       "   ('ge', 'spear'),\n",
       "   ('ge', 'arrow'),\n",
       "   ('tkp', '???'),\n",
       "   ('dt', '28/Jan/2005'),\n",
       "   ('ex', 'Kairi isi-va uriou Pita koie togasia.'),\n",
       "   ('xp', 'Pita kam sutim pik long spia.'),\n",
       "   ('xe', 'Pita came to spear the pig with an arrow.')]),\n",
       " ('kairiro',\n",
       "  [('ps', 'N'),\n",
       "   ('pt', 'NT'),\n",
       "   ('ge', 'bushes'),\n",
       "   ('ge', 'small trees'),\n",
       "   ('tkp', 'ol liklik diwai'),\n",
       "   ('nt', 'generic?'),\n",
       "   ('cmt',\n",
       "    'Is the <ro> part of the stem or is it bound morphology? Can you get <kairi>, <kairirei>, and <kairiro>?'),\n",
       "   ('dt', '29/Nov/2006'),\n",
       "   ('ex', 'Evao kairiro-va uriou.'),\n",
       "   ('xp', 'Yu kam wantaim ol liklik diwai.'),\n",
       "   ('xe', 'You come with the little trees.')]),\n",
       " ('kairo',\n",
       "  [('ps', 'N'),\n",
       "   ('pt', 'NT'),\n",
       "   ('ge', 'neck'),\n",
       "   ('tkp', 'nek'),\n",
       "   ('sf', 'BP'),\n",
       "   ('cmt', 'Is it toupa vokiia?'),\n",
       "   ('dt', '12/Feb/2005'),\n",
       "   ('ex', 'Kairo okairo vo uva aioara varapapeira kopapaperia.'),\n",
       "   ('xp', 'Kaikai i save ga down long neck bilong yumi.'),\n",
       "   ('xe', '??? and food ???.'),\n",
       "   ('ex', 'Koike ira kairo-ia asiroi toupa voki-ia.'),\n",
       "   ('xp', 'Koike em i putim nektae long sande.'),\n",
       "   ('xe', 'Koike ???.')]),\n",
       " ('kaita',\n",
       "  [('ps', 'N'),\n",
       "   ('pt', 'NT'),\n",
       "   ('ge', 'white beads'),\n",
       "   ('tkp', 'waitpela bis'),\n",
       "   ('cmt', 'Is it kaita or kaaita?'),\n",
       "   ('dt', '28/Jan/2005'),\n",
       "   ('ex', 'Eresivie kaaitauaia aasipaoi.'),\n",
       "   ('xp', 'Eresivie i putim waitpela bis.'),\n",
       "   ('xe', 'Eresivie is puttong on white beads.')]),\n",
       " ('kaitutu',\n",
       "  [('alt', 'kaitu'),\n",
       "   ('ps', 'V'),\n",
       "   ('pt', 'A'),\n",
       "   ('ge', 'resolute'),\n",
       "   ('ge', 'steadfast'),\n",
       "   ('ge', 'tight'),\n",
       "   ('tkp', 'tait'),\n",
       "   ('cmt', 'Are kaitutu and kaitu really just alternates? Any difference?'),\n",
       "   ('dcsv', 'true'),\n",
       "   ('vx', '1'),\n",
       "   ('sc', '???'),\n",
       "   ('dt', '29/Oct/2005'),\n",
       "   ('ex', 'Kaitutuparoepa uriri asavira.'),\n",
       "   ('xp', '???'),\n",
       "   ('xe', 'He was fearlessly steadfast.'),\n",
       "   ('ex', 'Pita, kaitupai eva iroiro oa iava tokopiroi varo tavava.'),\n",
       "   ('xp', 'Pita, rop ia em i tait olsem na i bruk wantaim ol laplap.'),\n",
       "   ('xe',\n",
       "    'Peter, that rope is tight and therefore it broke with the clothes.')]),\n",
       " ('kaitutupie',\n",
       "  [('alt', 'kaitupie'),\n",
       "   ('rt', 'kaitutu'),\n",
       "   ('ps', 'V'),\n",
       "   ('pt', 'B'),\n",
       "   ('ge', 'smooth out'),\n",
       "   ('ge', 'tighten'),\n",
       "   ('tkp', '???'),\n",
       "   ('cmt', 'Again, check on the kaitutu and kaitu difference...'),\n",
       "   ('arg', 'O'),\n",
       "   ('vx', '2'),\n",
       "   ('cmt', 'Figure out semantics of this...'),\n",
       "   ('nt',\n",
       "    'Refers to smoothing out cloth during process of pressing it with hot ???'),\n",
       "   ('dt', '29/Oct/2005'),\n",
       "   ('ex', 'Iroiro kaitutupieri.'),\n",
       "   ('xp', 'Yu taitim strong rop.'),\n",
       "   ('xe', 'You tighten the rope.'),\n",
       "   ('ex',\n",
       "    'Vutevi viapau iroiro kaitupievoi oa iava varo tava rasitoa-ia rirue uva vuriei.'),\n",
       "   ('xp',\n",
       "    'Vutevi em i no taitim rop olsem na ol laplap long lain i tasim graon na i bagarap.'),\n",
       "   ('xe',\n",
       "    \"Vutevi didn't tighten the rope and therefore the clothes on the ground fell down and got messed up.\")]),\n",
       " ('kaitutuvira',\n",
       "  [('rt', 'kaitutu'),\n",
       "   ('ps', 'ADV'),\n",
       "   ('pt', 'MANNER'),\n",
       "   ('ge', 'resolutely'),\n",
       "   ('ge', 'steadfast'),\n",
       "   ('ge', 'tightly'),\n",
       "   ('tkp', '???'),\n",
       "   ('dt', '11/Feb/2005'),\n",
       "   ('ex', 'Vivisi ira oisioa kaitutuvira toreparo.'),\n",
       "   ('xp', 'Vivisi em i save sanap strong.'),\n",
       "   ('xe', 'Vivisi always stand resolute.')]),\n",
       " ('kakae',\n",
       "  [('ps', 'N'),\n",
       "   ('pt', 'HUM'),\n",
       "   ('ge', 'child'),\n",
       "   ('tkp', 'pikinini'),\n",
       "   ('nt', 'plural is irregular, <kakaevure>, and NOT <kakaeirara>'),\n",
       "   ('cmt', 'Check vowel length. Is it avae or avai?'),\n",
       "   ('dt', '04/Sep/2005'),\n",
       "   ('ex', 'Oira kakae kavauevo Sipirie.'),\n",
       "   ('xp', 'Sipirie i bonim pikinini man.'),\n",
       "   ('xe', 'Sipirie gave birth to a boy.'),\n",
       "   ('ex', 'Kakaevure avae skurusia.'),\n",
       "   ('xp', 'Ol pikinini i bin go long skul.'),\n",
       "   ('xe', 'The children are going to school.')]),\n",
       " ('kakae',\n",
       "  [('ps', '???'),\n",
       "   ('ge', 'small'),\n",
       "   ('ge', 'little'),\n",
       "   ('tkp', 'liklik'),\n",
       "   ('cmt', 'Need ex of this used as verb'),\n",
       "   ('dt', '29/Oct/2005'),\n",
       "   ('ex',\n",
       "    'Pita, vii kaekae rugovira toupari, viapau uvuipauei ra oiraopavira rugopau.'),\n",
       "   ('xp',\n",
       "    'Pita, tingting bilong yu olsem pikinini, yu no inap i gat trupela tingting.'),\n",
       "   ('xe', \"Peter, you are short-sighted, you can't think correctly.\")]),\n",
       " ('kakae',\n",
       "  [('ps', 'CLASS'),\n",
       "   ('ge', 'child'),\n",
       "   ('tkp', 'pikinini'),\n",
       "   ('dt', '04/Sep/2005'),\n",
       "   ('ex', 'Sigo kakae kovorevo Patriki uva rera upoevo aakova.'),\n",
       "   ('xp', 'Patrik em i pundaunim liklik naip na mama i paitim em.'),\n",
       "   ('xe', 'Patrick dropped the little knife and his mother smacked him.')]),\n",
       " ('kakaevira',\n",
       "  [('rt', 'kakae'),\n",
       "   ('ps', 'ADV'),\n",
       "   ('pt', 'MANNER'),\n",
       "   ('ge', 'small-like'),\n",
       "   ('tkp', 'liklik'),\n",
       "   ('dt', '12/Feb/2005'),\n",
       "   ('ex', 'Kakaevira touparivoi viapau uvuipau va riakovavai ouri.'),\n",
       "   ('xp', 'Yu liklik meri tumas yu no i nap kisim wanpela man.'),\n",
       "   ('xe', \"You're too small; you can't get a woman.\"),\n",
       "   ('ex', 'Kakaevira toupaoro ro opitato pauriva.'),\n",
       "   ('xp', 'Yu bin i stap liklik na yu bin planim dispela kokonas.'),\n",
       "   ('xe', 'When you were little, you planted this coconut tree.')]),\n",
       " ('kakapikoa',\n",
       "  [('rt', 'kakapiko'),\n",
       "   ('ps', '???'),\n",
       "   ('ge', 'small'),\n",
       "   ('ge', 'little'),\n",
       "   ('tkp', 'liklik'),\n",
       "   ('dt', '31/Oct/2005'),\n",
       "   ('ex', 'Rarasori kakapikoa aioa aioparevoi uva rera-pa siraoparoe Pita.'),\n",
       "   ('xp', 'Rarasori em i kaikaim liklik hap kaikai na Pita i sori long em.'),\n",
       "   ('xe', 'Robinson is eating little food and Peter feels sorry for him.')]),\n",
       " ('kakapikoto',\n",
       "  [('rt', 'kakapiko'),\n",
       "   ('ps', 'N'),\n",
       "   ('pt', 'HUM'),\n",
       "   ('ge', 'newborn baby'),\n",
       "   ('tkp', '???'),\n",
       "   ('dt', '31/Oct/2005'),\n",
       "   ('ex', 'Garetoavi kakapikoto kakaeto ira kavau aakova vovokio.'),\n",
       "   ('xp', 'Liklik pikinini tru mama i karim em tude tasol.'),\n",
       "   ('xe', '???'),\n",
       "   ('ex', 'Kakaeto kakapikoto ira kavaue aakova vovokio raga.'),\n",
       "   ('xp', 'Liklik pikinini, mama i karim tude.'),\n",
       "   ('xe', '???')]),\n",
       " ('kakapu',\n",
       "  [('ps', 'V'),\n",
       "   ('pt', 'B'),\n",
       "   ('ge', 'place in sling for purpose of carrying'),\n",
       "   ('tkp', 'slingim'),\n",
       "   ('tkp', 'pasim laplap'),\n",
       "   ('arg', 'O'),\n",
       "   ('vx', '2'),\n",
       "   ('dt', '08/Jun/2005'),\n",
       "   ('ex', 'Aakova kakaeto kakapupae.'),\n",
       "   ('xp', '???'),\n",
       "   ('xe', 'The mother places the child in the sling.'),\n",
       "   ('ex', 'Aakova kakaeto kakapupae varoa-ia rera kaepaoro.'),\n",
       "   ('xp', 'Mama i karim liklik pikinini blong long laplap.'),\n",
       "   ('xe', 'The mother is carrying the child ???.')]),\n",
       " ('kakapua',\n",
       "  [('rt', 'kakapu'),\n",
       "   ('ps', 'N'),\n",
       "   ('pt', 'NT'),\n",
       "   ('ge', 'sling for lifting'),\n",
       "   ('tkp', 'sling'),\n",
       "   ('dt', '12/Feb/2005'),\n",
       "   ('cmt', \"Don't understand syntax of third example.\"),\n",
       "   ('ex', 'Kakapuava ena ra ro kakaeto kakapua rera kaeoro rera Tutuoro.'),\n",
       "   ('xp', 'Yu kalim dispela pikinini long dispela slins bek.'),\n",
       "   ('xe', '???'),\n",
       "   ('ex', 'Kakapuava uriou ra kakaeto kaea.'),\n",
       "   ('xp', 'Yu kam wantaim sling bai mi karim pikinini.'),\n",
       "   ('xe', \"Come with the sling and I'll carry the child.\"),\n",
       "   ('ex', 'Uvuoa-ia kakapua toupaivoi kotokotoara verapasia rasiuaro-re.'),\n",
       "   ('xp', 'Long sip i gat sling bilong rausim ol kago i go long graun.'),\n",
       "   ('xe', 'On a ship there is a crane ??? to leave cargo on the ground.')]),\n",
       " ('kakara',\n",
       "  [('ps', 'N'),\n",
       "   ('pt', 'NT'),\n",
       "   ('ge', 'arm band'),\n",
       "   ('ge', 'bracelet'),\n",
       "   ('tkp', 'paspas'),\n",
       "   ('cmt',\n",
       "    \"Check gloss. Is translation of example right? What about 'kakara pako' vs. simply 'pakoua'?\"),\n",
       "   ('dt', '31/Oct/2005'),\n",
       "   ('ex', 'Auoro, uriou asi kakara-va.'),\n",
       "   ('xp', 'Yu kam wantaim hap rop buai.'),\n",
       "   ('xe', 'Hey, come with a betel nut rope.'),\n",
       "   ('ex', 'Tesi vearo kekepaoi kakara pako tovoevoi ora oira vavaearo-ia.'),\n",
       "   ('xp', 'Tesi em i luk gut bikos em i putim paspas long han bilong em yet.'),\n",
       "   ('xe', 'Tesi looks good, she put a bracelet on her wrist.')]),\n",
       " ('Kakarapaia',\n",
       "  [('ps', 'N'),\n",
       "   ('pt', 'PN'),\n",
       "   ('ge', 'village name'),\n",
       "   ('tkp', 'ples nem'),\n",
       "   ('dx', 'Pipipaia'),\n",
       "   ('dt', '12/Feb/2005'),\n",
       "   ('ex', 'Kakarapai urui - uruia vaisiavo aue kakarabaia.'),\n",
       "   ('xp', 'Name blong peles em long kakarapaia.'),\n",
       "   ('xe', '???'),\n",
       "   ('ex', 'Kakarapaia sevendepairara vo uruiaro.'),\n",
       "   ('xp', 'Kakarapaia ples bilong ol sevende.'),\n",
       "   ('xe', 'Kakarapaia is a village of Seventh Day Adventists.')]),\n",
       " ('kakarau',\n",
       "  [('ps', 'N'),\n",
       "   ('pt', 'FEM'),\n",
       "   ('ge', 'frog'),\n",
       "   ('ge', 'stingray'),\n",
       "   ('tkp', 'rokrok'),\n",
       "   ('tkp', 'prok'),\n",
       "   ('tkp', 'epa korvo'),\n",
       "   ('sf', 'FAUNA'),\n",
       "   ('nt', 'this type of frog lives in the bush'),\n",
       "   ('dt', '28/Feb/2005'),\n",
       "   ('ex', 'Kakarau vo toupava vegoaro ora vovuko gaevo sirova.'),\n",
       "   ('xp',\n",
       "    'Kakarau tros em i save tstap long buck na long arere long ol wara.'),\n",
       "   ('xe', 'The ??? frog lived in the bush and ???.'),\n",
       "   ('ex', 'Kakarau iria vo toupaeveira uuko gaero sirova aiopava.'),\n",
       "   ('xp', 'Rokrok em i save i stap arere long wara na em i bilong kaikai.'),\n",
       "   ('xe', 'The kakarau frog lives on the ??? and is food.')]),\n",
       " ('Kakarera',\n",
       "  [('ps', 'N'),\n",
       "   ('pt', 'PN'),\n",
       "   ('ge', 'name'),\n",
       "   ('tkp', 'nem'),\n",
       "   ('dt', '11/Feb/2005'),\n",
       "   ('ex', 'Kakarera-ia uva opitara paureva Raupeto.'),\n",
       "   ('xp', 'Raupeto i bin palanim ol kokonas long Kakarera.'),\n",
       "   ('xe', 'Raupeto is planting coconuts in Kakarera.')]),\n",
       " ('kakata',\n",
       "  [('ps', 'N'),\n",
       "   ('pt', 'FEM'),\n",
       "   ('ge', 'cockatoo'),\n",
       "   ('tkp', 'koki'),\n",
       "   ('dt', '31/Aug/2005'),\n",
       "   ('ex', 'Kakata popoteva kokiova riro vavioko aiova.'),\n",
       "   ('xp', 'Koki em i waitpela pisin na i save kaikai popo.'),\n",
       "   ('xe', 'The kakata bird is a white bird and a big eater of pawpaw.')]),\n",
       " ('kakate',\n",
       "  [('ps', 'N'),\n",
       "   ('pt', 'FEM'),\n",
       "   ('ge', 'bamboo.tube'),\n",
       "   ('tkp', 'mambu bilong karim wara'),\n",
       "   ('eng', 'bamboo tube for water'),\n",
       "   ('dt', '27/Jul/2005'),\n",
       "   ('ex', 'Kakate aue kaepava uko kakate purapai aue rava veta uuko kaepas.'),\n",
       "   ('xp', 'Kakate bamboo ol i save wokim long bamboo karim water.'),\n",
       "   ('xe', '???'),\n",
       "   ('ex', 'Raru kakate ukoro avaroe eisi-re kovoa.'),\n",
       "   ('xp', 'Raru i pulamapim wara long mambu na go long wok.'),\n",
       "   ('xe', 'Raru fills up the bamboo water tub and goes to work.')]),\n",
       " ('kakatuara',\n",
       "  [('ps', 'N'),\n",
       "   ('pt', 'MASC'),\n",
       "   ('ge', 'type of lizard'),\n",
       "   ('tkp', '???'),\n",
       "   ('nt', 'dark body, tan scales, eats snakes, skin not used for drum'),\n",
       "   ('sf', 'FAUNA'),\n",
       "   ('dt', '12/Feb/2005'),\n",
       "   ('ex',\n",
       "    'Kakatuara kanora oiso rera osia kariana ira gagopaiveira aue-re kututoroia-re.'),\n",
       "   ('xp',\n",
       "    'Kakatuara lizard em i wanpela lizard ol save kisim skin blong blong putim long kustu drum.'),\n",
       "   ('xe', '???'),\n",
       "   ('ex', 'Kakatuara riro torito ikaupavira.'),\n",
       "   ('xp', 'Palai em i save ranawe kwik.'),\n",
       "   ('xe', 'The kakatuara is a quick runner.')]),\n",
       " ('kakau',\n",
       "  [('ps', 'N'),\n",
       "   ('pt', 'FEM'),\n",
       "   ('ge', 'cocoa'),\n",
       "   ('tkp', 'kakao'),\n",
       "   ('nt', 'Tok Pisin loan'),\n",
       "   ('dt', '28/Jan/2005'),\n",
       "   ('ex', 'Kakau kovoro purapaivoi oirara moni oupasia.'),\n",
       "   ('xp', 'Gaden kakau ol man i save wokim bilong kisim moni.'),\n",
       "   ('xe', 'Men made cocoa gardens in order to get money.')]),\n",
       " ('kakauoa',\n",
       "  [('ps', 'N'),\n",
       "   ('pt', 'NT'),\n",
       "   ('ge', 'skin'),\n",
       "   ('eng', 'skin'),\n",
       "   ('eng', 'shell'),\n",
       "   ('eng', 'husk'),\n",
       "   ('tkp', 'skin'),\n",
       "   ('cmt', 'Can it be a shell? Need to check semantics.'),\n",
       "   ('dt', '10/Nov/2005'),\n",
       "   ('ex', 'Kakauoa aue iava evaova vararo-ia tegoro.'),\n",
       "   ('xp', 'Skin blong diwai ir wile banana.'),\n",
       "   ('xe', '???'),\n",
       "   ('ex', 'Tetevutoa iava kakauoa verarevoi aue Reivasia.'),\n",
       "   ('xp', 'Reivasia i rausim skin bilong saksak.'),\n",
       "   ('xe', 'Reivasia is removing the husk from the sago.')]),\n",
       " ('kakavea',\n",
       "  [('ps', 'N'),\n",
       "   ('pt', '???'),\n",
       "   ('cl', 'isi'),\n",
       "   ('ge', 'fern tree'),\n",
       "   ('tkp', 'wankain diwai i no strong'),\n",
       "   ('nt', 'generic term'),\n",
       "   ('sf', 'FLORA'),\n",
       "   ('dt', '12/Feb/2005'),\n",
       "   ('ex', 'Kakavea oiso va osa evaova rao ra toupai ora kupei.'),\n",
       "   ('xp', 'Kakave em wanpela kain diwai em gro long bus.'),\n",
       "   ('xe', '???'),\n",
       "   ('ex', 'Kakaveasia oo vaisi oiso rasaita osa aue kakavea vaisi toopai.'),\n",
       "   ('xp', 'Kakaveasi em I wan kain nem olsem tasol kakavea.'),\n",
       "   ('xe', '???'),\n",
       "   ('ex', 'Kakavea oa vegoaro toupaiveira.'),\n",
       "   ('xp', 'Pen i save i stap long bus.'),\n",
       "   ('xe', 'Ferns live in the bush.'),\n",
       "   ('ex', 'Kakavea isi aisia toepaiveira kepa purapasia vo vukoro-ia.'),\n",
       "   ('xp', 'Pen ol i save katim bilong wokim haus.'),\n",
       "   ('xe', '???')]),\n",
       " ('kakavoro',\n",
       "  [('ps', 'N'),\n",
       "   ('pt', 'FEM'),\n",
       "   ('ge', 'Malay apple tree'),\n",
       "   ('tkp', 'laulau'),\n",
       "   ('dt', '28/Jan/2005'),\n",
       "   ('ex', 'Tevire kakavoro kue-ia tuparevoi.'),\n",
       "   ('xp', 'Tevire i tambuim laulau.'),\n",
       "   ('xe', 'Tevire put a taboo on Malay apple trees.')]),\n",
       " ('kakavu',\n",
       "  [('ps', 'V'),\n",
       "   ('pt', 'B'),\n",
       "   ('ge', 'scoop up with the hands'),\n",
       "   ('tkp', '???'),\n",
       "   ('arg', 'O'),\n",
       "   ('vx', '2'),\n",
       "   ('dt', '08/Jun/2005'),\n",
       "   ('ex', 'Avo, varoo rutu kakavuri piratiara ora vii varaearo-ia.'),\n",
       "   ('xp', 'Meri yu mas kisim olgeta pinat long han bilong yu.'),\n",
       "   ('xe', 'Woman, you pick up all of the coconuts in your hands.'),\n",
       "   ('ex', 'Varoo rutu pirati kakavuavoi.'),\n",
       "   ('xp', 'Y mi kisim olgeta pinats.'),\n",
       "   ('xe', 'I am scooping up all of the peanuts.'),\n",
       "   ('ex', 'Vareapi pinatiara rutu kakavure.'),\n",
       "   ('xp', 'Vareapi i kisim olgeta pinat.'),\n",
       "   ('xe', 'Vareapi scooped up peanuts.'),\n",
       "   ('ex', 'Kuriara kakavuri.'),\n",
       "   ('xp', '???'),\n",
       "   ('xe', 'Scoop up the scrapings with your hands.')]),\n",
       " ('kakeoto',\n",
       "  [('ps', 'N'),\n",
       "   ('pt', 'MASC'),\n",
       "   ('ge', 'inside'),\n",
       "   ('eng', 'inside'),\n",
       "   ('eng', 'insides'),\n",
       "   ('eng', 'internals'),\n",
       "   ('eng', 'innards'),\n",
       "   ('tkp', 'insait'),\n",
       "   ('dt', '31/Oct/2005'),\n",
       "   ('ex',\n",
       "    'Sera karuveraisi rakaraiaro vikievoi uva sovarai apa raga aioevoi kakeoa.'),\n",
       "   ('xp',\n",
       "    'Sera em i tromem skin bilong singapo na kaikaim insait bilong em tasol.'),\n",
       "   ('xe', 'Sera threw away ??? and ???.')]),\n",
       " ('kaki',\n",
       "  [('ps', 'V'),\n",
       "   ('pt', 'A'),\n",
       "   ('ge', 'open'),\n",
       "   ('eng', 'cracked open'),\n",
       "   ('eng', 'split open'),\n",
       "   ('tkp', 'bruk'),\n",
       "   ('cmt', 'Need clear example illustrating subject agreement'),\n",
       "   ('vx', '1'),\n",
       "   ('dt', '22/Nov/2005'),\n",
       "   ('ex', 'Kakioviro rivuko.'),\n",
       "   ('xp', '???'),\n",
       "   ('xe', 'The mosquito is burst open.'),\n",
       "   ('ex', 'Opita isi kaki va isi toeoro.'),\n",
       "   ('xp', 'Yu katim kokonas bai bruk.'),\n",
       "   ('xe', 'Split up a coconut by cutting it.'),\n",
       "   ('ex',\n",
       "    'Opita isi kaki va isi toeovo vii kukueno kakipanoi tooro vii ragiovo.'),\n",
       "   ('xp', 'Yu brukim kokonas taim yu katim bai mi brukim het bilong yu.'),\n",
       "   ('xe', '???')]),\n",
       " ('kaki',\n",
       "  [('ps', 'V'),\n",
       "   ('pt', 'B'),\n",
       "   ('ge', 'open'),\n",
       "   ('eng', 'crack open'),\n",
       "   ('eng', 'split open'),\n",
       "   ('tkp', 'brukim'),\n",
       "   ('vx', '2'),\n",
       "   ('arg', 'O'),\n",
       "   ('dt', '14/Nov/2005'),\n",
       "   ('ex', 'Opita isi kaki va isi toeoro.'),\n",
       "   ('xp', 'Yu katim kokonas bai bruk.'),\n",
       "   ('xe', 'Split up a coconut by cutting it.'),\n",
       "   ('ex',\n",
       "    'Opita isi kaki va isi toeoro vii kukuero kakipaavoi tooro vii ragiovo.'),\n",
       "   ('xp', 'Yu brukim kokonas taim yu katim bai mi brukim het bilong yu.'),\n",
       "   ('xe', '???'),\n",
       "   ('ex',\n",
       "    'Tapipava-ia kakia toupaivo gareavi ovusia oira-ia uko rovu kokoavo kasiraopa rovu uva pegeovoioviro.'),\n",
       "   ('xp',\n",
       "    'Mi kapsaitim hot wara long kap i gat liklik mak olsem i bruk na kap i bruk olgeta.'),\n",
       "   ('xe', '???')]),\n",
       " ('kakiaki',\n",
       "  [('ps', 'V'),\n",
       "   ('pt', 'B'),\n",
       "   ('ge', 'crack open'),\n",
       "   ('ge', 'fracture'),\n",
       "   ('tkp', 'bruk'),\n",
       "   ('arg', 'O'),\n",
       "   ('vx', '2'),\n",
       "   ('dt', '08/Jun/2005'),\n",
       "   ('ex', 'Vetatou kakiakirivoi va varipiero.'),\n",
       "   ('xp', 'Yu brukim het bilong yu.'),\n",
       "   ('xe', 'You cracked your head.'),\n",
       "   ('ex', 'Vi kukuearo kakiakipaavoi viuparo.'),\n",
       "   ('xp', 'Bai mi brukim het blong yu.'),\n",
       "   ('xe', \"I'm going to break your head open.\"),\n",
       "   ('ex', 'Teva iru kakiakipaoi Tasia kukuearoia.'),\n",
       "   ('xp', 'Teva i paitim laus long het bilong Tasia.'),\n",
       "   ('xe', \"Teva cracks open lice on Tasia's head.\")]),\n",
       " ('kakiri',\n",
       "  [('ps', 'N'),\n",
       "   ('pt', 'NT'),\n",
       "   ('ge', 'type of insect'),\n",
       "   ('tkp', '???'),\n",
       "   ('nt', 'resembles sandfly, lives near beach area'),\n",
       "   ('dt', '11/Feb/2005'),\n",
       "   ('ex', 'Kakiri ira-ia riro kou toupai aue oru.'),\n",
       "   ('xp', 'Binatang i gat plenti gras long skin.'),\n",
       "   ('xe', 'As for the ???, it has lots of ???.')]),\n",
       " ('kakiua',\n",
       "  [('rt', 'kaki'),\n",
       "   ('ps', 'N'),\n",
       "   ('pt', 'NT'),\n",
       "   ('ge', 'cave'),\n",
       "   ('ge', 'cavern'),\n",
       "   ('tkp', 'hol ston'),\n",
       "   ('dt', '11/Feb/2007'),\n",
       "   ('cmt', 'Check spelling on originals'),\n",
       "   ('ex',\n",
       "    'Ave kakikakiva vo toupai aveke keparo-ia kakiua vo uva uvuipai usipasa vo vegoaro.'),\n",
       "   ('xp', 'Kakiua cave ol mom i kan sleep long em .'),\n",
       "   ('xe', '???'),\n",
       "   ('ex', 'Kakiua vo uva uvuipai akauko kakau karu waipave.'),\n",
       "   ('xp', 'Na tu ol animal i kan slip long em.'),\n",
       "   ('xe', '???'),\n",
       "   ('ex', 'Kakiua oua siovaraia rakoru kare toupaiveira riropa kare.'),\n",
       "   ('xp', 'Insait long hol ol snek i save i stap long em.'),\n",
       "   ('xe', 'Inside of a cave, there are many snakes.')]),\n",
       " ('kaku',\n",
       "  [('ps', 'V'),\n",
       "   ('pt', 'B'),\n",
       "   ('ge', 'split open'),\n",
       "   ('tkp', 'op bruk'),\n",
       "   ('arg', 'O'),\n",
       "   ('vx', '2'),\n",
       "   ('nt', 'using instrument (axe or knife)'),\n",
       "   ('dcsv', 'true'),\n",
       "   ('dt', '08/Jun/2005'),\n",
       "   ('ex', 'Kepa pausia oira kakurivere.'),\n",
       "   ('xp', '???'),\n",
       "   ('xe', 'Split it open in order to build the house.'),\n",
       "   ('ex', 'Pita opita isi kakurevoi va isi toeoro.'),\n",
       "   ('xp', 'Pita i katim kokonas na i bruk.'),\n",
       "   ('xe', 'Peter cut the coconut, breaking it.')]),\n",
       " ('kakua',\n",
       "  [('rt', 'kaku'),\n",
       "   ('ps', 'N'),\n",
       "   ('pt', '???'),\n",
       "   ('ge', 'axe'),\n",
       "   ('ge', 'knife'),\n",
       "   ('dt', '11/Feb/2007'),\n",
       "   ('ex', 'Kareviri kakua-ia torara paure.'),\n",
       "   ('xp', 'Kareviri i putim tamiok long andoro.'),\n",
       "   ('xe', 'Kareviri ???.'),\n",
       "   ('ex',\n",
       "    'Ata torara iva kaku rao gasirevoi uva viapau uvuipa ra evaovavai toreve oira-ia oa-ia oavu raga tovorevoi torara-ia.'),\n",
       "   ('xp',\n",
       "    'Ata em i brukim andol bilong tamiok olsem na em i no inap katim wanpela diwai olsem na em putim narapela andol gen.'),\n",
       "   ('xe', '???')]),\n",
       " ('kakuaku',\n",
       "  [('ps', 'V'),\n",
       "   ('pt', 'B'),\n",
       "   ('ge', 'break'),\n",
       "   ('tkp', '???'),\n",
       "   ('eng', 'break into pieces with instrument'),\n",
       "   ('arg', 'O'),\n",
       "   ('vx', '2'),\n",
       "   ('nt', 'typically the instrument is a knife'),\n",
       "   ('dt', '08/Jun/2005'),\n",
       "   ('ex', 'Kaukau kakuakuri.'),\n",
       "   ('xp', '???'),\n",
       "   ('xe', 'Break open the sweet potato with some instrument.'),\n",
       "   ('ex', 'Iovore upiriko-isi kakuakuevoi pitokava iare garepa visivi.'),\n",
       "   ('xp', 'Iovore i katkatim kaukau i go long sospen.'),\n",
       "   ('xe', 'Iovore broke the sweet potato into pieces in the saucepan.')]),\n",
       " ('kakupaa',\n",
       "  [('rt', 'kaku'),\n",
       "   ('ps', 'N'),\n",
       "   ('pt', 'NT'),\n",
       "   ('ge', 'landslide'),\n",
       "   ('ge', 'mudslide'),\n",
       "   ('tkp', 'graun i bruk'),\n",
       "   ('dt', '31/Oct/2005'),\n",
       "   ('ex', 'Vosia kokeva tavira kokeo ra rakakupape 13 days.'),\n",
       "   ('xp',\n",
       "    'Taim rain i pundaun bai araun i bruk inap 4 days or taim guria earthquake I kam stong bai groun I bruk.'),\n",
       "   ('xe', 'When the rain ???.'),\n",
       "   ('ex',\n",
       "    'Vosa vovava voki roia kove kokeva ra kakupape ravurike tape vusireve rakakupape.'),\n",
       "   ('xp', '???'),\n",
       "   ('xe', '???'),\n",
       "   ('ex', 'Rirova-ia kokeva kakupa varae vavo.'),\n",
       "   ('xp', 'Long traipela rein graun i bruk long hap.'),\n",
       "   ('xe', 'From ??? a landslide ???.'),\n",
       "   ('ex',\n",
       "    'Rirovira kokeva koveoe uva pukuia iava kakupa varae uva Pita vo kovoaro upiriko kovo rakuvo.'),\n",
       "   ('xp',\n",
       "    'Ren i pundaun bikpela na graun i bruk kam daun long maunten na karampim gaden kaukau bilong Pita.'),\n",
       "   ('xe',\n",
       "    \"The rain fell down heavily and a landslide fell from the mountains and it covered up Pita's sweet potato garden.\")]),\n",
       " ('kakuparei',\n",
       "  [('rt', 'kaku'),\n",
       "   ('ps', 'N'),\n",
       "   ('pt', 'NT'),\n",
       "   ('ge', 'two halves'),\n",
       "   ('tkp', 'tuhap'),\n",
       "   ('dt', '11/Feb/2005'),\n",
       "   ('ex', 'Sio vo kakuparei purarevoi evaova-ia.'),\n",
       "   ('xp', 'So i katim diwai long tupela hap.'),\n",
       "   ('xe', 'Sio made two halves from the tree.')]),\n",
       " ('kakupato',\n",
       "  [('rt', 'kaku'),\n",
       "   ('ps', 'N'),\n",
       "   ('pt', 'MASC'),\n",
       "   ('dx', 'Central'),\n",
       "   ('ge', '???'),\n",
       "   ('tkp', 'samting bilong brukim diwai'),\n",
       "   ('avm', 'pa_required'),\n",
       "   ('dt', '02/Sep/2005')]),\n",
       " ('kakupie',\n",
       "  [('rt', 'kaku'),\n",
       "   ('ps', 'V'),\n",
       "   ('pt', 'B'),\n",
       "   ('ge', 'shout'),\n",
       "   ('ge', 'yodel'),\n",
       "   ('tkp', 'singaut'),\n",
       "   ('tkp', 'bikmausim'),\n",
       "   ('vx', '1'),\n",
       "   ('nt', '???'),\n",
       "   ('dt', '15/Nov/2005'),\n",
       "   ('ex', 'Kakupierevorao roruvira.'),\n",
       "   ('xp', '???'),\n",
       "   ('xe', 'He was shouting merrily.'),\n",
       "   ('ex', 'Oirato kakupieparevo uvavuva.'),\n",
       "   ('xp', 'Manpela man i singaut long places.'),\n",
       "   ('xe', 'A man shouts ???.'),\n",
       "   ('ex', 'Virepa kakupiepare vavoisio pukui-ia.'),\n",
       "   ('xp', 'Virepa i saot long maunten.'),\n",
       "   ('xe', 'Virepa is shouting on the mountain.'),\n",
       "   ('ex',\n",
       "    'Virepa rirovira kakupierevo ovusia evaova kove uvare va toerevo koratoa-va.'),\n",
       "   ('xp',\n",
       "    'Virepa em i singautim bik maus taim diwai i pundaun bikos em i katim wantaim kapul.'),\n",
       "   ('xe',\n",
       "    'Virepa shouted loudly when the tree fell because he cut it with a kapul (on it).'),\n",
       "   ('ex',\n",
       "    'Vioviokoa o ipavuia toupaoro kakupiepaivo ovusia vvoea urupiepavo.'),\n",
       "   ('xp',\n",
       "    'Ol yangpela man wok long singaut long narapela hap taim mi harim ol.'),\n",
       "   ('xe', '???')]),\n",
       " ('kakupute',\n",
       "  [('ps', 'N'),\n",
       "   ('pt', 'FEM'),\n",
       "   ('ge', 'fern tree'),\n",
       "   ('tkp', '???'),\n",
       "   ('nt', 'grows at high elevations'),\n",
       "   ('sa', 'kakavea'),\n",
       "   ('sf', 'FLORA'),\n",
       "   ('dt', '12/Feb/2005'),\n",
       "   ('ex', 'Kakupute kouro oara toupaiveira eisi Tutue pukui vituaro.'),\n",
       "   ('xp', 'Dispela kain diwai pen i save istap long maunten Balbi tasol.'),\n",
       "   ('xe', 'The fern tree kakapute lives on Mt. Balbi.')]),\n",
       " ('kakutauo',\n",
       "  [('ps', 'N'),\n",
       "   ('pt', 'NT'),\n",
       "   ('ge', 'flower sheath of palms'),\n",
       "   ('tkp', 'lim'),\n",
       "   ('sf', 'FLORA'),\n",
       "   ('dt', '29/Jan/2005'),\n",
       "   ('ex', 'Kakutauo oa iava opita kuero purapapiroveira.'),\n",
       "   ('xp', 'Parao bilong kokonas i save kamap.'),\n",
       "   ('xe', '???')]),\n",
       " ('kakuto',\n",
       "  [('rt', 'kaku'),\n",
       "   ('ps', 'N'),\n",
       "   ('pt', 'MASC'),\n",
       "   ('ge', 'fight club'),\n",
       "   ('tkp', 'stik bilong pait'),\n",
       "   ('avm', 'pa_barred'),\n",
       "   ('dt', '31/Oct/2005'),\n",
       "   ('ex', 'Kakuto ira-ia oisioa oraupopave.'),\n",
       "   ('xp', 'Pakoo ol i save yusim long pait.'),\n",
       "   ('xe', 'We always fight with a club.'),\n",
       "   ('ex',\n",
       "    'Kakuto ira purapaiveira oeavu iava sirivuko sara iava uva eera kakuto ira-ia upo purapaveira.'),\n",
       "   ('xp',\n",
       "    'Stik bilong pait ol i save wokim long wanpela kain limbum na ol i save yusim dispela stik long pait.'),\n",
       "   ('xe', '???')]),\n",
       " ('kakutuiato',\n",
       "  [('ps', 'N'),\n",
       "   ('pt', 'MASC'),\n",
       "   ('ge', 'type of tree'),\n",
       "   ('tkp', '???'),\n",
       "   ('nt', 'leaves have rough edges, used for sandpaper'),\n",
       "   ('sf', 'FLORA'),\n",
       "   ('dt', '12/Feb/2005'),\n",
       "   ('ex',\n",
       "    'Kakutuiato ira guruvaroja kakuava tuiapa vara gausisi piepaovo. Oaravu kovoara toupa kakutuato gurava roia.'),\n",
       "   ('xp',\n",
       "    'Plisave kisim lefi blong em napim ol kain timber bai kam sumt tru em use long plant kan work.'),\n",
       "   ('xe', '???'),\n",
       "   ('ex', 'Kakutuiato ira guruvaro oupaiveira kakuraoro gausisipiepasia.'),\n",
       "   ('xp',\n",
       "    'Diwai ol i save kisim lip bilong mekim smut ol andoro bilong tamiok.'),\n",
       "   ('xe', 'The kakutuiato tree, they get its leaves in order to ???.')]),\n",
       " ('kakuva',\n",
       "  [('ps', 'N'),\n",
       "   ('pt', 'FEM'),\n",
       "   ('ge', 'frog'),\n",
       "   ('tkp', '???'),\n",
       "   ('nt',\n",
       "    'brown body, cry sounds like the striking of an axe on wood, lives ???'),\n",
       "   ('dt', '11/Feb/2005'),\n",
       "   ('ex',\n",
       "    'Kakuva riropovira gaupaeveira vuri vuri varava vo toupaevei ra viavaia vasia.'),\n",
       "   ('xp',\n",
       "    'Kakuva em i save karai bikpela tru em brown body em I save istap tasol long antap long oldiwai.'),\n",
       "   ('xe', 'The frog was crying loudly ???.'),\n",
       "   ('ex', 'Kakuva iria gaupaeveira ovaiarovi ora avitoava.'),\n",
       "   ('xp', 'Rokrok i save krai long avinun na long moning.'),\n",
       "   ('xe', 'The frog cries in the afternoon and at night.')]),\n",
       " ('kakuvira',\n",
       "  [('rt', 'kaku'),\n",
       "   ('ps', 'ADV'),\n",
       "   ('pt', 'MANNER'),\n",
       "   ('ge', 'split-like'),\n",
       "   ('tkp', 'olsem bruk'),\n",
       "   ('dt', '11/Feb/2005'),\n",
       "   ('ex', 'Kakuvira va toeri opita vao kaukuvira va toe.'),\n",
       "   ('xp', 'Katim hap yu katim kokomas long twopela hap.'),\n",
       "   ('xe', '???'),\n",
       "   ('ex', 'Kakuvira opita isi toeri.'),\n",
       "   ('xp', 'Yu katim kokonas long tupela hap.'),\n",
       "   ('xe', 'You cut the coconut, splitting it in two.')]),\n",
       " ('kameoro',\n",
       "  [('ps', 'N'),\n",
       "   ('pt', '???'),\n",
       "   ('ge', 'camel'),\n",
       "   ('tkp', 'kamel'),\n",
       "   ('ig', 'yes'),\n",
       "   ('nt', 'Tok Pisin loan'),\n",
       "   ('dt', '12/Feb/2005'),\n",
       "   ('cmt', \"Check original for second example. What's up with tapirs?\"),\n",
       "   ('ex', 'Kameoro vo toupaevo raka tapi, viapau vo toupai.'),\n",
       "   ('xp', 'Kameoro em i stap long ol dert place i no i stap long bus ia.'),\n",
       "   ('xe', \"The camel lives in a dray place, they don't exist here.\"),\n",
       "   ('ex', 'O kameovo iria-ia vokapaivei vo raka tapirs.'),\n",
       "   ('xp', 'Kameoro ol i usim long mekim sampela kain work.'),\n",
       "   ('xe', 'The camel, they walk around on it in dry places.'),\n",
       "   ('ex',\n",
       "    'Kameoro iria oisioa vokapaive isippairara oira avuaro kotokoto kaepaoro.'),\n",
       "   ('xp',\n",
       "    'Kamel em ol i sip ol i save yusim long wokabaut na long karim kago.'),\n",
       "   ('xe', '???')]),\n",
       " ('kandora',\n",
       "  [('alt', 'ketoroa'),\n",
       "   ('ps', 'N'),\n",
       "   ('pt', 'NT'),\n",
       "   ('ge', 'candle'),\n",
       "   ('tkp', 'kandol'),\n",
       "   ('ig', 'yes'),\n",
       "   ('nt', 'Tok Pisin loan'),\n",
       "   ('dt', '10/May/2005')]),\n",
       " ('kaokao',\n",
       "  [('rt', 'kao'),\n",
       "   ('ps', 'N'),\n",
       "   ('pt', 'FEM'),\n",
       "   ('ge', 'frog'),\n",
       "   ('tkp', 'rokrok'),\n",
       "   ('nt', 'mate of epioto, cry sounds like its name'),\n",
       "   ('dt', '12/Feb/2005'),\n",
       "   ('ex', 'Kaokao vo toupaiveira uuko gaero sirova.'),\n",
       "   ('xp', 'Dispela rokrok i save i stap tasol long ol wara.'),\n",
       "   ('xe', '???'),\n",
       "   ('ex', 'Kaokao oisio raga ita oira osia kakarau.'),\n",
       "   ('xp',\n",
       "    'Em wanpela lain rokrok bilong kaikai na ol i save i stap arere long wara.'),\n",
       "   ('xe', '???')]),\n",
       " ('kaokaoara',\n",
       "  [('rt', 'kaokao'),\n",
       "   ('ps', 'N'),\n",
       "   ('pt', 'NT'),\n",
       "   ('ge', 'invitations'),\n",
       "   ('tkp', '???'),\n",
       "   ('dt', '12/Feb/2005'),\n",
       "   ('ex',\n",
       "    'Kaokoara vavosio-va uriopai Sisivi-ia. Kaokaoara sipok vigei-re ra avavio aiosia.'),\n",
       "   ('xp',\n",
       "    'Ol singaut i kam long sisivi. Ol salim il singaut long yumi bai yumi go kaikai.'),\n",
       "   ('xe', 'Invitations come from Sisivi. ???.')]),\n",
       " ('kaokaoto',\n",
       "  [('rt', 'kaokao'),\n",
       "   ('ps', 'N'),\n",
       "   ('pt', 'HUM'),\n",
       "   ('ge', 'messenger'),\n",
       "   ('tkp', 'man bilong karim tok'),\n",
       "   ('dt', '11/Feb/2005'),\n",
       "   ('ex',\n",
       "    'Kaokaoto urioro rupika eisi Ibu-ia. Kaokaoto uriovoi eisi-va Kereaka (ibu)(toisikoaro).'),\n",
       "   ('xp',\n",
       "    'Man bilong karim tok i kam long Kereaka. Ibu tosikoa wanpela man blong karim tok blong singsing kau long Ibu ikam.'),\n",
       "   ('xe', 'The messenger came to Ibu. ???.'),\n",
       "   ('ex', 'Kaekaoto avaroe eisi-re Wakunai.'),\n",
       "   ('xp', 'Man bilong toksave i go pinis long Wakunai.'),\n",
       "   ('xe', 'The messenger went to Wakunai.')]),\n",
       " ('kapa',\n",
       "  [('ps', 'N'),\n",
       "   ('pt', 'NT'),\n",
       "   ('ge', 'food'),\n",
       "   ('eng', 'food cooked to break a period of fasting'),\n",
       "   ('tkp', 'kaikai'),\n",
       "   ('nt',\n",
       "    'The food like koora kapa or koie kapa (opossum or pig) was [MISSING]'),\n",
       "   ('dt', '31/Oct/2005'),\n",
       "   ('ex',\n",
       "    'Vovokio-ia Uruate ora Toupie koora kapa vatepaere Kokora ovitoaro-pa, ra koora aioparo.'),\n",
       "   ('xp',\n",
       "    'Tude bai Uruate na Toupie i givim kapul long pikinini bilong Kokora, bai em i save kaikai kapul.'),\n",
       "   ('xe',\n",
       "    \"Today Uruate and Toupie is giving possum meat to Kokora's child, and eats possum.\"),\n",
       "   ('ex', 'see notebook'),\n",
       "   ('xp', 'see notebook'),\n",
       "   ('xe', 'see notebook')]),\n",
       " ('kapa',\n",
       "  [('ps', 'V'),\n",
       "   ('pt', 'B'),\n",
       "   ('ge', 'break.fast'),\n",
       "   ('tkp', 'kaikai'),\n",
       "   ('eng', 'eat after fasting'),\n",
       "   ('vx', '2'),\n",
       "   ('arg', 'O'),\n",
       "   ('cmt', 'Need examples'),\n",
       "   ('dt', '17/Oct/2005'),\n",
       "   ('ex',\n",
       "    'Raviata ira kokai kapare erikapa kavua tokosia oa purarevora erika-ia kokaiarapa rera kavupieoro oa iava rera-pa vara kaparevoi..'),\n",
       "   ('xp',\n",
       "    'Aviata i kukim kakaruk long Elika bilong brukim tambu em i bin wokim long tambuim Elika long kakaruk. Olsem na em i givim ol dispela samting long em na em i kaikaim.'),\n",
       "   ('xe', '???')]),\n",
       " ('kapaava',\n",
       "  [('ps', 'N'),\n",
       "   ('pt', 'FEM'),\n",
       "   ('ge', 'teeth'),\n",
       "   ('tkp', 'bikpela tit'),\n",
       "   ('nt', 'specifically, molars'),\n",
       "   ('cmt', \"Check vowel length: kapaava or kapava? What's plural?\"),\n",
       "   ('dt', '15/Apr/2006'),\n",
       "   ('ex', 'Kapaava reuriva iria upiapaoe.'),\n",
       "   ('xp', 'Nambawan tit bilong mi i pen.'),\n",
       "   ('xe', 'My molar hurts.')]),\n",
       " ('kapai',\n",
       "  [('ps', 'N'),\n",
       "   ('pt', 'NT'),\n",
       "   ('ge', 'wild pitpit'),\n",
       "   ('tkp', 'liklik pitpit'),\n",
       "   ('nt', 'Used for shelves/platforms.'),\n",
       "   ('dt', '12/Feb/2005'),\n",
       "   ('ex', 'Kapai aoopauparveira urupurapaso riro goru arute.'),\n",
       "   ('xp', 'Kapai pitpit ol save plain blong wokim bed em stang pela.'),\n",
       "   ('xe', '???'),\n",
       "   ('ex', 'Kapaiara oupaiveira varaia uru purapasia.'),\n",
       "   ('xp', 'Wail pitpit ol i save kisim bilong wokim bet.'),\n",
       "   ('xe', 'Wild pitpit is used to make beds.')]),\n",
       " ('kapara',\n",
       "  [('ps', 'V'),\n",
       "   ('pt', 'B'),\n",
       "   ('ge', 'roast without pan or container'),\n",
       "   ('tkp', 'kukim long paia'),\n",
       "   ('arg', 'O'),\n",
       "   ('vx', '2'),\n",
       "   ('dt', '08/Jun/2005'),\n",
       "   ('ex', 'Isivairi korato kapararevoi etokasi raga-ia.'),\n",
       "   ('xp', 'Isivairi i kukim kapul long paia tasol.'),\n",
       "   ('xe', 'Isivairi is cooking possum in the fire.'),\n",
       "   ('ex', 'Orekerovu aue keruara oara oisoa kaparapaive oearovu.'),\n",
       "   ('xp', '???'),\n",
       "   ('xe', 'Other people would always roast the bones.')]),\n",
       " ('kaparu',\n",
       "  [('ps', 'V'),\n",
       "   ('pt', 'B'),\n",
       "   ('ge', 'short of'),\n",
       "   ('ge', 'missing'),\n",
       "   ('tkp', 'wanpela i lus'),\n",
       "   ('dt', '08/Jun/2005'),\n",
       "   ('arg', 'O'),\n",
       "   ('vx', '2'),\n",
       "   ('cmt', 'Check whether uporo is really okay...'),\n",
       "   ('ex', 'Pita vaio ora Sera kaparuivoi Sera raga uporo.'),\n",
       "   ('xp', 'Ol man i misim Pita na ol i paitim tasol Sera.'),\n",
       "   ('xe', 'They are missing Pita and Sera and hitting only Sera.'),\n",
       "   ('ex', 'Kareroepa gaupaoro vore Rotokasi-ia vo uvare vo aaorei kaparuiva.'),\n",
       "   ('xp', '???'),\n",
       "   ('xe',\n",
       "    'He returned to the Rotokas area crying because he missed the father and.'),\n",
       "   ('ex', 'Pita ora Sera aiterea kaparu vaitere uporo vegei kaparuvoi vavo.'),\n",
       "   ('xp', 'Pita na Sera kols tru ol kitim tupela na ol misim tupela.'),\n",
       "   ('xe', 'Peter and Sera ???')]),\n",
       " ('kaparuvira',\n",
       "  [('rt', 'kaparu'),\n",
       "   ('ps', 'ADV'),\n",
       "   ('pt', 'MANNER'),\n",
       "   ('ge', 'one missing'),\n",
       "   ('tkp', 'olsem i sot'),\n",
       "   ('dt', '31/Oct/2005'),\n",
       "   ('ex', 'Atari vavae vao kaparuvira vateri ragaipi.'),\n",
       "   ('xp', 'Yu gonim avepela pis hap tasol.'),\n",
       "   ('xe', '???'),\n",
       "   ('ex', 'Vovavae rutu toupaivo uva kaparuvira toupai.'),\n",
       "   ('xp', 'I bin gat paipela i stap tasol wanpela i lus.'),\n",
       "   ('xe', 'Five are here and one is missing.'),\n",
       "   ('ex',\n",
       "    'Sopia vaio ora Kepii Pita vasiaro aioerevo upiriko isi oa iava vairei kaparuvira vovouroe uva sopia raga uporevoi ovusia kepii torievo vegoaro-re.'),\n",
       "   ('xp',\n",
       "    'Sopia wantaim Kepii tupela kaikaim kaukau bilong Pita na Pita em i ???.'),\n",
       "   ('xe', '???')]),\n",
       " ('kapatau',\n",
       "  [('ps', 'V'),\n",
       "   ('pt', 'B'),\n",
       "   ('ge', 'add to'),\n",
       "   ('tkp', '???'),\n",
       "   ('eng', 'augment'),\n",
       "   ('eng', 'add to'),\n",
       "   ('eng', 'cap up'),\n",
       "   ('eng', 'supplement'),\n",
       "   ('arg', 'O'),\n",
       "   ('vx', '2'),\n",
       "   ('dt', '08/Jun/2005'),\n",
       "   ('ex', 'Uuko rovu kapatauevere oai tovooro.'),\n",
       "   ('xp', '???'),\n",
       "   ('xe', 'She will add to the water putting some other (water in).'),\n",
       "   ('ex',\n",
       "    'Rupieri iria reoa kapatauevoi Siuripiri tapo oiso ra toupaeve ita vo Kuritaturi.'),\n",
       "   ('xp',\n",
       "    'Rupieri i wokim niupela tok orait gen wantaim Siuripiri bai em i ken i stap long Kuritaturi.'),\n",
       "   ('xe',\n",
       "    'Rupieri added words with Siuripiri ??? that he can still be in Kuritaturi.')]),\n",
       " ('kapatoro',\n",
       "  [('ps', 'N'),\n",
       "   ('pt', '???'),\n",
       "   ('ge', 'leprous'),\n",
       "   ('tkp', 'liea'),\n",
       "   ('dt', '03/Jun/2005'),\n",
       "   ('ex', 'Kapatoro ro irai kapuora toupai vo kokotoa-ia sivi kapuari.'),\n",
       "   ('xp', 'Man i got ol soa nogut i stap long em.'),\n",
       "   ('xe', 'A leper is one who ???.')]),\n",
       " ('kapatoroto',\n",
       "  [('rt', 'kapatoro'),\n",
       "   ('ps', 'N'),\n",
       "   ('pt', 'HUM'),\n",
       "   ('ge', 'leperous person'),\n",
       "   ('tkp', 'lepaman'),\n",
       "   ('dt', '12/Feb/2005'),\n",
       "   ('ex', 'Viapau uvaipa va koetapape masin ouragaparovere osa viapau.'),\n",
       "   ('xp', 'Em kisim manas bilong dispela sore tasol bai i no gat tru.'),\n",
       "   ('xe', '???')]),\n",
       " ('kape',\n",
       "  [('ps', 'V'),\n",
       "   ('pt', 'B'),\n",
       "   ('ge', 'unable to meet'),\n",
       "   ('tkp', 'i no nap bung'),\n",
       "   ('arg', '???'),\n",
       "   ('vx', '???'),\n",
       "   ('cmt',\n",
       "    'Try to find clearer example to establish transitivity, Class A or B.'),\n",
       "   ('dt', '11/Feb/2007'),\n",
       "   ('ex', 'Kapepaivoi siguva.'),\n",
       "   ('xp', '???'),\n",
       "   ('xe', 'The joint does not meet together.'),\n",
       "   ('ex', 'Kapepaavoi, viia kovaeto.'),\n",
       "   ('xp', 'Han bilong mi i sot bikos yu bikbel.'),\n",
       "   ('xe', \"I can't reach because you're fat.\"),\n",
       "   ('ex',\n",
       "    'Kape vo vavaearei oiratoa iava rikova-ia pituarapa uvare riro varava.'),\n",
       "   ('xp',\n",
       "    'Han bilong man i sot long holim bodi bilong meri bikos em i pat tumas.'),\n",
       "   ('xe', \"The man's hands ???.\"),\n",
       "   ('ex',\n",
       "    'Oirato riakova raure uva rera vavaearo kovutoa-ia kapere oisio riakova torievoi uvare rera iava vavaearei. Viapau uvuipae oarea etekupae riakova-ia pitu goruarapa.'),\n",
       "   ('xp',\n",
       "    'Man i holim meri na han bilong em i sot long holim bel bilong meri. Taim meri i ranawe bikos tupela han bilong em i sot long holim pas meri.'),\n",
       "   ('xe',\n",
       "    'The man is hugging the woman ??? the woman has run away because ???')]),\n",
       " ('kapeaa',\n",
       "  [('ps', 'V'),\n",
       "   ('pt', 'A'),\n",
       "   ('ge', 'flimsy'),\n",
       "   ('eng', 'insubstantial'),\n",
       "   ('eng', 'flimsy'),\n",
       "   ('eng', 'unstable'),\n",
       "   ('tkp', 'no strong tumas'),\n",
       "   ('tkp', 'i no pas tumas'),\n",
       "   ('vx', '1'),\n",
       "   ('sc', '???'),\n",
       "   ('dt', '31/Oct/2005'),\n",
       "   ('ex', 'Vo kovo kapeapape.'),\n",
       "   ('xp', '???'),\n",
       "   ('xe', 'The work is unstable.'),\n",
       "   ('ex',\n",
       "    'Oirato kapea vovouvira touparevoi oa iava rasii varu-ia vori ouroe uva viapau rera-pa rasi avaiei.'),\n",
       "   ('xp',\n",
       "    'Man i no gat strongpela tingting olsem na em i salim hap graun na em i nogat graun nau.'),\n",
       "   ('xe', 'The man was weak-minded and therefore he sold and ???.')]),\n",
       " ('kapeaa',\n",
       "  [('ps', 'V'),\n",
       "   ('pt', 'B'),\n",
       "   ('ge', 'flimsy'),\n",
       "   ('tkp', 'no strong tumas'),\n",
       "   ('arg', 'O'),\n",
       "   ('vx', '2'),\n",
       "   ('cmt', 'Think about a better gloss'),\n",
       "   ('dt', '28/Aug/2005'),\n",
       "   ('ex', 'Rataoa kapearevoi viapau va gorurevo.'),\n",
       "   ('xp', 'Em i no bin pasim strong doa.'),\n",
       "   ('xe', \"He didn't ??? the door, ???.\"),\n",
       "   ('ex', 'Aiteto viapau oisio kakaevure kapeapareveira voea-re reopaoro.'),\n",
       "   ('xp', 'Papa i no save isi long ol pikinini taim em i toktok long ol.'),\n",
       "   ('xe', 'Dad ??? talking to them.'),\n",
       "   ('ex', 'Ae, rera kapeaatavo uva torirevo.'),\n",
       "   ('xp', 'Hei, yupela isi long man ia na em i ranawe.'),\n",
       "   ('xe', 'hey, you ??? him and he ran away.'),\n",
       "   ('ex', 'Oira-ia tupareve aiteto oira kapeapareveira.'),\n",
       "   ('xp', '???'),\n",
       "   ('xe', 'He always is paying in advance to secure her with her father.')]),\n",
       " ('kapeaavira',\n",
       "  [('alt', 'kapeaapavira'),\n",
       "   ('rt', 'kaapea'),\n",
       "   ('ps', 'ADV'),\n",
       "   ('pt', 'MANNER'),\n",
       "   ('ge', 'flimsy'),\n",
       "   ('ge', 'loosely'),\n",
       "   ('tkp', 'no strong tumas'),\n",
       "   ('tkp', 'i no pas tumas'),\n",
       "   ('cmt', 'Check vowel length'),\n",
       "   ('dt', '29/Oct/2005'),\n",
       "   ('ex', 'Opeita kaaeavira pitupari- opeita kaapeavira torepau.'),\n",
       "   ('xp', 'Yumas holim pasi stong - yu mas sanap stong.'),\n",
       "   ('xe', '???'),\n",
       "   ('ex', 'Kaapeavira toupaivoi vao kepa.'),\n",
       "   ('xp', 'Dispela haus i no strong.'),\n",
       "   ('xe', 'This house is ???.'),\n",
       "   ('ex',\n",
       "    'Kapeavira raga Iteipirie sigoa-ia pitupaevo uva kove oira togasia.'),\n",
       "   ('xp',\n",
       "    'Iteipirie em i no holim pas gut naip. Na naip i pundaon na sutim em.'),\n",
       "   ('xe', 'Iteipirie held the knife loosely and it fell down, cutting her.'),\n",
       "   ('ex',\n",
       "    'Teiavi kaapeavira aio pitoka ivitaevo uva epusi ivita veraevo aioara aiosia.'),\n",
       "   ('xp',\n",
       "    'Teiavi em i no pasim gut sospen kaikai, na pusi i opim sospen na kaikaim ol kaikai.'),\n",
       "   ('xe',\n",
       "    \"Teiavi didn't shut the saucepan tightly and the cat ??? in order to eat all of the food.\")]),\n",
       " ('kapekape',\n",
       "  [('rt', 'kape'),\n",
       "   ('ps', 'V'),\n",
       "   ('pt', 'B'),\n",
       "   ('rdp', 'full'),\n",
       "   ('ge', 'embrace'),\n",
       "   ('ge', 'grip with arms not meeting'),\n",
       "   ('tkp', 'i laik pasim han waintim'),\n",
       "   ('cm', '-ia'),\n",
       "   ('arg', 'OBL'),\n",
       "   ('vx', '2'),\n",
       "   ('cmt', 'Can verb appear without oblique argument?'),\n",
       "   ('dt', '08/Jun/2005'),\n",
       "   ('ex', 'Opita ipasia kapekapepasivoi.'),\n",
       "   ('xp', '???'),\n",
       "   ('xe', 'The two men are embracing the coconnut tree to climb up.'),\n",
       "   ('ex', 'Kapekapeiraoavoi opita govuko-ia.'),\n",
       "   ('xp', 'Han bilong mi i no inap long traipela kokonas.'),\n",
       "   ('xe', 'I tried to get my hands around a ???.')]),\n",
       " ('kapekapevira',\n",
       "  [('alt', 'kapekapepavira'),\n",
       "   ('rt', 'kapekape'),\n",
       "   ('ps', 'ADV'),\n",
       "   ('pt', 'MANNER'),\n",
       "   ('ge', 'with arms barely encircling'),\n",
       "   ('tkp', '???'),\n",
       "   ('dt', '28/Aug/2005'),\n",
       "   ('ex', 'Oirato kapekapevira iiparoi opita atosia.'),\n",
       "   ('xp', '???'),\n",
       "   ('xe',\n",
       "    'The man climbs the coconut tree, nearly embracing the trunk with [MISSING].'),\n",
       "   ('ex', 'Kapekapevira rutu iiparai opitatoa-ia.'),\n",
       "   ('xp', 'Mi go antap long kokonas na tupela han bilong mi i sot.'),\n",
       "   ('xe', 'I am going climbing the coconut without my hands meetings.')]),\n",
       " ('kapere',\n",
       "  [('ps', 'V'),\n",
       "   ('pt', 'B'),\n",
       "   ('ge', 'swim'),\n",
       "   ('tkp', 'suim'),\n",
       "   ('eng', 'swim with part of the body out of the water'),\n",
       "   ('vx', '1'),\n",
       "   ('cmt', \"There's something weird about the 2nd ex sentence!\"),\n",
       "   ('dt', '31/Oct/2005'),\n",
       "   ('ex', 'Kaperepareva avakava-ia.'),\n",
       "   ('xp', '???'),\n",
       "   ('xe', 'He was swimming on the surface of the ocean.'),\n",
       "   ('ex', 'Mak kaperepare kavua-ia.'),\n",
       "   ('xp', 'Mak i suim long raun wara.'),\n",
       "   ('xe', 'Mark swims in the ???.'),\n",
       "   ('ex',\n",
       "    'Oiratoa-va petoviropa opuruva avakava ivaraia uva kaperesiva rogara iare.'),\n",
       "   ('xp',\n",
       "    'Man i bin kapsait long kanu hantap long solwara na tupela suim i kam long nambis.'),\n",
       "   ('xe',\n",
       "    'The canoe capsized with the man on the ocean and the two of them swam to the shore.')]),\n",
       " ('kaperepie',\n",
       "  [('rt', 'kapere'),\n",
       "   ('ps', 'V'),\n",
       "   ('pt', 'B'),\n",
       "   ('dx', 'Central'),\n",
       "   ('ge', 'make.swim'),\n",
       "   ('tkp', 'mekim subim'),\n",
       "   ('eng', 'make swim'),\n",
       "   ('vx', '2'),\n",
       "   ('arg', 'O'),\n",
       "   ('dt', '22/Nov/2005'),\n",
       "   ('ex', 'Suke kaperepieivo rovua-ia.'),\n",
       "   ('xp', 'Ol i mekim Suke subim wara.'),\n",
       "   ('xe', 'They made Suke swim in the water.')]),\n",
       " ('kapi',\n",
       "  [('ps', 'N'),\n",
       "   ('pt', '???'),\n",
       "   ('ge', 'beak'),\n",
       "   ('ge', 'bill'),\n",
       "   ('tkp', 'maus bilong pisin'),\n",
       "   ('dt', '11/Feb/2005'),\n",
       "   ('ex',\n",
       "    'Riro kaekae kapito kokioto. Vo toupare avakava sirova vuoto riro kaekae kapito aue aioparovei okoe va kaviri.'),\n",
       "   ('xp',\n",
       "    'Longpela neck pinic em Isane istap long Solwana wanpela Pisin vuoto em I long pela neck isana kaikaim kuka crab na or kitam.'),\n",
       "   ('xe', '???'),\n",
       "   ('ex', 'Riro kaekae kapito ovuveo.'),\n",
       "   ('xp', 'Kokomo i gat long nek.'),\n",
       "   ('xe', 'The ??? is long-necked.')]),\n",
       " ('kapiaa',\n",
       "  [('ps', '???'),\n",
       "   ('dx', 'Central'),\n",
       "   ('ge', '???'),\n",
       "   ('tkp', 'bek bilong pisin'),\n",
       "   ('eng', '???'),\n",
       "   ('dt', '13/Nov/2005'),\n",
       "   ('ex',\n",
       "    'Tako ovuveo kapiaa ro ritarevoi porokoa-ia uva koveroi vo-re rasito uva rera orisia kareroi vo atoia.'),\n",
       "   ('xp',\n",
       "    'Tako em i sutim bek bilong kokomo long ponook na kokomo em i pundaun i go daun long graun na em i kisim em na go kukim long peles.'),\n",
       "   ('xe', '???')]),\n",
       " ('kapiaavira',\n",
       "  [('rt', 'kapiaa'),\n",
       "   ('ps', 'ADV'),\n",
       "   ('pt', 'MANNER'),\n",
       "   ('ge', 'available'),\n",
       "   ('ge', 'easy'),\n",
       "   ('ge', 'clearly'),\n",
       "   ('tkp', '???'),\n",
       "   ('cmt',\n",
       "    'Is it kapeaa or kapiaa? And is the last vowel really long? Not recognized by informants. Needs to be double-checked.'),\n",
       "   ('dt', '31/Oct/2005'),\n",
       "   ('ex', 'Eake-a ra va iava kapiaavira taviro?'),\n",
       "   ('xp', '???'),\n",
       "   ('xe', 'What is it that he can explain it clearly?'),\n",
       "   ('ex',\n",
       "    'Pita viapau uvuipa ra taviro, uvare viapau oisio kapeavira toupaivoi.'),\n",
       "   ('xp', 'Pita i no inap tru long tokaut.'),\n",
       "   ('xe', \"Peter can't talk, because he isn't available.\"),\n",
       "   ('ex',\n",
       "    'Veeta tou gasivoi vavaea raga-ia uvare aireviraga riroe oa iava kapeavira vo tou gasirivoi.'),\n",
       "   ('xp',\n",
       "    'Mambu yu brukim tasol long han bikos i no olsem i strong bikos i no long taim em i gro.'),\n",
       "   ('xe', '???')]),\n",
       " ('kapikapi',\n",
       "  [('rt', 'kapi'),\n",
       "   ('ps', 'N'),\n",
       "   ('pt', 'NT'),\n",
       "   ('ge', 'bow of ship'),\n",
       "   ('ge', 'peak of house'),\n",
       "   ('tkp', 'poret bilong sip'),\n",
       "   ('tkp', 'antap long haus'),\n",
       "   ('dt', '30/Oct/2005'),\n",
       "   ('ex',\n",
       "    'Uvuoa iava kapikai ora tuguruei raka-ia uvare oira vokapiepato viapau vearovira uraparevo.'),\n",
       "   ('xp',\n",
       "    'Poret bilong sip em i bam long rip bikos man i save stiaim in no lukluk gut.'),\n",
       "   ('xe', \"??? because the helmsman didn't ??? good.\")]),\n",
       " ('kapiro',\n",
       "  [('ps', 'V'),\n",
       "   ('pt', 'B'),\n",
       "   ('ge', 'clamp'),\n",
       "   ('ge', 'hold in place'),\n",
       "   ('tkp', 'holim pas'),\n",
       "   ('arg', '???'),\n",
       "   ('vx', '???'),\n",
       "   ('cmt', '???'),\n",
       "   ('dt', '30/Oct/2005'),\n",
       "   ('ex',\n",
       "    'Pita, uriou ra avekeara kasiiraopara kapiro upirikoara ivarai vara tovotovo evaia kapiroa. Oa oisio kekevira toupai osa sisisi uvare votapopierei toupaiveira.'),\n",
       "   ('xp',\n",
       "    'Pita, yu kam na holim ol hotpela ston wantaim clamp na bai yu putim hantap long ol kaukau. Dispela clamp em i sae luk olsem sises bikos tupela hap i pas wantaim.'),\n",
       "   ('xe', '???')]),\n",
       " ('kapiroa',\n",
       "  [('rt', 'kapiro'),\n",
       "   ('ps', 'N'),\n",
       "   ('pt', 'NT'),\n",
       "   ('ge', 'clamp'),\n",
       "   ('eng', 'clamp'),\n",
       "   ('eng', 'vise'),\n",
       "   ('tkp', 'holim pas'),\n",
       "   ('dt', '30/Apr/2006'),\n",
       "   ('ex',\n",
       "    'Tevire kapiraa-ia evaoarei kapiroparevoi airepa kepa sovaraia oisio ra takuvuvira tarevokovira toave osa varei ririreve goruvira.'),\n",
       "   ('xp',\n",
       "    'Tevire em i klamim tupela hap timba insait long niupela haus olsem bai tupela hap tim.'),\n",
       "   ('xe',\n",
       "    'Tevire has clamped the two branches with a clamp inside of the new house so that ???.')]),\n",
       " ('kapiroko',\n",
       "  [('rt', 'kapiro'),\n",
       "   ('ps', 'N'),\n",
       "   ('pt', 'NT'),\n",
       "   ('ge', 'clamp'),\n",
       "   ('ge', 'boundary'),\n",
       "   ('tkp', 'swinge'),\n",
       "   ('dt', '30/Oct/2005'),\n",
       "   ('ex', 'Kapirokoa-ia avekeara verapaiveira kasiraopara.'),\n",
       "   ('xp', 'Ol i save kalamim ol ston i hot.'),\n",
       "   ('xe', '???'),\n",
       "   ('ex',\n",
       "    'Vosia avekeara kapirokopaiveira riakora auero-ia vetapariero oara upievira toupaiveira oa iava kapiroko pariero rataupa varataro-ia pitupaiveira avearai ava vovoarataro.'),\n",
       "   ('xp',\n",
       "    'Taim ol meri i save holim ol ston wantaim ol hap mambu i save bum wantaim olsem na tupela hap mambu i save holim ol hap autsait bilong ol ston.'),\n",
       "   ('xe', '???')]),\n",
       " ('kapisi',\n",
       "  [('ps', 'N'),\n",
       "   ('pt', '???'),\n",
       "   ('ge', 'tobacco'),\n",
       "   ('tkp', 'brus'),\n",
       "   ('tkp', 'tabak'),\n",
       "   ('dt', '30/Oct/2005'),\n",
       "   ('ex',\n",
       "    'Kapisi ragai-pa avai ras sivuka. Kapisi vosia reropire kapisi tabacco.'),\n",
       "   ('xp',\n",
       "    'Yu gave tabacco bai me smok. Kapisi tabacco taim em I dry na I ready long smokim.'),\n",
       "   ('xe', '???'),\n",
       "   ('ex', 'Popoteirara oisioa topeka purapave aue iava kapisi guruvaro.'),\n",
       "   ('xp', 'Ol waitman ol i save wokim tapak long lip bilong burus.'),\n",
       "   ('xe', 'White men make tobacco from the leaf of the tobacco leaf.'),\n",
       "   ('ex',\n",
       "    'Kapisia oavivu rutu oapa oirara kopipaveira vosia viapau sivukapave.'),\n",
       "   ('xp',\n",
       "    'Brus i wanpela samting tru ol man i save dai long sapos ol i no simuk.'),\n",
       "   ('xe', '???'),\n",
       "   ('ex',\n",
       "    'Sivukapairara kapisi paupaveira uvare oavivu rutua oapa upiavira ora ravapaveira oirara ora riakora voeao pea sivukapaveira.'),\n",
       "   ('xp',\n",
       "    'Ol man i save smok ol i save planim brus bikos em wanpela samting ol man meri ol i save pilim olsem ol i sik ol manmeri ol i save simuk.')]),\n",
       " ('kapisito',\n",
       "  [('rt', 'kapisi'),\n",
       "   ('ps', 'N'),\n",
       "   ('pt', 'MASC'),\n",
       "   ('ge', 'tobacco'),\n",
       "   ('ge', 'plant with long wide leaves used for smoking'),\n",
       "   ('tkp', '???'),\n",
       "   ('sf', 'FLORA'),\n",
       "   ('nt', 'A bundle of tobacco leaves kapisi is neuter gender.'),\n",
       "   ('dt', '12/Feb/2005'),\n",
       "   ('ex', 'Pikaito ira kapisito paurevora riropa guruvato.'),\n",
       "   ('xp', 'Pikaito i bin palanim burus i gat ol bikpela lip.'),\n",
       "   ('xe', 'Pikaito planted tobacco plant with big leaves.')]),\n",
       " ('kapiu',\n",
       "  [('ps', 'N'),\n",
       "   ('pt', '???'),\n",
       "   ('ge', 'twigs'),\n",
       "   ('ge', 'kindling'),\n",
       "   ('tkp', 'liklik haphap stik'),\n",
       "   ('dt', '30/Oct/2005'),\n",
       "   ('ex', 'Kapiuarava uriou ra tuitui kasi pitupiea.'),\n",
       "   ('xp', 'Yu kam wantaim ol liklik stik na bai mi statim pie.'),\n",
       "   ('xe', \"Come here with the firewood and I'll build a fire.\"),\n",
       "   ('ex',\n",
       "    'Kapiuara oara evao rao ro-ia toupaiveira gareparaoro oara uvuipai ra ikauvira rutu erakopape uvare garepa raorovia oara riropa raoro vara roia toupaiveira.'),\n",
       "   ('xp',\n",
       "    'Ol liklik han bilong diwai i save stap long han bilong ol diwai ol dispela liklik han i save drai kuik bikos em ol liklik han tumas i save stap long skin bilong ol bikpela han diwai.'),\n",
       "   ('xe', '???')]),\n",
       " ('kapiua',\n",
       "  [('rt', 'kapi'),\n",
       "   ('ps', 'N'),\n",
       "   ('pt', 'NT'),\n",
       "   ('ge', 'bill of bird'),\n",
       "   ('ge', 'beak'),\n",
       "   ('tkp', '???'),\n",
       "   ('cmt', \"Is 'ua' part of the word or not?\"),\n",
       "   ('dt', '30/Oct/2005'),\n",
       "   ('ex',\n",
       "    'Ovuveo ira-ia riro kaekaeua toupaiveira kapiua ouaiava uvuiparoi ratauavisivi aio ouparo uvare riro kaekaeua kapiua. Ari okare rovu iava kokio kare okarea iava ouarovu kapiuaro porokovira toupaiveira. Oiso osia roia keravo ira iava porokovira toupaiveira kapiua.'),\n",
       "   ('xp',\n",
       "    'Longpela maus i save stap long kokomo em i nap kisim kaikai long wai liklik bikos i gat longpela maus. Tasol ol narapela pisin i gat maus i krungut olsem dispela tarangu.'),\n",
       "   ('xe', '???')]),\n",
       " ('kapo',\n",
       "  [('ps', 'V'),\n",
       "   ('pt', 'B'),\n",
       "   ('ge', 'fasten.cover.strip'),\n",
       "   ('tkp', 'rabis'),\n",
       "   ('tkp', 'pasim banis long haus'),\n",
       "   ('eng', 'join together'),\n",
       "   ('eng', 'clamp together'),\n",
       "   ('eng', 'fasten on coverstrips'),\n",
       "   ('eng', 'put cover strips on house or wall'),\n",
       "   ('arg', 'O'),\n",
       "   ('vx', '2'),\n",
       "   ('dt', '30/Oct/2005'),\n",
       "   ('ex', 'Leo kepa kapoparerevoi.'),\n",
       "   ('xp', 'Leo i wok long pasim wol long ol sitirips.'),\n",
       "   ('xe', 'Leo is covering the house with cover strips.'),\n",
       "   ('ex', 'Take kapoave ra opesipe.'),\n",
       "   ('xp', '???'),\n",
       "   ('xe', \"I'll clamp on the bamboo wall material and it will be finished.\"),\n",
       "   ('ex', 'Kaposi tovo kepaio vavao kaposi tovori evoa takei.'),\n",
       "   ('xp', 'Putim vap timber long wall.'),\n",
       "   ('xe', '???'),\n",
       "   ('ex',\n",
       "    'Leo ira evaova iava kapoara tekarevoi oisio ravara-ia takei takireve vara tapo oira ririoro.'),\n",
       "   ('xp', 'Leo em i sapim ol diwai bilong pasim wol na nilim wantaim.'),\n",
       "   ('xe', '???')]),\n",
       " ('kapoa',\n",
       "  [('rt', 'kapo'),\n",
       "   ('ps', 'N'),\n",
       "   ('pt', 'NT'),\n",
       "   ('ge', 'cover.strip'),\n",
       "   ('tkp', 'banis long haus'),\n",
       "   ('eng', 'cover strips on house or wall'),\n",
       "   ('cmt', 'Check vowel length--kapo vs. kapoo!'),\n",
       "   ('dt', '30/Oct/2005'),\n",
       "   ('ex', 'Kapooara tekapaivoi ragai vokeparo takear?? kapoosia.'),\n",
       "   ('xp',\n",
       "    'Ol i sapim ol lik strip diwai bilong pasim wol long haus bilong mi.'),\n",
       "   ('xe', 'They are ??? cover strips'),\n",
       "   ('ex',\n",
       "    'Ragai urioparai kata-ia ragava kapoa uvare kepa rutu opesiera osa vakapoapavora.'),\n",
       "   ('xp',\n",
       "    'Mi bai mi kam wantaim wanpela hap diwai tasol bikos haus i bin pinis olgeta taim mi pasim wantaim ol hap diwai taim mi bin wok long pasim wantaim ol strip.'),\n",
       "   ('xe', '???')]),\n",
       " ('kapokao',\n",
       "  [('ps', 'N'),\n",
       "   ('pt', 'NT'),\n",
       "   ('ge', 'kapok tree'),\n",
       "   ('tkp', '???'),\n",
       "   ('dt', '29/Jan/2005')]),\n",
       " ('kapokapo',\n",
       "  [('rt', 'kapo'),\n",
       "   ('ps', 'V'),\n",
       "   ('pt', 'B'),\n",
       "   ('rdp', 'full'),\n",
       "   ('ge', 'fasten.cover.strips'),\n",
       "   ('tkp', '???'),\n",
       "   ('vx', '2'),\n",
       "   ('arg', 'O'),\n",
       "   ('dt', '30/Oct/2005'),\n",
       "   ('ex', 'Takei kapokapoa ari kepa opesiei.'),\n",
       "   ('xp', 'Mi nailim wol bikos haus i pinis.'),\n",
       "   ('xe', '???'),\n",
       "   ('ex', 'Kepa iava takei kapokapo.'),\n",
       "   ('xp', 'Yu putim sitirip long olgeta wol bilong haus.'),\n",
       "   ('xe', '???'),\n",
       "   ('ex',\n",
       "    'Kepa iava takei kapokapoa teapi koveovere rara kiuvu urioro oira peosia rakoveo rasitoa iare.'),\n",
       "   ('xp',\n",
       "    'Wol bilong haus mi papas wantaim ol hap diwai nogut i pundaun sapos win i kam bai pusim i go daon long graun.'),\n",
       "   ('xe', '???')]),\n",
       " ('kapokapoa',\n",
       "  [('rt', 'kapokapo'),\n",
       "   ('ps', 'N'),\n",
       "   ('pt', 'NT'),\n",
       "   ('ge', 'cover.strips'),\n",
       "   ('tkp', 'diwai i pasim banis bilong haus'),\n",
       "   ('eng', 'cover strips of wall or house'),\n",
       "   ('dt', '30/Oct/2005')]),\n",
       " ('kapokapora',\n",
       "  [('rt', 'kapora'),\n",
       "   ('ps', 'V'),\n",
       "   ('pt', 'B'),\n",
       "   ('ge', \"carry between two people's shoulders\"),\n",
       "   ('tkp', 'karim'),\n",
       "   ('vx', '2'),\n",
       "   ('arg', 'O'),\n",
       "   ('dt', '30/Oct/2005'),\n",
       "   ('ex', 'Ararai kapokaporosivoi Visa vaio ora Apoka.'),\n",
       "   ('xp', 'Visa wantaim Apoka, tupela i karim Arari i go.'),\n",
       "   ('xe', 'Visa and Apoka are carrying Arari between their shoulders.'),\n",
       "   ('ex',\n",
       "    'Vuri vakato oirato kopoka pora tvaiterei vi kapokapora pasi osa vaokavi. Ragai kopokapora si.'),\n",
       "   ('xp', 'Yut bai mi woik bout namel long tuopela bikos lags blong em ino.'),\n",
       "   ('xe', '???'),\n",
       "   ('ex',\n",
       "    'Siropiri kapokaporopaoro avase ausiki iare vutuouarei iava uvare koveroe.'),\n",
       "   ('xp',\n",
       "    'Tupela man i karim Siropiri long tupela soldia i go long haus bikos em i pundaun.'),\n",
       "   ('xe', '???'),\n",
       "   ('ex', 'Rera kapokaporoereva voa raivaaro.'),\n",
       "   ('xp', '???'),\n",
       "   ('xe',\n",
       "    'The two (girls) carried him (supporting him) between their shoulders.'),\n",
       "   ('ex', 'Rera kapokaporooro avasi ari viapau uvuipa vokasia.'),\n",
       "   ('xp', 'Yutupela karim em i go, emi ni inao wokabaut.'),\n",
       "   ('xe', \"You two carry him between your shoulders, because he can't walk.\"),\n",
       "   ('ex',\n",
       "    'Ata vaio ora Vavaviri aiterea Perapera kapokaporopaoro avasie eisi-re ruvarupa tapi. Vaiterei vutuoaro-ia vokaparevo uvare vurivira upiaparoe rutu.'),\n",
       "   ('xp',\n",
       "    'Ata wantaim Vaviri tupela i go wantaim Perapera long haus sik. Em i wokabaut namel long solda bilong tupela bikos em i sik nogut tru.'),\n",
       "   ('xe',\n",
       "    'Ata and Vavaviri, the two of them went carrying Perapera on their shoulders to the medical station. He walked (leaning) on their shoulders because he was really sick.')]),\n",
       " ('kapokaporo',\n",
       "  [('rt', 'kaporo'),\n",
       "   ('ps', 'V'),\n",
       "   ('pt', 'B'),\n",
       "   ('dx', 'Central'),\n",
       "   ('ge', 'grip'),\n",
       "   ('eng', 'grip'),\n",
       "   ('eng', 'hold'),\n",
       "   ('tkp', 'holim'),\n",
       "   ('dt', '12/Jul/2006')]),\n",
       " ('kapokari',\n",
       "  [('ps', 'N'),\n",
       "   ('pt', 'FEM'),\n",
       "   ('ge', 'type of vine'),\n",
       "   ('tkp', '???'),\n",
       "   ('nt', 'red, used for weaving'),\n",
       "   ('dt', '14/Sep/2004'),\n",
       "   ('ex', 'Kapokari ova oa iava oaravu ruvaruara purapaiveira.'),\n",
       "   ('xp', 'Long diwai kapokari ol i save wokim ol marasin.'),\n",
       "   ('xe', '???')]),\n",
       " ('kapokarito',\n",
       "  [('ps', 'N'),\n",
       "   ('pt', 'MASC'),\n",
       "   ('ge', 'tree roots'),\n",
       "   ('tkp', '???'),\n",
       "   ('nt', 'used for make red/purple-colored stain'),\n",
       "   ('dt', '17/Jul/2006'),\n",
       "   ('ex', 'Kapokarito vavurupato ora vu toupai.'),\n",
       "   ('xp', 'Kapokarito roots igat kovoara sampela kain work long ai.'),\n",
       "   ('xe', '???'),\n",
       "   ('ex', 'Kapokarito ira epao vavo Rarova, ira iava vavurupaara ouavorao.'),\n",
       "   ('xp', 'Diwai kapokarito i stap long Rarova, mi bin kisim roots long em.'),\n",
       "   ('xe', 'The tree that is in Rarova, I got roots from it.')]),\n",
       " ('kapokoa',\n",
       "  [('ps', 'N'),\n",
       "   ('pt', '???'),\n",
       "   ('ge', 'kapok tree'),\n",
       "   ('tkp', 'kapok'),\n",
       "   ('dt', '30/Oct/2005'),\n",
       "   ('ex', 'Kopokoa evaova evaoa kuepapuva vutara-ia.'),\n",
       "   ('xp',\n",
       "    'Kapok em I wampela diurai em I save karnu flau ou fruit lovy seasome blong em.'),\n",
       "   ('xe', '???'),\n",
       "   ('ex', 'Kapokoo aue purapaive vaio orave uusipasia.'),\n",
       "   ('xp', 'Ol i save usim bilong mekim pilo.'),\n",
       "   ('xe', 'They make use of kapok for pillows to sleep on.'),\n",
       "   ('ex', 'Kapoko pupupuro iava oraveara purapaiveira voriako.'),\n",
       "   ('xp', 'Ol meri i save wokim pilo long wul bilong kapok.'),\n",
       "   ('xe', 'From kapok cotton the women make pillows.'),\n",
       "   ('ex',\n",
       "    'Kapokoa evaova oa kuepapeira rava iava kueisiro oupaive oravepara purapasia.'),\n",
       "   ('xp',\n",
       "    'Kapok em wanpela diwai i save karim ol prut. Ol dispela prut ol save kisim bilong mekim pilo long dispela samting.'),\n",
       "   ('xe', '???')]),\n",
       " ('kapoo',\n",
       "  [('ps', 'V'),\n",
       "   ('pt', 'A'),\n",
       "   ('ge', 'poor'),\n",
       "   ('ge', 'destitute'),\n",
       "   ('tkp', 'lus long moni'),\n",
       "   ('sa', 'apota'),\n",
       "   ('vx', '1'),\n",
       "   ('sc', '???'),\n",
       "   ('dt', '30/Oct/2005'),\n",
       "   ('ex', 'Kapooparoi aue-pa moni.'),\n",
       "   ('xp', '???'),\n",
       "   ('xe', 'He is poor, lacking money.'),\n",
       "   ('ex',\n",
       "    'Ragaivi kapooparai uvare viapau ragai kakau kovovai raoa-ia vori oupara.'),\n",
       "   ('xp',\n",
       "    'Mi tarangu mi lus long moni bikos mi nogat gaden kakau bilong mi bai mi inap kisim mani long em.'),\n",
       "   ('xe',\n",
       "    \"Little me is poor because I don't earn money from cocoa gardens.\")]),\n",
       " ('kapooto',\n",
       "  [('rt', 'kapoo'),\n",
       "   ('ps', 'N'),\n",
       "   ('pt', 'HUM'),\n",
       "   ('ge', 'poor person'),\n",
       "   ('tkp', 'man i no gat moni'),\n",
       "   ('dt', '30/Oct/2005'),\n",
       "   ('ex', 'Kapooto vi aue-pa moni apotato auepa moni.'),\n",
       "   ('xp',\n",
       "    'Poor man long maney wanpela word abotato kapogt - lusia?? Man long samting.'),\n",
       "   ('xe', '???'),\n",
       "   ('ex',\n",
       "    'Sevei oaravu rutu-pa kapooto uvare vegoaro toupareveira. Viapau moni oupa kovorovai oa iava kapootoa rutu arera.'),\n",
       "   ('xp',\n",
       "    'Sevei em i lus man tru long olgeta samting bikos em i save stap long bus. Em i nogat ol wok bilong kisim mani olsem na em i stap lusman.'),\n",
       "   ('xe',\n",
       "    'Sevei is poor with respect to everything because he is usually in the jungle. ???.')]),\n",
       " ('kapoovira',\n",
       "  [('alt', 'kapoopavira'),\n",
       "   ('rt', 'kapoo'),\n",
       "   ('ps', 'ADV'),\n",
       "   ('pt', 'MANNER'),\n",
       "   ('ge', 'poor'),\n",
       "   ('ge', 'without much'),\n",
       "   ('tkp', 'olsem i no gat tru'),\n",
       "   ('dt', '30/Oct/2005'),\n",
       "   ('ex', 'Kapoovira rutu toupaavoi vovokio-ia.'),\n",
       "   ('xp', 'Mi i stap lus tru long ol dispela taim.'),\n",
       "   ('xe', 'I was very poor during this time.'),\n",
       "   ('ex', 'Kapovira toupari kapovira touba voi ravi vatea aue mon.'),\n",
       "   ('xp', 'Mi lusiman minogat samting bai mi gavim long yu.'),\n",
       "   ('xe', '???'),\n",
       "   ('ex', 'Kapovira toupaavoi vo vuutao-ia aue-pa moni.'),\n",
       "   ('xp', 'Mi lus tru long mani dispela taim.'),\n",
       "   ('xe', 'I was poor during this time as far as money is concerned.'),\n",
       "   ('ex',\n",
       "    'Ragaivi kapoovira rutu toupaavoi uvare kavirupairara moniara rutu kaviruivorao oa iava kapoovira toupaavoi.'),\n",
       "   ('xp',\n",
       "    'Mi trangu nogat moni tru bikos ol stilman ol i stilim olgeta moni bilong mi olsem na mi stap poaman tru.'),\n",
       "   ('xe',\n",
       "    \"Little me is poor because thieves stole lots of money and that's why I am poor.\")]),\n",
       " ('kapopaa',\n",
       "  [('rt', 'kapo'),\n",
       "   ('ps', 'N'),\n",
       "   ('pt', 'NT'),\n",
       "   ('ge', 'wrench'),\n",
       "   ('ge', 'spanner'),\n",
       "   ('tkp', 'spana'),\n",
       "   ('dt', '14/Sep/2004'),\n",
       "   ('ex', 'Kapopa aue-pa varo morn sigo alo eakepa.'),\n",
       "   ('xp', 'Em sot long laplap maney knife kaikai angthing.'),\n",
       "   ('xe', '???'),\n",
       "   ('ex', 'Kapopaa-va uriou.'),\n",
       "   ('xp', 'Yu kam wantaim sipana.'),\n",
       "   ('xe', 'You come with the spanner.')]),\n",
       " ('kaporo',\n",
       "  [('ps', 'N'),\n",
       "   ('pt', 'NT'),\n",
       "   ('ge', 'passage'),\n",
       "   ('tkp', 'pasis apes'),\n",
       "   ('eng', 'space between objects'),\n",
       "   ('eng', 'mountain passage'),\n",
       "   ('eng', 'passage'),\n",
       "   ('dt', '29/Jan/2005'),\n",
       "   ('ex', 'Kaporoa vao oa toupai vopa Togaraoia ora vo Kikisova.'),\n",
       "   ('xp', 'I gat baret namel long Togarao na Kikisova.'),\n",
       "   ('xe', '???')]),\n",
       " ('kaporo',\n",
       "  [('ps', 'V'),\n",
       "   ('pt', 'B'),\n",
       "   ('dx', 'Central'),\n",
       "   ('ge', 'grip'),\n",
       "   ('eng', 'grip'),\n",
       "   ('eng', 'hold'),\n",
       "   ('tkp', 'holim'),\n",
       "   ('dt', '12/Jul/2006')]),\n",
       " ('kaporopa',\n",
       "  [('rt', 'kaporo'),\n",
       "   ('ps', 'N'),\n",
       "   ('pt', 'NT'),\n",
       "   ('ge', 'clamp'),\n",
       "   ('tkp', 'samting bilong holim ol samting'),\n",
       "   ('dt', '30/Oct/2005'),\n",
       "   ('ex',\n",
       "    'Ragai aveke kaporopa puraavoi oa-ia avekeara kaporopaavere vosia upiriko vagi purasia auepara.'),\n",
       "   ('xp',\n",
       "    'Mi wokim samting bilong olim ol ston taim mi laik wokim mumu kaukau,'),\n",
       "   ('xe',\n",
       "    \"I'm making a stone clamp with which I will turn the stones when I am preparing sweet potato ???.\")]),\n",
       " ('kaporoto',\n",
       "  [('rt', 'kaporo'),\n",
       "   ('ps', 'N'),\n",
       "   ('pt', 'MASC'),\n",
       "   ('ge', 'scissors'),\n",
       "   ('tkp', '???'),\n",
       "   ('dt', '14/Sep/2004'),\n",
       "   ('ex', 'Kaporotoava uriou ra varoa tokoa.'),\n",
       "   ('xp', 'Yu kam wantaim sisisi, bai mi katim laplap.'),\n",
       "   ('xe', '???')]),\n",
       " ('kapoto',\n",
       "  [('rt', 'kapo'),\n",
       "   ('ps', '???'),\n",
       "   ('ge', 'poor man'),\n",
       "   ('tkp', 'rabisman'),\n",
       "   ('dt', '17/Sep/2004'),\n",
       "   ('ex', 'Kapoto vi auepa orekerovu mani auepa sigo.'),\n",
       "   ('xp', 'Lusiman long ol samting mani na long knife.'),\n",
       "   ('xe', '???'),\n",
       "   ('ex', 'Oraeviri kapoto oreke rovu rutupa.'),\n",
       "   ('xp', 'Oraeviri em i lusman tru long ol narapela samting.'),\n",
       "   ('xe', '???')]),\n",
       " ('kapu',\n",
       "  [('ps', 'N'),\n",
       "   ('pt', '???'),\n",
       "   ('ge', 'cup'),\n",
       "   ('eng', 'cup'),\n",
       "   ('nt', 'Tok Pisin loan'),\n",
       "   ('dt', '29/Jan/2005'),\n",
       "   ('ex', 'Gisipo kapupierevoi kopiioro.'),\n",
       "   ('xp', 'Em i pasim maus na dai.'),\n",
       "   ('xe', 'He closed his mouth while dying.')]),\n",
       " ('kapua',\n",
       "  [('ps', 'N'),\n",
       "   ('pt', 'NT'),\n",
       "   ('ge', 'sore'),\n",
       "   ('tkp', 'sua'),\n",
       "   ('eng', 'sore'),\n",
       "   ('eng', 'infection'),\n",
       "   ('eng', 'wound'),\n",
       "   ('dt', '30/Oct/2005'),\n",
       "   ('ex', 'Kapua eva vii kokotoaro-ia toupai.'),\n",
       "   ('xp', 'Soa i stap long lek bilong yu.'),\n",
       "   ('xe', 'That sore is on your leg.'),\n",
       "   ('ex',\n",
       "    'Kapua kakaetoa-ia toupai uvare aakova viapau rera sisiupaeveira oa iava eva kapua rera kokotoaro vuripievo.'),\n",
       "   ('xp',\n",
       "    'Soa i stap long pikinini bikos mama i no save wasim em olsem na soa bagarapim lek bilong em.'),\n",
       "   ('xe',\n",
       "    \"The sore was on the child because his mother didn't wash him and therefore that sore damaged his leg.\")]),\n",
       " ('kapua',\n",
       "  [('ps', 'V'),\n",
       "   ('pt', 'A'),\n",
       "   ('ge', 'have sores'),\n",
       "   ('tkp', '???'),\n",
       "   ('dcsv', 'true'),\n",
       "   ('vx', '1'),\n",
       "   ('dt', '01/Apr/2006'),\n",
       "   ('ex', 'Riakova kapuapaoi uvare vatuato oira uporevoi vurivira rutu.'),\n",
       "   ('xp', 'Meri bai gat sua bikos man bilong em i paitim meri nogut tru.'),\n",
       "   ('xe', '???'),\n",
       "   ('ex', 'Gisipo ragai iava kapuaoi uvare tavute isi aioavoi kopupa isi.'),\n",
       "   ('xp', 'Maus bilolng mi i sua bikos mi kaikaim mango i no red.'),\n",
       "   ('xe', 'My mouth is sore because I ate a red mango.')]),\n",
       " ('kapuapato',\n",
       "  [('rt', 'kapua'),\n",
       "   ('ps', 'N'),\n",
       "   ('pt', 'MASC'),\n",
       "   ('ge', 'fruit damaged by insect or disease with mark (sore) on it'),\n",
       "   ('tkp', '???'),\n",
       "   ('dt', '14/Sep/2004'),\n",
       "   ('ex',\n",
       "    'Kapuapoto oveuto tavuteto kapuapato vi vigoa vuriue rutu. Kapuapato vigoa gesipau.'),\n",
       "   ('xp',\n",
       "    'Kapka em I gat sore mago em I sat sore yu gat sore yu smell long ol sore istap long yu dog igat sore sore man.'),\n",
       "   ('xe', '???'),\n",
       "   ('ex', 'Kapuapato era oveuto.'),\n",
       "   ('xp', 'Kapiak i gat soa.'),\n",
       "   ('xe', 'The breadfruit is damaged.')]),\n",
       " ('kapuapie',\n",
       "  [('rt', 'kapua'),\n",
       "   ('ps', 'V'),\n",
       "   ('pt', 'B'),\n",
       "   ('ge', 'wound'),\n",
       "   ('tkp', 'mekim sua'),\n",
       "   ('arg', 'O'),\n",
       "   ('vx', '2'),\n",
       "   ('dt', '30/Oct/2005'),\n",
       "   ('ex', 'Rera kapuapierivora.'),\n",
       "   ('xp', '???'),\n",
       "   ('xe', 'You wounded him so that he had sores on his body.'),\n",
       "   ('ex', 'Auro, era kapuapieri rera ragipaoro.'),\n",
       "   ('xp', 'Hei, yu stikim em na em i gat soa.'),\n",
       "   ('xe', 'Hey, you gave him sores by beating him.'),\n",
       "   ('ex',\n",
       "    'Oirato kapuapieiva rera upooro uvare kepaa tokooro koataroe torara kavirusia.'),\n",
       "   ('xp',\n",
       "    'Man ol i mekim sua taim ol i paitim em bikos em i brukim haus na em i go insait na stilim tamiok.'),\n",
       "   ('xe',\n",
       "    'They injured the man by hitting him because he went and broke into a house to steal an axe.')]),\n",
       " ('kapuasisi',\n",
       "  [('ps', 'N'),\n",
       "   ('pt', 'NT'),\n",
       "   ('ge', 'type of vine'),\n",
       "   ('tkp', '???'),\n",
       "   ('nt', 'covers everything'),\n",
       "   ('dt', '10/Feb/2005'),\n",
       "   ('ex', 'Kapuasisi oa oiso toupai osa aue iro rirovira toupai vo rotokasi.'),\n",
       "   ('xp', 'Kapuasisi em wampela rop am planin long hio long rotokas.'),\n",
       "   ('xe', '???'),\n",
       "   ('ex', 'Kapuasisi kouro kakauara erakopiepaiveira vara-ia iipapaoro.'),\n",
       "   ('xp',\n",
       "    'Kapuasisi em i save go antap long ol kakao na ol kakao i save drai.'),\n",
       "   ('xe', 'The kauasisi vine dries out the cocoa by climbing on top of it.')]),\n",
       " ('kapupie',\n",
       "  [('rt', 'kapu'),\n",
       "   ('ps', 'V'),\n",
       "   ('pt', 'B'),\n",
       "   ('ge', 'close tight'),\n",
       "   ('tkp', 'taitim'),\n",
       "   ('vx', '2'),\n",
       "   ('arg', 'O'),\n",
       "   ('dt', '08/Jun/2005'),\n",
       "   ('cmt',\n",
       "    \"Syntax is weird and Rotokas doesn't seem to match Tok Pisin. What's up? Where's the tense on the second example?\"),\n",
       "   ('ex', 'Ivita kapupieeva goruvira rakapa tou iava.'),\n",
       "   ('xp', 'Yu pasim strong lit bilong dram.'),\n",
       "   ('xe', '???'),\n",
       "   ('ex', 'Tupa kapupiea goruviva rutu ra viapau irai va karureve.'),\n",
       "   ('xp', 'Mi pasim stong door mom wanpela mav ino nap opim.'),\n",
       "   ('xe', 'I close the door very strongly and nobody can open it.')]),\n",
       " ('kapupiea',\n",
       "  [('rt', 'kapu'),\n",
       "   ('ps', '???'),\n",
       "   ('ge', 'lock'),\n",
       "   ('tkp', 'slos'),\n",
       "   ('cmt',\n",
       "    'Check vowel length; second sentence seems to be missing a verb (special construction?)'),\n",
       "   ('dt', '30/Oct/2005'),\n",
       "   ('ex',\n",
       "    'Taupirie, uriou kapupiea kekesia kepa-ia oa puraivo vegei-re teapi voa uusive.'),\n",
       "   ('xp',\n",
       "    'Taupirie, yu kam na lukim dua i pas ol i mekim long mitupela olsem bai yumi no inap insait na slip.'),\n",
       "   ('xe', '???'),\n",
       "   ('ex',\n",
       "    'Ragai raiva-ia vokapaavo uva kepa-ia kapupiea kekeava oa iava vorevira vorerae uvare viapau uvuiparae rakoatara.'),\n",
       "   ('xp',\n",
       "    'Mi wokabaut i go long rot na mi lukim haus i pas olsem na mi go bek bikos mi no inap go insait.'),\n",
       "   ('xe',\n",
       "    \"I walked along the road and I saw the locked house and therefore I returned because I couldn't the door.\")]),\n",
       " ('kapupiepaa',\n",
       "  [('rt', 'kapupie'),\n",
       "   ('ps', 'N'),\n",
       "   ('pt', 'NT'),\n",
       "   ('ge', 'pincers'),\n",
       "   ('tkp', 'pinsis'),\n",
       "   ('cmt', 'Check vowel length'),\n",
       "   ('dt', '30/Oct/2005'),\n",
       "   ('ex', 'Vii kapupiepa vi toro vi gisipoara.'),\n",
       "   ('xp', 'Bai mi lockim masi blong yu.'),\n",
       "   ('xe', '???'),\n",
       "   ('ex',\n",
       "    'Vao kapuepa va-ia goruviara pituoro. Vokeruo kapupiepa parais keru.'),\n",
       "   ('xp', 'Pinccers em blong holim samting.'),\n",
       "   ('xe', '???'),\n",
       "   ('ex',\n",
       "    'Kapupiepa puraivo Teiavi tavaripieoro uvare Sipirievi kepiivo kikipaoro.'),\n",
       "   ('xp',\n",
       "    'Olo putim Teiavi long kisim ples bilong Sipirievi bikos ol i brukim lek bilong em tain ol i pila soka.'),\n",
       "   ('xe', '???')]),\n",
       " ('kapuu',\n",
       "  [('ps', 'V'),\n",
       "   ('pt', 'B'),\n",
       "   ('ge', 'dumb'),\n",
       "   ('ge', 'not speaking'),\n",
       "   ('tkp', '???'),\n",
       "   ('dcsv', 'true'),\n",
       "   ('vx', '1'),\n",
       "   ('dt', '16/Nov/2005'),\n",
       "   ('ex', 'Roku kapurevo, viapau uvuipa reoreosia.'),\n",
       "   ('xp', 'Roki em i pasim maus pinis, em i no inap toktok.'),\n",
       "   ('xe', \"Roki is dumb, he can't speak.\"),\n",
       "   ('ex', 'Kapuuevoi.'),\n",
       "   ('xp', '???'),\n",
       "   ('xe', 'She (=the mouth) is dumb.'),\n",
       "   ('ex',\n",
       "    'Gisipo kapuuvira raga toupaevo Sera iava uvare varoa kaviruevo uva kapuuvira raga toupaevo. Viapau uvuipaoe ra reoreopao uvare aripaoe evo pitupitu-ia oa puraevo.'),\n",
       "   ('xp',\n",
       "    'Maus bilong Sera i stap pas tasol bikos em i stilim laplap na em i stap maus pas tasol bikos em i sem long pasin em i mekim.'),\n",
       "   ('xe',\n",
       "    \"Sera's mouth was shut because she stole clothes and she kept her mouth shut. She couldn't talk because she was ashamed of the deeds she had done.\")]),\n",
       " ('kapuupie',\n",
       "  [('rt', 'kapuu'),\n",
       "   ('ps', 'V'),\n",
       "   ('pt', 'B'),\n",
       "   ('ge', 'close'),\n",
       "   ('tkp', '???'),\n",
       "   ('eng', 'close (mouth or jaws)'),\n",
       "   ('vx', '2'),\n",
       "   ('arg', 'O'),\n",
       "   ('dt', '16/Nov/2005'),\n",
       "   ('ex', 'Spana kapuupieri.'),\n",
       "   ('xp', '???'),\n",
       "   ('xe', 'Close up the jaws of the wrench.'),\n",
       "   ('ex', 'Ragai tupa kapuupiea.'),\n",
       "   ('xp', 'Mi lokim doa.'),\n",
       "   ('xe', \"I'm closing the door.\"),\n",
       "   ('ex', 'Orakapuupieroe kopiioro.'),\n",
       "   ('xp', 'Taim man i dai em i pasim maus bilong em.'),\n",
       "   ('xe', '???')]),\n",
       " ('kapuupiepa',\n",
       "  [('rt', 'kapuu'),\n",
       "   ('ps', 'N'),\n",
       "   ('pt', 'NT'),\n",
       "   ('ge', 'pincers'),\n",
       "   ('tkp', '???'),\n",
       "   ('dt', '15/Feb/2004')]),\n",
       " ('Kara',\n",
       "  [('ps', 'N'),\n",
       "   ('pt', 'PN'),\n",
       "   ('ge', 'name'),\n",
       "   ('eng', 'name'),\n",
       "   ('ig', 'yes'),\n",
       "   ('dt', '26/Jan/2005')]),\n",
       " ('kara',\n",
       "  [('ps', 'N'),\n",
       "   ('pt', 'NT'),\n",
       "   ('ge', 'leaf'),\n",
       "   ('tkp', 'lip bilong wokim mat'),\n",
       "   ('nt', 'used for mat weaving'),\n",
       "   ('dt', '10/Feb/2005'),\n",
       "   ('ex', 'Kara tria guruvaroia, mat uspara turupai.'),\n",
       "   ('xp', 'Kara karuaka usin long mekim sleep mat.'),\n",
       "   ('xe', '???'),\n",
       "   ('ex', 'Kara kouro oara kaarukaa purapaveira riakora.'),\n",
       "   ('xp', 'Long lip bilong karaa ol meri i save wokim mat.'),\n",
       "   ('xe', 'The kara leaf, women make leaves from it.')]),\n",
       " ('karaava',\n",
       "  [('rt', 'karaa'),\n",
       "   ('ps', 'N'),\n",
       "   ('pt', 'FEM'),\n",
       "   ('ge', 'large Chinese bamboo'),\n",
       "   ('tkp', '???'),\n",
       "   ('nt', 'cultivated'),\n",
       "   ('cmt', 'Is this related to kara?'),\n",
       "   ('dt', '29/Jan/2005'),\n",
       "   ('ex',\n",
       "    'Karaava oiso toupaiveiro osa aue veta (siaira vetata) votoupai siaira veta.'),\n",
       "   ('xp', 'Karaava bamboo em i blong chinase.'),\n",
       "   ('xe', '???'),\n",
       "   ('ex', 'Auea vao etepeua oua vaisipaiveira toisikopairara oisio karaava.'),\n",
       "   ('xp', 'Ol Toisiko ol i save kolim het bilong suka ken olsem karaava.'),\n",
       "   ('xe', '???')]),\n",
       " ('karakarao',\n",
       "  [('alt', 'karakaro'),\n",
       "   ('rt', 'karao'),\n",
       "   ('ps', 'V'),\n",
       "   ('pt', 'B'),\n",
       "   ('rdp', 'partial'),\n",
       "   ('ge', 'take without permission'),\n",
       "   ('tkp', '???'),\n",
       "   ('cmt', 'Double check that karakaro is in fact a possible alt'),\n",
       "   ('arg', 'O'),\n",
       "   ('vx', '2'),\n",
       "   ('dt', '17/Oct/2005'),\n",
       "   ('ex', 'Karakaraovira rutu ro itova ourevo ake asiavira.'),\n",
       "   ('xp', 'Man ia kisim banana na em i no askim pastaim.'),\n",
       "   ('xe',\n",
       "    'Without asking persmission at all he took the banana without asking.'),\n",
       "   ('ex', 'Karakaraoiraouei oirato kukuakue atoro.'),\n",
       "   ('xp', 'Man yu no askim pastaim na yu daunim garip bilong mi.'),\n",
       "   ('xe', '???'),\n",
       "   ('ex',\n",
       "    'Vavaviri karakaraoroe tuupato ouoro ata reraro viapau vearo vaisi va iava rera ourevoi.'),\n",
       "   ('xp',\n",
       "    'Vavaviri em i kisim nating traus bilong Ata nogat tok orait na em i kisim.'),\n",
       "   ('xe', '???')]),\n",
       " ('karakaraoa',\n",
       "  [('rt', 'karakarao'),\n",
       "   ('ps', 'N'),\n",
       "   ('pt', 'NT'),\n",
       "   ('ge', 'trough for carrying liquids'),\n",
       "   ('tkp', 'diwai bilong karim wara'),\n",
       "   ('dt', '30/Oct/2005'),\n",
       "   ('ex', 'Karakaraoa-ia uukoa uriopieri.'),\n",
       "   ('xp', 'Yu putim wara i kam long hos paip.'),\n",
       "   ('xe', 'Bring the water for the trough.'),\n",
       "   ('ex',\n",
       "    'Ragai uukoa karakaraoa tetevu kuriare uva tetevu gagaukoa-ia uriopae ukoa tetevu kuri iare oa iava aioa orapurae.'),\n",
       "   ('xp',\n",
       "    'Mi kisim wara long pangal bilong saksak olsem na wara i kam long meme bilong saksak, olsem na kaikai bilong saksak i kamap.'),\n",
       "   ('xe', '???')]),\n",
       " ('karakaraoto',\n",
       "  [('rt', 'karakarao'),\n",
       "   ('ps', 'N'),\n",
       "   ('pt', 'HUM'),\n",
       "   ('ge', 'boldly possessive person'),\n",
       "   ('tkp', '???'),\n",
       "   ('avm', 'pa_barred'),\n",
       "   ('dt', '02/Sep/2005'),\n",
       "   ('ex', 'Karakaraoto akuku oaravu outo oerovu vararo oirara.'),\n",
       "   ('xp', 'Man bilong kisim nating samting bilong narapela man.'),\n",
       "   ('xe', '???')]),\n",
       " ('karakaraovira',\n",
       "  [('alt', 'karakaraopavira'),\n",
       "   ('rt', 'karakarao'),\n",
       "   ('ps', 'ADV'),\n",
       "   ('pt', 'MANNER'),\n",
       "   ('ge', 'take without permission'),\n",
       "   ('tkp', '???'),\n",
       "   ('dt', '28/Aug/2005'),\n",
       "   ('ex', 'Karakaraovira rutu ro itova ourevo ake asiavira.'),\n",
       "   ('xp', 'Man ia kisim banana na em i no askim pastaim.'),\n",
       "   ('xe',\n",
       "    'Without asking persmission at all he took the banana without asking.')]),\n",
       " ('karakaroto',\n",
       "  [('rt', 'karakaro'),\n",
       "   ('ps', 'N'),\n",
       "   ('pt', '???'),\n",
       "   ('ge', 'boldly possessive man'),\n",
       "   ('tkp', 'man bilong kisim man'),\n",
       "   ('cmt',\n",
       "    'Is this related to karakarao? Can it be men or women? Is the POS N.HUM or simply N.MASC?'),\n",
       "   ('dt', '08/Dec/2005'),\n",
       "   ('ex', 'Roia oirato karakaraotoa rutu akukupapa pitutoa rutu.'),\n",
       "   ('xp', 'Man ia em i man bilong kisim nating samting bilong narapela man.'),\n",
       "   ('xe', 'This possessive man is a grabber of ???.'),\n",
       "   ('ex', 'Apeisi Kare karakaroragaroe asi kue pakosia.'),\n",
       "   ('xp', 'Kare em i mekim pasin nogut long daunim nating rop buai.'),\n",
       "   ('xe', '???')]),\n",
       " ('karakuku',\n",
       "  [('ps', 'N'),\n",
       "   ('pt', 'MASC'),\n",
       "   ('ge', 'coconut sheath'),\n",
       "   ('tkp', 'gai imbong'),\n",
       "   ('dt', '10/Feb/2005'),\n",
       "   ('ex',\n",
       "    'Karakuku vo uva opita isoro toupaivura ira ia kotoviva toupaivei aue opita kororo.'),\n",
       "   ('xp', 'Sheath coconuts i save agamp long em.'),\n",
       "   ('xe', '???'),\n",
       "   ('ex', 'Karakuku ira-ia opita isiro toupaiveira.'),\n",
       "   ('xp', 'Long sut ol kokonas i save hangamap.'),\n",
       "   ('xe', 'Coconut shells hang on their sheathes.')]),\n",
       " ('karaova',\n",
       "  [('ps', 'N'),\n",
       "   ('pt', 'FEM'),\n",
       "   ('ge', 'betel nut'),\n",
       "   ('tkp', 'kambibi'),\n",
       "   ('tkp', 'wail buai'),\n",
       "   ('eng', 'Highland Betel Nut Palm (Areca macrocalyx)'),\n",
       "   ('cmt', 'But the form <karaoto> also seems to exist...'),\n",
       "   ('dt', '15/Apr/2006'),\n",
       "   ('ex', 'Karaova iria vo toupaeveira tuvuara-ia.'),\n",
       "   ('xp', 'Kavivi i save i stap long tais wara.'),\n",
       "   ('xe', 'Highland Betel Nut Palms are found in the swamp.'),\n",
       "   ('ex',\n",
       "    'Karaova rarepavavi asiva iria vegoaro toupaeveira iria aiopaiveira iso kare vegoarapairara.'),\n",
       "   ('xp',\n",
       "    'Wail buai i liklik kain buai i save stap long bus. Em ol tambaran bilong bus i save kaikai.'),\n",
       "   ('xe', '???')]),\n",
       " ('karapi',\n",
       "  [('ps', 'V'),\n",
       "   ('pt', 'A'),\n",
       "   ('ge', 'sing high pitched'),\n",
       "   ('tkp', 'sing antap'),\n",
       "   ('sc', 'EMISSION.SOUND'),\n",
       "   ('vx', '1'),\n",
       "   ('cmt', \"Can you specify what you're singing (cognate object)?\"),\n",
       "   ('dt', '30/Oct/2005'),\n",
       "   ('ex', 'Irouto-a karapiroi.'),\n",
       "   ('xp', '???'),\n",
       "   ('xe', 'Who is the man singing with the high pitched voice?'),\n",
       "   ('ex',\n",
       "    'Kikiviori pupiva-ia karapivira kovaroe uva viapau oirara uvuipae ra oisi karapivira kovaave.'),\n",
       "   ('xp',\n",
       "    'Kikiviori em i singsing kaul antap tru olsem na ol man i no inap singsing antap olsem.'),\n",
       "   ('xe', 'Kikiviori ???.')]),\n",
       " ('karapivira',\n",
       "  [('alt', 'karapipavira'),\n",
       "   ('rt', 'karapi'),\n",
       "   ('ps', 'ADV'),\n",
       "   ('pt', 'MANNER'),\n",
       "   ('ge', 'high-pitched'),\n",
       "   ('eng', 'high-pitched'),\n",
       "   ('eng', 'soprano'),\n",
       "   ('tkp', 'antap'),\n",
       "   ('dt', '30/Oct/2005'),\n",
       "   ('ex', 'Karapivira erata.'),\n",
       "   ('xp', 'Yupela sing antap.'),\n",
       "   ('xe', 'You guys sing in a high pitch.'),\n",
       "   ('ex', 'Karapivira erapai riakora.'),\n",
       "   ('xp', 'Ol meri ol i singsing antap.'),\n",
       "   ('xe', 'Women sing in a high pitch.'),\n",
       "   ('ex', 'Riakora karapivira erapaveira eraara rutu-ia vovokiro rutu-ia.'),\n",
       "   ('xp',\n",
       "    'Ol meri ol i save singsing olsem antap long olgeta singsing olgeta dei.'),\n",
       "   ('xe', 'The women sang soprano ???.')]),\n",
       " ('karara',\n",
       "  [('ps', 'N'),\n",
       "   ('pt', 'FEM'),\n",
       "   ('ge', 'crab'),\n",
       "   ('tkp', 'kuka'),\n",
       "   ('nt', 'lives in the beach sand'),\n",
       "   ('dt', '30/Oct/2005'),\n",
       "   ('ex', 'Karara vo toupaiveira avaka rogaraia.'),\n",
       "   ('xp', 'Dispela kuka em i stap long solwara.'),\n",
       "   ('xe', 'The beach crab lives in saltwater.'),\n",
       "   ('ex', 'Kararakare vo toupaiveira rogarauaia.'),\n",
       "   ('xp', 'Bis kuka ol i save i stap long wet sen.'),\n",
       "   ('xe', 'Beach crabs are found in wet sand.'),\n",
       "   ('ex',\n",
       "    'Karara garevavi okoe iria rogaraua-ia toupaeveira vo avaka vatuaro-ia.'),\n",
       "   ('xp',\n",
       "    'Karara em i liklik kuka i save stap long waisand arere bilong solwara.'),\n",
       "   ('xe', '???')]),\n",
       " ('karata',\n",
       "  [('ps', 'V'),\n",
       "   ('pt', 'B'),\n",
       "   ('ge', 'deal out'),\n",
       "   ('ge', 'divide up'),\n",
       "   ('ge', 'apportion'),\n",
       "   ('tkp', '???'),\n",
       "   ('arg', 'O'),\n",
       "   ('vx', '2'),\n",
       "   ('nt',\n",
       "    'When much is to be divided the reduplicated form is used, karakarata.'),\n",
       "   ('dt', '08/Jun/2005'),\n",
       "   ('ex', 'Aioara karatareva.'),\n",
       "   ('xp', 'Em i dilim ol kaikai.'),\n",
       "   ('xe', 'He divided up the food.'),\n",
       "   ('ex', 'Sera kukara guru karataevoi.'),\n",
       "   ('xp', 'Sera i dilim ol kon.'),\n",
       "   ('xe', 'Sera is dealing out the corn.')]),\n",
       " ('karato',\n",
       "  [('ps', 'N'),\n",
       "   ('pt', 'MASC'),\n",
       "   ('ge', 'small stream of water'),\n",
       "   ('tkp', 'wara ol i pulim long wanpela samting'),\n",
       "   ('dt', '30/Oct/2005'),\n",
       "   ('cmt', 'Double-check translation of example'),\n",
       "   ('ex', 'Vopae karepieivora karatoa-ia.'),\n",
       "   ('xp', 'Ol i bin pulim wara Vopae long paip.'),\n",
       "   ('xe', 'They diverted Vopae to a small stream of water.'),\n",
       "   ('ex',\n",
       "    'Karato vosia oavu-ia uukovi ivuri oisio osia aue vetapariero uvavu rutu-re. Oisio osia rariketo ora vopae aitere-ia karatoarei puraivora vaiterei karaoro atoia-re vegoarova.'),\n",
       "   ('xp',\n",
       "    'Karato i olsem sapos yu pulim wara long wanpela samting i go long wei olsem Rariketo wantaim Vopae ol i bin pulim dispela tupela wara i kam long bus na kam long ples.'),\n",
       "   ('xe', '???')]),\n",
       " ('karavau',\n",
       "  [('ps', 'N'),\n",
       "   ('pt', 'NT'),\n",
       "   ('ge', 'mushroom'),\n",
       "   ('tkp', 'papai'),\n",
       "   ('eng', 'small type of mushroom'),\n",
       "   ('dt', '29/Jan/2005'),\n",
       "   ('ex', 'Karavauara vo purapapiroveira tetevu tatagaro-ia.'),\n",
       "   ('xp', 'Masrum i save kamap long sting saksak.'),\n",
       "   ('xe', 'Mushrooms appear on the ??? of sago.')]),\n",
       " ('karavisi',\n",
       "  [('ps', 'V'),\n",
       "   ('pt', 'A'),\n",
       "   ('ge', 'angry'),\n",
       "   ('ge', 'upset'),\n",
       "   ('tkp', '???'),\n",
       "   ('vx', '1'),\n",
       "   ('sc', 'EMOTION'),\n",
       "   ('dt', '11/Feb/2007'),\n",
       "   ('cmt', 'Check out this vstem + ovoi construction.'),\n",
       "   ('ex', 'Ikauvira raga karavisi ovoirovere.'),\n",
       "   ('xp', '???'),\n",
       "   ('xe', 'Quickly he becomes very upset.'),\n",
       "   ('ex', 'Saimon ira karavisi ovoiparoveira.'),\n",
       "   ('xp', 'Saimon man bilong kros kwik.'),\n",
       "   ('xe', 'Saimon is a man who quickly gets angry.'),\n",
       "   ('ex',\n",
       "    'Karavisi ovoiparoveira Pita. Viapau uvuipa ra reoara roviriei rovopareve. Ari kasipua ikau ovoipaiveira rera-ia.'),\n",
       "   ('xp',\n",
       "    'Wan tu tasol Pita i save koros o wari em i no save skelim pastaim ol toktok. Tasol koro i save kam hariap long em.'),\n",
       "   ('xe', '??? but anger quickly gets to him.')]),\n",
       " ('karavisito',\n",
       "  [('rt', 'karavisi'),\n",
       "   ('ps', 'N'),\n",
       "   ('pt', 'HUM'),\n",
       "   ('ge', 'person who is easily angered or upset'),\n",
       "   ('tkp', '???'),\n",
       "   ('dt', '12/Feb/2005'),\n",
       "   ('ex', 'Riro karavisito ro oirato garepara-IA reoreoara kasipupaoro.'),\n",
       "   ('xp', '???'),\n",
       "   ('xe', 'Easily at just a little talk that man gets angry.'),\n",
       "   ('ex', 'Devid riro ikaupa karavisito garepa reo rovia.'),\n",
       "   ('xp', 'Devid man bilong kros hariap long liklik toktok.'),\n",
       "   ('xe', 'David is a very hot-tempered man ???.')]),\n",
       " ('karavuru',\n",
       "  [('ps', 'V'),\n",
       "   ('pt', 'A'),\n",
       "   ('ge', 'get dusty'),\n",
       "   ('tkp', 'kamap das'),\n",
       "   ('vx', '1'),\n",
       "   ('dt', '30/Oct/2005'),\n",
       "   ('ex', 'Karavuruiraouei poupou-ia.'),\n",
       "   ('xp', 'Yu bagarap tru long das.'),\n",
       "   ('xe', \"You're really dusty.\"),\n",
       "   ('ex', 'Kakaeto karavururoe uvare poupou-ia uusiparoe visikopaoro.'),\n",
       "   ('xp', 'Pikinini em i das bikos em i slip long das taim em i pilai.'),\n",
       "   ('xe', 'The child is dusty because he slept in dust while playing.')]),\n",
       " ('kare',\n",
       "  [('ps', 'FFP'),\n",
       "   ('ge', 'animals'),\n",
       "   ('tkp', 'plenti'),\n",
       "   ('dt', '17/Oct/2005'),\n",
       "   ('ex', 'O karevu koie kare kouevo ita akova.'),\n",
       "   ('xp', 'Pik mama i karim ol narapela pik.'),\n",
       "   ('xe', 'The mother carried the other pigs.')]),\n",
       " ('kare',\n",
       "  [('ps', 'V'),\n",
       "   ('pt', 'A'),\n",
       "   ('ge', 'return'),\n",
       "   ('tkp', 'bekim'),\n",
       "   ('tkp', 'kam bek'),\n",
       "   ('dcsv', 'true'),\n",
       "   ('vx', '1'),\n",
       "   ('sc', 'MOTION'),\n",
       "   ('dt', '30/Oct/2005'),\n",
       "   ('ex', 'Kareparai atoi iare.'),\n",
       "   ('xp', 'Mi go bak gen long ples.'),\n",
       "   ('xe', 'I am going back to the village.'),\n",
       "   ('ex', 'Petero kareroe eisi atoia.'),\n",
       "   ('xp', 'Petero i go pinis long ples.'),\n",
       "   ('xe', 'Petero went to the village.'),\n",
       "   ('ex', 'Ovu iava kareuei, auoro?'),\n",
       "   ('xp', 'Yu kam long we?'),\n",
       "   ('xe', 'Where are you coming from, man?'),\n",
       "   ('ex', 'Rarasori kare kepa iare uvare ogoeroi uva kare kepa iare aiosia.'),\n",
       "   ('xp',\n",
       "    'Rarason em i go long haus bikos em i hangere na em i go long haus bai em i kaikai.'),\n",
       "   ('xe',\n",
       "    'Robinson returned to the house because he was hungry and he returned to eat.')]),\n",
       " ('karekare',\n",
       "  [('rt', 'kare'),\n",
       "   ('ps', 'V'),\n",
       "   ('pt', 'A'),\n",
       "   ('sn', '1'),\n",
       "   ('rdp', 'full'),\n",
       "   ('ge', 'itch'),\n",
       "   ('tkp', 'skrap'),\n",
       "   ('vx', '1'),\n",
       "   ('sc', '???'),\n",
       "   ('cmt', \"What's the deal with 'voka voiva'? What about kaskas?\"),\n",
       "   ('dt', '30/Oct/2005'),\n",
       "   ('ex', 'Ae, karekarerai kokeva-ia voka voiva.'),\n",
       "   ('xp', 'Mi skirap bikos mi raun long ren.'),\n",
       "   ('xe', 'Hey, I itch from the rain ???.'),\n",
       "   ('ex',\n",
       "    'Oirato kaskas iava karekareparoe uvare rera vavaearo aioevo kaskas.'),\n",
       "   ('xp',\n",
       "    'Man em i kirap long kaskas bikos kaskas em i kaikaim han bilong em.'),\n",
       "   ('xe', 'The man is itchy from ??? because he ate the hand of the ???')]),\n",
       " ('karekare',\n",
       "  [('rt', 'kare'),\n",
       "   ('ps', 'V'),\n",
       "   ('pt', 'A'),\n",
       "   ('sn', '2'),\n",
       "   ('rdp', 'full'),\n",
       "   ('ge', 'return'),\n",
       "   ('tkp', 'go bek'),\n",
       "   ('vx', '1'),\n",
       "   ('sc', '???'),\n",
       "   ('dt', '08/Dec/2005'),\n",
       "   ('ex', 'Oirara karekare atoia-re uvare pupipa iare avaera Asitaipa-ia.'),\n",
       "   ('xp',\n",
       "    'Ol man i kam bek long ples bikos ol i bin go long singsing kaul long Asitaipa.'),\n",
       "   ('xe',\n",
       "    'The men return to the village because they went to sing in Asitaipa.'),\n",
       "   ('ex', 'Oirara rutu karekareae eisi atoia.'),\n",
       "   ('xp', 'Olgeta  man i bin go long ol ples.'),\n",
       "   ('xe', 'Everyone went back to their villages.')]),\n",
       " ('karekarererava',\n",
       "  [('rt', 'karekarearava'),\n",
       "   ('ps', 'N'),\n",
       "   ('pt', 'FEM'),\n",
       "   ('ge', 'slit gong signal of patrol officer'),\n",
       "   ('tkp', 'garamut krai bilong klap'),\n",
       "   ('dt', '15/Apr/2006'),\n",
       "   ('ex', 'Karekarearava togaivoi toiva eisi Ibu, ari iravu kopiiroi.'),\n",
       "   ('xp', 'Ol i paitim garamut long Ibu, bikos wanpela man i dai.'),\n",
       "   ('xe', 'They beat drums in Ibu because somebody died.')]),\n",
       " ('karekareto',\n",
       "  [('rt', 'karekare'),\n",
       "   ('ps', 'N'),\n",
       "   ('pt', 'HUM'),\n",
       "   ('ge', 'person with grille or ringworm'),\n",
       "   ('tkp', 'man i gat girire'),\n",
       "   ('dx', 'Pipipaia'),\n",
       "   ('dt', '30/Oct/2005'),\n",
       "   ('ex', 'Ririuvea karekareto.'),\n",
       "   ('xp', 'Ririuve em i girireman.'),\n",
       "   ('xe', 'Ririuvea is a man with grille/ringworm.'),\n",
       "   ('ex',\n",
       "    'Riakora airoa oisioa reasipave oirato apa uvare karekaretoa oisio teapi iriai-re vuri gesiparo oa iava oisoa reasipave riakora rera-pa.'),\n",
       "   ('xp',\n",
       "    'Ol meri ol i save les long man bikos em grille man. Olsem nogut em i smel nogut long wanpela meri olsem an ol meri ol i save les long em.'),\n",
       "   ('xe', '???')]),\n",
       " ('kareke',\n",
       "  [('ps', 'V'),\n",
       "   ('pt', 'A'),\n",
       "   ('ge', 'appear'),\n",
       "   ('tkp', 'kamap'),\n",
       "   ('eng', 'appear'),\n",
       "   ('eng', 'happen'),\n",
       "   ('eng', 'come to be'),\n",
       "   ('dcsv', 'true'),\n",
       "   ('vx', '1'),\n",
       "   ('sc', '???'),\n",
       "   ('dt', '03/Jun/2005'),\n",
       "   ('ex', 'Viapau oiso vearoavai karekepape kovoa oaio-ia.'),\n",
       "   ('xp', '???'),\n",
       "   ('xe', 'Nothing good would come from our (exclusive) work.'),\n",
       "   ('ex', 'Vape oa oisiri avu karekepere rara.'),\n",
       "   ('xp', 'Larim bai em i mas kamap yet.'),\n",
       "   ('xe', '???')]),\n",
       " ('karekepie',\n",
       "  [('rt', 'kareke'),\n",
       "   ('ps', 'V'),\n",
       "   ('pt', 'B'),\n",
       "   ('ge', 'show'),\n",
       "   ('tkp', 'soim'),\n",
       "   ('vx', '2'),\n",
       "   ('arg', 'O'),\n",
       "   ('dt', '30/Oct/2005'),\n",
       "   ('ex', 'Opesioto ira kokopuoto karekepiepareveira.'),\n",
       "   ('xp', 'Em binatang i save kamapim bata palae.'),\n",
       "   ('xe', 'The butterfly becomes a butterfly.'),\n",
       "   ('ex', 'Gavman vii-pa tauva karekepiereve.'),\n",
       "   ('xp', '???'),\n",
       "   ('xe', 'The government would come up with some help for you.'),\n",
       "   ('ex', 'Tugoropato uraurato vigei varaaro vuriara karekepiepareveira.'),\n",
       "   ('xp', 'Holi spirit i save kamapim ol pasin nogut bilong yumi.'),\n",
       "   ('xe', 'The holy spirit shows our sins.'),\n",
       "   ('ex',\n",
       "    'Rarasori rera vo kovoaro karekepiesia kare rovere rera rirotoaro ruvaraia.'),\n",
       "   ('xp',\n",
       "    'Rarason bai em i go bek na soim wok bilong em long bikman bilong em.'),\n",
       "   ('xe', 'Robinson will return to show his work to the bigman.')]),\n",
       " ('karekova',\n",
       "  [('ps', 'N'),\n",
       "   ('pt', 'FEM'),\n",
       "   ('ge', 'vine'),\n",
       "   ('tkp', 'rop i gat wara'),\n",
       "   ('nt', 'water can be extracted from it'),\n",
       "   ('dt', '29/Jan/2005'),\n",
       "   ('ex',\n",
       "    'Karekova iriaia varia tupaveira auere kora. Ora uvuipau ra oira tokori ra ukaiou.'),\n",
       "   ('xp',\n",
       "    'Rop bilong bus ol i save wokim trap bilong kisim kapul, tu sapos yu raun long bus yu ken katim na dring long em.'),\n",
       "   ('xe', '???')]),\n",
       " ('kareo',\n",
       "  [('ps', 'V'),\n",
       "   ('pt', 'B'),\n",
       "   ('ge', 'penetrate'),\n",
       "   ('ge', 'pierce through'),\n",
       "   ('tkp', 'sutim'),\n",
       "   ('vx', '2'),\n",
       "   ('arg', 'O'),\n",
       "   ('dt', '30/Oct/2005'),\n",
       "   ('ex', 'Riopeiri kakau kareore oira iiaoro.'),\n",
       "   ('xp', 'Riopeiri i sutim dok na spia i kamap long narapela sait.'),\n",
       "   ('xe', 'Riopeiri is shooting the dog spearing it.'),\n",
       "   ('ex', 'Oirato kaakau kareorevora rera iiaoro koetava-ia.'),\n",
       "   ('xp', '???'),\n",
       "   ('xe', 'The man shooting the dog with a bow and arrow pierced it through.'),\n",
       "   ('ex', 'Riopeiri kaakau kareorevo sigoa-ia uva kopioe.'),\n",
       "   ('xp', 'Riopeiri em i sutim dok long naip i dai.'),\n",
       "   ('xe', 'Riopeiri stabbed the dog with a knife and it died.')]),\n",
       " ('kareovira',\n",
       "  [('alt', 'kareopavira'),\n",
       "   ('rt', 'kareo'),\n",
       "   ('ps', 'ADV'),\n",
       "   ('pt', 'MANNER'),\n",
       "   ('ge', 'clear through-like'),\n",
       "   ('tkp', '???'),\n",
       "   ('dt', '30/Oct/2005'),\n",
       "   ('ex', 'Kareovira vusire.'),\n",
       "   ('xp', '???'),\n",
       "   ('xe', 'He burst throught from one side to the other.'),\n",
       "   ('ex', 'Kareovira toupaevoi rauruva.'),\n",
       "   ('xp', 'Spia i stap long tupela sait wantaim.'),\n",
       "   ('xe', '???'),\n",
       "   ('ex',\n",
       "    'Oirato kekeavo kapua-va oa revasipae uva kareovira va vurapaavo oisio sigoa-ia rera kareoivo.'),\n",
       "   ('xp',\n",
       "    'Man mi lukim wantaim sua em i wok long bulut. Na mi lukim olsem ol i sutim long naip.'),\n",
       "   ('xe',\n",
       "    'I saw the man with a sore that bled and I saw him stabbed as they stabbed him with a knife.')]),\n",
       " ('karepie',\n",
       "  [('rt', 'kare'),\n",
       "   ('ps', 'V'),\n",
       "   ('pt', 'B'),\n",
       "   ('ge', 'return'),\n",
       "   ('tkp', 'bekim'),\n",
       "   ('eng', 'return'),\n",
       "   ('eng', 'pay back'),\n",
       "   ('eng', 'send back'),\n",
       "   ('arg', 'O'),\n",
       "   ('vx', '2'),\n",
       "   ('dt', '08/Jun/2005'),\n",
       "   ('ex', 'Vii vaaro vukua oa vii iare karepieavere.'),\n",
       "   ('xp', '???'),\n",
       "   ('xe', 'I will return your book to you.'),\n",
       "   ('ex', 'Oire vii varo vukua karepieavere.'),\n",
       "   ('xp', 'Em i orait, bai mi bekim buk bilong yu.'),\n",
       "   ('xe', \"Okay, I'll give you your book back.\")]),\n",
       " ('karepieto',\n",
       "  [('rt', 'kare'),\n",
       "   ('ps', 'N'),\n",
       "   ('pt', 'MASC'),\n",
       "   ('ge', 'entrance to village'),\n",
       "   ('ge', 'village entrance'),\n",
       "   ('tkp', 'maus rot'),\n",
       "   ('dx', 'Central'),\n",
       "   ('dx', 'Pipipaia'),\n",
       "   ('dt', '30/Oct/2005'),\n",
       "   ('ex', 'Aia vavo situepasivere karepieto.'),\n",
       "   ('xp', 'Hei, bai yutupela i was long maus rot.'),\n",
       "   ('xe', '???'),\n",
       "   ('ex',\n",
       "    'Oiratoarei karepietoa-ia ora aivaropiesiei uva aioara-ia oratavariosiei.'),\n",
       "   ('xp', 'Tupela man i bung long maus rot na tupela i senis long ol kaikai.'),\n",
       "   ('xe',\n",
       "    'The two men met at the entrance to the village and exchanged food.')]),\n",
       " ('Karepirie',\n",
       "  [('ps', 'N'),\n",
       "   ('pt', 'PN'),\n",
       "   ('ig', 'yes'),\n",
       "   ('ge', 'name'),\n",
       "   ('tkp', 'nem'),\n",
       "   ('dt', '25/Jan/2005')]),\n",
       " ('kari',\n",
       "  [('ps', 'V'),\n",
       "   ('pt', 'B'),\n",
       "   ('ge', 'rip'),\n",
       "   ('ge', 'tear'),\n",
       "   ('tkp', 'bruk'),\n",
       "   ('arg', 'O'),\n",
       "   ('vx', '2'),\n",
       "   ('dcpv', 'true'),\n",
       "   ('dt', '18/Nov/2006'),\n",
       "   ('ex', 'Ragai varoa karia.'),\n",
       "   ('xp', 'Mi brukim laplap.'),\n",
       "   ('xe', 'I ripped the clothes.'),\n",
       "   ('ex', 'Sera, varoa kari eva ra kapua tukea va-ia teapi revasipe.'),\n",
       "   ('xp', 'Sera, yu brukim laplap bai mi pasim sua nogut em i blut.'),\n",
       "   ('xe',\n",
       "    \"Sera, rip the clothes and I'll cover my sore with them lest it bleed.\")]),\n",
       " ('karia',\n",
       "  [('rt', 'kari'),\n",
       "   ('ps', 'N'),\n",
       "   ('pt', 'NT'),\n",
       "   ('ge', 'hole'),\n",
       "   ('ge', 'rip'),\n",
       "   ('ge', 'tear'),\n",
       "   ('tkp', 'hol'),\n",
       "   ('tkp', 'bruk'),\n",
       "   ('dt', '18/Nov/2006'),\n",
       "   ('ex', 'Karia eva varoa-ia.'),\n",
       "   ('xp', 'Bruk i stap long laplap.'),\n",
       "   ('xe', 'There is a rip in the clothes.'),\n",
       "   ('ex',\n",
       "    'Risevi Pairi tavievo oisio vii reraro-ia koros karia toupaivoi rera verari ra rera turua vii-pa.'),\n",
       "   ('xp',\n",
       "    'Risievi tokim Pairi olsem long kolos bilong yu i gat hul, yu raosim na bai mi somapim bilong yu.'),\n",
       "   ('xe',\n",
       "    \"Risevi told Pairi, your clothes have holes, take them off and I'll sew them for you.\")]),\n",
       " ('kariava',\n",
       "  [('ps', 'N'),\n",
       "   ('pt', 'FEM'),\n",
       "   ('ge', 'lizard'),\n",
       "   ('tkp', 'palai'),\n",
       "   ('nt', 'dark body with tan to yellow scales, no spines, skin used for ???'),\n",
       "   ('cmt', 'What does kundu  mean in Tok Pisin?'),\n",
       "   ('dt', '30/Oct/2005'),\n",
       "   ('ex', 'Kariava rakariaro oupaiveira aue iare kundu touro vara tovopasia.'),\n",
       "   ('xp', 'Ol i save kisim skin bilong palai na putim long kundu.'),\n",
       "   ('xe', 'They get the skin of the ??? lizard in order to put it on drums.'),\n",
       "   ('ex',\n",
       "    'Kariava iria oisio kekevira toupaeveira osia oteote iria iava rakaria oupaiveira aue purapasia kundu touro aue-re vara-ia kovapasia.'),\n",
       "   ('xp',\n",
       "    'Palai i save luk olsem pukpuk. Skin bilong em ol save kisim na mekim ol kundu bilong singsing.'),\n",
       "   ('xe',\n",
       "    'The ??? lizard resembles a crocodile from which they get the skin to make drums for singing with.')]),\n",
       " ('karikari',\n",
       "  [('rt', 'kari'),\n",
       "   ('ps', 'V'),\n",
       "   ('pt', 'B'),\n",
       "   ('rdp', 'full'),\n",
       "   ('ge', 'tear'),\n",
       "   ('ge', 'shred'),\n",
       "   ('tkp', 'brubru kim'),\n",
       "   ('vx', '2'),\n",
       "   ('arg', 'O'),\n",
       "   ('dt', '18/Nov/2006'),\n",
       "   ('ex', 'Pepa karikariri rera-pa va vatesia.'),\n",
       "   ('xp', 'Yu brubrukim pepa na givim long em.'),\n",
       "   ('xe', 'Shred the paper and give it to him.'),\n",
       "   ('ex', 'Pepa karikari eva ra va vate Sera-pa.'),\n",
       "   ('xp', 'Yu brukbrukim pepa na givim long Sera.'),\n",
       "   ('xe', 'Rip the paper and give it to Sera.')]),\n",
       " ('karirapa',\n",
       "  [('ps', 'N'),\n",
       "   ('pt', '???'),\n",
       "   ('ge', 'young banana leaf'),\n",
       "   ('tkp', 'yangpela lip bilong banana'),\n",
       "   ('dt', '30/Oct/2005'),\n",
       "   ('ex',\n",
       "    'Airepa guruva itotoa iava oaoupaiveira varatarata pasia tuitui kasiro-ia. Evaoa vaisipaiveira oisio karirapa ra vo guruva-ia aioara tovotovopaive vasiovar-ia ra voru tovoive aveke oriia ivaraia ra vo vagi rakuive.'),\n",
       "   ('xp',\n",
       "    'Yangpela lip banana ol i save kisim na boenim long paia. Na long dispela lip ol i save putiputim ol kaikai insait long em. Na dispela karamap bai ol i putim long ston i paia na bai oli karamapim dispela mumu.'),\n",
       "   ('xe', '???')]),\n",
       " ('karisito',\n",
       "  [('ps', 'N'),\n",
       "   ('pt', 'PN'),\n",
       "   ('ge', 'Christ'),\n",
       "   ('tkp', 'krais'),\n",
       "   ('ig', 'yes'),\n",
       "   ('dt', '12/Feb/2005'),\n",
       "   ('ex', 'Karisito vigei varaaro-ia vuriara kopiroepa.'),\n",
       "   ('xp', 'Krais i bin dai long ol sin bilong yumi.'),\n",
       "   ('xe', 'Christ died for our sins.')]),\n",
       " ('karivai',\n",
       "  [('ps', 'V'),\n",
       "   ('pt', 'A'),\n",
       "   ('ge', 'have an appetite'),\n",
       "   ('tkp', '???'),\n",
       "   ('eng', 'have an appetite'),\n",
       "   ('nt', 'also has a sexual dimension'),\n",
       "   ('vx', '1'),\n",
       "   ('sc', '???'),\n",
       "   ('dt', '30/Oct/2005'),\n",
       "   ('ex', 'Karivaiparai.'),\n",
       "   ('xp', '???'),\n",
       "   ('xe', 'I have a desire for food.'),\n",
       "   ('ex', 'Rirovira rutu karivaiparai.'),\n",
       "   ('xp', 'Mi sikirap tru long koap.'),\n",
       "   ('xe', 'I am very horny.'),\n",
       "   ('ex',\n",
       "    'Avukato rirovira karivaiparoe oisio ra varuavai aioreve oisio osia aue kokotu ora koie.'),\n",
       "   ('xp', 'Lapun man em i skirap tru long kaikai abus olsem kakaruk o pik.'),\n",
       "   ('xe',\n",
       "    'The old man had a big appetite to eat meat such as chicken or pig.'),\n",
       "   ('ex',\n",
       "    'Oirato kaakau rirovira karivaiparoe uvare riakova kaakau geesirevo ovusia kekira va toupaevo.'),\n",
       "   ('xp',\n",
       "    'Dok man em i skirap tru taim em i smelim dok meri taim em i gat sik mun.'),\n",
       "   ('xe',\n",
       "    'The male dog he was really horny because he smelled the female dog while she was in heat.')]),\n",
       " ('karivaito',\n",
       "  [('rt', 'karivai'),\n",
       "   ('ps', 'N'),\n",
       "   ('pt', 'MASC'),\n",
       "   ('ge', 'man who always desires sex'),\n",
       "   ('tkp', 'man bilong skirap'),\n",
       "   ('dt', '18/Nov/2006'),\n",
       "   ('ex', 'Era vuri osireito karivaito.'),\n",
       "   ('xp', 'Ai nogut ia man bilong sikirap long koap.'),\n",
       "   ('xe', 'The horny man has a bad eye.'),\n",
       "   ('ex',\n",
       "    'Oirato riro karivaito ira toeivoi uvare riakora-va vuri pitupitu purapareveira riro karivaitoa rutu.'),\n",
       "   ('xp',\n",
       "    'Man bilong skirap ol i katim em long wanem em i save mekim pasin nogut wantaim ol meri. Man bilong skirap tru.'),\n",
       "   ('xe',\n",
       "    'The very horny man, they cut him because he was always up to no good with the women, the big sex fiend.')]),\n",
       " ('karivara',\n",
       "  [('ps', 'N'),\n",
       "   ('pt', 'PN'),\n",
       "   ('ge', 'Buka'),\n",
       "   ('tkp', 'Buka'),\n",
       "   ('nt', 'name given to Buka area or Buka people by Rotokas'),\n",
       "   ('dt', '30/Oct/2005'),\n",
       "   ('ex', 'Avapaiei eisi-re Karivara-ia.'),\n",
       "   ('xp', 'Mipela go long Buka.'),\n",
       "   ('xe', 'We went to Buka.'),\n",
       "   ('ex',\n",
       "    'Vaisia vao-ia Rotokasipairara oa vateiva Bukapairara-pa oisio karivara.'),\n",
       "   ('xp', 'Nem ia ol Rotokas i bin givim long ol Buka olsem Karivara.'),\n",
       "   ('xe', 'The name that the Rotokas gave to the Buka is Karivara.')]),\n",
       " ('karo',\n",
       "  [('ps', 'V'),\n",
       "   ('pt', 'B'),\n",
       "   ('ge', 'spoon out a liquid'),\n",
       "   ('tkp', 'sipunim'),\n",
       "   ('dt', '30/Oct/2005'),\n",
       "   ('arg', 'O'),\n",
       "   ('vx', '2'),\n",
       "   ('ex', 'Uukoavai karori rerapa.'),\n",
       "   ('xp', '???'),\n",
       "   ('xe', 'Spoon out some water for him.'),\n",
       "   ('ex', 'Ukoa karo eva evoa rakapa tou.'),\n",
       "   ('xp', 'Yu kisim wara long dram.'),\n",
       "   ('xe', '???'),\n",
       "   ('ex',\n",
       "    'Ragai roviva karoavoi sipuru-ia tauo iare uvava vatapipavoi rara ogoera.'),\n",
       "   ('xp',\n",
       "    'Mi kapim sup long sipun i go long pleit long hap bai mi dringim bihain.'),\n",
       "   ('xe',\n",
       "    \"I am spooning the ??? with a spoon to the plate from which I'll drink later ???.\")]),\n",
       " ('karokaropo',\n",
       "  [('rt', 'karopo'),\n",
       "   ('ps', 'V'),\n",
       "   ('pt', 'B'),\n",
       "   ('ge', 'deal out'),\n",
       "   ('eng', 'deal out'),\n",
       "   ('eng', 'distribute'),\n",
       "   ('eng', 'send'),\n",
       "   ('tkp', 'tilim'),\n",
       "   ('ge', 'skelim'),\n",
       "   ('vx', '2'),\n",
       "   ('arg', 'O'),\n",
       "   ('dt', '30/Oct/2005'),\n",
       "   ('rdp', 'partial'),\n",
       "   ('ex', 'Rarasori vukuara karokaropoparevoi.'),\n",
       "   ('xp', 'Rarason em i tilim ol buk.'),\n",
       "   ('xe', 'Robinson is dealing out the books.'),\n",
       "   ('ex',\n",
       "    'Sipito oirara karokaroporevoi kovoara purasia uvare riroara kovoara oa iava vearovira voea karokaroporevoi kovoara rutu iare.'),\n",
       "   ('xp',\n",
       "    'Sip em i tilim ol man i go wokim ol wok bikos ol wok i planti olsem na em i tilim gut ol man i go long ol wok.'),\n",
       "   ('xe',\n",
       "    'The chief sent out the men to do work because there is a lot of work and therefore he send them all to the work.')]),\n",
       " ('karopato',\n",
       "  [('rt', 'karo'),\n",
       "   ('ps', 'N'),\n",
       "   ('pt', 'MASC'),\n",
       "   ('ge', 'spoon'),\n",
       "   ('tkp', 'spun'),\n",
       "   ('avm', 'pa_required'),\n",
       "   ('sc', 'INSTRUMENT'),\n",
       "   ('dt', '30/Oct/2005'),\n",
       "   ('ex',\n",
       "    'Sera Viki-re kerapoe, uriou karopatoa-va ra aio pitoka karoa ra va aiope.'),\n",
       "   ('xp',\n",
       "    'Sera em i singautim Viki, yu kam wantaim spun na bai mi spunim sospen kaikai bai yumi kaikai.'),\n",
       "   ('xe',\n",
       "    \"Sera called out to Viki, come with a spoon and I'll spoon the sauce pan and we'll eat.\")]),\n",
       " ('karopo',\n",
       "  [('ps', 'V'),\n",
       "   ('pt', 'B'),\n",
       "   ('ge', 'portion out'),\n",
       "   ('ge', 'divide up'),\n",
       "   ('tkp', '???'),\n",
       "   ('nt', 'Repeated action is marked by the reduplicated form karokaropo.'),\n",
       "   ('arg', 'O'),\n",
       "   ('vx', '2'),\n",
       "   ('dt', '18/Nov/2006'),\n",
       "   ('ex', 'Aioara karopori voea-pa.'),\n",
       "   ('xp', '???'),\n",
       "   ('xe', 'Divide up the food for them.'),\n",
       "   ('ex', 'Vitera kotokotoara karopoevoi.'),\n",
       "   ('xp', 'Vitera em i dilim aut ol kago.'),\n",
       "   ('xe', 'Vitera dealt out the cargo.'),\n",
       "   ('ex',\n",
       "    'Vitera vaio ora Jackie varoara karopoerevoi ora vairei vuruvuruia roia oisio ra vairei rutu vaeavira varoara-va toupaere.'),\n",
       "   ('xp',\n",
       "    'Vitera wantaim Jackie tupela i tilim ol laplap namel long tupela yet. Olsem bai tupela wantaim stap wantaim ol laplap.'),\n",
       "   ('xe', 'Vitera and Jackie ??? the clothes and ???.')]),\n",
       " ('karot',\n",
       "  [('ps', 'N'),\n",
       "   ('pt', 'NT'),\n",
       "   ('dx', 'Central'),\n",
       "   ('ge', 'carrot'),\n",
       "   ('tkp', 'carot'),\n",
       "   ('nt', 'Tok Pisin loan'),\n",
       "   ('dt', '18/Nov/2006'),\n",
       "   ('ex',\n",
       "    'Karotara ora iava rakariara turuevira toupaiveira orakesikesikevira oara aiopaiveira opopotepairara ora oisio kekepapeira osia upirikoara.'),\n",
       "   ('xp',\n",
       "    'Ol karot skin bilong ol i ret o ielo ol waitman i save kaikaim. Na i save luk olsem kaukau.'),\n",
       "   ('xe', '??? white people eat them and they resemble a sweet potato.')]),\n",
       " ('karoto',\n",
       "  [('rt', 'karo'),\n",
       "   ('ps', 'N'),\n",
       "   ('pt', 'NT'),\n",
       "   ('ge', 'rafters'),\n",
       "   ('tkp', 'sparen'),\n",
       "   ('dt', '15/Feb/2004')]),\n",
       " ('karova',\n",
       "  [('rt', 'karo'),\n",
       "   ('ps', 'N'),\n",
       "   ('pt', 'NT'),\n",
       "   ('ge', 'shelf'),\n",
       "   ('ge', 'table'),\n",
       "   ('tkp', 'tebol'),\n",
       "   ('dt', '18/Nov/2006'),\n",
       "   ('ex', 'Tauoara tovotovori evoa karova.'),\n",
       "   ('xp', 'Yu putim ol pelet long selv.'),\n",
       "   ('xe', 'Put the plates there on the shelf.'),\n",
       "   ('ex',\n",
       "    'Ririuto karova purare erako tovopasia. Ra vo karova-ia erakoara posiposipaive kuparetoa-ia ra vara-ia tuitui kasiave.'),\n",
       "   ('xp',\n",
       "    'Ririuto mekim bet bilong putim paia wut. Na long dispela bet bai ol paia wut i drai long simuk.'),\n",
       "   ('xe',\n",
       "    'Ririuto is making a shelf to put firewood. And on this shelf firewood would dry from smoke and they make fire from them.')]),\n",
       " ('karu',\n",
       "  [('ps', 'V'),\n",
       "   ('pt', 'B'),\n",
       "   ('ge', 'open'),\n",
       "   ('ge', 'unlock'),\n",
       "   ('ge', 'untie'),\n",
       "   ('ge', 'unhook'),\n",
       "   ('tkp', 'opim op'),\n",
       "   ('arg', 'O'),\n",
       "   ('vx', '2'),\n",
       "   ('cm', '???'),\n",
       "   ('cmt',\n",
       "    'I think that this verb takes -re case-marking. Also, it looks like the object follows the verb in the first example! Gotta look into this more.'),\n",
       "   ('dt', '30/May/2005'),\n",
       "   ('ex', 'Masta Kostro ira vao karu rovoreva Rotokas taere.'),\n",
       "   ('xp', '???'),\n",
       "   ('xe', 'Mr. Kostro opened up the Rotokas area initially.'),\n",
       "   ('ex', 'Samson rataoa karu.'),\n",
       "   ('xp', 'Samson, yu opim doa.'),\n",
       "   ('xe', 'Samson, open the door.')]),\n",
       " ('karuka',\n",
       "  [('ps', 'N'),\n",
       "   ('pt', 'FEM'),\n",
       "   ('ge', 'mat'),\n",
       "   ('tkp', 'mat'),\n",
       "   ('dt', '18/Nov/2006'),\n",
       "   ('ex', 'Karuka iria iava mat purapaveira riakora.'),\n",
       "   ('xp', 'Ol meri i save wokim mat long padanas.'),\n",
       "   ('xe', 'From the wild pandanus women make mats.'),\n",
       "   ('ex',\n",
       "    'Ragai karuka tokosia avaparai ra urupavavai puraa ra iria-ia uusipara.'),\n",
       "   ('xp',\n",
       "    'Mi go katim wail pandanats. Bai mi mekim wanpela mat bai mi save slip long wanpela.'),\n",
       "   ('xe', 'I am going to cut wild pandanus and make a mat and sleep on it.')]),\n",
       " ('karukaru',\n",
       "  [('rt', 'karu'),\n",
       "   ('ps', 'V'),\n",
       "   ('pt', 'B'),\n",
       "   ('rdp', 'full'),\n",
       "   ('ge', 'open'),\n",
       "   ('tkp', 'opim'),\n",
       "   ('nt', 'describes action done repeatedly or to many thing'),\n",
       "   ('arg', 'O'),\n",
       "   ('vx', '2'),\n",
       "   ('dt', '08/Jun/2005'),\n",
       "   ('ex', 'Ora vurevureoro oira karukarureva.'),\n",
       "   ('xp', '???'),\n",
       "   ('xe', 'Moving himself about, he opened up (his bindings).'),\n",
       "   ('ex', 'Pauro iroiro karukarurevoi uva koie avaoe.'),\n",
       "   ('xp', 'Pauro em i lusim rop na pik i go.'),\n",
       "   ('xe', 'Pauro loosened the rope and the pig got away.')]),\n",
       " ('karukava',\n",
       "  [('rt', 'karuka'),\n",
       "   ('ps', 'N'),\n",
       "   ('pt', '???'),\n",
       "   ('ge', 'rat'),\n",
       "   ('tkp', 'mumut'),\n",
       "   ('eng', 'type of large bush rat'),\n",
       "   ('dt', '18/Nov/2006'),\n",
       "   ('ex', 'Karukava riropava iria aiopaiveira oisio kekeva osia isike.'),\n",
       "   ('xp', 'Rat bilong bus ol i save kaikai, em i wankain olsem rat.'),\n",
       "   ('xe',\n",
       "    'The ??? is a large one which they eat, since it looks like a rat.')]),\n",
       " ('Karuru',\n",
       "  [('ps', 'N'),\n",
       "   ('pt', 'PN'),\n",
       "   ('dx', 'Central'),\n",
       "   ('ge', 'name'),\n",
       "   ('tkp', 'nem'),\n",
       "   ('eng', 'name'),\n",
       "   ('ig', 'yes'),\n",
       "   ('dt', '15/Feb/2007')]),\n",
       " ('karutu',\n",
       "  [('ps', 'V'),\n",
       "   ('pt', 'B'),\n",
       "   ('ge', 'divide up'),\n",
       "   ('ge', 'portion out'),\n",
       "   ('tkp', 'tilim'),\n",
       "   ('arg', 'O'),\n",
       "   ('vx', '2'),\n",
       "   ('dt', '30/Oct/2005'),\n",
       "   ('ex', 'Moniara rutu karukaruturi.'),\n",
       "   ('xp', '???'),\n",
       "   ('xe', 'Divide up all of the money.'),\n",
       "   ('ex', 'Mak, e monia karuturivo.'),\n",
       "   ('xp', 'Mak, yu hapim moni.'),\n",
       "   ('xe', 'Mark, divide up the money.'),\n",
       "   ('ex',\n",
       "    'Ravereto voriara karutere uva oaravu vatatoporevoi oarava ava pa eisi-re Buka-ia kotokoto vorisia ari oaravu kavuparevoi kakau orisia vo atoia.'),\n",
       "   ('xp',\n",
       "    'Ravereto em i tilim ol mani na em i redim narapela bai em i go baem kago long Buka na bai em i lusim narapela bilong baem kakau long ples.'),\n",
       "   ('xe', '???')]),\n",
       " ('karuvira',\n",
       "  [('alt', 'karupavira'),\n",
       "   ('rt', 'karu'),\n",
       "   ('ps', 'ADV'),\n",
       "   ('pt', 'MANNER'),\n",
       "   ('ge', 'open'),\n",
       "   ('tkp', 'olsem op'),\n",
       "   ('dt', '28/Aug/2005'),\n",
       "   ('ex', 'Rataoa karuvira toupai kepa-ia.'),\n",
       "   ('xp', 'Doa i op i stap long haus.'),\n",
       "   ('xe', 'The door on the house is open.')]),\n",
       " ('kasi',\n",
       "  [('ps', 'V'),\n",
       "   ('pt', 'A'),\n",
       "   ('ge', 'build.fire'),\n",
       "   ('eng', 'start a fire'),\n",
       "   ('eng', 'make a fire'),\n",
       "   ('tkp', 'boinim'),\n",
       "   ('vx', '1'),\n",
       "   ('sc', '???'),\n",
       "   ('dcpv', 'true'),\n",
       "   ('cmt', 'Is it kasi or eto kasi?'),\n",
       "   ('dt', '13/Nov/2005'),\n",
       "   ('ex', 'Oire eto kasiaepa, oripaaepa.'),\n",
       "   ('xp', '???'),\n",
       "   ('xe', 'They built a fire and cooked.'),\n",
       "   ('ex',\n",
       "    'Aakova avaoe kovoa iare kepa tupaoro oa iava oira varaaro varoara kasipiro.'),\n",
       "   ('xp',\n",
       "    'Mam em i pasim doa na go long gaden olsem na ol laplap bilong em i paia.'),\n",
       "   ('xe',\n",
       "    'Mother went to work, closing up the house, and her clothes burned.')]),\n",
       " ('kasi',\n",
       "  [('ps', 'N'),\n",
       "   ('pt', '???'),\n",
       "   ('ge', 'fire'),\n",
       "   ('tkp', 'paia'),\n",
       "   ('dt', '18/Nov/2006'),\n",
       "   ('ex', 'Tom, etokasi kasi araisi orisia.'),\n",
       "   ('xp', 'Tom yu wokim paia na kukim rais.'),\n",
       "   ('xe', 'Tom, start a fire in order to cook rice.'),\n",
       "   ('ex',\n",
       "    'Tuituia kasi purapaavoi ra rirovira vuvuve ra vo kasi-ia ito pitoka oria.'),\n",
       "   ('xp', 'Bai mi laitim bai i lait bai mi kukim sospen banana.'),\n",
       "   ('xe',\n",
       "    \"I'll make a fire so that it burns and I'll cook a saucepan of bananas on the fire.\")]),\n",
       " ('kasi',\n",
       "  [('ps', 'V'),\n",
       "   ('pt', 'B'),\n",
       "   ('ge', 'burn'),\n",
       "   ('tkp', 'boinim'),\n",
       "   ('vx', '2'),\n",
       "   ('arg', 'O'),\n",
       "   ('dt', '08/Dec/2005'),\n",
       "   ('ex',\n",
       "    'Pita kepa kasirevora tuituia-ia uva auero rutu kasipirora kepa sovaraia.'),\n",
       "   ('xp',\n",
       "    'Pita i bin paiaim haus long paia. Na olgeta samting i bin paia insait long haus.'),\n",
       "   ('xe',\n",
       "    'Peter burnt the house with fire and everything burned inside of the house.'),\n",
       "   ('ex', 'Kepa kasirevo Veruve eisi Rarova.'),\n",
       "   ('xp', 'Veruve em i bin paiaim haus long Rarova.'),\n",
       "   ('xe', 'Veruve burned down a house in Rarova.')]),\n",
       " ('kasiarao',\n",
       "  [('ps', 'N'),\n",
       "   ('pt', 'FEM'),\n",
       "   ('ge', 'limbum'),\n",
       "   ('tkp', '???'),\n",
       "   ('nt', \"large leaf variety, used for making pakou 'fighting ???\"),\n",
       "   ('cmt', 'Double-check original ex. sentence (from Timothy).'),\n",
       "   ('dt', '30/Oct/2005'),\n",
       "   ('alt', 'kasarao'),\n",
       "   ('ex', 'Kasarao kaku puraveira upo purapasia oreke.'),\n",
       "   ('xp', 'Kasarao limbum blong wokim pako blong part.'),\n",
       "   ('xe', '???'),\n",
       "   ('ex', 'Kasiarao iria tatupaiveira auere uru purapasia vo keparaia.'),\n",
       "   ('xp', 'Limbum ol i save paitim bilong wokim poloa long haus.'),\n",
       "   ('xe', '???'),\n",
       "   ('ex',\n",
       "    'Kasiarao iria govukoaro tekapaiveira kakuara purapasia auere upo purapasia.'),\n",
       "   ('xp',\n",
       "    'Wuel limbum ol save sarim namel bilong em bilong wokim pako bilong pait.'),\n",
       "   ('xe', '???')]),\n",
       " ('kasiava',\n",
       "  [('ps', 'N'),\n",
       "   ('pt', 'MASC'),\n",
       "   ('ge', 'tree'),\n",
       "   ('tkp', 'diwai bilong wokim ???'),\n",
       "   ('eng', 'Milkwood (Alstonia scholaris)'),\n",
       "   ('nt', 'Used for making canoes. This type of tree is also used to be ???'),\n",
       "   ('dt', '30/Oct/2005'),\n",
       "   ('ex', 'Kasiava opuru purapaveira vars avakava kepa paupasia.'),\n",
       "   ('xp', 'Kasiava tree blong workim canoes na house.'),\n",
       "   ('xe', '???'),\n",
       "   ('ex',\n",
       "    'Kasiava ira sovara riroa ukoa toupaiveira oisio kekevira osia roroa. Uva va iava eva evaova opuruara purapaiveira oraauero kepaara.'),\n",
       "   ('xp',\n",
       "    'Diwai kanu insait bilong em i gat bikpela wara insait em. Wara i save stap insait i luk olsem susu.'),\n",
       "   ('xe', '???')]),\n",
       " ('kasikasi',\n",
       "  [('rt', 'kasi'),\n",
       "   ('ps', 'V'),\n",
       "   ('pt', 'A'),\n",
       "   ('rdp', 'full'),\n",
       "   ('ge', 'angry'),\n",
       "   ('tkp', 'kros'),\n",
       "   ('tkp', 'bel i hat'),\n",
       "   ('eng', 'cross'),\n",
       "   ('eng', 'angry'),\n",
       "   ('eng', 'difficult'),\n",
       "   ('eng', 'diligent'),\n",
       "   ('vx', '1'),\n",
       "   ('sc', 'EMOTION'),\n",
       "   ('cmt', 'Is the 2nd sentence lacking conjugation?'),\n",
       "   ('dt', '30/Oct/2005'),\n",
       "   ('ex', 'Vii kasikasiu.'),\n",
       "   ('xp', 'Yu kros.'),\n",
       "   ('xe', \"You're angry.\"),\n",
       "   ('ex', 'Oirato kasikasi uva upo pura.'),\n",
       "   ('xp', 'Man i kros na em i pait.'),\n",
       "   ('xe', 'The man was angry and wanted to fight.'),\n",
       "   ('ex', 'Auro, kasikasirai, ari oravatatopou.'),\n",
       "   ('xp', 'Hei, yu lukaut, mi kros nau.'),\n",
       "   ('xe', \"Hey, I'm mad, so be prepared.\"),\n",
       "   ('ex',\n",
       "    'Vii kasikasiuei ikauvira osia viapau reoreoara iava vii tavipaavoi.'),\n",
       "   ('xp', 'Yu bel hat kuik taim mi no tokim yu yet long ol toktok.'),\n",
       "   ('xe', \"You get angry quickly when I don't tell you about the words.\")]),\n",
       " ('Kasikasiua',\n",
       "  [('ps', 'N'),\n",
       "   ('pt', 'PN'),\n",
       "   ('ge', 'name'),\n",
       "   ('tkp', 'name'),\n",
       "   ('cmt',\n",
       "    \"Is this a place name? Where is it? And what's up with rara in the example?\"),\n",
       "   ('dt', '12/Feb/2005'),\n",
       "   ('ex',\n",
       "    'Kasikasiua uva oisioa oirara rarearo tovopaive rara voea kasirovopaive.'),\n",
       "   ('xp',\n",
       "    'Ples we ol i save putim bun bilong ol man taim ol i kukim ol pastaim long paia.'),\n",
       "   ('xe', 'Kasikasiua is where they put the bones of people ??? burn them.')]),\n",
       " ('kasipie',\n",
       "  [('rt', 'kasi'),\n",
       "   ('ps', 'V'),\n",
       "   ('pt', 'B'),\n",
       "   ('ge', 'care for'),\n",
       "   ('tkp', 'lukautim'),\n",
       "   ('vx', '2'),\n",
       "   ('arg', 'O'),\n",
       "   ('cmt', 'Is this derived from kasi? Check vowel length.'),\n",
       "   ('dt', '15/Nov/2005'),\n",
       "   ('ex', 'Voea vearovira kasipiepaive.'),\n",
       "   ('xp', 'Ol i lukautim ol gut.'),\n",
       "   ('xe', 'They would diligently care for them.'),\n",
       "   ('ex', 'Kakaevure kasipieparivere.'),\n",
       "   ('xp', 'Bai yu lukautim gut ol pikinini.'),\n",
       "   ('xe', 'You will take care of the children.'),\n",
       "   ('ex',\n",
       "    'Ovoteivi kasipievira o kovo rovu rutu purapaeveira vo vokiro rutu-ia. Viapau uveipaoi ra o kovovu-re ovauo vara rutu rugopaevere vara purapaoro.'),\n",
       "   ('xp',\n",
       "    'Ovoteivi em i save wokim olgeta wok. Em i inap lus tingim wanpela wok em i mas tingting na wokim olgeta wok.'),\n",
       "   ('xe', '???'),\n",
       "   ('ex',\n",
       "    'Aiteto kakaeto kasipieparevo teapi kovero riku-ia uvare kepa ruvara-ia toupaevoi.'),\n",
       "   ('xp',\n",
       "    'Papa i lukluk gut long pikinini nogut em i pundaon long hul bikos hul em i stap klostu long haus.'),\n",
       "   ('xe',\n",
       "    'Father looked out for the child lest he fell down in the hole because it is close to the house.'),\n",
       "   ('ex', 'Ragai kasipievira rutu evaova tokiava uva riroepa vearopievira.'),\n",
       "   ('xp', 'Mi bin lukautim gut diwai na em i gro gut.'),\n",
       "   ('xe', '???')]),\n",
       " ('kasipu',\n",
       "  [('ps', 'V'),\n",
       "   ('pt', 'A'),\n",
       "   ('ge', 'angry'),\n",
       "   ('eng', 'angry'),\n",
       "   ('eng', 'cross'),\n",
       "   ('eng', 'pissed off'),\n",
       "   ('tkp', 'kros'),\n",
       "   ('tkp', 'bel i hat'),\n",
       "   ('dcsv', 'true'),\n",
       "   ('cm', '-re'),\n",
       "   ('vx', '2'),\n",
       "   ('arg', 'OBL'),\n",
       "   ('sc', 'EMOTION'),\n",
       "   ('cmt', 'Is this related to <kasi>'),\n",
       "   ('dt', '30/Oct/2005'),\n",
       "   ('ex', 'Ragai kasipurai.'),\n",
       "   ('xp', 'Mi kros.'),\n",
       "   ('xe', \"I'm angry.\"),\n",
       "   ('ex', 'Evo reoreo uvuragapaoro kasipupaopa.'),\n",
       "   ('xp', '???'),\n",
       "   ('xe', 'Not paying attention to those words she was angry.'),\n",
       "   ('ex', 'Areipiri kasipu oirara-re ora riakora.'),\n",
       "   ('xp', 'Areipiri em i kros long ol man na meri.'),\n",
       "   ('xe', 'Areipiri is angry at the men and women.'),\n",
       "   ('ex',\n",
       "    'Areipiri oirara-re kasipu uvare viapau ikauvira urioae osia vero gaurevo kovo ousia.'),\n",
       "   ('xp',\n",
       "    'Areipiri em i koros long man na meri bikos ol i no kam kuik taim belo i krai bilong kisim wok.'),\n",
       "   ('xe',\n",
       "    \"Areipiri is angry at people because they didn't come quickly when he cried [vero???] to get work.\")]),\n",
       " ('kasipupie',\n",
       "  [('rt', 'kasipu'),\n",
       "   ('ps', 'V'),\n",
       "   ('pt', 'B'),\n",
       "   ('ge', 'anger'),\n",
       "   ('eng', 'anger'),\n",
       "   ('eng', 'enrage'),\n",
       "   ('tkp', 'mekim kros'),\n",
       "   ('vx', '2'),\n",
       "   ('arg', 'O'),\n",
       "   ('dt', '30/Oct/2005'),\n",
       "   ('ex', 'Teapi rera kasipupieive orareoreopaoro.'),\n",
       "   ('xp', '???'),\n",
       "   ('xe', \"Don't make him angry talking among yourselves.\"),\n",
       "   ('ex', 'Ae, visii ragai kasipupietavoi.'),\n",
       "   ('xp', 'Hei, yupela i mekim mi kros.'),\n",
       "   ('xe', 'Hey, you guys are making me angry.'),\n",
       "   ('ex',\n",
       "    'Viapau oisio ra Vavaviri kasipupiepata. Teapi vigei uporeve rara kasipuro eva-pa oa aiotavo rera varo vaviokoa.'),\n",
       "   ('xp',\n",
       "    'No ken mekim koros Vavaviri. Nogut em i paitim yumi long dispela popo bilong em yupela i kaikaim.'),\n",
       "   ('xe', \"Don't anger Vavaviri. ???.\")]),\n",
       " ('kasipuvira',\n",
       "  [('alt', 'kasipupavira'),\n",
       "   ('rt', 'kasipu'),\n",
       "   ('ps', 'ADV'),\n",
       "   ('pt', 'MANNER'),\n",
       "   ('ge', 'sharp flavor'),\n",
       "   ('ge', 'angrily'),\n",
       "   ('tkp', '???'),\n",
       "   ('dt', '28/Aug/2005'),\n",
       "   ('ex', 'Sipeipai kasipuvira.'),\n",
       "   ('xp', '???'),\n",
       "   ('xe', 'It has a sharp flavor.'),\n",
       "   ('ex', 'Kasipuvira rutu toupae.'),\n",
       "   ('xp', 'Em i kros nogut tru.'),\n",
       "   ('xe', 'He is really angry.'),\n",
       "   ('ex', 'Era ita kasipuvira rutu toupare.'),\n",
       "   ('xp', 'Man ia kros nogut tru na i stap.'),\n",
       "   ('xe', 'He is very angry.')]),\n",
       " ('kasirao',\n",
       "  [('rt', 'kasi'),\n",
       "   ('ps', 'V'),\n",
       "   ('pt', 'A'),\n",
       "   ('ge', 'hot'),\n",
       "   ('eng', 'hot'),\n",
       "   ('tkp', 'hot'),\n",
       "   ('vx', '1'),\n",
       "   ('sc', '???'),\n",
       "   ('cmt', 'Not clear whether this is distinct sense or lexicalized or what.'),\n",
       "   ('dt', '13/Nov/2005'),\n",
       "   ('ex', 'Siori rirovira kasiraoroi uvare rirovira upiaparoi.'),\n",
       "   ('xp', 'Jon em i skin hot nogut tru bikos em i sik nogut tru.'),\n",
       "   ('xe', 'John is really hot because he is really sick.')]),\n",
       " ('kasiraopie',\n",
       "  [('rt', 'kasi'),\n",
       "   ('ps', 'V'),\n",
       "   ('pt', 'B'),\n",
       "   ('ge', 'heat up'),\n",
       "   ('ge', 'make hot'),\n",
       "   ('tkp', 'hatim'),\n",
       "   ('vx', '2'),\n",
       "   ('arg', 'O'),\n",
       "   ('cmt',\n",
       "    'Not sure whether kasirao is really a separate stem. It seems -pie has some freedom of movement, occuring either before or after -pie.'),\n",
       "   ('dt', '24/Aug/2005'),\n",
       "   ('ex', 'Uukoo kasiraopie aioa kasiraopie ra va aiori.'),\n",
       "   ('xp', 'Hotim wara na kaikai bai yu kaikai.'),\n",
       "   ('xe', '???'),\n",
       "   ('ex', 'Aio kuro ro kasiraopieri, Dokas.'),\n",
       "   ('xp', 'Dokas, yu hotim ol hap kaikai.'),\n",
       "   ('xe', 'Dokas, heat up the leftovers.'),\n",
       "   ('ex', 'Ukoo rovu kasiraopie etokasi-ia.'),\n",
       "   ('xp', 'Yu hotim wara long paia.'),\n",
       "   ('xe', 'Heat up the water on the fire.')]),\n",
       " ('kasiraovira',\n",
       "  [('alt', 'kasiraopavira'),\n",
       "   ('rt', 'kasirao'),\n",
       "   ('ps', 'ADV'),\n",
       "   ('pt', 'MANNER'),\n",
       "   ('ge', 'hot'),\n",
       "   ('ge', 'energetically'),\n",
       "   ('ge', 'diligently'),\n",
       "   ('tkp', '???'),\n",
       "   ('dt', '13/Nov/2005'),\n",
       "   ('ex', 'Kasiraovira toupaivoi voia.'),\n",
       "   ('xp', 'Em i hot tumas long hia.'),\n",
       "   ('xe', \"It's too hot here.\"),\n",
       "   ('ex', 'Kasiraovi kovopaiovoi.'),\n",
       "   ('xp', 'Mipela work hat tu.'),\n",
       "   ('xe', \"We're working hard.\"),\n",
       "   ('ex', 'Kasiraovira kovopaavoi.'),\n",
       "   ('xp', 'Mi wok hat tru.'),\n",
       "   ('xe', 'I am working very hard.'),\n",
       "   ('ex',\n",
       "    'Vakora-ia riro kasiraovira toupaiveira oa iava oirara voa-pa reasipaveira voa toupaarapa.'),\n",
       "   ('xp',\n",
       "    'Wakunai em i ples hot tru olsem na ol man i save les long stap long hap.'),\n",
       "   ('xe',\n",
       "    \"In Wakunai it is very hot and therefore people don't want to be there.\"),\n",
       "   ('ex', 'Kasiraovira uusirae vokiaro, viapau rirovira uteopae.'),\n",
       "   ('xp',\n",
       "    'Las nait mi silip hot long nait bikos i no gat bikpela kol tumas long nait.'),\n",
       "   ('xe',\n",
       "    \"Last night it was really hot sleeping because it wasn't very cold.\")]),\n",
       " ('kasiu',\n",
       "  [('ps', 'N'),\n",
       "   ('pt', '???'),\n",
       "   ('ge', 'cassowary'),\n",
       "   ('tkp', '???'),\n",
       "   ('nt', 'Tok Pisin loan'),\n",
       "   ('ig', 'yes'),\n",
       "   ('dt', '15/Sep/2004')]),\n",
       " ('kasiura',\n",
       "  [('ps', 'N'),\n",
       "   ('pt', 'NT'),\n",
       "   ('ge', 'fence'),\n",
       "   ('tkp', 'banis'),\n",
       "   ('cmt', 'Need a full sentence.'),\n",
       "   ('dt', '30/Oct/2005'),\n",
       "   ('ex', 'Kasiura auere koie kare.'),\n",
       "   ('xp', 'Banis bilong ol pik.'),\n",
       "   ('xe', '???'),\n",
       "   ('ex',\n",
       "    'Kasiura iria purapaiveira koie kare tovopasia ra viapau ratau aio kovoro aiopaive rara kasiura sovaraia toupaive.'),\n",
       "   ('xp',\n",
       "    'Banis ol i save mekim bilong putim ol pik insait long em na bai ol i no ken kaikaim ol gaden autsait taim ol i stap insait long banis.'),\n",
       "   ('xe', '???')]),\n",
       " ('kasivari',\n",
       "  [('ps', 'V'),\n",
       "   ('pt', 'A'),\n",
       "   ('ge', 'scavenge'),\n",
       "   ('ge', 'be diligent'),\n",
       "   ('tkp', 'mumutim'),\n",
       "   ('tkp', 'paipainim'),\n",
       "   ('tkp', 'kiskisim'),\n",
       "   ('vx', '???'),\n",
       "   ('cmt', 'Is this also a name? Need better examples.'),\n",
       "   ('dt', '22/Nov/2005'),\n",
       "   ('ex', 'Kasivari vorouto vovouva riakova.'),\n",
       "   ('xp', '???'),\n",
       "   ('xe', '???')]),\n",
       " ('kasuari',\n",
       "  [('ps', 'N'),\n",
       "   ('pt', 'MASC'),\n",
       "   ('ge', 'cassowary'),\n",
       "   ('tkp', 'muruk'),\n",
       "   ('nt', 'Tok Pisin loan'),\n",
       "   ('ig', 'yes'),\n",
       "   ('dt', '05/Feb/2005'),\n",
       "   ('ex', 'Ira oiso toupareveira osa kokai. Viapau vo toupare vo.'),\n",
       "   ('xp', 'Em I save luk olsem kakaruk. Em i no save i stap long hia.'),\n",
       "   ('xe', \"It looks like a rooster. It doesn't live here.\"),\n",
       "   ('ex',\n",
       "    'Kasiuari ira oisio toupare osia kokai uva eisi toupareveira turue vego.'),\n",
       "   ('xp', 'Kasiowari em i olsem kakaruk na em i stap long highlands.'),\n",
       "   ('xe', 'The cassowary is like a rooster and lives in the highlands.')]),\n",
       " ('kata',\n",
       "  [('ps', 'V'),\n",
       "   ('pt', 'B'),\n",
       "   ('ge', 'exhaust'),\n",
       "   ('tkp', 'skin dai'),\n",
       "   ('dcpv', 'true'),\n",
       "   ('vx', '2'),\n",
       "   ('arg', 'O'),\n",
       "   ('dt', '31/Jan/2007'),\n",
       "   ('cmt', 'Need an example without -piro'),\n",
       "   ('ex', 'Ragai iava varaua katapiro uvare riro kaekaevira vokaavo.'),\n",
       "   ('xp', 'Skin bilong mi i dai bikos mi wakabaut longwe hap.'),\n",
       "   ('xe', 'My skin was exhausted because I walked a long way.'),\n",
       "   ('ex',\n",
       "    'Kakaeto Tovariri katarevoi uvare kakaeto kaepaoro kareroe riro kaekae tapi-va uva varaua katarevoi uvare riro vavatatoa kakaeto.'),\n",
       "   ('xp',\n",
       "    'Pikinini mekim Tovariri skin dai bikos em i wok long karim pikinini i kam longwe hap na em i skin dai bikos pikinini i hevi tumas..'),\n",
       "   ('xe',\n",
       "    'The boy exhausted Tovariri because he was carrying the boy from a far away place and his it exhausted his body because he was a heavy boy.')]),\n",
       " ('katai',\n",
       "  [('ps', 'NUM'),\n",
       "   ('ge', 'one'),\n",
       "   ('tkp', 'wan'),\n",
       "   ('tkp', 'wanpela'),\n",
       "   ('dt', '15/Sep/2004'),\n",
       "   ('ex', 'Vieia rovoaroa vaoia katai.'),\n",
       "   ('xp', 'Stat bilong kauntim em i wan.'),\n",
       "   ('xe', 'Counting starts with one.')]),\n",
       " ('kataitoarei',\n",
       "  [('rt', 'katai'),\n",
       "   ('ps', 'N'),\n",
       "   ('pt', 'MASC'),\n",
       "   ('ge', 'two small things'),\n",
       "   ('ge', 'limited to two only'),\n",
       "   ('tkp', '???'),\n",
       "   ('dt', '12/Feb/2005'),\n",
       "   ('ex', 'Kataitoareivi raga kokai vaio aiterea ouavo.'),\n",
       "   ('xp', 'Mi kisim tupela kakaruk tasol.'),\n",
       "   ('xe', 'I only got two little chickens.')]),\n",
       " ('katakatai',\n",
       "  [('ps', '???'),\n",
       "   ('dx', 'Central'),\n",
       "   ('ge', 'one.by.one'),\n",
       "   ('tkp', 'wanwan'),\n",
       "   ('eng', 'one by one'),\n",
       "   ('eng', 'individually'),\n",
       "   ('dt', '13/Nov/2005'),\n",
       "   ('ex', 'Katakatai kovoro iare avapata voa kovosia visii rutu.'),\n",
       "   ('xp', 'Bai yupela olgeta bai go wok long wanwan gaden.'),\n",
       "   ('xe', '???')]),\n",
       " ('katakataivira',\n",
       "  [('rt', 'katakatai'),\n",
       "   ('ps', 'ADV'),\n",
       "   ('pt', 'MANNER'),\n",
       "   ('ge', 'individually'),\n",
       "   ('eng', 'individually'),\n",
       "   ('eng', 'one by one'),\n",
       "   ('eng', 'separately'),\n",
       "   ('tkp', 'wanwan'),\n",
       "   ('dt', '13/Nov/2005'),\n",
       "   ('ex', 'Katakataipavira erako kaeuoro karepatai visi rutu vo-re kepa.'),\n",
       "   ('xp', 'Yupela olgeta bai karim wanwan paia wut go long haus.'),\n",
       "   ('xe', '???'),\n",
       "   ('ex', 'Katakataivira toupa vo keparaia - usipata - kovopata ikaupata.'),\n",
       "   ('xp', 'Istap wanwan tong all dispela house sleep wonwon work wonwon.'),\n",
       "   ('xe', '???'),\n",
       "   ('ex', 'Visii rutu katakataivira uriopatavere.'),\n",
       "   ('xp', 'Yupela olgeta bai yupela kam wanwan.'),\n",
       "   ('xe', 'All of you come individually.'),\n",
       "   ('ex', 'Katakataivira voia roopierivere aue-ia kovoara ra vara puraive.'),\n",
       "   ('xp', 'Bai yu givim ol wanwan long ol wok na bai ol i wokim.'),\n",
       "   ('xe', 'Give everyone their work they will do it.'),\n",
       "   ('ex',\n",
       "    'Oirara katakataivira paupae paupara-ia uvare kepa aitearo voea-re keeraroe aiosia rera vo kepaaro-ia.'),\n",
       "   ('xp',\n",
       "    'Ol man i sindaon wanwan long ol chia bikos papa bilong em em i singautim ol long kaikai long haus bilong em.'),\n",
       "   ('xe',\n",
       "    'The men came one by one to the chairs because the head of the house called out for them to eat at his house.')]),\n",
       " ('kataraua',\n",
       "  [('rt', 'katarau'),\n",
       "   ('ps', '???'),\n",
       "   ('ge', 'chest'),\n",
       "   ('ge', 'ribs'),\n",
       "   ('ge', 'sternum'),\n",
       "   ('tkp', 'brus'),\n",
       "   ('tkp', 'banis'),\n",
       "   ('dt', '30/Oct/2005'),\n",
       "   ('ex', 'Viava kataraua vagaiava karaua upopai.'),\n",
       "   ('xp', '???'),\n",
       "   ('xe', '???')]),\n",
       " ('katarauto',\n",
       "  [('rt', 'katarau'),\n",
       "   ('ps', 'N'),\n",
       "   ('pt', 'MASC'),\n",
       "   ('ge', 'chest'),\n",
       "   ('ge', 'rib'),\n",
       "   ('ge', 'sternum'),\n",
       "   ('tkp', 'bros'),\n",
       "   ('dt', '30/Oct/2005'),\n",
       "   ('ex', 'Katarauto Luke iava upiaparoi.'),\n",
       "   ('xp', 'Banis bun bilong Luke i pen.'),\n",
       "   ('xe', \"Luke's ribs hurt.\"),\n",
       "   ('ex', 'Katarauto ira kasiuravira toupareveira vovou isi-re.'),\n",
       "   ('xp', 'Bros i save stap olsem banis bilong hat.'),\n",
       "   ('xe', 'The chest fences in the heart.')]),\n",
       " ('katavira',\n",
       "  [('alt', 'katapavira'),\n",
       "   ('rt', 'kata'),\n",
       "   ('ps', 'ADV'),\n",
       "   ('pt', 'MANNER'),\n",
       "   ('ge', 'mashed and mixed together'),\n",
       "   ('tkp', 'malumalum'),\n",
       "   ('tkp', 'meme'),\n",
       "   ('cmt', 'Check vowel length. What is adv modifying in example?'),\n",
       "   ('dt', '30/Oct/2005'),\n",
       "   ('ex', 'Kataavira aiopapi vo aio.'),\n",
       "   ('xp', '???'),\n",
       "   ('xe', '???'),\n",
       "   ('ex', 'Katavira kakaeto aiopieri.'),\n",
       "   ('xp', 'Yu simasim pastaim na givim long pikinini.'),\n",
       "   ('xe', 'Feed it to the children mashed up.'),\n",
       "   ('ex',\n",
       "    'Arais katavira aiopaoe uvare Pide rirovira uuko tovoroe oa iava katavira aiopaovi araisara ragai gisipoaro-ia votopai uvare katavira orioviro riroa-ia ukoa.'),\n",
       "   ('xp',\n",
       "    'Rais i kaikai olsem malumalu bikos Fide em i putim bikpela wara. Olsem na rais i kaikai olsem malumalum rais i pas long maus bilong mi. Bikos em i ??? long bikpela wara.'),\n",
       "   ('xe', '???')]),\n",
       " ('katokato',\n",
       "  [('rt', 'kato'),\n",
       "   ('ps', 'N'),\n",
       "   ('pt', '???'),\n",
       "   ('rdp', 'full'),\n",
       "   ('ge', 'black'),\n",
       "   ('ge', 'filthy'),\n",
       "   ('tkp', 'blak'),\n",
       "   ('tkp', 'doti'),\n",
       "   ('dt', '30/Oct/2005'),\n",
       "   ('ex', 'Bogenvilpairara katokatoirara.'),\n",
       "   ('xp', 'Ol lain bilong Bogenvil ol i blak.'),\n",
       "   ('xe', 'Bougainvilleans are black.'),\n",
       "   ('ex',\n",
       "    'Kepara rutu katokatopapeira rara kupareto vara katokatopiepareve katokatoirara voeao votoko iava Bogenvil.'),\n",
       "   ('xp',\n",
       "    'Olgeta haus smuk i save mekim blak. Ol blak man ol i bilong dispela ailan Bogenvil.'),\n",
       "   ('xe', '???')]),\n",
       " ('katokatoto',\n",
       "  [('rt', 'katokato'),\n",
       "   ('ps', 'N'),\n",
       "   ('pt', 'HUM'),\n",
       "   ('ge', 'black person'),\n",
       "   ('ge', 'negro'),\n",
       "   ('tkp', 'netif'),\n",
       "   ('dt', '30/Oct/2005'),\n",
       "   ('ex', 'Oirato katokatoto.'),\n",
       "   ('xp', 'Black man.'),\n",
       "   ('xe', 'Blakman.'),\n",
       "   ('ex', 'Ragai katokatoto.'),\n",
       "   ('xp', 'Mi blakman.'),\n",
       "   ('xe', \"I'm a black man.\"),\n",
       "   ('ex', 'Igeia katokatoirara ora apirikapairara.'),\n",
       "   ('xp', 'Mipela wantaim ol Apirika i blak.'),\n",
       "   ('xe', '???'),\n",
       "   ('ex',\n",
       "    'P. Ona katokatoto ira votoko-ia upoa rovoreva aue-pa rasia uvare popotepai rara vo rasi eriiva oa iava upoa rovoepa.'),\n",
       "   ('xp',\n",
       "    'P. Ona em i blak man. Long dispela ailan em i bin statim pait long graun bikos ol waitman i bin digim ol dispela graun olsem na pait i bin stat.'),\n",
       "   ('xe', '???')]),\n",
       " ('katokatovira',\n",
       "  [('alt', 'katokatopavira'),\n",
       "   ('rt', 'katokato'),\n",
       "   ('ps', 'ADV'),\n",
       "   ('pt', 'MANNER'),\n",
       "   ('ge', 'black-like'),\n",
       "   ('ge', 'dirty'),\n",
       "   ('tkp', 'blak'),\n",
       "   ('dt', '30/Oct/2005'),\n",
       "   ('ex', 'Katokatovira kekepi.'),\n",
       "   ('xp', 'Em i luk black.'),\n",
       "   ('xe', 'It looks black.'),\n",
       "   ('ex', 'Katokatovira paruvoi uukovi.'),\n",
       "   ('xp', 'Wara i blak nau.'),\n",
       "   ('xe', 'The river is flowing black now.'),\n",
       "   ('ex',\n",
       "    'Revasiva katokatovira kekepaoviro oiratoa iava uvare rera vavaearo toeivo torara-ia.'),\n",
       "   ('xp',\n",
       "    'Blut bilong man i luk olsem blakpela bikos ol i katim han bilong em.'),\n",
       "   ('xe',\n",
       "    'The blood of the man looked black because they cut his hand with an axe.')]),\n",
       " ('katokoi',\n",
       "  [('ps', 'N'),\n",
       "   ('pt', 'FEM'),\n",
       "   ('ge', 'strip of limbum used for sago leaf shingle'),\n",
       "   ('tkp', '???'),\n",
       "   ('nt', 'The sago leaves are folded over and fastened onto the strip.'),\n",
       "   ('dt', '30/Oct/2005'),\n",
       "   ('ex', 'Katokoi-ia tetevua turari vii.'),\n",
       "   ('xp', 'Yu samapim saksak long limbun.'),\n",
       "   ('xe', 'Sew up the sago with limbum.'),\n",
       "   ('ex', 'Asia, uriou katokoi vatesia ra oira-ia tetevuara turaa.'),\n",
       "   ('xp',\n",
       "    'Asia, yu kam wantaim stik bilong samapim saksak bai mi samapim saksak long em.'),\n",
       "   ('xe', '???')]),\n",
       " ('katopato',\n",
       "  [('rt', 'kato'),\n",
       "   ('ps', 'N'),\n",
       "   ('pt', 'HUM'),\n",
       "   ('ge', 'skin-and-bones'),\n",
       "   ('tkp', '???'),\n",
       "   ('eng', 'skinny person'),\n",
       "   ('eng', 'thin person'),\n",
       "   ('eng', 'bony animal'),\n",
       "   ('nt', 'Insulting when applied to humans. Otherwise used for animals.'),\n",
       "   ('dt', '30/Oct/2005'),\n",
       "   ('ex', 'Kaakau era katopato.'),\n",
       "   ('xp', 'Dok hia em i bun nating.'),\n",
       "   ('xe', 'This dog is skin-and-bones.'),\n",
       "   ('ex',\n",
       "    'Katopato oirato ira raga-ia puterevo ovusia pauuparae raivaro. Ragai rera vurapaavo rirovira uvare katopatoa raga viapau varu aravai rera varaaro-ia uvare riro kaekaevira upiaroepa oa iava katopatoa rera oirato.'),\n",
       "   ('xp',\n",
       "    'Bu nating man em i pas by long mi taim mi sundaon long rot. Mi lukluk stron glong em bikos em i bun nating man tasol. Em i nogat mit long bodi bilong em. Bikos em i bin sik longpela taim olsem na em i bun nating man.'),\n",
       "   ('xe', '???')]),\n",
       " ('katoto',\n",
       "  [('ps', 'N'),\n",
       "   ('pt', 'MASC'),\n",
       "   ('ge', 'rib (sternal)'),\n",
       "   ('ge', 'rib cage'),\n",
       "   ('tkp', 'banis'),\n",
       "   ('dt', '29/Jan/2005'),\n",
       "   ('ex', 'Pauto katoto oureva Adam iava Evi purasia.'),\n",
       "   ('xp', 'God i kisim banis bun bilong Adam na wokim Eve.'),\n",
       "   ('xe', 'God took a rib from Adam in order to make Eve.')]),\n",
       " ('katuara',\n",
       "  [('ps', 'V'),\n",
       "   ('pt', 'B'),\n",
       "   ('ge', 'scour'),\n",
       "   ('tkp', 'brosim'),\n",
       "   ('arg', 'O'),\n",
       "   ('vx', '2'),\n",
       "   ('dt', '30/Oct/2005'),\n",
       "   ('ex', 'Saspan katuarari?'),\n",
       "   ('xp', '???'),\n",
       "   ('xe', 'Are you scouring the saucepan?'),\n",
       "   ('ex', 'Pitokava katuarari oira riruuoro aue-ia rogara.'),\n",
       "   ('xp', 'Yu klinim sospen long weitsan.'),\n",
       "   ('xe', 'Scour the saucepan ???-ing it with ???'),\n",
       "   ('ex',\n",
       "    'Sera pitokara katuaraevoi pitoka rirupa-ia uvare vara rutu pitokara katokatoerao.'),\n",
       "   ('xp',\n",
       "    'Sera em i brasim ol sospen long stil wul bikos olgeta sospen i bilak.'),\n",
       "   ('xe',\n",
       "    'Sera is scrubbing the saucepans with steel wool because all of the saucepans are dirty.')]),\n",
       " ('katuarato',\n",
       "  [('alt', 'katuarapato'),\n",
       "   ('rt', 'katuara'),\n",
       "   ('ps', 'N'),\n",
       "   ('pt', 'MASC'),\n",
       "   ('ge', 'brush'),\n",
       "   ('tkp', 'bras'),\n",
       "   ('sc', 'INSTRUMENT'),\n",
       "   ('dt', '30/Oct/2005'),\n",
       "   ('ex',\n",
       "    'Ragai viapau vaaro katuarapatoavai. Uva ruipaparai ra irai voria ra ira-ia varoara katuara.'),\n",
       "   ('xp',\n",
       "    'Mi nogat wanpela bras bilong brasim ol laplap. Na mi laik baim wanpela bilong brasim ol laplap.'),\n",
       "   ('xe', '???')]),\n",
       " ('katukatu',\n",
       "  [('rt', 'katu'),\n",
       "   ('ps', 'V'),\n",
       "   ('pt', 'A'),\n",
       "   ('rdp', 'full'),\n",
       "   ('ge', 'rot away'),\n",
       "   ('ge', 'flake off'),\n",
       "   ('ge', 'unfastened'),\n",
       "   ('tkp', 'brukbruk'),\n",
       "   ('tkp', 'sting'),\n",
       "   ('nt',\n",
       "    'Clasp breaks or knot becomes untied and binding becomes unfastened'),\n",
       "   ('vx', '1'),\n",
       "   ('sc', '???'),\n",
       "   ('dt', '30/Oct/2005'),\n",
       "   ('ex', 'Katukaturoviro.'),\n",
       "   ('xp', '???'),\n",
       "   ('xe', 'His skin has rotted and is flaking off.'),\n",
       "   ('ex', 'Kaakau katukaturovi eruoro.'),\n",
       "   ('xp', 'Dok i sting na i lus.'),\n",
       "   ('xe', '???'),\n",
       "   ('ex',\n",
       "    'Varoa Pita varo oa katukature uvare va raga-ia tuuparoveira vokiara rutu-ia.'),\n",
       "   ('xp', 'Laplap bilong Pita i sting bikos olgeta taim em i save werim.'),\n",
       "   ('xe', '???')]),\n",
       " ('katuta',\n",
       "  [('ps', 'N'),\n",
       "   ('pt', 'FEM'),\n",
       "   ('ge', 'long spear'),\n",
       "   ('tkp', 'longpela spia'),\n",
       "   ('dt', '20/Sep/2004'),\n",
       "   ('ex',\n",
       "    'Katuta riro kaekaeva iria-ia oisioa oirara togapaive oraupopaoro tuariri.'),\n",
       "   ('xp',\n",
       "    'Longpela supsup ol i save yusim long sutim ol man long taim bilong pait bipo.'),\n",
       "   ('xe',\n",
       "    'The katuta is a long spear that people used when fighting each other long ago.')]),\n",
       " ('kau',\n",
       "  [('ps', '???'),\n",
       "   ('ge', 'solid'),\n",
       "   ('ge', 'hard'),\n",
       "   ('tkp', '???'),\n",
       "   ('cmt', 'Ex. sentence not a sentence.'),\n",
       "   ('dt', '11/Feb/2007'),\n",
       "   ('ex', 'Kauva rutu oia asiva.'),\n",
       "   ('xp', 'Strongpela buai.'),\n",
       "   ('xe', '???'),\n",
       "   ('ex', 'Oia asiva kauva rutu oa iava viapau uvuiparai ra oira aioa.'),\n",
       "   ('xp', 'Dispela buai i strong tumas olsem na mi no inap kaikaim.'),\n",
       "   ('xe', \"??? and that's why I can't eat it.\")]),\n",
       " ('kaukau',\n",
       "  [('rt', 'kau'),\n",
       "   ('ps', 'N'),\n",
       "   ('pt', '???'),\n",
       "   ('ge', 'sweet potato'),\n",
       "   ('tkp', 'kaukau'),\n",
       "   ('nt', 'Tok Pisin loan'),\n",
       "   ('dt', '30/Oct/2005'),\n",
       "   ('ex', 'Rotokasi-pa riako rirovira kaukau paupaveira.'),\n",
       "   ('xp', 'Ol meri Rotokas i save planim plat kaukau.'),\n",
       "   ('xe', '???')]),\n",
       " ('kaukaupie',\n",
       "  [('rt', 'kaukau'),\n",
       "   ('ps', 'V'),\n",
       "   ('pt', 'B'),\n",
       "   ('ge', 'shine intensely'),\n",
       "   ('ge', 'intense sunlight'),\n",
       "   ('tkp', '???'),\n",
       "   ('vx', '2'),\n",
       "   ('arg', 'O'),\n",
       "   ('dt', '11/Feb/2007'),\n",
       "   ('ex', 'Ravireo kaukaupieparevoi.'),\n",
       "   ('xp', '???'),\n",
       "   ('xe', 'The sun shines intensely.'),\n",
       "   ('ex', 'Ravireo ragai kaukaupiere.'),\n",
       "   ('xp', 'San i hatim skin bilong mi.'),\n",
       "   ('xe', 'The sun is ???-ing me.'),\n",
       "   ('ex',\n",
       "    'Poroirie oisio ruipapaoe ra ravireo kaukaupiereve, ra kovoa iare avao kovosia.'),\n",
       "   ('xp',\n",
       "    'Poroirie em i laik bai san i hat pastaim na bai em i go long gaden.'),\n",
       "   ('xe',\n",
       "    'Poroirie wants the sun to shine for him to go to the garden to work.')]),\n",
       " ('kaukauvira',\n",
       "  [('alt', 'kaukaupavira'),\n",
       "   ('rt', 'kaukau'),\n",
       "   ('ps', 'ADV'),\n",
       "   ('pt', 'MANNER'),\n",
       "   ('ge', 'intensely'),\n",
       "   ('tkp', '???'),\n",
       "   ('nt', 'For example, in the manner of a very bright hot sun.'),\n",
       "   ('sa', 'kaukaupievira'),\n",
       "   ('dt', '15/Oct/2005'),\n",
       "   ('ex', 'Kaukauvira rutu roroparevoi ravireo.'),\n",
       "   ('xp', '???'),\n",
       "   ('xe', 'The sun is shining intensely.'),\n",
       "   ('ex', 'Ravireo kaukauvira rororevoi 9 kiloki-ia.'),\n",
       "   ('xp', 'San i hat strong tru long 9 klok.'),\n",
       "   ('xe', \"The sun shines intensely at 9 o'clock.\"),\n",
       "   ('ex',\n",
       "    'Vovokio oisio kekepai kaukauvira roroparevoi ravireo ora vokua tapo vearpiea.'),\n",
       "   ('xp', 'Tudei i luk olsem san bai lait strong na dei tu i naispela dei.'),\n",
       "   ('xe', 'Today it looked like the sun was shining strongly and ???.')]),\n",
       " ('kaukovo',\n",
       "  [('ps', 'N'),\n",
       "   ('pt', '???'),\n",
       "   ('ge', 'water cress'),\n",
       "   ('tkp', 'kango'),\n",
       "   ('cmt', 'According to Firchow, not originally Rotokas. Why not?'),\n",
       "   ('dt', '05/Feb/2005'),\n",
       "   ('alt', 'Is kaukovu an alterate form?'),\n",
       "   ('ex', 'Kaukovo kouro eisi toupaiveira tuvuara-ia.'),\n",
       "   ('xp', 'Kangkong i save gro long ol tais.'),\n",
       "   ('xe', 'Water cress grows in the mud.')]),\n",
       " ('kauo',\n",
       "  [('ps', 'V'),\n",
       "   ('pt', 'A'),\n",
       "   ('ge', 'jump'),\n",
       "   ('tkp', 'kalap'),\n",
       "   ('tkp', 'mama'),\n",
       "   ('sc', '???'),\n",
       "   ('vx', '1'),\n",
       "   ('dt', '15/Oct/2005'),\n",
       "   ('ex', 'Ragai rorupaoro kauoparai.'),\n",
       "   ('xp', 'Mi amamas na mi kalap.'),\n",
       "   ('xe', 'I jumped out of happiness.'),\n",
       "   ('ex',\n",
       "    'Verisevi riro kauova vosia oaravu-ia roropaeve, ra kauopao rorupaoro.'),\n",
       "   ('xp',\n",
       "    'Verisevi em meri bilong danis taim em i hamamas long ol sampela samting.'),\n",
       "   ('xe',\n",
       "    'Verisevi is a celebrator if she is happy about things, and she dances happily.')]),\n",
       " ('kauokauo',\n",
       "  [('rt', 'kauo'),\n",
       "   ('ps', 'V'),\n",
       "   ('pt', 'A'),\n",
       "   ('rdp', 'full'),\n",
       "   ('ge', 'jump up and down'),\n",
       "   ('tkp', 'kalkalap'),\n",
       "   ('vx', '1'),\n",
       "   ('sc', '???'),\n",
       "   ('dt', '15/Oct/2005'),\n",
       "   ('ex', 'Vii kauokauo.'),\n",
       "   ('xp', 'Yu jumpjump.'),\n",
       "   ('xe', 'Jump up and down!'),\n",
       "   ('ex', 'Rirovira rutu rorupaoro kauokauoparai.'),\n",
       "   ('xp', 'Mi amamas tru na mi kalapkalap.'),\n",
       "   ('xe', 'I jumped up and down truly happy.'),\n",
       "   ('ex', 'Riakora kauokauopaveira vosia iriavu aire-pa kakae kavaueve.'),\n",
       "   ('xp',\n",
       "    'Ol meri i save hamamas na kalakalap taim wanpela meri i karim niupela pikinini.'),\n",
       "   ('xe',\n",
       "    'The women dance for joy when someone gives birth to a new child.')]),\n",
       " ('kaureo',\n",
       "  [('ps', 'V'),\n",
       "   ('pt', 'A'),\n",
       "   ('ge', 'stubborn'),\n",
       "   ('tkp', 'bikhet'),\n",
       "   ('tkp', 'sakim tok'),\n",
       "   ('eng', 'contradict'),\n",
       "   ('eng', 'disagree'),\n",
       "   ('eng', 'stubbornly against'),\n",
       "   ('eng', 'rebellious'),\n",
       "   ('cm', '-va'),\n",
       "   ('am', 'false'),\n",
       "   ('dcsv', '???'),\n",
       "   ('arg', 'OBL'),\n",
       "   ('vx', '2'),\n",
       "   ('cmt', 'Is kauro an alternate form?'),\n",
       "   ('dt', '15/Oct/2005'),\n",
       "   ('ex', 'Rirovira oisoa rera-va kaureopaave.'),\n",
       "   ('xp', '???'),\n",
       "   ('xe', 'They were always in much disagreement with him.'),\n",
       "   ('ex', 'Kakaevure rirovira kaureopaai uva avuka voea-re kasipuoe.'),\n",
       "   ('xp', 'Ol pikinini i bikhet tumas na lapun meri i krosim ol.'),\n",
       "   ('xe',\n",
       "    'The children are very stubborn and the old woman is angry at them.')]),\n",
       " ('kaureoto',\n",
       "  [('rt', 'kaureo'),\n",
       "   ('ps', 'N'),\n",
       "   ('pt', 'HUM'),\n",
       "   ('ge', 'braggart'),\n",
       "   ('ge', 'back talker'),\n",
       "   ('tkp', 'hambakman'),\n",
       "   ('dt', '15/Oct/2005'),\n",
       "   ('ex', 'Via kaureoto viapau uvupariveira.'),\n",
       "   ('xp', 'Yu bikhat man yu no save harim tok.'),\n",
       "   ('xe', \"You're stubborn, you don't listen.\"),\n",
       "   ('ex', 'Raraviri riro kaureoto akova-re.'),\n",
       "   ('xp', 'Raraviri man bilong sakim bilong mama.'),\n",
       "   ('xe', 'Raraviri is very stubborn to his mother. (???)'),\n",
       "   ('ex', 'Kaureoto ro oirato ira viapau reo uvuparoveira, riro reo atoto.'),\n",
       "   ('xp',\n",
       "    'Bikhet man em kain man i no save harim tok o man bilong bekim tok.'),\n",
       "   ('xe', \"A braggart is a man who doesn't listen, and is a bit ???.\")]),\n",
       " ('kausiopa',\n",
       "  [('alt', 'kausopa'),\n",
       "   ('ps', 'V'),\n",
       "   ('pt', 'A'),\n",
       "   ('ge', 'stubborn'),\n",
       "   ('ge', 'unrelenting'),\n",
       "   ('ge', 'concerned'),\n",
       "   ('ge', 'anxious'),\n",
       "   ('tkp', '???'),\n",
       "   ('cmt',\n",
       "    \"Need to check translation. Is it just stubborn? What about 'concerned' and 'anxious'?\"),\n",
       "   ('cm', '-re'),\n",
       "   ('arg', 'OBL'),\n",
       "   ('vx', '2'),\n",
       "   ('nt', \"From the two words kau `strong' and sopa `inside'.\"),\n",
       "   ('dt', '15/Oct/2005'),\n",
       "   ('ex', 'E va-re kausopapau?'),\n",
       "   ('xp', '???'),\n",
       "   ('xe', 'Are you very concerned about it?'),\n",
       "   ('ex', 'Kausiopa vovoutoa rutu ro oirato.'),\n",
       "   ('xp', 'Dispela bikhet man.'),\n",
       "   ('xe', '???'),\n",
       "   ('ex',\n",
       "    'Isivairi kausiopairaoparoe oisio ra voriavai oureve kovoa-ia oa purarevora.'),\n",
       "   ('xp',\n",
       "    'Isivairi em i strong bikos em i laikim man i long wok em i bin wokim.'),\n",
       "   ('xe', 'Isivairi is unrelenting because ???.')]),\n",
       " ('kausiovira',\n",
       "  [('alt', 'kausiopavira'),\n",
       "   ('rt', 'kausio'),\n",
       "   ('ps', 'ADV'),\n",
       "   ('pt', 'MANNER'),\n",
       "   ('ge', 'anxiously'),\n",
       "   ('tkp', '???'),\n",
       "   ('nt', 'archaic, possibly dialectal or idiolectal'),\n",
       "   ('cmt',\n",
       "    'Sera claims the use of this term is confined to a small group of people--dubious'),\n",
       "   ('dt', '13/Nov/2005'),\n",
       "   ('ex', 'Kausiopavira icepa paurivoi viva.'),\n",
       "   ('xp', 'Man yu wanpela tasol yu wokim dispela house.'),\n",
       "   ('xe', '???'),\n",
       "   ('ex', 'Kausiopavira rutu vao erakoa kaerivoi.'),\n",
       "   ('xp', 'Yu strong inap na yu karim paia wut.'),\n",
       "   ('xe', '???'),\n",
       "   ('ex',\n",
       "    'Oirato kausiopavira rutu reoreoparoe ovusia rera-re koruragapae riropairara.'),\n",
       "   ('xp', 'Man i bikhet tru long toktok taim ol bikman i stopim em nating.'),\n",
       "   ('xe', 'The man spoke stubbornly when the big men tried to stop him.'),\n",
       "   ('ex',\n",
       "    'Kausiovira rugoopareveira oirato oa iava viapau vii-pa ra oaravu vatepareve oearovu-pa.'),\n",
       "   ('xp',\n",
       "    'Man i gat strongpela tingting na em i no save givim ol samting long ol man.'),\n",
       "   ('xe', \"The man is thinking anxiously and that's why ???.\")]),\n",
       " ('Kava',\n",
       "  [('ps', 'N'),\n",
       "   ('pt', 'PN'),\n",
       "   ('ge', 'name'),\n",
       "   ('tkp', 'nem'),\n",
       "   ('eng', 'name'),\n",
       "   ('dt', '24/Feb/2004')]),\n",
       " ('kavakavau',\n",
       "  [('rt', 'kavau'),\n",
       "   ('ps', 'V'),\n",
       "   ('pt', 'B'),\n",
       "   ('rdp', 'partial'),\n",
       "   ('ge', 'reproduce'),\n",
       "   ('tkp', 'karikarim planti pikinini'),\n",
       "   ('eng', 'reproduce'),\n",
       "   ('eng', 'bear many children'),\n",
       "   ('vx', '2'),\n",
       "   ('arg', 'O'),\n",
       "   ('dt', '31/Jan/2007'),\n",
       "   ('ex', 'Vovokio-ia rirovira kakae kavakavaupae.'),\n",
       "   ('xp', 'Tude ol i wok long bonim plenti pikinini.'),\n",
       "   ('xe', \"Today they're having a lot of children.\"),\n",
       "   ('ex', 'Rirovira oisoa kavakavaupaive tuariri.'),\n",
       "   ('xp', '???'),\n",
       "   ('xe', 'In the past they reproduced greatly.'),\n",
       "   ('ex',\n",
       "    'Riakora rirovira kakae kavakavaupaai. Oa iava rasivaruro potepaiovoi.'),\n",
       "   ('xp', 'Ol meri i karikarim planti pikinini olsem na ol hap graun i sot.'),\n",
       "   ('xe',\n",
       "    \"Women are having many children and that's why land is in short supply.\")]),\n",
       " ('kavatao',\n",
       "  [('ps', 'N'),\n",
       "   ('pt', '???'),\n",
       "   ('ge', 'newlywed.house'),\n",
       "   ('eng', 'newlywed house'),\n",
       "   ('tkp', 'haus bilong niupela marit'),\n",
       "   ('dt', '26/Sep/2006'),\n",
       "   ('ex', 'Kavatao kepa vao vaitei varo.'),\n",
       "   ('xp', 'Niupela marit i stap insait.'),\n",
       "   ('xe', '???'),\n",
       "   ('ex', 'Kavatao kepa airepa ora outorei vokeparo.'),\n",
       "   ('xp', 'Haus bilong tupela nupela marit.'),\n",
       "   ('xe', '???'),\n",
       "   ('ex',\n",
       "    'Vokepao kavatao kepa oa oisio toupaiveira. Vosia rovopa vuta-ia riakova aivaropieive oiratoa taporo, ra kavatao kepa-ia vaiterei koatapieive.'),\n",
       "   ('xp',\n",
       "    'Dispela haus niupela haus i save stap olsem. Sapos nambawan taim ol bungim meri wantaim man. Bai ol ol i putim tupela insait long dispela haus.')]),\n",
       " ('Kavatara',\n",
       "  [('ps', 'N'),\n",
       "   ('pt', 'PN'),\n",
       "   ('ge', 'name'),\n",
       "   ('tkp', 'nem'),\n",
       "   ('eng', 'name'),\n",
       "   ('dt', '24/Feb/2004')]),\n",
       " ('kavau',\n",
       "  [('ps', 'V'),\n",
       "   ('pt', 'A'),\n",
       "   ('ge', 'be born'),\n",
       "   ('tkp', 'bon'),\n",
       "   ('cmt', 'Example needed'),\n",
       "   ('vx', '1'),\n",
       "   ('dt', '08/Dec/2005')]),\n",
       " ('kavau',\n",
       "  [('ps', 'V'),\n",
       "   ('pt', 'B'),\n",
       "   ('ge', 'give birth'),\n",
       "   ('tkp', 'bonim'),\n",
       "   ('tkp', 'karim pikinini'),\n",
       "   ('arg', 'O'),\n",
       "   ('vx', '2'),\n",
       "   ('dt', '08/Dec/2005'),\n",
       "   ('ex', 'Kakaeto kavauevora.'),\n",
       "   ('xp', 'Em i bonim pikinini man.'),\n",
       "   ('xe', 'She gave birth to the child.'),\n",
       "   ('ex', 'Oriri kakaeto kavauevo.'),\n",
       "   ('xp', 'Oriri i bonim pikinini man.'),\n",
       "   ('xe', 'Oriri gave birth to a son.'),\n",
       "   ('ex',\n",
       "    'Aakova kakaeto kavauevo vovokio-ia uva aiteto riroa-va rorua toupare.'),\n",
       "   ('xp', 'Mama i karim pikinini tudei na papa i stap wantaim hamamas.'),\n",
       "   ('xe', 'Mother gave birth to a boy today and father is really happy.'),\n",
       "   ('ex', 'Kiuwi kaakau kakaero kavauevo.'),\n",
       "   ('xp', 'Kiuwi em i bonim ol pikinini dok.'),\n",
       "   ('xe', 'Kiuwi gave birth to puppies.')]),\n",
       " ('kavau asiava',\n",
       "  [('rt', 'kavau'),\n",
       "   ('ps', '???'),\n",
       "   ('ge', 'barren woman'),\n",
       "   ('tkp', 'meri i no ken karim pikinini'),\n",
       "   ('dt', '17/Oct/2005'),\n",
       "   ('ex', 'Viia kakae kavau asiava.'),\n",
       "   ('xp', 'Yu no save kalim pikinini.'),\n",
       "   ('xe', '???'),\n",
       "   ('ex', 'Oia riakova kakae kavau asiva.'),\n",
       "   ('xp', 'Dispela meri i no save bonim pikinini.'),\n",
       "   ('xe', '???'),\n",
       "   ('ex', 'Riakova kakae kavau asiava uva okakaerovu raga tokipaeveira.'),\n",
       "   ('xp',\n",
       "    'Meri em meri i no save karim pikinini, em save lukautim pikinini bilong ol narapela ol narapela man yet.'),\n",
       "   ('xe', '???')]),\n",
       " ('kave',\n",
       "  [('ps', 'V'),\n",
       "   ('pt', 'B'),\n",
       "   ('ge', 'whisper'),\n",
       "   ('ge', 'reduce the strength or heat of something'),\n",
       "   ('tkp', '???'),\n",
       "   ('vx', '2'),\n",
       "   ('arg', 'O'),\n",
       "   ('dt', '17/Oct/2005'),\n",
       "   ('cmt', 'Who is angry in the first sentence? John, no?'),\n",
       "   ('ex', 'Pita ira Jon kaveepare uvare kasipupa.'),\n",
       "   ('xp', 'Pita i givim bel isi tok long Jon bikos em i kros.'),\n",
       "   ('xe', 'Pita whispered to John because he was mad.'),\n",
       "   ('ex', 'Vii kaveeparevere.'),\n",
       "   ('xp', '???'),\n",
       "   ('xe', 'He will whisper to yo.'),\n",
       "   ('ex',\n",
       "    'Pita ira soripa kave vovou vatepare uvare rirovira kasipuroe uva rera tapo toupare Pita rera-pa kave vovou vatepaoro.'),\n",
       "   ('xp',\n",
       "    'Pita em man i wok long givim bel isi long Jon bikos em i kros tumas olsem na Pita i stap wantaim em, na givim bel isi long em.'),\n",
       "   ('xe', '???')]),\n",
       " ('kavee',\n",
       "  [('ps', 'V'),\n",
       "   ('pt', 'A'),\n",
       "   ('ge', 'cool off in a shaded spot'),\n",
       "   ('tkp', 'karamap namel long lait bilong san na kol'),\n",
       "   ('vx', '1'),\n",
       "   ('sc', '???'),\n",
       "   ('cmt',\n",
       "    'Double-check vowel length. Is there really a kave/kavee minimal pair?'),\n",
       "   ('dt', '17/Oct/2005'),\n",
       "   ('ex', 'Kave voki viapau ravire vai ova kokevavai.'),\n",
       "   ('xp', 'Kave nogat sun hat tumas na i no gat ran.'),\n",
       "   ('xe', '???'),\n",
       "   ('ex', 'Vo kavesia uriou ari ravireoa eva virovira roropare.'),\n",
       "   ('xp', 'Yu kam kul liklik pasitaw long hia bikpela sun i hot.'),\n",
       "   ('xe', '???'),\n",
       "   ('ex',\n",
       "    'Kaveea oatoupaiveira ravireo kasikasiaro vurvuruia roia ora uteoa.'),\n",
       "   ('xp', 'Karamap i save i stap namel long hot bilong san na kol.')]),\n",
       " ('kaveepaa',\n",
       "  [('rt', 'kavee'),\n",
       "   ('ps', 'N'),\n",
       "   ('pt', 'NT'),\n",
       "   ('ge', 'shade'),\n",
       "   ('tkp', 'hap i no gat planti san moa long ol narapela hap'),\n",
       "   ('dt', '17/Oct/2005'),\n",
       "   ('ex', 'Kavepa guvaguva vao-ia.'),\n",
       "   ('xp', 'Em cool tru long dispeta diwai.'),\n",
       "   ('xe', '???'),\n",
       "   ('ex', 'Vate toupare kaveepa kepa-ia.'),\n",
       "   ('xp', 'Vate i stap long haus win.'),\n",
       "   ('xe', '???'),\n",
       "   ('ex',\n",
       "    'Igei vo paupaiei evaova vituaroi uva viapau rirovira ravireo roropare.'),\n",
       "   ('xp',\n",
       "    'Mipela i sindaun adanit ol dispela diwai i no gat bikpela lait o hot bilong san.'),\n",
       "   ('xe', '???')]),\n",
       " ('kaverui',\n",
       "  [('ps', 'N'),\n",
       "   ('pt', 'FEM'),\n",
       "   ('ge', 'gourd container'),\n",
       "   ('tkp', 'sel kabang'),\n",
       "   ('nt', \"used for keeping akoro `lime powder'\"),\n",
       "   ('dt', '17/Oct/2005'),\n",
       "   ('ex', 'Kaverui iria purapaiveira aue iava opita isi ro, akoro tovopasia.'),\n",
       "   ('xp', 'Kointena ol i save wokim long kokonas bilong putim kabang.'),\n",
       "   ('xe', '???'),\n",
       "   ('ex', 'Kaverui iria purapaiveira aue iava opita isiro akoro tovopasia.'),\n",
       "   ('xp',\n",
       "    'Sel kabang ol save mekim long sel bilong kokonat bilong putim kabang long em.'),\n",
       "   ('xe',\n",
       "    'They make gourd containers from coconut shells in order to put lime (in them).')]),\n",
       " ('kaveruko',\n",
       "  [('ps', 'V'),\n",
       "   ('pt', 'B'),\n",
       "   ('ge', 'hold in arms'),\n",
       "   ('tkp', 'holim pikinini'),\n",
       "   ('vx', '2'),\n",
       "   ('arg', 'O'),\n",
       "   ('dt', '08/Jun/2005'),\n",
       "   ('ex', 'Oira kaverukopaoro vorevira karero oira-ia rorupaoro.'),\n",
       "   ('xp', '???'),\n",
       "   ('xe', 'Holding her in his arms he returned being very pleased with her.'),\n",
       "   ('ex', 'Henry, Rosa kaverukopaoro ava kepa iare, oira ia rorupaoro.'),\n",
       "   ('xp', 'Henry i amamas long Rosa na holim em i go long haus.'),\n",
       "   ('xe', '???')]),\n",
       " ('kavesi',\n",
       "  [('ps', 'N'),\n",
       "   ('pt', '???'),\n",
       "   ('ge', 'cabbage'),\n",
       "   ('tkp', 'kabis'),\n",
       "   ('dt', '29/Jan/2005'),\n",
       "   ('ex', 'Aputu riro kavesi pauto eisi Sisisivi.'),\n",
       "   ('xp', 'Aputu man bilong planim kebis long Sisisivi.'),\n",
       "   ('xe', 'Aputu is a big cabbage farmer in Sisisivi.')]),\n",
       " ('kavikavi',\n",
       "  [('rt', 'kavi'),\n",
       "   ('ps', 'V'),\n",
       "   ('pt', 'B'),\n",
       "   ('rdp', 'full'),\n",
       "   ('ge', 'combine'),\n",
       "   ('ge', 'work together'),\n",
       "   ('tkp', 'ol i wok wantaim'),\n",
       "   ('cm', '-re'),\n",
       "   ('vx', '2'),\n",
       "   ('arg', 'OBL'),\n",
       "   ('dt', '08/Jun/2005'),\n",
       "   ('ex', 'Uva oavu-re kavikaviiva. Va vaisiaro avata.'),\n",
       "   ('xp', '???'),\n",
       "   ('xe',\n",
       "    \"They worked together for something else. Its name is, single men's house.\"),\n",
       "   ('ex',\n",
       "    'Sipito oirara rutu ora riakora tavirevoi aio kavikavisia riroa aioa purasia.'),\n",
       "   ('xp',\n",
       "    'Sip i tokim olgeta man na meri long kisim kaikai bilong wokim bikpela pati.'),\n",
       "   ('xe',\n",
       "    'The chief told all of the men and women to gather food in order to have a feast.')]),\n",
       " ('kavikaviru',\n",
       "  [('rt', 'kaviru'),\n",
       "   ('ps', 'V'),\n",
       "   ('pt', 'B'),\n",
       "   ('rdp', 'partial'),\n",
       "   ('ge', 'steal'),\n",
       "   ('tkp', 'stil stil'),\n",
       "   ('vx', '2'),\n",
       "   ('arg', 'O'),\n",
       "   ('dt', '17/Oct/2005'),\n",
       "   ('ex', 'Sorato aio kuroro kavikaviruparevoi.'),\n",
       "   ('xp', 'Poison man em i stilim ol haphap kaikai.'),\n",
       "   ('xe', 'The poison man steals crumbs of food.'),\n",
       "   ('ex',\n",
       "    'Ro oirato ira kavikaviruparo reraera riro pokapokato. Ira oirara vuripieparevere kavikaviru kovo purapaoro.'),\n",
       "   ('xp',\n",
       "    'Em dispela man i save stilstil. Em dispela kain man em les man, em i laik wokim wok stil tasol na bagarapim ol man.'),\n",
       "   ('xe', '???')]),\n",
       " ('kavikaviru',\n",
       "  [('rt', 'kaviru'),\n",
       "   ('ps', 'N'),\n",
       "   ('pt', 'HUM'),\n",
       "   ('dx', 'Central'),\n",
       "   ('ge', 'thief'),\n",
       "   ('tkp', 'stilman'),\n",
       "   ('dt', '17/Jul/2005'),\n",
       "   ('ex', 'Riro kavikaviruirara visi, visigoa atarikare kavirutavora.'),\n",
       "   ('xp', 'Yupela ol man bilong stil, yupela i bin stilim ol pis.'),\n",
       "   ('xe', \"You're big thieves, you stole the fish.\")]),\n",
       " ('kaviko',\n",
       "  [('ps', 'V'),\n",
       "   ('pt', 'B'),\n",
       "   ('ge', 'love intensely'),\n",
       "   ('tkp', 'laikim tumas'),\n",
       "   ('cm', '-pa'),\n",
       "   ('vx', '2'),\n",
       "   ('arg', 'OBL'),\n",
       "   ('dt', '17/Oct/2005'),\n",
       "   ('cmt', 'Why no case marking on second example?'),\n",
       "   ('ex', 'Ira oviitoa-pa oisoa kavikoiraopareve.'),\n",
       "   ('xp', '???'),\n",
       "   ('xe', 'He was always intensely loving his son.'),\n",
       "   ('ex', 'Raratuiri ira oirara rutu kavikopareveira voea aio vatepaoro.'),\n",
       "   ('xp', 'Pol i save lovim ol man na givim kaikai long ol.'),\n",
       "   ('xe', 'Paul loves mankind and gives food to everyone.'),\n",
       "   ('ex',\n",
       "    'Oirato ro ira oirara rutu-pa siraoparo rera era kaviko-pa vovouto.'),\n",
       "   ('xp',\n",
       "    'Man i save sori long ol man, em dispela man i gat marimari long bel bilong em.'),\n",
       "   ('xe', '???')]),\n",
       " ('kavikoa',\n",
       "  [('ps', 'N'),\n",
       "   ('pt', 'NT'),\n",
       "   ('ge', 'love'),\n",
       "   ('ge', 'filial love'),\n",
       "   ('tkp', 'laik'),\n",
       "   ('dt', '29/Jan/2005'),\n",
       "   ('ex',\n",
       "    'Riroa rutu kavikoa oa purareva Pauto Jisu varapieoro vo rasio iare.'),\n",
       "   ('xp',\n",
       "    'Bikpela i bin marimari tru na em i bin salim Jisas i kam daun long graun.'),\n",
       "   ('xe', '???')]),\n",
       " ('kaviru',\n",
       "  [('ps', 'V'),\n",
       "   ('pt', 'A'),\n",
       "   ('ge', 'steal'),\n",
       "   ('ge', 'rob'),\n",
       "   ('tkp', 'stil'),\n",
       "   ('vx', '1'),\n",
       "   ('sc', '???'),\n",
       "   ('cmt', \"Is it possible to specify what's stolen?\"),\n",
       "   ('dt', '17/Oct/2005'),\n",
       "   ('ex', 'Opeita kavirupau.'),\n",
       "   ('xp', 'Yu no ken stil.'),\n",
       "   ('xe', \"Don't steal!\")]),\n",
       " ('kaviru',\n",
       "  [('ps', 'V'),\n",
       "   ('pt', 'B'),\n",
       "   ('ge', 'steal'),\n",
       "   ('ge', 'rob'),\n",
       "   ('tkp', 'stil'),\n",
       "   ('vx', '2'),\n",
       "   ('arg', 'O'),\n",
       "   ('dt', '08/Jun/2005'),\n",
       "   ('ex', 'Opeita oaravu avu vai kavirupari.'),\n",
       "   ('xp', '???'),\n",
       "   ('xe', 'Do not be stealing anything.'),\n",
       "   ('ex', 'Oeavu kaukau kovo kaviruivo uva vuraraga sia vokie eisi kovoa.'),\n",
       "   ('xp',\n",
       "    'Sampela man i stilum gaden kaukau na moning taim mipela i go lukluk nating long gaden.'),\n",
       "   ('xe', '???')]),\n",
       " ('kaviruto',\n",
       "  [('alt', 'kavirupato'),\n",
       "   ('rt', 'kaviru'),\n",
       "   ('ps', 'N'),\n",
       "   ('pt', 'HUM'),\n",
       "   ('ge', 'thief'),\n",
       "   ('ge', 'robber'),\n",
       "   ('tkp', 'stilman'),\n",
       "   ('dt', '17/Oct/2005'),\n",
       "   ('ex', 'Era oirato riro kaviruto.'),\n",
       "   ('xp', 'Dispela man em i stil man tru.'),\n",
       "   ('xe', 'This man is a big thief.'),\n",
       "   ('ex',\n",
       "    'Kaviruto ira vokiaro urioparoveira oaravu kavirapasia, oirara vararo.'),\n",
       "   ('xp',\n",
       "    'Stilman i save kam long nait na stilim ol sampela samting bilong ol man.'),\n",
       "   ('xe', '???')]),\n",
       " ('kaviruvira',\n",
       "  [('alt', 'kavirupavira'),\n",
       "   ('rt', 'kaviru'),\n",
       "   ('ps', 'ADV'),\n",
       "   ('pt', 'MANNER'),\n",
       "   ('ge', 'stealthily'),\n",
       "   ('ge', 'secretly'),\n",
       "   ('tkp', 'olsem stil'),\n",
       "   ('dt', '28/Aug/2005'),\n",
       "   ('ex', 'Opeita kaviruvira oaravu oupari oearovu vararo.'),\n",
       "   ('xp', 'Yu no ken stil na kisim nating samting bilong narapela man.'),\n",
       "   ('xe', '???')]),\n",
       " ('kavo',\n",
       "  [('ps', 'V'),\n",
       "   ('pt', 'B'),\n",
       "   ('ge', 'collect'),\n",
       "   ('eng', 'scavenge'),\n",
       "   ('eng', 'pick up'),\n",
       "   ('eng', 'collect'),\n",
       "   ('tkp', 'mumutim'),\n",
       "   ('tkp', 'kisim ol samting ol narapela i tromoem'),\n",
       "   ('arg', 'O'),\n",
       "   ('vx', '2'),\n",
       "   ('dt', '26/Sep/2006'),\n",
       "   ('ex', 'Uva oisoa rera keruaro kavoive rareto guruoro.'),\n",
       "   ('xp', '???'),\n",
       "   ('xe',\n",
       "    'They would always hunt around for the bones collecting the charred parts.'),\n",
       "   ('ex',\n",
       "    'Sorairara oirara varaaro kavopaiveira aio kuroro vosia vara vikipaive ra vara kavopaive vara tovopasia okavikavi rovu sovaraia vara tovopasia vuri kavikaviro.'),\n",
       "   ('xp',\n",
       "    'Ol poisin man i save kisim ol hap kaikai bilong ol man taim ol tromoem na bai ol i kisim na putim insait long ol sampela kain marasin i nogut.'),\n",
       "   ('xe', '???')]),\n",
       " ('kavokavo',\n",
       "  [('rt', 'kavo'),\n",
       "   ('ps', 'V'),\n",
       "   ('pt', 'B'),\n",
       "   ('rdp', 'full'),\n",
       "   ('ge', 'perform sorcery'),\n",
       "   ('ge', 'work black magic'),\n",
       "   ('tkp', 'posin'),\n",
       "   ('vx', '2'),\n",
       "   ('arg', 'O'),\n",
       "   ('dt', '17/Oct/2005'),\n",
       "   ('ex', 'Eera kavokavoto ira oirara kavokavoparoveira.'),\n",
       "   ('xp', 'Poison man em i save poisonim ol man.'),\n",
       "   ('xe', 'That sorcerer is always working black magic on people.'),\n",
       "   ('ex',\n",
       "    'Rakaisirea ora Reviteri aiterea riroirara oirara ora riakora oisioa kavokavopasi ra kopiipave uvare oisioa vuri goruro-ia pitupasi.'),\n",
       "   ('xp',\n",
       "    'Rakaisirea wantaim Reviteri tupela i bin poisim ol planti man na meri na ol i save dai. Bikos tupela i save holim ol bilak paua.'),\n",
       "   ('xe', '???')]),\n",
       " ('kavokavoa',\n",
       "  [('rt', 'kavokavo'),\n",
       "   ('ps', 'N'),\n",
       "   ('pt', 'NT'),\n",
       "   ('ge', 'sorcery'),\n",
       "   ('ge', 'black magic'),\n",
       "   ('tkp', 'posin'),\n",
       "   ('dt', '17/Oct/2005'),\n",
       "   ('ex',\n",
       "    'Aakova kakaeto tavipaeva oisio teapi evoa avapau uva kavokavoa iava tavipaera.'),\n",
       "   ('xp',\n",
       "    'Mama i tokim ol pikinini olsem no ken go long hap i gat poisin ol man i toktok long em.'),\n",
       "   ('xe', '???')]),\n",
       " ('kavokavoto',\n",
       "  [('rt', 'kavokavo'),\n",
       "   ('ps', 'N'),\n",
       "   ('pt', 'HUM'),\n",
       "   ('ge', 'sorcerer'),\n",
       "   ('tkp', 'posin man'),\n",
       "   ('dt', '11/Feb/2007'),\n",
       "   ('ex', 'Kavokavoto sorato oira kopipiepato.'),\n",
       "   ('xp', 'Posin man i man blong mekim man i dai.'),\n",
       "   ('xe', 'A black magic sorcerer kills people.'),\n",
       "   ('ex',\n",
       "    'Rakaisirea iravu kavokavoto. Ira kavokavoa-ia vuria rutu oisioa pitupareve. Oa goruaro uvuipai ra katai voki raga-ia upiau ra kopiu ovoiu.'),\n",
       "   ('xp',\n",
       "    'Rakaisirea em wanpela poisin man. Em i save holim poisin i nogut tru. Strong bilong em inap wanpela dei tasol bai yu sik na yu dai olgeta.'),\n",
       "   ('xe',\n",
       "    \"Rakaisirea is a sorcerer. He always has really bad black magic, and it's strength is such that you will you get sick and die in one day.\")]),\n",
       " ('kavora',\n",
       "  [('ps', 'N'),\n",
       "   ('pt', 'FEM'),\n",
       "   ('ge', 'red rash on skin'),\n",
       "   ('ge', 'ringworm'),\n",
       "   ('ge', 'tinea'),\n",
       "   ('ge', 'grille'),\n",
       "   ('tkp', 'skin i bagarap grile'),\n",
       "   ('dt', '17/Oct/2005'),\n",
       "   ('ex', 'Vii kavora kavorato.'),\n",
       "   ('xp', 'Yu grille man.'),\n",
       "   ('xe', '???'),\n",
       "   ('ex',\n",
       "    'Kavorara oara oirara ora riakora varaararo-ia orapurapapeira oa rakariara kaekaepiepaiveira ra vuri kekepave oirara or riakora.'),\n",
       "   ('xp',\n",
       "    'Ol grile i save kamap long skin bilong ol man meri. Ol dispela grile i save hantapim skin na bai ol man meri i luk nogut.'),\n",
       "   ('xe', '???')]),\n",
       " ('kavorato',\n",
       "  [('rt', 'kavora'),\n",
       "   ('ps', 'N'),\n",
       "   ('pt', 'HUM'),\n",
       "   ('ge', 'person with ringworm or tinea'),\n",
       "   ('tkp', 'grile man'),\n",
       "   ('nt', 'common insult'),\n",
       "   ('dt', '17/Oct/2005'),\n",
       "   ('ex', 'Vii kavorato.'),\n",
       "   ('xp', 'Yu grille man.'),\n",
       "   ('xe', 'You you have grille.'),\n",
       "   ('ex',\n",
       "    'Riakova kavoratoa-pa reasipaopa oa iava rera arova torioro voreopa.'),\n",
       "   ('xp',\n",
       "    'Meri i bin les long grile man na em i ranawe long em na em i ranawe i go bek.'),\n",
       "   ('xe', '???')]),\n",
       " ('kavori',\n",
       "  [('ps', 'N'),\n",
       "   ('pt', '???'),\n",
       "   ('ge', 'crayfish'),\n",
       "   ('ge', 'lobster'),\n",
       "   ('tkp', 'kindam'),\n",
       "   ('dt', '11/Feb/2007'),\n",
       "   ('cmt', 'What does <kakare> mean in last example sentence?'),\n",
       "   ('ex', 'Kavori votoupai ukoviroia.'),\n",
       "   ('xp', 'Kindam i save istap blong wara.'),\n",
       "   ('xe', 'Lobsters are usually in the water.'),\n",
       "   ('ex', 'Ragai kavoriparai ukova sirova uvare rirovira kavori ruipaparai.'),\n",
       "   ('xp', 'Mi kisim kindam arere long wara bikos mi laik kaikai tru kindam.'),\n",
       "   ('xe',\n",
       "    'I am catching crayfish by the water because I really like crayfish.'),\n",
       "   ('ex',\n",
       "    'Riropa kakare kavori okarea avakava sovaraia toupaiveira uva vokare ritapaiveira.'),\n",
       "   ('xp',\n",
       "    'Ol bikpela kindam i save stap insait long solwara we ol i save sutim ol.'),\n",
       "   ('xe',\n",
       "    'The big ??? crayfish, they live in the ocean where we spear them.')]),\n",
       " ('kavori',\n",
       "  [('ps', 'V'),\n",
       "   ('pt', 'A'),\n",
       "   ('ge', 'collect crayfish or lobster'),\n",
       "   ('tkp', 'kisim kindam'),\n",
       "   ('vx', '1'),\n",
       "   ('cmt', 'Need example to illustrate agreement'),\n",
       "   ('dt', '17/Oct/2005'),\n",
       "   ('ex', 'Kavorisia avau eisi ukovi.'),\n",
       "   ('xp', 'Yu go kisim kindam long wara.'),\n",
       "   ('xe', 'You go lobster-hunting in the water.')]),\n",
       " ('kavorou',\n",
       "  [('ps', 'V'),\n",
       "   ('pt', 'A'),\n",
       "   ('ge', 'covet'),\n",
       "   ('ge', 'keep something intended for another'),\n",
       "   ('ge', 'intercept'),\n",
       "   ('tkp', '???'),\n",
       "   ('cmt', 'Find an example without a discontinous NP'),\n",
       "   ('arg', 'OBL'),\n",
       "   ('vx', '2'),\n",
       "   ('cm', '-ia'),\n",
       "   ('sa', 'ogo'),\n",
       "   ('dt', '17/Oct/2005'),\n",
       "   ('ex', 'Eakere ragai vaaro-ia kavorouuei monia.'),\n",
       "   ('xp', '???'),\n",
       "   ('xe', 'Why are you keeping my money?'),\n",
       "   ('ex',\n",
       "    'Opeita oearovu vararo-ia kovorou ragapata vara oupasia voea siraopiepaoro.'),\n",
       "   ('xp',\n",
       "    'Noken putim nating skin nating long samting bilong narapela na putim nating long ol na mekim ol sori.'),\n",
       "   ('xe', '???')]),\n",
       " ('kavovoa',\n",
       "  [('rt', 'kavovo'),\n",
       "   ('ps', 'N'),\n",
       "   ('pt', 'NT'),\n",
       "   ('ge', 'valley'),\n",
       "   ('ge', 'ravine'),\n",
       "   ('tkp', 'maunten i stap olsem banis'),\n",
       "   ('tkp', 'maunten i stap raonim ol narapela'),\n",
       "   ('dt', '13/Nov/2005'),\n",
       "   ('ex', 'Kavovao va vao varata viapau karuviva toupai.'),\n",
       "   ('xp', 'Dispela valley i tumas open.'),\n",
       "   ('xe', '???'),\n",
       "   ('ex',\n",
       "    'Opukuirovu oara kavovoa purapaiveira opukui rovupa raviapau opukuiro? vurapape.'),\n",
       "   ('xp',\n",
       "    'Ol sampela maunten i save stap olsem banis long ol narapela maunten olsem na yumi no inap lukim ol narapela maunten.'),\n",
       "   ('xe', '???'),\n",
       "   ('ex', 'Kavovoa aue opukuirovu oara opukuirovu-re utopaiveira.'),\n",
       "   ('xp', 'Ol maunten i stap olsem banis long ol narapela maunten.'),\n",
       "   ('xe', '???'),\n",
       "   ('ex', 'Kavovovira pukuiara toupaiveira Sureko urui-re.'),\n",
       "   ('xp', 'Ol maunten i save stap raunim peles Sureko.'),\n",
       "   ('xe', '???')]),\n",
       " ('kavovovira',\n",
       "  [('alt', 'kavovopavira'),\n",
       "   ('rt', 'kavovo'),\n",
       "   ('ps', 'ADV'),\n",
       "   ('pt', 'MANNER'),\n",
       "   ('ge', 'open slightly'),\n",
       "   ('tkp', 'bikpela open spes'),\n",
       "   ('dt', '17/Oct/2005'),\n",
       "   ('ex', 'Kavovovira pukuiare toupai.'),\n",
       "   ('xp', 'Twopela mauntem istap op opew??.'),\n",
       "   ('xe', '???'),\n",
       "   ('ex',\n",
       "    'Sureko urui kavovovira toupaiveira uvare pukuiara vo uroi utopaivera.'),\n",
       "   ('xp',\n",
       "    'Ples Sureko i stap insait long banis bikos ol maunten i pasim dispela ples.'),\n",
       "   ('xe', '???')]),\n",
       " ('kavu',\n",
       "  [('ps', 'V'),\n",
       "   ('pt', 'A'),\n",
       "   ('ge', 'left.over'),\n",
       "   ('eng', 'left behind'),\n",
       "   ('eng', 'left over'),\n",
       "   ('tkp', 'lusim bihain'),\n",
       "   ('tkp', 'larim'),\n",
       "   ('vx', '1'),\n",
       "   ('sc', '???'),\n",
       "   ('dcpv', 'true'),\n",
       "   ('dt', '17/Oct/2005'),\n",
       "   ('cmt', 'Is there a transitive usage?'),\n",
       "   ('ex', 'Vokipavira-re varao kavupapiroi.'),\n",
       "   ('xp', '???'),\n",
       "   ('xe', 'These are left for tomorrow.'),\n",
       "   ('ex', 'Varao kavu vokipavirare oara aiopere.'),\n",
       "   ('xp', 'Ol dispela samting bai yu lusi bilong tumoro bai yumi kaikai.'),\n",
       "   ('xp', '???')]),\n",
       " ('kavu',\n",
       "  [('ps', 'V'),\n",
       "   ('pt', 'B'),\n",
       "   ('ge', 'leave.behind'),\n",
       "   ('eng', 'leave behind'),\n",
       "   ('tkp', 'larim'),\n",
       "   ('tkp', 'lusim'),\n",
       "   ('vx', '2'),\n",
       "   ('arg', 'O'),\n",
       "   ('sc', '???'),\n",
       "   ('dt', '08/Dec/2005'),\n",
       "   ('ex', 'Vaipeiri kavuoro kareroe Palavi eisi Vakora.'),\n",
       "   ('xp', 'Palavi em i bin lusim Vaipeiri long Wakunai.'),\n",
       "   ('xe', 'Palavi returned to Wakunai, leaving Vaiperi behind.')]),\n",
       " ('kavuava',\n",
       "  [('ps', 'N'),\n",
       "   ('pt', 'FEM'),\n",
       "   ('ge', 'limbum'),\n",
       "   ('tkp', '???'),\n",
       "   ('nt', 'small but very strong trunk'),\n",
       "   ('cmt', \"What's the plural?\"),\n",
       "   ('dt', '15/Apr/2006'),\n",
       "   ('ex', 'Koeta purapaveira aueia kavuova ova aue keta.'),\n",
       "   ('xp', 'Ol save wokum bubnana mhouse long piapela limbum??.'),\n",
       "   ('xe', '???'),\n",
       "   ('ex',\n",
       "    'Kavuava iria vosarao iava sirivuko siara uva garepaoi rutu sirivuko arapa.'),\n",
       "   ('xp', 'Wanpela kain limbum na i liklik tru long ol limbum.'),\n",
       "   ('xe', '???')]),\n",
       " ('kavupie',\n",
       "  [('rt', 'kavu'),\n",
       "   ('ps', 'V'),\n",
       "   ('pt', 'B'),\n",
       "   ('ge', 'leave.behind'),\n",
       "   ('tkp', 'wanpela man tasol oli lusim i dai'),\n",
       "   ('eng', 'leave behind'),\n",
       "   ('vx', '2'),\n",
       "   ('arg', 'O'),\n",
       "   ('nt', 'nickname of man left after all his relatives had died'),\n",
       "   ('dt', '08/Dec/2005'),\n",
       "   ('ex',\n",
       "    'Koikea iravu ira vaisipaiveira oisio kavupie aue iava uvare rera tatariako ora araoko irara rutu kopiiaepa rera raga arova oa iava rera vaisipaiveira oisio kavupie.'),\n",
       "   ('xp',\n",
       "    'Koike em wanpela man ol i save kolim em olsem kavupie long wanem olgeta lain. Brata na sista i dai lusim em tasol. Olsem na oli save kolim em olsem kavupie.'),\n",
       "   ('xe', '???'),\n",
       "   ('ex', 'Kavupietoavi era ira arova kopikopiaepa.'),\n",
       "   ('xp', 'Ol i bin dai lusim dispela man.'),\n",
       "   ('xe', '???'),\n",
       "   ('ex', 'Kavupietoavia era patoto ira kavuivo.'),\n",
       "   ('xp', 'Dispela pato ia em ol i lusim na ol i go nambaut.'),\n",
       "   ('xe', '???')]),\n",
       " ('kavura',\n",
       "  [('ps', 'N'),\n",
       "   ('pt', 'FEM'),\n",
       "   ('ge', 'copra'),\n",
       "   ('tkp', 'kopra'),\n",
       "   ('dt', '17/Oct/2005'),\n",
       "   ('ex',\n",
       "    'Opita kouro iava kavura purapaveira ra vara sipopaive vara-ia vori oupasia.'),\n",
       "   ('xp',\n",
       "    'Ol kokonat ol i save mekim kopra long em na ol i save salim bilong kisim moni.'),\n",
       "   ('xe',\n",
       "    'From coconuts they make copra and send them in order to make money from them.')]),\n",
       " ('kavurao',\n",
       "  [('ps', 'N'),\n",
       "   ('pt', 'FEM'),\n",
       "   ('ge', 'dust'),\n",
       "   ('tkp', 'das'),\n",
       "   ('dt', '17/Oct/2005'),\n",
       "   ('ex',\n",
       "    'Vori isi koveavo urua reroaro uva vaisi-re tararagapaoro kavurao-pa vavaerae.'),\n",
       "   ('xp',\n",
       "    'Moni mi mekim pundaun handanit long bet na mi painim nating na han bilong mi i pulap long das.'),\n",
       "   ('xe', '???')]),\n",
       " ('kavusi',\n",
       "  [('ps', 'V'),\n",
       "   ('pt', 'B'),\n",
       "   ('ge', 'spit_out'),\n",
       "   ('tkp', 'spet'),\n",
       "   ('eng', 'spit forcefully towards mark'),\n",
       "   ('eng', 'spit out'),\n",
       "   ('arg', 'O'),\n",
       "   ('vx', '2'),\n",
       "   ('dt', '31/Jan/2007'),\n",
       "   ('ex', 'Oira kopaoro rera kavusireva.'),\n",
       "   ('xp', '???'),\n",
       "   ('xe', 'Swallowing it, he spit it (something else) out.'),\n",
       "   ('ex',\n",
       "    'Tugarato riakorirei kopaoro uva okaotoova guruvaro kavusireva aue-ia revasi.'),\n",
       "   ('xp',\n",
       "    'Masalai i bin daonim pinis tupela meri na em i spetim lip bilong diwai talisa long blut.'),\n",
       "   ('xe', '???')]),\n",
       " ('kavuvo',\n",
       "  [('ps', 'N'),\n",
       "   ('pt', '???'),\n",
       "   ('ge', 'valley'),\n",
       "   ('ge', 'ravine'),\n",
       "   ('tkp', 'ples name long tupela maunten'),\n",
       "   ('dt', '29/Jan/2005')]),\n",
       " ('kea',\n",
       "  [('ps', 'V'),\n",
       "   ('pt', 'A'),\n",
       "   ('ge', 'confused'),\n",
       "   ('eng', 'think mistakenly'),\n",
       "   ('eng', 'confused'),\n",
       "   ('eng', 'deceived'),\n",
       "   ('tkp', 'giaman'),\n",
       "   ('cm', '-ia'),\n",
       "   ('arg', 'OBL COMP'),\n",
       "   ('cmt', 'Can you also get simply OBL for an argument?'),\n",
       "   ('vx', '2'),\n",
       "   ('dt', '17/Oct/2005'),\n",
       "   ('ex', 'Uva eva-ia keasiepa oiso iria ita uusipaoi.'),\n",
       "   ('xp', '???'),\n",
       "   ('xe', 'They both though in error (confused) that she was just sleeping.'),\n",
       "   ('ex',\n",
       "    'Aisi ragai kea-re uva voria oure oisio puraoro vavatepaavoi ikauvira.'),\n",
       "   ('xp',\n",
       "    'Aisi em i giamanim mi na em i kisim moni. Em i tok olsem bai mi givim hariap.'),\n",
       "   ('xe', '???')]),\n",
       " ('keakea',\n",
       "  [('rt', 'kea'),\n",
       "   ('ps', 'V'),\n",
       "   ('pt', 'B'),\n",
       "   ('rdp', 'full'),\n",
       "   ('ge', 'lie'),\n",
       "   ('tkp', 'tok giaman'),\n",
       "   ('eng', 'lie'),\n",
       "   ('arg', '???'),\n",
       "   ('vx', '???'),\n",
       "   ('cmt', \"What's going on with the second sentence?\"),\n",
       "   ('dt', '17/Feb/2006'),\n",
       "   ('ex',\n",
       "    'Vokiara rutu-ia ragai keakeapaiveira oisio vii vatepaio aue vori vii varo-ia kovoa.'),\n",
       "   ('xp',\n",
       "    'Olgeta dei ol i save giagiamanim mi olsem bai mipela i givim yu moni long wok bilong yu.'),\n",
       "   ('xe', 'Every day they deceive me ???.'),\n",
       "   ('ex', 'Voea keakea reo Vairi oisio eisi-va kareroe Vakora.'),\n",
       "   ('xp', 'Vairi em i giamanim ol olsem em i kam long Wakunai.'),\n",
       "   ('xe', '???')]),\n",
       " ('keakeato',\n",
       "  [('rt', 'keakea'),\n",
       "   ('ps', 'N'),\n",
       "   ('pt', 'HUM'),\n",
       "   ('ge', 'deceiver'),\n",
       "   ('tkp', 'man bilong giaman'),\n",
       "   ('dt', '17/Oct/2005'),\n",
       "   ('ex', 'Riro keakeato vii.'),\n",
       "   ('xp', 'Yu man bilong giaman.'),\n",
       "   ('xe',\n",
       "    'Pita kakaevure taviparevo oisio keakeato era ira urioparoi raiva-ia vokopaoro.'),\n",
       "   ('xp',\n",
       "    'Pita i tokim ol pikinini olsem em giaman ia i wokabaut i kam long rot.'),\n",
       "   ('xe', '???')]),\n",
       " ('keari',\n",
       "  [('ps', 'N'),\n",
       "   ('pt', 'MASC'),\n",
       "   ('ge', 'bamboo'),\n",
       "   ('tkp', 'mambu bilong wokim spia'),\n",
       "   ('nt', 'used for making arrow shafts'),\n",
       "   ('dt', '17/Oct/2005'),\n",
       "   ('ex', 'Keari aue paupasia rauru iapasi aue-ia koeta.'),\n",
       "   ('xp', 'Blong putim arrow na bai shut long bamboo.'),\n",
       "   ('xe', '???'),\n",
       "   ('ex',\n",
       "    'Kearia oa paupaiveira aue purapasia rauru vara-ia orekerovu riitapasia vara-ia.'),\n",
       "   ('xp',\n",
       "    'Tiktik ol i save planim bilong mekim spia bilong sutim ol narapela samting long em.'),\n",
       "   ('xe', '???')]),\n",
       " ('kearito',\n",
       "  [('rt', 'keari'),\n",
       "   ('ps', 'N'),\n",
       "   ('pt', 'MASC'),\n",
       "   ('ge', 'long arrow'),\n",
       "   ('tkp', 'longpela spia'),\n",
       "   ('dt', '17/Oct/2005'),\n",
       "   ('ex', 'Uriou kearitoa-va ira-ia rauruva puravere oira-ia kora ritapasia.'),\n",
       "   ('xp', 'Kam wantaim tiktik bai mi mekim spia bilong sutim kapul long em.'),\n",
       "   ('xe',\n",
       "    \"Come with an arrow from which I'll make a spear with which to spear possums.\")]),\n",
       " ('keavira',\n",
       "  [('alt', 'keapavira'),\n",
       "   ('rt', 'kea'),\n",
       "   ('ps', 'ADV'),\n",
       "   ('pt', 'MANNER'),\n",
       "   ('ge', 'deceptively'),\n",
       "   ('ge', 'confused'),\n",
       "   ('tkp', 'olsem giaman'),\n",
       "   ('dt', '17/Oct/2005'),\n",
       "   ('cmt',\n",
       "    'Is there an objevt missing in the second clause of the 2nd example sentence?'),\n",
       "   ('ex', 'Keavira uusisia avau.'),\n",
       "   ('xp', 'Yu go slip giaman long hap.'),\n",
       "   ('xe', 'You go pretend to be asleep.'),\n",
       "   ('ex', 'Vao keavira tousia avau.'),\n",
       "   ('xp', 'Yu go i stap giaman long hap.'),\n",
       "   ('xe', '???'),\n",
       "   ('ex',\n",
       "    'Suparai keavira tuutaa taparevoi uva kepa rutu kovei uvare viapau oiraopavira rutu vataparevo.'),\n",
       "   ('xp',\n",
       "    'Suparai em i giaman nilim pos na haus i pundaun olgeta bikos em i no nilim tru.'),\n",
       "   ('xe',\n",
       "    \"Suparai didn't really nail the post and the house fell down because he didn't nail it properly.\")]),\n",
       " ('kee',\n",
       "  [('ps', 'V'),\n",
       "   ('pt', 'B'),\n",
       "   ('ge', 'shatter'),\n",
       "   ('ge', 'fracture'),\n",
       "   ('ge', 'chip'),\n",
       "   ('tkp', 'brukim'),\n",
       "   ('nt', 'applies to brittle objects'),\n",
       "   ('arg', 'O'),\n",
       "   ('vx', '2'),\n",
       "   ('dt', '27/Oct/2005'),\n",
       "   ('ex', 'Botol tou keerevora va kovepaoro.'),\n",
       "   ('xp', '???'),\n",
       "   ('xe', 'He shattered the bottle, dropping it.'),\n",
       "   ('ex', 'Aguvi tou keepi Pita votouaru uvare rasito iare kove.'),\n",
       "   ('xp', 'Botol i bruk bikos i pundaon i go daon long graon.'),\n",
       "   ('xe', '???')]),\n",
       " ('keekee',\n",
       "  [('rt', 'kee'),\n",
       "   ('ps', 'V'),\n",
       "   ('pt', 'A'),\n",
       "   ('rdp', 'full'),\n",
       "   ('ge', 'chipped'),\n",
       "   ('ge', 'shattered'),\n",
       "   ('tkp', '???'),\n",
       "   ('vx', '1'),\n",
       "   ('cmt', \"What's up with -viro?\"),\n",
       "   ('dt', '27/Oct/2005'),\n",
       "   ('ex', 'Sisiro keekeeoviropa.'),\n",
       "   ('xp', '???'),\n",
       "   ('xe', 'The mirror is shattered.'),\n",
       "   ('ex', 'Sisiro keekee eva evoa toupai rasito ivaraia.'),\n",
       "   ('xp', 'Brukbruk mirror ia istap hantap long graon.'),\n",
       "   ('xe', '???')]),\n",
       " ('keekeepa',\n",
       "  [('rt', 'kee'),\n",
       "   ('ps', 'N'),\n",
       "   ('pt', 'NT'),\n",
       "   ('ge', 'shattered object'),\n",
       "   ('ge', 'fractured object'),\n",
       "   ('tkp', '???'),\n",
       "   ('dt', '27/Oct/2005'),\n",
       "   ('ex', 'Keekeepa sigoa.'),\n",
       "   ('xp', 'Naip i bruk pinis.'),\n",
       "   ('xe', 'The knife is broken.'),\n",
       "   ('ex', 'Pita keekeepa sigoa ari ragai vearoa sigoa.'),\n",
       "   ('xp', 'Pita i gat naip i brukbruk tasol mi gat gutpela.'),\n",
       "   ('xe', 'Peter has a broken knife but I have a good one.')]),\n",
       " ('keekeeri',\n",
       "  [('rt', 'keeri'),\n",
       "   ('ps', 'N'),\n",
       "   ('pt', 'NT'),\n",
       "   ('ge', 'spear'),\n",
       "   ('tkp', '???'),\n",
       "   ('nt',\n",
       "    'similar toraavai but only small area fitted with flying fox bones,'),\n",
       "   ('dt', '07/Sep/2006'),\n",
       "   ('ex',\n",
       "    'Keekeerin puraiveira aueiva gari araivo ra auetapo tukepaiveira aatu keruro.'),\n",
       "   ('xp', 'Spia ol i sone putim makmak long en wantim bones blon blak bokis.'),\n",
       "   ('xe', '???'),\n",
       "   ('ex', 'Rauru kae keekeeri-pa.'),\n",
       "   ('xp', 'Spia i gat makmak long em.'),\n",
       "   ('xe', 'The spear has marking.')]),\n",
       " ('keekeerito',\n",
       "  [('rt', 'keekeeri'),\n",
       "   ('ps', 'N'),\n",
       "   ('pt', 'MASC'),\n",
       "   ('ge', 'insert to hold arrow tip'),\n",
       "   ('tkp', 'het bilong mekpas bilong spia'),\n",
       "   ('dt', '07/Sep/2006'),\n",
       "   ('ex',\n",
       "    'Keekeerito ira purapaiveira aue iava aari ova aatu keruro rauru kaero-ia.'),\n",
       "   ('xp',\n",
       "    'Ol save workim ol makmak na putim i go bowes bilong [flying fox] long ol spia; na kamapim ol makmak.'),\n",
       "   ('xe', '???, they made it from ??? flying fox bones on the spears.')]),\n",
       " ('keera',\n",
       "  [('ps', 'V'),\n",
       "   ('pt', 'A'),\n",
       "   ('ge', 'call.for'),\n",
       "   ('eng', 'call for'),\n",
       "   ('eng', 'beckon to'),\n",
       "   ('eng', 'signal for meeting'),\n",
       "   ('tkp', 'singaut'),\n",
       "   ('tkp', 'kolim'),\n",
       "   ('cm', '-re'),\n",
       "   ('vx', '2'),\n",
       "   ('arg', 'OBL'),\n",
       "   ('sc', 'EMISSION.SOUND'),\n",
       "   ('cmt',\n",
       "    \"What's the story with the last sentence, Pita keerapa viire pausia?\"),\n",
       "   ('dt', '15/Nov/2005'),\n",
       "   ('ex', 'Rerare keeraiepa, Auoro Soraviri, varau!'),\n",
       "   ('xp', '???'),\n",
       "   ('xe', 'We (exclusive) called to him, Hey Soraviri, come down!'),\n",
       "   ('ex', 'Keera avakava sirova toupareveira atari aiopaaro.'),\n",
       "   ('xp', 'Keera em i save i stap tasol solwara kaikaim of liklik fish.'),\n",
       "   ('xe', '???'),\n",
       "   ('ex', 'Gurukoa eva toivaiva oa oirara-re keerapai.'),\n",
       "   ('xp', 'Krai bilong garamut i singautim ol man.'),\n",
       "   ('xe', 'The garamut is a ??? that signals people.'),\n",
       "   ('ex', 'Keerapa ra avasi eisi karoa.'),\n",
       "   ('xp', 'Tun i singaut long yu bai yupela i go long gaden.'),\n",
       "   ('xe', '???'),\n",
       "   ('ex', 'Pita keerapa vii-re pausia.'),\n",
       "   ('xp', 'Pita sigaut long yu bai yupela sitdown.'),\n",
       "   ('xe', 'Pita calls for you to sit down.')]),\n",
       " ('keeriva',\n",
       "  [('ps', '???'),\n",
       "   ('ge', 'crest of cockatoo'),\n",
       "   ('tkp', 'kangai'),\n",
       "   ('cmt',\n",
       "    'glossed in Tok Pisin as \"gras bilong koki ol i save brukim na pas bilogn putim long het\"'),\n",
       "   ('dt', '27/Oct/2005'),\n",
       "   ('ex',\n",
       "    'Keeriva iria purapaiveira kokio kare oruaro-ia oisio osia kakata ra vara-va pupipaive.'),\n",
       "   ('xp',\n",
       "    'Gras bilong feather ol i save mekim gras bilong ol pisin olsem koki na ol i save singsing kaul wantaim.'),\n",
       "   ('xe', '???')]),\n",
       " ('keesi',\n",
       "  [('ps', 'N'),\n",
       "   ('pt', 'NT'),\n",
       "   ('ge', 'box'),\n",
       "   ('eng', 'box'),\n",
       "   ('eng', 'case'),\n",
       "   ('tkp', 'kes'),\n",
       "   ('nt', 'Tok Pisin loan'),\n",
       "   ('dt', '30/Apr/2006')]),\n",
       " ('keetaa',\n",
       "  [('ps', 'N'),\n",
       "   ('pt', 'NT'),\n",
       "   ('ge', 'jaw'),\n",
       "   ('tkp', 'wasket'),\n",
       "   ('eng', 'chin'),\n",
       "   ('eng', 'jaw'),\n",
       "   ('eng', 'mandible'),\n",
       "   ('dt', '27/Oct/2005'),\n",
       "   ('ex',\n",
       "    'Keetaa oirato iava gasiivo ora upopaoro vokiaro. Uva viapau vearovira aioparevo uvare keetaa grasipiro.'),\n",
       "   ('xp',\n",
       "    'Wisket bilong man ol i brukim taim ol i pait long nait. Na em i no wok long kaikai bikos wisket em i bruk.'),\n",
       "   ('xe', '???')]),\n",
       " ('keevuru',\n",
       "  [('ps', 'V'),\n",
       "   ('pt', 'A'),\n",
       "   ('ge', 'glide'),\n",
       "   ('tkp', '???'),\n",
       "   ('cmt', 'Check classification. Example has Class B agreement, no?'),\n",
       "   ('vx', '1'),\n",
       "   ('dt', '27/Oct/2005'),\n",
       "   ('ex', 'Keevuruparoi keravo.'),\n",
       "   ('xp', '???'),\n",
       "   ('xe', 'The hawk is gliding (through the air).')]),\n",
       " ('keevuruvira',\n",
       "  [('rt', 'keevuru'),\n",
       "   ('ge', '???'),\n",
       "   ('tkp', '???'),\n",
       "   ('dt', '18/Apr/2007'),\n",
       "   ('ex',\n",
       "    'Kokio kare keevuruvira papapaiveira keauvere oisio koveroi rara kevururo vara???.'),\n",
       "   ('xp',\n",
       "    'Ol pisin i save plai isisi antap. Na ai yu ting olsem bai em i pundaun taim i plai ???.'),\n",
       "   ('xe', 'Birds fly gliding ???')]),\n",
       " ('kegi',\n",
       "  [('ps', 'V'),\n",
       "   ('pt', 'B'),\n",
       "   ('ge', 'taunt'),\n",
       "   ('tkp', 'duim'),\n",
       "   ('tkp', 'posim'),\n",
       "   ('vx', '2'),\n",
       "   ('arg', 'O COMP'),\n",
       "   ('dt', '27/Oct/2005'),\n",
       "   ('ex', 'Ragai kegiparevoi va purasia osa reasiparai va puraarapa.'),\n",
       "   ('xp', '???'),\n",
       "   ('xe', 'He is taunting me to do it, as I am not wanting to do it.'),\n",
       "   ('ex',\n",
       "    'Virievi iria ragai kegipaoro ragai tapo avaoe eisi-re kovoa osia reasiragaparae.'),\n",
       "   ('xp',\n",
       "    'Virievi i wok long posim mi na em i go wantaim mi long gaden taim mi wok long les.'),\n",
       "   ('xe', '???')]),\n",
       " ('kei',\n",
       "  [('ps', 'N'),\n",
       "   ('pt', 'NT'),\n",
       "   ('ge', 'house with a single pitch roof'),\n",
       "   ('tkp', 'haus i gat wanpela sait rup bilong haus'),\n",
       "   ('nt', 'Full form is <kei kepa>.'),\n",
       "   ('cmt', 'Is \"lean-to\" a good translation?'),\n",
       "   ('dt', '10/Jan/2007'),\n",
       "   ('ex', 'Avaisisi ira kei kepa-ia uusiparoveira vegoaro.'),\n",
       "   ('xp', 'Avaisisi em i save slip long wansait haus long bus.'),\n",
       "   ('xe', 'Avaisisi sleeps in a lean-to in the jungle.')]),\n",
       " ('keke',\n",
       "  [('ps', 'V'),\n",
       "   ('pt', 'B'),\n",
       "   ('ge', 'look_at'),\n",
       "   ('eng', 'look at'),\n",
       "   ('tkp', 'lukim'),\n",
       "   ('vx', '2'),\n",
       "   ('arg', 'O'),\n",
       "   ('cmt', 'Example needed'),\n",
       "   ('sc', 'PERCEPTION'),\n",
       "   ('dcpv', 'true'),\n",
       "   ('dt', '15/Feb/2007'),\n",
       "   ('ex',\n",
       "    'Aakova kakaeto tavipaevo oisio keke osia vitavipaveira oisio opeita sigoa-ia pitupari teapi oratoeu.'),\n",
       "   ('xp',\n",
       "    'Mama i tokim pikinini olsem, Lukim nau, olsem mi save tokim, yu no ken holim naip nogut yu katim yu yet.'),\n",
       "   ('xe', '???'),\n",
       "   ('ex', 'Asia ira Arari kekere ovusia gaupare aakova-pa.'),\n",
       "   ('xp', 'Asia em i lukim Arari taim emi krai long mama bilong em.'),\n",
       "   ('xe', '???'),\n",
       "   ('ex', 'Ragai keke ovusia oravikira vo rovua-ia.'),\n",
       "   ('xp', 'Lukim mi taim mi kalap long wara.'),\n",
       "   ('xe', '???')]),\n",
       " ('keke',\n",
       "  [('ps', 'V'),\n",
       "   ('pt', 'A'),\n",
       "   ('ge', 'look'),\n",
       "   ('tkp', 'luk'),\n",
       "   ('dcsv', 'true'),\n",
       "   ('vx', '1'),\n",
       "   ('dcpv', '???'),\n",
       "   ('dadv', '???'),\n",
       "   ('dt', '19/Mar/2006'),\n",
       "   ('ex', 'Vearo kekepau ragai osireiaro-ia vii oupa ovusia ragai taviri.'),\n",
       "   ('xp',\n",
       "    'Yu luk gut tru long ai bilong mi bai mi maritim yu sapos yu tok orait.'),\n",
       "   ('xe', 'You look good in my eyes I will marry you if you tell me.'),\n",
       "   ('ex', 'Vo araorei kataivira kekepasiei.'),\n",
       "   ('xp', 'Tupela brata i luk wankain.'),\n",
       "   ('xe', 'The two brothers look the same.')]),\n",
       " ('kekepie',\n",
       "  [('rt', 'keke'),\n",
       "   ('ps', 'V'),\n",
       "   ('pt', 'B'),\n",
       "   ('ge', 'show'),\n",
       "   ('tkp', 'soim'),\n",
       "   ('tkp', 'kamapim'),\n",
       "   ('arg', '???'),\n",
       "   ('vx', '???'),\n",
       "   ('dt', '08/Dec/2005'),\n",
       "   ('ex',\n",
       "    'Rarasori oirara kekepiepare kovoa-ia oisio osia ragavira va sirova utuavere va puraoro.'),\n",
       "   ('xp', 'Rarason em i soim ol man long hao bai ol lukim na bihainim.'),\n",
       "   ('xe',\n",
       "    'Robinson is showing people the work so that they can do it in the same way.'),\n",
       "   ('ex', 'Kekepie sopa rutu vavao oa karekepiepareva Rarasori.'),\n",
       "   ('xp', 'Wanpela kain samting tru ia Rarason wok long soim.'),\n",
       "   ('xe', '???')]),\n",
       " ('kekeputu',\n",
       "  [('ps', 'V'),\n",
       "   ('pt', 'A'),\n",
       "   ('ge', 'nearly'),\n",
       "   ('ge', 'almost'),\n",
       "   ('tkp', 'klostu tru'),\n",
       "   ('vx', '1'),\n",
       "   ('cmt', 'Can this have a real subject, as opposed to a dummy subject?'),\n",
       "   ('dt', '27/Oct/2005'),\n",
       "   ('ex', 'Kekeputui vuuta ra karesi.'),\n",
       "   ('xp', '???'),\n",
       "   ('xe', 'The time is nearly present for you both to return.'),\n",
       "   ('ex',\n",
       "    'Vuuta kekeputupaoro avapai Rarasori-pa ra vatuava kekesia karero atoia.'),\n",
       "   ('xp',\n",
       "    'Taim i wok long klostu nao bilong Rarason bai em go bek long ples na lukim meri bilong em.'),\n",
       "   ('xe', '???')]),\n",
       " ('kekeputuvira',\n",
       "  [('alt', 'kekeputupavira'),\n",
       "   ('rt', 'kekeputu'),\n",
       "   ('ps', 'ADV'),\n",
       "   ('pt', 'MANNER'),\n",
       "   ('ge', 'close'),\n",
       "   ('ge', 'nearly'),\n",
       "   ('tkp', '???'),\n",
       "   ('nt', 'Alternate forms kekeputu and keputu are used.'),\n",
       "   ('dt', '27/Oct/2005'),\n",
       "   ('ex', 'Kekeputuvira va tovorivo.'),\n",
       "   ('xp', '???'),\n",
       "   ('xe', 'You put it very close to the edge.'),\n",
       "   ('ex',\n",
       "    'Vuuta vurapaavoi kekeputuvira kokeva vo vuutaro. Oa-ia viapau avarae eisi-re kovoa.'),\n",
       "   ('xp',\n",
       "    'Taim em mi lukim olsem i klostu taim bilong ren bai pundaon olsem na mi no go long gaden.'),\n",
       "   ('xe', '???')]),\n",
       " ('kekeraokovira',\n",
       "  [('alt', 'kekeraokopavira'),\n",
       "   ('rt', 'kekeraoko'),\n",
       "   ('ps', 'ADV'),\n",
       "   ('pt', 'MANNER'),\n",
       "   ('ge', 'nicely'),\n",
       "   ('tkp', '???'),\n",
       "   ('dt', '12/Dec/2006'),\n",
       "   ('ex', 'Kekeraokovira rutu va puraparivoi.'),\n",
       "   ('xp', '???'),\n",
       "   ('xe', 'You are making it very nicely.'),\n",
       "   ('ex',\n",
       "    'Tevire ira torara iava kakurao purarevo kekeraukovira uva eva raga oa iava vaa voriavo.'),\n",
       "   ('xp',\n",
       "    'Tevire i wokim handol bilong tamiok i luk olsem naispela tru. Long dispela tasol na m baim.'),\n",
       "   ('xe', 'Tevire made a nice handle for the axe ???.'),\n",
       "   ('ex', 'Kekeraokovira Tevire kakuraoro purapareveira torarara iare.'),\n",
       "   ('xp', 'Tevire em i save wokim ol gutpela handol bilong ol tamiok.'),\n",
       "   ('xe', '???')]),\n",
       " ('kekesopa',\n",
       "  [('ps', 'N'),\n",
       "   ('pt', 'FEM'),\n",
       "   ('ge', 'tree'),\n",
       "   ('tkp', '???'),\n",
       "   ('nt', 'Its fragrant leaves used when cooking opossum.'),\n",
       "   ('sf', 'FLORA'),\n",
       "   ('dt', '28/Jan/2005'),\n",
       "   ('ex',\n",
       "    'Kekesopa riro sesi arut va guruvaro ia kova oripaveira ora oaravu varuere ara.'),\n",
       "   ('xp',\n",
       "    'Kekesopa wanpola kain diwai isave simell get toy ol save kukua wantam olmeat blong kapul na ol kain hamusi.'),\n",
       "   ('xe', '???')]),\n",
       " ('kekevoto',\n",
       "  [('ps', '???'),\n",
       "   ('dx', 'Central'),\n",
       "   ('ge', '???'),\n",
       "   ('tkp', '???'),\n",
       "   ('dt', '27/Aug/2005'),\n",
       "   ('nt',\n",
       "    'hypothetical root which does not occur without derivational morphology--<ora>- or -<vira>'),\n",
       "   ('cmt', 'Sera not sure about word---possibly archaic')]),\n",
       " ('kekevotovira',\n",
       "  [('alt', 'kekevotopavira'),\n",
       "   ('rt', 'kekevoto'),\n",
       "   ('ps', 'ADV'),\n",
       "   ('pt', 'MANNER'),\n",
       "   ('ge', 'out of sight'),\n",
       "   ('ge', 'slyly'),\n",
       "   ('tkp', 'luk olsem holim pas'),\n",
       "   ('tkp', 'i no inap larim'),\n",
       "   ('dt', '11/Feb/2007'),\n",
       "   ('ex', 'Kekevotovira va kaeri.'),\n",
       "   ('xp', '???'),\n",
       "   ('xe', 'Carry it so that no one sees it.'),\n",
       "   ('ex',\n",
       "    'Vuataevi iria kekevotovira voriara-ia pitupaeveira viapau uvuipaoi ra ikauvira oa-ia vorio.'),\n",
       "   ('xp',\n",
       "    'Vuataevi em meri holim pas moni. em i no nap baem kuik samting long moni.'),\n",
       "   ('xe',\n",
       "    \"Vuataevi always holds on to money secretely and won't go shopping with it.\")]),\n",
       " ('kekira',\n",
       "  [('ps', 'N'),\n",
       "   ('pt', 'MASC'),\n",
       "   ('ge', 'moon'),\n",
       "   ('ge', 'month'),\n",
       "   ('tkp', 'mun'),\n",
       "   ('dt', '27/Oct/2005'),\n",
       "   ('ex', 'Kekira viei vo katai iva sovaraia.'),\n",
       "   ('xp', 'Namben blong ol moon long wonpela year.'),\n",
       "   ('xe', '???'),\n",
       "   ('ex', 'Eraopiepatoa-ia kekira ira-ia kakaevure sikuru rovopaveira.'),\n",
       "   ('xp', 'Nabatu mun ol pikinini i save statim skul bilong ol.'),\n",
       "   ('xe', '???')]),\n",
       " ('keo',\n",
       "  [('ps', 'V'),\n",
       "   ('pt', 'B'),\n",
       "   ('ge', 'give a party'),\n",
       "   ('ge', 'make a feast'),\n",
       "   ('tkp', 'mekim pati'),\n",
       "   ('vx', '???'),\n",
       "   ('arg', '???'),\n",
       "   ('cmt', 'Clearer examples needed.'),\n",
       "   ('dt', '08/Jun/2005'),\n",
       "   ('ex', 'Vao vioia keo uva aioro opoa.'),\n",
       "   ('xp', 'Yo kaikai diapela hap taro.'),\n",
       "   ('xe', '???'),\n",
       "   ('ex', 'Keosia uriouei vo aio-ia oa puraiovoi vii-pa riro aio rutu.'),\n",
       "   ('xp', 'Mipela mekim dispela bikpela party long yu.'),\n",
       "   ('xe', '???'),\n",
       "   ('ex', 'Sisivarea kookai rutu aiorevo rera-ia keoro uva kopiiroe.'),\n",
       "   ('xp', 'Sisivarea em i kaikaim kakaruk olgeta na em dai.'),\n",
       "   ('xe', 'Sisivarea ate all of the roosters ??? and he died.')]),\n",
       " ('keoka',\n",
       "  [('ps', 'V'),\n",
       "   ('pt', 'A'),\n",
       "   ('ge', 'left over'),\n",
       "   ('ge', 'surplus'),\n",
       "   ('tkp', 'lep'),\n",
       "   ('vx', '???'),\n",
       "   ('dt', '27/Oct/2005'),\n",
       "   ('cmt', 'Archaic?'),\n",
       "   ('ex', 'Vao oa putepaivo voviei ivaraia.'),\n",
       "   ('xp', 'Waneme I left over long wamber??.'),\n",
       "   ('xe', '???'),\n",
       "   ('ex',\n",
       "    'Keoka iraorai riroara rutu aiooro varuara osia viapau vara opesipieavo uvare vukurae uva oaravu touvira toupaivo.'),\n",
       "   ('xp',\n",
       "    'Mi napim laik bilong kaikai planti habus tru. Tasol mi no pinisim olgeta bikos mi pulap olsem na sampela i stap yet.'),\n",
       "   ('xe', '???')]),\n",
       " ('keopa',\n",
       "  [('ps', 'V'),\n",
       "   ('pt', 'A'),\n",
       "   ('ge', 'taste good'),\n",
       "   ('tkp', 'swit'),\n",
       "   ('am', 'false'),\n",
       "   ('vx', '1'),\n",
       "   ('dt', '27/Oct/2005'),\n",
       "   ('ex', 'Vearo supu rutu vaoia atari supu oa-ia ora keopa.'),\n",
       "   ('xp', '???'),\n",
       "   ('xe', '???'),\n",
       "   ('ex', 'Keoparoi rutu rovo supu oia va aioro.'),\n",
       "   ('xp', '???'),\n",
       "   ('xe', '???'),\n",
       "   ('ex',\n",
       "    'Keopa rutu eva varua oavaterevora Rarasori Mateas-pa. Uva va-ia keopa va aiopaoro.'),\n",
       "   ('xp',\n",
       "    'Em wanpela gutpela mit Rarason i bin givim long Matias. Nea em i wok long testim gut tru taim em i kaikai.'),\n",
       "   ('xe', '???')]),\n",
       " ('keovira',\n",
       "  [('alt', 'keopavira'),\n",
       "   ('rt', 'keo'),\n",
       "   ('ps', 'ADV'),\n",
       "   ('pt', 'MANNER'),\n",
       "   ('ge', 'sweetly'),\n",
       "   ('tkp', '???'),\n",
       "   ('dt', '27/Oct/2005'),\n",
       "   ('ex', 'Keopavira rutu vo supue??purariroi oa aiopaiovoi.'),\n",
       "   ('xp', 'Dispela sop emi sweet tra mipalal ikaikaim.'),\n",
       "   ('xe', '???'),\n",
       "   ('ex',\n",
       "    'Kokai pitoka keopavira rutu gesiei uvare va iava ivita verarevo kakaeto.'),\n",
       "   ('xp',\n",
       "    'Sospen kakaruk i olsem smel suit tru, bikos pikinini i raosim lit bilong pot.'),\n",
       "   ('xe', '???')]),\n",
       " ('kepa',\n",
       "  [('ps', 'N'),\n",
       "   ('pt', 'NT'),\n",
       "   ('ge', 'house'),\n",
       "   ('tkp', 'haus'),\n",
       "   ('eng', 'house'),\n",
       "   ('eng', 'building'),\n",
       "   ('dt', '27/Oct/2005'),\n",
       "   ('ex', 'Uusipa kepa.'),\n",
       "   ('xp', 'Haus bilong sleep.'),\n",
       "   ('xe', 'Sleep house.'),\n",
       "   ('ex', 'Kepa oavivu rutu oa oirara rutu tauvapaiveira rasitoa rutu-ia.'),\n",
       "   ('xp',\n",
       "    'Haus em wanpela samting tru i save halivim tru olgeta man olgeta hap bilong graun.'),\n",
       "   ('xe', '???')]),\n",
       " ('kepa toupato',\n",
       "  [('rt', 'kepa'),\n",
       "   ('rt', 'tou'),\n",
       "   ('ps', 'N'),\n",
       "   ('pt', 'HUM'),\n",
       "   ('dx', 'Central'),\n",
       "   ('ge', 'homebody'),\n",
       "   ('tkp', 'man i save stap long haus tasol'),\n",
       "   ('dt', '02/Sep/2005')]),\n",
       " ('kepetai',\n",
       "  [('ps', 'N'),\n",
       "   ('pt', 'FEM'),\n",
       "   ('ge', 'tall woman'),\n",
       "   ('tkp', '???'),\n",
       "   ('dt', '28/Jan/2005')]),\n",
       " ('kepi',\n",
       "  [('ps', 'V'),\n",
       "   ('pt', 'B'),\n",
       "   ('ge', 'fracture'),\n",
       "   ('ge', 'break'),\n",
       "   ('tkp', 'brukim'),\n",
       "   ('arg', 'O'),\n",
       "   ('vx', '2'),\n",
       "   ('dt', '20/Nov/2006'),\n",
       "   ('ex', 'Teapi ragai kokotoaro kepiive.'),\n",
       "   ('xp', '???'),\n",
       "   ('xe', \"It wouldn't be good if they fractured my leg.\"),\n",
       "   ('ex', 'Vosia kokotoa vii iava kepipiro ra viapau uvuipauei ra vokapari.'),\n",
       "   ('xp', 'Sapos lek bilong yu i bruk bai yu no inap wokabaut.'),\n",
       "   ('xe', \"If your leg is broken, you can't walk around.\")]),\n",
       " ('kepia',\n",
       "  [('ps', 'N'),\n",
       "   ('pt', 'NT'),\n",
       "   ('ge', 'nest'),\n",
       "   ('tkp', '???'),\n",
       "   ('nt',\n",
       "    'made of sticks and woven into loose platform, built by crows, hawks, etc.'),\n",
       "   ('dt', '27/Oct/2005'),\n",
       "   ('ex',\n",
       "    'Kepia oa purapaiveira kokio kare aue-ia garepa raorovi rutu evaoraoro ra voa takura kouave vo kepi-ia.'),\n",
       "   ('xp',\n",
       "    'Haus ol pisin i save wokim long ol liklik han tru bilong diwai. Na bai oli putim kiau long dispela haus.'),\n",
       "   ('xe', '???')]),\n",
       " ('kepikepi',\n",
       "  [('rt', 'kepi'),\n",
       "   ('ps', 'N'),\n",
       "   ('pt', 'NT'),\n",
       "   ('cl', 'isi'),\n",
       "   ('ge', 'tree fern'),\n",
       "   ('tkp', '???'),\n",
       "   ('sf', 'FAUNA'),\n",
       "   ('nt', 'small with thorns and edible new shoots'),\n",
       "   ('dt', '12/Feb/2005'),\n",
       "   ('ex',\n",
       "    'Kepikesi oiso toupai oga evava?? Votoupai veira regoarorirovira kupei aro karupiepai vosa aire paraoro purasa auepa pe ra kupeivira toupaive ra kavupaive.'),\n",
       "   ('xp',\n",
       "    'Em iotsen?? Wanpela diwai??em isave kamapim ol new pela hand blong plaint istap long bush.'),\n",
       "   ('xe', '???')]),\n",
       " ('kepiko',\n",
       "  [('rt', '???'),\n",
       "   ('ps', '???'),\n",
       "   ('ge', '???'),\n",
       "   ('tkp', 'wanpela plant'),\n",
       "   ('dt', '27/Oct/2005'),\n",
       "   ('ex', '???'),\n",
       "   ('xp', '???'),\n",
       "   ('xe', '???'),\n",
       "   ('ex', 'Votoupai vegoao riro kaekaepa guruvaro.'),\n",
       "   ('xp', 'Kepiko isave istap long ol diwai em long pela leaf.'),\n",
       "   ('xe', '???'),\n",
       "   ('ex',\n",
       "    'Kepikoa oa kovapapaeira evaoara kovuaro-ia. Vara ivaratapo korakare toupaiveira.'),\n",
       "   ('xp',\n",
       "    'Kepiko emi wanpela kain plant i save gro long namel bilong diwai. Na ol kapul i save stap hantap long em tu.'),\n",
       "   ('xe', '???')]),\n",
       " ('kepiriko',\n",
       "  [('ps', 'N'),\n",
       "   ('pt', 'NT'),\n",
       "   ('ge', 'betel pepper vine with fragrant leaf'),\n",
       "   ('tkp', 'sampela kain diwai'),\n",
       "   ('nt', 'A wild type and not eaten.'),\n",
       "   ('dt', '27/Oct/2005'),\n",
       "   ('ex',\n",
       "    'Kepiriko evaova vaisiaro oa oupaiveira va-va pupipasia ovusia gesipape vearopievira.'),\n",
       "   ('xp',\n",
       "    'Kepiriko i nem bilong wanpela diwai ol i save kisim bilong singsing kaul wantaim na bai save smel gut tru.'),\n",
       "   ('xe',\n",
       "    'Kepiriko is the name of a tree that they get to singsing with while it smells good.')]),\n",
       " ('kepiro',\n",
       "  [('ps', 'N'),\n",
       "   ('pt', 'FEM'),\n",
       "   ('ge', 'cicada'),\n",
       "   ('tkp', 'wanpela kain binatang'),\n",
       "   ('nt', 'largest type'),\n",
       "   ('sf', 'FAUNA.INSECT'),\n",
       "   ('dt', '27/Oct/2005'),\n",
       "   ('ex',\n",
       "    'Kepiro vosia raoiava sikokare vosiararo. Riro kukueva irova ora putaeuarei pokopokopiepaeveira ra gurukopaive.'),\n",
       "   ('xp',\n",
       "    'Cicada em i wanpela binatang long ol lain bilong grasopa. Em i gat bikpela het na tu emi sae pairapim tupela wing bilong em i save krai.'),\n",
       "   ('xe', '???')]),\n",
       " ('kepisi',\n",
       "  [('ps', 'V'),\n",
       "   ('pt', '???'),\n",
       "   ('dx', 'Central'),\n",
       "   ('ge', 'dam'),\n",
       "   ('tkp', 'pasim wara'),\n",
       "   ('vx', '???'),\n",
       "   ('dt', '22/Nov/2005'),\n",
       "   ('ex', '???'),\n",
       "   ('xp', '???'),\n",
       "   ('xe', '???')]),\n",
       " ('kepisiva',\n",
       "  [('rt', 'kepisi'),\n",
       "   ('ps', 'N'),\n",
       "   ('pt', 'FEM'),\n",
       "   ('dx', 'Central'),\n",
       "   ('ge', 'dam'),\n",
       "   ('tkp', 'dam'),\n",
       "   ('dt', '21/Aug/2005'),\n",
       "   ('ex', '???'),\n",
       "   ('xp', '???'),\n",
       "   ('xe', '???')]),\n",
       " ('kepita',\n",
       "  [('rt', 'kepi'),\n",
       "   ('ps', 'N'),\n",
       "   ('pt', 'NT'),\n",
       "   ('ge', 'firewood stick'),\n",
       "   ('tkp', '???'),\n",
       "   ('dt', '27/Oct/2005'),\n",
       "   ('ex', 'Kepitara evao raortro gareparavi.'),\n",
       "   ('xp', 'Liklik hand blong diwai.'),\n",
       "   ('xe', '???'),\n",
       "   ('ex', 'Sopia kepitara ouri ra tuitui kasi puraa.'),\n",
       "   ('xp', 'Spia, yu kisim ol pai wut na bai  mi wokim paia.'),\n",
       "   ('xe', '???')]),\n",
       " ('kepitai',\n",
       "  [('ps', 'N'),\n",
       "   ('pt', 'FEM'),\n",
       "   ('ge', 'small girl'),\n",
       "   ('tkp', '???'),\n",
       "   ('nt',\n",
       "    'Also used as a nickname which stays with the female even as an adult.'),\n",
       "   ('dt', '27/Oct/2005'),\n",
       "   ('ex',\n",
       "    'Kepitai vosia garevisivi aakova vo kakae kavaueve ra eisi oira vaisipaive oisio kepitai.'),\n",
       "   ('xp',\n",
       "    'Liklik bun nating meri taim mama i karim em ol i save kolim liklik longpela bun nating meri.'),\n",
       "   ('xe', '???'),\n",
       "   ('ex',\n",
       "    'Kepitai riro kaekaeva riakova, iria vararo viapau riro vututuvira toupaive.'),\n",
       "   ('xp', 'Liklik longpla meri, skin bilong em i no pat.'),\n",
       "   ('xe', '???')]),\n",
       " ('kepito',\n",
       "  [('alt', 'kepipato'),\n",
       "   ('rt', 'kepi'),\n",
       "   ('ps', 'N'),\n",
       "   ('pt', 'HUM'),\n",
       "   ('ge', 'crippled person'),\n",
       "   ('tkp', 'man i gat bun i bruk'),\n",
       "   ('nt', 'can be a broken leg or a broken arm'),\n",
       "   ('dt', '27/Oct/2005'),\n",
       "   ('ex', 'Ro oirato ira kepivira vokapareve.'),\n",
       "   ('xp', 'Man i no wokabaut gut.'),\n",
       "   ('xe', \"A man who can't walk well.\"),\n",
       "   ('ex',\n",
       "    'Oirato ro ira iava kokotoa kepivira toupaive. Oire reraera ira viaispaivere oisio kepito.'),\n",
       "   ('xp',\n",
       "    'Man em lek bilong em i bruk. Orait em dispela kain man ol i save kolim olsem lek bruk man.')]),\n",
       " ('kepo',\n",
       "  [('ps', 'V'),\n",
       "   ('pt', 'A'),\n",
       "   ('ge', 'two-sided'),\n",
       "   ('tkp', 'i gat tupela sait'),\n",
       "   ('vx', '???'),\n",
       "   ('cmt', 'Need ex illustrating verb agreement.'),\n",
       "   ('dt', '27/Oct/2005'),\n",
       "   ('ex',\n",
       "    'Pita Sera taviparevoi oisio uriou ragai-pa asi kepo reiva. Ravarei ura uvare aasi ruipaparai.'),\n",
       "   ('xp',\n",
       "    'Pita i tokim Sera olsem, yu kam wantaim tupela hap buai. na bai mi kaikai bikos mi laik kaikai buai.'),\n",
       "   ('xe', '???')]),\n",
       " ('kepoi',\n",
       "  [('ps', 'N'),\n",
       "   ('pt', 'FEM'),\n",
       "   ('ge', 'small type of shell'),\n",
       "   ('tkp', 'wanpela kain sel'),\n",
       "   ('dt', '27/Oct/2005'),\n",
       "   ('ex', 'Kepoi vo toupai avakona savaraa.'),\n",
       "   ('xp', 'Kepoi shell em i save i stap long sol wara.'),\n",
       "   ('xe', '???'),\n",
       "   ('ex', 'Kepoi garevavi iria avakava sovara-ia toupaeveira.'),\n",
       "   ('xp', 'Kepoi em i wanpela liklik sel, i save stap insait long solwara.'),\n",
       "   ('xe', '???')]),\n",
       " ('keposi',\n",
       "  [('ps', 'N'),\n",
       "   ('pt', 'NT'),\n",
       "   ('ge', 'wood chips from a cut'),\n",
       "   ('ge', 'sliver of wood'),\n",
       "   ('tkp', 'haphap diwai akis i wokim'),\n",
       "   ('dt', '27/Oct/2005'),\n",
       "   ('ex', 'Keposiara oara verapaiveira vosia evaoara toepaive.'),\n",
       "   ('xp',\n",
       "    'Ol liklik haphap diwai ol save raosim taim ol i save katim ol diwai.'),\n",
       "   ('xe', '???')]),\n",
       " ('kepoto',\n",
       "  [('ps', 'N'),\n",
       "   ('pt', 'MASC'),\n",
       "   ('ge', 'vulva opening'),\n",
       "   ('ge', 'labia'),\n",
       "   ('tkp', 'bokis'),\n",
       "   ('dt', '27/Oct/2005'),\n",
       "   ('ex', 'Kepoto ira toupareveira riakora rutu-ia vataupa tavukia.'),\n",
       "   ('xp', 'Hap i save stap op long olgeta meri long ples tambu.'),\n",
       "   ('xe', '???')]),\n",
       " ('kera',\n",
       "  [('ps', 'N'),\n",
       "   ('pt', 'MASC'),\n",
       "   ('ge', 'albatross-like bird'),\n",
       "   ('tkp', 'pisin i save stap long solwara'),\n",
       "   ('nt', 'sea bird, sharp pointed wings, probably a Frigate Bird'),\n",
       "   ('sf', 'FAUNA.BIRD'),\n",
       "   ('dt', '28/Jan/2005'),\n",
       "   ('ex', 'Kokioto kera votoupaiveira avakava-ia.'),\n",
       "   ('xp', 'Kera em wanpela pinis Isave istap long solwara.'),\n",
       "   ('xe', 'The bird called kera likes being on the beach.')]),\n",
       " ('kerakera',\n",
       "  [('ps', 'N'),\n",
       "   ('pt', 'MASC'),\n",
       "   ('ge', 'mushroom'),\n",
       "   ('tkp', '???'),\n",
       "   ('nt', 'very large edible variety'),\n",
       "   ('dt', '27/Oct/2005'),\n",
       "   ('ex', 'Kerakera arua aiopara.'),\n",
       "   ('xp', 'Em I olsem kum tasol blong kaiken??.'),\n",
       "   ('xe', '???'),\n",
       "   ('ex',\n",
       "    'Kerakera aruato iraora puraparoveira rasitoa-ia. Ira oripaiveira rera aiopasia.'),\n",
       "   ('xp',\n",
       "    'Masrum em wanpela kain kumu i save gro long graon. Ol save kukim na kaikaim.'),\n",
       "   ('xe', '???')]),\n",
       " ('kerari',\n",
       "  [('ps', 'N'),\n",
       "   ('pt', '???'),\n",
       "   ('ge', 'all vegetation'),\n",
       "   ('ge', 'glory of God'),\n",
       "   ('tkp', 'olgeta purpur samting'),\n",
       "   ('dt', '27/Oct/2005'),\n",
       "   ('ex', 'Keraria purareva oisio ravaia toupaoro rera vaisaro kaepiepape.'),\n",
       "   ('xp',\n",
       "    'Dispela kriesen god i bin wokim olsem bai olgeta man i mas givim glori na bik nem i go long em.'),\n",
       "   ('xe', '???')]),\n",
       " ('keraria',\n",
       "  [('rt', 'kerari'),\n",
       "   ('ps', 'N'),\n",
       "   ('pt', 'NT'),\n",
       "   ('ge', 'all vegetation'),\n",
       "   ('ge', 'glory of God'),\n",
       "   ('tkp', '???'),\n",
       "   ('dt', '11/Feb/2007'),\n",
       "   ('ex', 'Keraria purari oveu atosia popita atosia.'),\n",
       "   ('xp', 'Wokem hook blong downim kapiaka na kokosi.'),\n",
       "   ('xe', '???'),\n",
       "   ('ex',\n",
       "    'Pauto ira keraria purareva vearopiea oa-ia touparo rera-pa uvuipai ra riro vaisi vorepiepaive oirara pautoa-pa.'),\n",
       "   ('xp',\n",
       "    'God i bin wokim dispela gutpela creation bai ol man stap long em na givim bik nem hona i go bek long God.'),\n",
       "   ('xe', 'God created all of the plants ???')]),\n",
       " ('kerau',\n",
       "  [('ps', 'V'),\n",
       "   ('pt', 'A'),\n",
       "   ('ge', 'stiff'),\n",
       "   ('ge', 'rigormortis'),\n",
       "   ('ge', 'rigid'),\n",
       "   ('tkp', '???'),\n",
       "   ('vx', '1'),\n",
       "   ('dt', '11/Feb/2007'),\n",
       "   ('ex', 'Keraurai.'),\n",
       "   ('xp', '???'),\n",
       "   ('xe', \"I'm stiff.\"),\n",
       "   ('ex',\n",
       "    'Viapau uvuiparai ra vavaea pukoa uvare kerae riro va-ia kokeva vokavoiva.'),\n",
       "   ('xp',\n",
       "    'Mi no inap bendim han bilong mi bikos mi wokabaut long bikpela ren.'),\n",
       "   ('xe', \"I can't bend my hand because I walked in a big rain.\")]),\n",
       " ('kerauto',\n",
       "  [('rt', 'kerau'),\n",
       "   ('ps', 'N'),\n",
       "   ('pt', 'HUM'),\n",
       "   ('ge', 'paralyzed person'),\n",
       "   ('tkp', '???'),\n",
       "   ('dt', '11/Feb/2007'),\n",
       "   ('ex', 'Kerauto ro ira viapau uvuipa ra vokapareve.'),\n",
       "   ('xp', 'Man i no inap wokabaut.'),\n",
       "   ('xe', \"A paralyzed person is one who can't walk.\"),\n",
       "   ('ex',\n",
       "    'Vosia kerauto oirato era ira viapau uvuipa ra vokapareve ari era urua raga-ia uusiparovere.'),\n",
       "   ('xp',\n",
       "    'Sapos paralyzed man, em dispela man i no inap wokabaut em bai slip tasol long bet.'),\n",
       "   ('xe',\n",
       "    \"If a man is paralyzed, he can't walk but instead will just sleep in bed.\")]),\n",
       " ('keravisi',\n",
       "  [('ps', 'V'),\n",
       "   ('pt', 'B'),\n",
       "   ('ge', 'plough under'),\n",
       "   ('ge', 'turn soil over'),\n",
       "   ('tkp', 'hukim'),\n",
       "   ('arg', 'O'),\n",
       "   ('vx', '2'),\n",
       "   ('dt', '28/Oct/2005'),\n",
       "   ('ex', 'Rasia keravisipaivorao.'),\n",
       "   ('xp', '???'),\n",
       "   ('xe', 'They turned the soil over yesterday.')]),\n",
       " ('keravisia',\n",
       "  [('rt', 'keravisi'),\n",
       "   ('ps', 'N'),\n",
       "   ('pt', 'NT'),\n",
       "   ('ge', 'hook'),\n",
       "   ('ge', 'plough'),\n",
       "   ('tkp', 'huk'),\n",
       "   ('cmt',\n",
       "    \"I don't think va-ia should be there twice in second ex. sentence.\"),\n",
       "   ('dt', '28/Oct/2005'),\n",
       "   ('ex', 'Ragai keravisi purapaa ra oveu atora rara utupaua.'),\n",
       "   ('xp', 'Mi wokim huk bai mi daonim kapiak long bihain.'),\n",
       "   ('xe', '???'),\n",
       "   ('ex', 'Keravisia oupaavoi ra va-ia opita isi rovai keravisia va-ia.'),\n",
       "   ('xp', 'Bai mi kisim huk na bai mi hukim ol kokonat long em.'),\n",
       "   ('xe', \"I'm going to get a hook and with it I'll hook it with it.\")]),\n",
       " ('keravo',\n",
       "  [('ps', 'N'),\n",
       "   ('pt', 'MASC'),\n",
       "   ('ge', 'hawk'),\n",
       "   ('tkp', 'tarangau'),\n",
       "   ('eng', 'Little Eagle (Hieraaetus morphnoides)'),\n",
       "   ('sa', 'avaruka'),\n",
       "   ('dt', '28/Oct/2005'),\n",
       "   ('ex', 'Kokioto keravo viaraia raga papapareveira.'),\n",
       "   ('xp', 'Pinis i save plai tasol long antap.'),\n",
       "   ('xe', '???'),\n",
       "   ('ex',\n",
       "    'Keravo ira tuura vegoro sovaraia toupareveira. Ra voa varuere kare upopareve oea aiopasia.'),\n",
       "   ('xp',\n",
       "    'Tarangau em i save stap long ol bik bus. na em i save kilim ol abus na kaikaim.'),\n",
       "   ('xe', '')]),\n",
       " ('Kereaka',\n",
       "  [('ps', 'N'),\n",
       "   ('pt', 'PN'),\n",
       "   ('ge', 'name'),\n",
       "   ('tkp', 'nem'),\n",
       "   ('eng', 'name'),\n",
       "   ('dt', '28/Oct/2005'),\n",
       "   ('ex', 'Kereaka uruia vaisiaro oisio uva ravireo rokopareveira.'),\n",
       "   ('xp', 'Kereaka em i nem bilong ples istap long hap bilong san i go daon.'),\n",
       "   ('xe', '???')]),\n",
       " ('kerekoi',\n",
       "  [('ps', 'N'),\n",
       "   ('pt', 'FEM'),\n",
       "   ('ge', 'fly'),\n",
       "   ('tkp', 'liklik kain palai i gat makmak'),\n",
       "   ('sf', 'FAUNA'),\n",
       "   ('nt', 'small type found in jungle area'),\n",
       "   ('dt', '28/Oct/2005'),\n",
       "   ('ex', 'Kerekoi votupaiveiro vegoaro.'),\n",
       "   ('xp', 'Em i save i stap tasol long bik bush.'),\n",
       "   ('xe', '???'),\n",
       "   ('ex', 'Kerekoi-ia toupaiveira korikoriara oira avuaro-ia.'),\n",
       "   ('xp',\n",
       "    'Kerekoi emi wanpela liklik kain palai i save gat makmak long beksait bilong em.'),\n",
       "   ('xe', '???')]),\n",
       " ('kerere',\n",
       "  [('ps', 'N'),\n",
       "   ('pt', '???'),\n",
       "   ('ge', 'arrow made of sago leaf midrib'),\n",
       "   ('tkp', 'supsup of i wokim long saksak nok'),\n",
       "   ('cmt', 'Does this word actually exist? Is it misspelled?'),\n",
       "   ('dt', '28/Oct/2005')]),\n",
       " ('kerereua',\n",
       "  [('rt', 'kerere'),\n",
       "   ('ps', 'N'),\n",
       "   ('pt', 'NT'),\n",
       "   ('ge', 'arrow made of sago leaf midrib'),\n",
       "   ('tkp', '???'),\n",
       "   ('dt', '18/Feb/2004'),\n",
       "   ('ex', 'Kerereua purapai aue iava tetevu guruva iapasia.'),\n",
       "   ('xp', 'Ol i mekim spia bilong sut long em.'),\n",
       "   ('xe', 'He is making a spear in order to shoot with it.')]),\n",
       " ('kerete',\n",
       "  [('ps', 'POST'),\n",
       "   ('ge', 'inside out'),\n",
       "   ('ge', 'reverse'),\n",
       "   ('tkp', 'tanim links'),\n",
       "   ('dt', '23/Feb/2005'),\n",
       "   ('cmt',\n",
       "    \"Described by Firchow, but haven't been able to find any examples\")]),\n",
       " ('kerete',\n",
       "  [('ps', 'V'),\n",
       "   ('pt', 'B'),\n",
       "   ('ge', 'turn around'),\n",
       "   ('tkp', 'tanim'),\n",
       "   ('cmt', \"Where's the subject agreement on the second example?\"),\n",
       "   ('arg', 'O'),\n",
       "   ('vx', '2'),\n",
       "   ('dt', '28/Oct/2005'),\n",
       "   ('ex', 'Vii keretea.'),\n",
       "   ('xp', 'Mi tanim yu.'),\n",
       "   ('xe', 'I am turning you around.'),\n",
       "   ('ex', 'Ragai-ia pituoro ragai kerete.'),\n",
       "   ('xp', 'Mi holim yu bai mi tanim yu.'),\n",
       "   ('xe', '???'),\n",
       "   ('ex',\n",
       "    'Pita koie korirevo uva oira iava kovuto kereterevo oisio ra voava rereoviro tuitui kasi-ia.'),\n",
       "   ('xp',\n",
       "    'Pita em i katim pik na em i tanim bel bilong em olsem bai drai long paia.'),\n",
       "   ('xe', '???'),\n",
       "   ('ex', 'Oirato riakova kereterevoi oira-va vuri pitupitu purasia.'),\n",
       "   ('xp', 'Man i tanim meri na mekim pasin nogut long em.'),\n",
       "   ('xe',\n",
       "    'The man turned around the woman in order to do naughty things to her.')]),\n",
       " ('Kerevaru',\n",
       "  [('ps', 'N'),\n",
       "   ('pt', 'PN'),\n",
       "   ('ge', 'river'),\n",
       "   ('tkp', 'wanpela raun wara'),\n",
       "   ('nt',\n",
       "    'river behind Sisisivi village which flows over high double waterfalls'),\n",
       "   ('dt', '28/Jan/2005'),\n",
       "   ('ex', 'Ukova kerevaru esis toupa sisivi.'),\n",
       "   ('xp', 'Em wampela river em istap long sisivi villege.'),\n",
       "   ('xe', 'It is a river that is in Sisivi village.')]),\n",
       " ('keri',\n",
       "  [('ps', 'V'),\n",
       "   ('pt', 'A'),\n",
       "   ('ge', 'make enemies with'),\n",
       "   ('ge', 'reject friendship'),\n",
       "   ('tkp', '???'),\n",
       "   ('cm', '-va'),\n",
       "   ('vx', '2'),\n",
       "   ('arg', 'OBL'),\n",
       "   ('dt', '28/Oct/2005'),\n",
       "   ('ex', 'Ragai-va keripauveira.'),\n",
       "   ('xp', '???'),\n",
       "   ('xe', 'You are always being my enemy.'),\n",
       "   ('ex', 'Pita ragai-va keriparoveira oa iava viapau vearovira toupave.'),\n",
       "   ('xp',\n",
       "    'Pita i save birua wantaim mi, olsem na mitupela i no save stap gut.'),\n",
       "   ('xe', '???')]),\n",
       " ('Keriaka',\n",
       "  [('ps', 'N'),\n",
       "   ('pt', 'PN'),\n",
       "   ('ge', 'name'),\n",
       "   ('tkp', 'nem'),\n",
       "   ('eng', 'name'),\n",
       "   ('dt', '28/Jan/2005')]),\n",
       " ('kerikerisi',\n",
       "  [('rt', 'kerisi'),\n",
       "   ('ps', 'V'),\n",
       "   ('pt', 'B'),\n",
       "   ('rdp', 'partial'),\n",
       "   ('ge', 'evaluate'),\n",
       "   ('ge', 'judge carefully'),\n",
       "   ('tkp', 'jas'),\n",
       "   ('tkp', 'skelim'),\n",
       "   ('vx', '2'),\n",
       "   ('arg', 'O'),\n",
       "   ('dt', '12/Dec/2006'),\n",
       "   ('ex', 'Vearovira rera vo reoaro kerikerisiri.'),\n",
       "   ('xp', '???'),\n",
       "   ('xe',\n",
       "    'Mark his words well. Think carefully about his talk evaluating it.'),\n",
       "   ('ex', 'Karurua reo kerikerisipato vo-va Rotokasi taere-ia.'),\n",
       "   ('xp', 'Karuru em i man bilong jasim tok long Rotokas area.'),\n",
       "   ('xe', 'Karuru is a judge from the Rotokas area.')]),\n",
       " ('kerio',\n",
       "  [('ps', 'N'),\n",
       "   ('pt', '???'),\n",
       "   ('ge', 'coconut leaf'),\n",
       "   ('tkp', 'lip bilong kokonas'),\n",
       "   ('dt', '28/Oct/2005'),\n",
       "   ('ex', 'Sirosia riro keriopato auere pekuri purapasia.'),\n",
       "   ('xp', 'Sirosia em boi bilong katim lip kokonat bilong wokim basket.'),\n",
       "   ('xe', '???')]),\n",
       " ('kerioua',\n",
       "  [('rt', 'kerio'),\n",
       "   ('ps', 'N'),\n",
       "   ('pt', 'NT'),\n",
       "   ('ge', 'coconut torch'),\n",
       "   ('ge', 'stalk of palm leaf'),\n",
       "   ('tkp', 'bumbum pangal'),\n",
       "   ('dt', '28/Oct/2005'),\n",
       "   ('ex', 'Kerioua kovei opitato iava uva kakaeto upovoi.'),\n",
       "   ('xp', 'Pangal bilong kokonat i pundaon na paitim pikinini.'),\n",
       "   ('xe', 'A palm leaf stalk fell from the coconut tree and hit the boy.')]),\n",
       " ('keripaara',\n",
       "  [('rt', 'keripa'),\n",
       "   ('ps', 'N'),\n",
       "   ('pt', 'NT'),\n",
       "   ('ge', 'enemies'),\n",
       "   ('tkp', 'birua'),\n",
       "   ('cmt', 'Double-check vowel length'),\n",
       "   ('dt', '28/Oct/2005'),\n",
       "   ('ex',\n",
       "    'Keripara oisioa purapaive voari tuariri vo osia osia ra reivu ora kasipupe ra viapau ora voeava vearovira toupaive.'),\n",
       "   ('xp',\n",
       "    'Pasin birua ol i bin save mekim long taim bipo. Sapos tupela klen i kros bai ol i no inap stap gut.'),\n",
       "   ('xe', '???')]),\n",
       " ('keripato',\n",
       "  [('rt', 'keripa'),\n",
       "   ('ps', 'N'),\n",
       "   ('pt', 'HUM'),\n",
       "   ('ge', 'enemy'),\n",
       "   ('tkp', 'birua'),\n",
       "   ('dt', '28/Oct/2005'),\n",
       "   ('ex', 'Viva keripato. Ira vii uposia auepaavoi vii-va.'),\n",
       "   ('xp', 'Em i enemi blong yu. Em i laik paitim yu.'),\n",
       "   ('xe', 'He is your enemy. He wants to fight with with you.'),\n",
       "   ('ex', 'Keripato oirato ro ira iravu-va vurivira toupareve.'),\n",
       "   ('xp', 'Birua man em i man istap nogut wantaim narapela man.'),\n",
       "   ('xe', '???')]),\n",
       " ('kerisi',\n",
       "  [('ps', 'V'),\n",
       "   ('pt', 'B'),\n",
       "   ('ge', 'evaluate'),\n",
       "   ('tkp', 'skelim gut tok'),\n",
       "   ('eng', 'discern'),\n",
       "   ('eng', 'evaluate'),\n",
       "   ('eng', 'judge talk or situation well'),\n",
       "   ('arg', 'O'),\n",
       "   ('vx', '2'),\n",
       "   ('dt', '28/Oct/2005'),\n",
       "   ('ex', 'Rera kerisiiva.'),\n",
       "   ('xp', '???'),\n",
       "   ('xe', 'They evaluated him.'),\n",
       "   ('ex',\n",
       "    'Kerisi oa oisio toupaivoi, vosia iravu vuria purareve, rariropai rara rera vo vavataro-ia pauavere va kerisisia vosia oirapa o kuuvua.'),\n",
       "   ('xp',\n",
       "    'Skelim gut, sapos wanpela man i mekim rong bai ol bikman i sindaun long hevi bilong em na skelim sapos i tru o nogat.'),\n",
       "   ('xe', '???')]),\n",
       " ('kerisito',\n",
       "  [('alt', 'kerisipato'),\n",
       "   ('rt', 'kerisi'),\n",
       "   ('ps', 'N'),\n",
       "   ('pt', 'HUM'),\n",
       "   ('ge', 'discerning person'),\n",
       "   ('tkp', '???'),\n",
       "   ('dt', '28/Oct/2005'),\n",
       "   ('ex',\n",
       "    'Kerisipato oirato ira oaravu-ia taraipaoro vara eveiparevoi oara karekepai.'),\n",
       "   ('xp', 'Man i save lukim na luksave long ol samting i wok long kamap.'),\n",
       "   ('xe', '???')]),\n",
       " ('kerisivira',\n",
       "  [('alt', 'kerisipavira'),\n",
       "   ('rt', 'kerisi'),\n",
       "   ('ps', 'ADV'),\n",
       "   ('pt', 'MANNER'),\n",
       "   ('ge', 'wisely'),\n",
       "   ('ge', 'discerningly'),\n",
       "   ('tkp', '???'),\n",
       "   ('dt', '28/Aug/2005'),\n",
       "   ('ex', 'Kerisivira reoparoi.'),\n",
       "   ('xp', '???'),\n",
       "   ('xe', 'He talks with good judgement.')]),\n",
       " ('keritara',\n",
       "  [('rt', 'kerita???'),\n",
       "   ('ps', 'N'),\n",
       "   ('pt', 'NT'),\n",
       "   ('ge', 'trash'),\n",
       "   ('tkp', 'pipia'),\n",
       "   ('eng', 'trash'),\n",
       "   ('eng', 'rubbish'),\n",
       "   ('eng', 'garbage'),\n",
       "   ('dt', '05/Feb/2005'),\n",
       "   ('ex', 'Kouekare aio kovoroia keritara puraivoi.'),\n",
       "   ('xp', 'Ol pik i kaikai nogut ol gaden bilong yu.'),\n",
       "   ('xe', \"Pigs eat your garden's garbage.\")]),\n",
       " ('keriva',\n",
       "  [('ps', 'N'),\n",
       "   ('pt', 'FEM'),\n",
       "   ('ge', 'hawk feather'),\n",
       "   ('tkp', '???'),\n",
       "   ('nt', \"used in coded leaf letter to mean keripa 'enemy'\"),\n",
       "   ('sa', 'keripa'),\n",
       "   ('dt', '28/Oct/2005'),\n",
       "   ('ex',\n",
       "    'Keriva iria purapaiveira aue iava kokio  kare oruaro ra oira takuvuive oira tukeoro votovopasia kukue pupia vutaro-ia.'),\n",
       "   ('xp',\n",
       "    'Bilas ol i save mekim long gras bilong pisin. na ol i sae olgeta gras pisin na pasim wantaim. na putim long het bilong ol na singsing wantaim.'),\n",
       "   ('xe', '???')]),\n",
       " ('keroroi',\n",
       "  [('ps', 'N'),\n",
       "   ('pt', 'NT'),\n",
       "   ('ge', 'lean-to'),\n",
       "   ('tkp', '???'),\n",
       "   ('nt', 'archaic'),\n",
       "   ('dt', '28/Oct/2005'),\n",
       "   ('ex', 'Keroroi kepa vao oa-ia viapau aue kovuaka vakukuearo-ia.'),\n",
       "   ('xp', 'Haus i nogat rup long het bilong em.'),\n",
       "   ('xe', '???')]),\n",
       " ('kerosiri',\n",
       "  [('alt', 'karasiri'),\n",
       "   ('ps', 'N'),\n",
       "   ('pt', '???'),\n",
       "   ('ge', 'kerosene'),\n",
       "   ('tkp', 'kerasin'),\n",
       "   ('nt', 'Tok Pisin loan'),\n",
       "   ('dt', '28/Oct/2005'),\n",
       "   ('ex',\n",
       "    'Pita ira ragai vaterevo karasiria uvare ragai oiraro vuravu viapau aviavipaevo.'),\n",
       "   ('xp', 'Pita i givim mi kerosin bikos lam bilong mi i no lait.'),\n",
       "   ('xe', \"Peter gave me kerosene because my lamp won't light.\")]),\n",
       " ('keru',\n",
       "  [('ps', 'V'),\n",
       "   ('pt', 'A'),\n",
       "   ('ge', 'harden like bone'),\n",
       "   ('tkp', 'bun'),\n",
       "   ('vx', '1'),\n",
       "   ('cmt', \"What's the telicity?\"),\n",
       "   ('dt', '28/Oct/2005'),\n",
       "   ('ex', 'Semen keruovere.'),\n",
       "   ('xp', '???'),\n",
       "   ('xe', 'The cement will become hard as bone.'),\n",
       "   ('ex',\n",
       "    'Tasia tapiakara vagievo aveke kasi-ia uva rovae oa iava kerue uva viapau uvuipai va aiosia.'),\n",
       "   ('xp',\n",
       "    'Tasa em i mumuim kapiok long ston. na i paia olsem na i no inap long kaikaim.'),\n",
       "   ('xe', '???')]),\n",
       " ('keru',\n",
       "  [('rt', 'keru'),\n",
       "   ('wf', 'kerua'),\n",
       "   ('wf', 'keruara'),\n",
       "   ('ps', 'N'),\n",
       "   ('pt', 'NT'),\n",
       "   ('ge', 'bone'),\n",
       "   ('tkp', '???'),\n",
       "   ('dt', '28/Oct/2005'),\n",
       "   ('ex', 'Koue kerua.'),\n",
       "   ('xp', 'Bun blong pig.'),\n",
       "   ('xe', 'Pig bone.'),\n",
       "   ('ex', 'Ragai-va kerua.'),\n",
       "   ('xp', 'Em bun blong mi.'),\n",
       "   ('xe', \"That's my bone.\"),\n",
       "   ('ex',\n",
       "    'Keruara oirara rutu-ia toupaiveira oara voea vararo gorupiepaiveira ravokapaive.'),\n",
       "   ('xp',\n",
       "    'Ol bun istap long olgeta man ol dispela bun i save strongim bodi bilong taim ol i wokabaut.'),\n",
       "   ('xe', '???')]),\n",
       " ('kerui',\n",
       "  [('ps', 'V'),\n",
       "   ('pt', 'A'),\n",
       "   ('ge', 'thin'),\n",
       "   ('ge', 'bony'),\n",
       "   ('ge', 'skinny'),\n",
       "   ('tkp', 'bun nating'),\n",
       "   ('vx', '1'),\n",
       "   ('dt', '28/Oct/2005'),\n",
       "   ('ex', 'Em ro ira viapau sopeiavoi toupa.'),\n",
       "   ('xp', 'Man i no gat mit i blong bodi.'),\n",
       "   ('xe', '???'),\n",
       "   ('ex',\n",
       "    'Ragaia keruito ragoa-ia viapau varuaravai toupaveira ora aue tuga ragai vararo-ia.'),\n",
       "   ('xp', 'Mi bun nating man mi nogat mit na gris istap long bodi bilong mi.'),\n",
       "   ('xe', '???')]),\n",
       " ('keruiato',\n",
       "  [('rt', 'keruia'),\n",
       "   ('ps', 'N'),\n",
       "   ('pt', 'NT'),\n",
       "   ('ge', 'determination'),\n",
       "   ('tkp', 'man i save laik painim aut'),\n",
       "   ('dt', '28/Oct/2005'),\n",
       "   ('ex',\n",
       "    'Keruiato ira oisio ruipaparoveira oaravu kekepareve o vara-ia tarai ruipaparo rutu.'),\n",
       "   ('xp', 'Man bilong laik lukim ol samting na save tru tru.'),\n",
       "   ('xe', '???')]),\n",
       " ('keruito',\n",
       "  [('rt', 'kerui'),\n",
       "   ('ps', 'N'),\n",
       "   ('pt', 'HUM'),\n",
       "   ('ge', 'skinny person'),\n",
       "   ('ge', 'thin person'),\n",
       "   ('tkp', '???'),\n",
       "   ('dt', '28/Oct/2005'),\n",
       "   ('ex', 'Vosia viapau Pita vearovira aiopareve rakeruitovira toupareve.'),\n",
       "   ('xp', 'Sapos Pita i no kaikai gut bai em i stap olsem bun nating man.'),\n",
       "   ('xe', '???')]),\n",
       " ('kerupiua',\n",
       "  [('rt', 'kerupi???'),\n",
       "   ('ps', 'N'),\n",
       "   ('pt', 'NT'),\n",
       "   ('ge', 'tree'),\n",
       "   ('tkp', '???'),\n",
       "   ('cmt', 'archaic?'),\n",
       "   ('nt', 'is a source of salt when burned'),\n",
       "   ('dt', '28/Oct/2005')]),\n",
       " ('keruria',\n",
       "  [('ps', 'V'),\n",
       "   ('pt', 'A'),\n",
       "   ('ge', 'persistent'),\n",
       "   ('ge', 'stubborn'),\n",
       "   ('ge', 'determined'),\n",
       "   ('tkp', 'strong yet'),\n",
       "   ('vx', '1'),\n",
       "   ('nt', 'archaic?'),\n",
       "   ('cmt', 'Does this take a sentential predicate? Can it occur alone?'),\n",
       "   ('dt', '28/Oct/2005'),\n",
       "   ('ex', 'Keruriaparoi avaarapa.'),\n",
       "   ('xp', '???'),\n",
       "   ('xe', 'He is determined not to go.')]),\n",
       " ('keruriato',\n",
       "  [('rt', 'keruria'),\n",
       "   ('ps', '???'),\n",
       "   ('ge', 'determination'),\n",
       "   ('tkp', 'strong pasin'),\n",
       "   ('dt', '18/Feb/2004')]),\n",
       " ('keruriavira',\n",
       "  [('alt', 'keruriapavira'),\n",
       "   ('rt', 'keruria'),\n",
       "   ('ps', 'ADV'),\n",
       "   ('pt', 'MANNER'),\n",
       "   ('ge', 'persistently'),\n",
       "   ('ge', 'obstinantly'),\n",
       "   ('tkp', '???'),\n",
       "   ('dt', '28/Aug/2005')]),\n",
       " ('kesi',\n",
       "  [('ps', 'V'),\n",
       "   ('pt', 'A'),\n",
       "   ('ge', 'limp'),\n",
       "   ('tkp', 'wokabaut nogut'),\n",
       "   ('cmt', 'No example'),\n",
       "   ('vx', '1'),\n",
       "   ('dt', '08/Dec/2005')]),\n",
       " ('kesie',\n",
       "  [('ps', '???'),\n",
       "   ('ge', 'yellow'),\n",
       "   ('tkp', 'yelo'),\n",
       "   ('dt', '28/Oct/2005'),\n",
       "   ('ex', 'Sem Akoitai vokeparo iava kaapara kesievira toupaiveira.'),\n",
       "   ('xp', 'Kapa long haus bilong Sam Akoitai i yelo.'),\n",
       "   ('xe', '???')]),\n",
       " ('kesievira',\n",
       "  [('rt', 'kesie'),\n",
       "   ('ps', 'ADV'),\n",
       "   ('pt', 'MANNER'),\n",
       "   ('ge', 'yellow'),\n",
       "   ('tkp', 'yelo'),\n",
       "   ('dt', '28/Oct/2005'),\n",
       "   ('ex', 'Sem Akoitai vo kepaaro iava kaapara kesievira toupaiveira.'),\n",
       "   ('xp', 'Kapa long haus bilong Sam Akoitai i yelo.'),\n",
       "   ('xe', \"The roof of Sam Akoitai's house is yellow.\")]),\n",
       " ('kesikea vaaguru',\n",
       "  [('ps', 'N'),\n",
       "   ('pt', '???'),\n",
       "   ('ge', 'Yellow Mangrove (Ceriops tagal)'),\n",
       "   ('tkp', '???'),\n",
       "   ('dt', '28/Oct/2005'),\n",
       "   ('ex', 'Kesiea vaagurua oa vo toupaiveira avakava sirova.'),\n",
       "   ('xp', 'Yelopela mangur i save stap arere long solwara.'),\n",
       "   ('xe', 'The Yellow Mangroves live along the coast.')]),\n",
       " ('kesio',\n",
       "  [('ps', '???'),\n",
       "   ('ge', 'clever'),\n",
       "   ('tkp', 'i save tumas'),\n",
       "   ('dt', '28/Oct/2005'),\n",
       "   ('ex',\n",
       "    'Kesiotoa rutuvi vosia ira iparo evaovaia via kesioti arutu vigo gareaia ipau iroa.'),\n",
       "   ('xp', 'Yu man tru yu clarem no yo go antap long liplip rop tasol.'),\n",
       "   ('xe', '???'),\n",
       "   ('ex', 'Kesio rugoirara vearovira rutu oaravu purapaiveira.'),\n",
       "   ('xp', 'Ol man i gat gutpela sae ol i save mekim gut ol samting.'),\n",
       "   ('xe', '???')]),\n",
       " ('kesioto',\n",
       "  [('rt', 'kesio'),\n",
       "   ('ps', 'N'),\n",
       "   ('pt', 'HUM'),\n",
       "   ('ge', 'clever man'),\n",
       "   ('tkp', 'man i save tumas'),\n",
       "   ('dt', '28/Oct/2005'),\n",
       "   ('ex',\n",
       "    'Kesioto ro oirato ira riroa vatoupare taraia. Oara rutu purapasia votara iava.'),\n",
       "   ('xp',\n",
       "    'Man save i gat bikpela save em i save stap wantaim em i kain wokim ol kain wok long dispela save.'),\n",
       "   ('xe', '???')]),\n",
       " ('kesivira',\n",
       "  [('alt', 'kesipavira'),\n",
       "   ('rt', 'kesi'),\n",
       "   ('ps', 'ADV'),\n",
       "   ('pt', 'MANNER'),\n",
       "   ('ge', 'limping'),\n",
       "   ('tkp', '???'),\n",
       "   ('dt', '08/Dec/2005'),\n",
       "   ('ex', 'Kesivira tasiparevoi.'),\n",
       "   ('xp', '???'),\n",
       "   ('xe', 'He steps in a limping way.'),\n",
       "   ('ex',\n",
       "    'Avukato kesivira tasiparevo uvare riroa kapua rera kokotoaro-ia toupaivo.'),\n",
       "   ('xp',\n",
       "    'Lapun man i no wokabaut gut tumas bikos em i gat bikpela sua long lek bilong em.'),\n",
       "   ('xe', 'The old man steps with a limp because many sores are on his leg.'),\n",
       "   ('ex', 'Ruke kesivira raga rakoru-ia pituparevo uvare ururiparoe oira-pa.'),\n",
       "   ('xp', 'Luk i no holim gut snek bikos em i wok long poretim.'),\n",
       "   ('xe', '???'),\n",
       "   ('ex', 'Kesivira vokapaoro avaroe Visia kokotu rausia.'),\n",
       "   ('xp',\n",
       "    'Visa em i wokabaut long ol pinga bilong lek bilong em long holim pasim kakaruk.'),\n",
       "   ('xe', '???')]),\n",
       " ('keta',\n",
       "  [('ps', 'V'),\n",
       "   ('pt', 'B'),\n",
       "   ('ge', 'comb hair'),\n",
       "   ('tkp', 'komim'),\n",
       "   ('dx', 'Pipipaia'),\n",
       "   ('vx', '2'),\n",
       "   ('arg', 'O'),\n",
       "   ('dt', '31/Jul/2005'),\n",
       "   ('ex', 'Orui ketaparevoi kakaeto.'),\n",
       "   ('xp', '???'),\n",
       "   ('xe', 'The boy is combing his hair.')]),\n",
       " ('ketaka',\n",
       "  [('ps', 'V'),\n",
       "   ('pt', 'B'),\n",
       "   ('ge', 'notch out'),\n",
       "   ('ge', 'make groove'),\n",
       "   ('tkp', 'wokim liklik baret'),\n",
       "   ('arg', 'O'),\n",
       "   ('vx', '2'),\n",
       "   ('nt', 'The notched end of the long pole is used to hold fruit'),\n",
       "   ('dt', '28/Oct/2005'),\n",
       "   ('ex', 'Tuuta ketakareva kovurui tovosia va-ia.'),\n",
       "   ('xp', '???'),\n",
       "   ('xe', 'He notched the pole in order to put up the rafter with it.'),\n",
       "   ('ex',\n",
       "    'Ragai tuuta ketakaarava-ia ravaivara-ia gareavi tovoa evaoa ra kepa puraa.'),\n",
       "   ('xp',\n",
       "    'Mi katim pos na mekim spes bai mi putim liklik diwai long na wokim.'),\n",
       "   ('xe', '???')]),\n",
       " ('ketakaa',\n",
       "  [('rt', 'ketaka'),\n",
       "   ('ps', 'N'),\n",
       "   ('pt', 'NT'),\n",
       "   ('ge', 'groove'),\n",
       "   ('ge', 'niche'),\n",
       "   ('tkp', '???'),\n",
       "   ('cmt', 'Check vowel length'),\n",
       "   ('dt', '28/Oct/2005')]),\n",
       " ('ketato',\n",
       "  [('ps', 'N'),\n",
       "   ('pt', 'MASC'),\n",
       "   ('ge', 'tusk of pig'),\n",
       "   ('tkp', 'tit bilong pik'),\n",
       "   ('dt', '28/Oct/2005'),\n",
       "   ('cmt', 'Bad ex. sentence'),\n",
       "   ('ex', 'Koueto ketato.'),\n",
       "   ('xp', 'Pig i gat teeth i kam autsait.'),\n",
       "   ('xe', '???'),\n",
       "   ('ex', 'Vosia ketato orapuraro koietoa-ia rarirovira kasipuparo.'),\n",
       "   ('xp', 'Sapos bikpela tit i kamap pik man em bai kros tumas.'),\n",
       "   ('xe', 'When tusks appear on the male pig, he gets ??? angry.')]),\n",
       " ('ketoo',\n",
       "  [('ps', 'N'),\n",
       "   ('pt', 'MASC'),\n",
       "   ('ge', 'plant which came up from seed'),\n",
       "   ('tkp', '???'),\n",
       "   ('dt', '28/Oct/2005'),\n",
       "   ('ex',\n",
       "    'Kovato ira purapa roviroveira vosia evao ara iava kueisiro keeto ravaisi kakuve teetoa vusioro.'),\n",
       "   ('xp',\n",
       "    'Kur i sae kamap sapos sit bilong ol diwai i bruk na kur bai kamap.'),\n",
       "   ('xe', '???')]),\n",
       " ('ketoo',\n",
       "  [('ps', 'V'),\n",
       "   ('pt', 'B'),\n",
       "   ('ge', 'sprout from seed'),\n",
       "   ('tkp', 'kru i kamap'),\n",
       "   ('dcsv', 'true'),\n",
       "   ('vx', '???'),\n",
       "   ('arg', '???'),\n",
       "   ('cmt', 'Check vowel length. Double-check verb class. A or B?'),\n",
       "   ('dt', '28/Oct/2005'),\n",
       "   ('ex',\n",
       "    'Kukuato aiava kovei aisivu raisuarore uva rakaria eruei oire ketoovoi.'),\n",
       "   ('xp',\n",
       "    'Long diwai galip wanpela galip i pundaun na skin bilong em i sting orait i grow.'),\n",
       "   ('xe', '???'),\n",
       "   ('ex',\n",
       "    'Vosia kakaupau ruipapau ra kakau takuraro keetopie rovorivere rakovape.'),\n",
       "   ('xp', 'Sapos yu laik planim kakau pastaim yu mas mekim kur i gro.'),\n",
       "   ('xe', '???')]),\n",
       " ('ketoopie',\n",
       "  [('rt', 'ketoo'),\n",
       "   ('ps', 'V'),\n",
       "   ('pt', 'B'),\n",
       "   ('ge', 'make sprout from seed'),\n",
       "   ('tkp', '???'),\n",
       "   ('arg', 'O'),\n",
       "   ('vx', '2'),\n",
       "   ('dt', '08/Jun/2005'),\n",
       "   ('ex', 'Ka kau takuraro ketopie.'),\n",
       "   ('xp', 'Seed blong cocaa em I igat sprout long seed.'),\n",
       "   ('xe', '???'),\n",
       "   ('ex', 'Auero rutu ketoopiepareveira.'),\n",
       "   ('xp', '???'),\n",
       "   ('xe', 'He makes all things (plants) sprout from seeds.')]),\n",
       " ('ketoopieara',\n",
       "  [('rt', 'ketoopie'),\n",
       "   ('ps', 'N'),\n",
       "   ('pt', 'NT'),\n",
       "   ('ge', 'sprouts'),\n",
       "   ('ge', 'buds'),\n",
       "   ('tkp', '???'),\n",
       "   ('cmt', 'Double-check vowel length'),\n",
       "   ('dt', '31/Oct/2005'),\n",
       "   ('ex',\n",
       "    'Ketoopiea vao oa rovuvira pukupaive evao kakura iava oisio kovape.'),\n",
       "   ('xp', 'Samting i solap liklik long pikinini diwai olsem bai gro.'),\n",
       "   ('xe', '???')]),\n",
       " ('ketoroa',\n",
       "  [('ps', 'N'),\n",
       "   ('pt', 'NT'),\n",
       "   ('dx', 'Central'),\n",
       "   ('ge', 'kettle'),\n",
       "   ('tkp', 'ketol'),\n",
       "   ('eng', 'kettle'),\n",
       "   ('nt', 'Tok Pisin loan'),\n",
       "   ('dt', '30/Apr/2006')]),\n",
       " ('ketu',\n",
       "  [('ps', 'V'),\n",
       "   ('pt', 'B'),\n",
       "   ('dx', 'Central'),\n",
       "   ('ge', 'break.off'),\n",
       "   ('ge', 'break off a piece'),\n",
       "   ('tkp', 'brukim liklik hap'),\n",
       "   ('vx', '2'),\n",
       "   ('arg', 'O'),\n",
       "   ('dt', '17/Oct/2005'),\n",
       "   ('ex', 'Vii ragai-pa opooavai ketu uvare vii riroa rutu aiopari.'),\n",
       "   ('xp', 'Yu brukim hap taro bilong mi bikos yu kaikaim bikpela hap.'),\n",
       "   ('xe', '???')]),\n",
       " ('kevaita',\n",
       "  [('ps', 'V'),\n",
       "   ('pt', 'A'),\n",
       "   ('ge', 'kid'),\n",
       "   ('ge', 'joke'),\n",
       "   ('ge', 'jest'),\n",
       "   ('tkp', 'tok pilai'),\n",
       "   ('vx', '1'),\n",
       "   ('dt', '28/Jan/2006'),\n",
       "   ('ex', 'Oiso ruipaparai ra orakevaitaragave.'),\n",
       "   ('xp', '???'),\n",
       "   ('xe', 'I want to just joke around between us.'),\n",
       "   ('ex',\n",
       "    'Ragai kevaitaparai uva vii kasipuuei  osia vii kevaitapaavoi aioarepaoro.'),\n",
       "   ('xp',\n",
       "    'Mi wok long pilai tasol yu kros. Mi pilai long yu long askim kaikai.'),\n",
       "   ('xe', 'I am kidding and you are angry as I kid you about giving food.')]),\n",
       " ('kevaita',\n",
       "  [('ps', 'V'),\n",
       "   ('pt', 'B'),\n",
       "   ('ge', 'kid'),\n",
       "   ('ge', 'joke'),\n",
       "   ('ge', 'jest'),\n",
       "   ('tkp', 'tok pilai'),\n",
       "   ('cmt', 'double check gloss'),\n",
       "   ('vx', '2'),\n",
       "   ('arg', 'O'),\n",
       "   ('dt', '11/Dec/2006'),\n",
       "   ('ex', 'Vii kevaitapaavoi aio arepaoro.'),\n",
       "   ('xp', 'Mi pilai long yu long askim kaikai.'),\n",
       "   ('xe', \"I'm joking with asking for food.\")]),\n",
       " ('kevaitato',\n",
       "  [('rt', 'kevaita'),\n",
       "   ('ps', 'N'),\n",
       "   ('pt', 'HUM'),\n",
       "   ('ge', 'jester'),\n",
       "   ('ge', 'kidder'),\n",
       "   ('tkp', '???'),\n",
       "   ('nt', 'In the good sense of the word jokester.'),\n",
       "   ('dt', '31/Oct/2005'),\n",
       "   ('ex', 'Oiratoa riro kevaitato oaravu puraporo oara viapau oiraopai.'),\n",
       "   ('xp',\n",
       "    'Man em man bilong tok pilai tasol long ol narapela samting em i save giaman.'),\n",
       "   ('xe',\n",
       "    \"The man is a big joker making up things, things which aren't true.\"),\n",
       "   ('ex',\n",
       "    'Sisiovara riro ora kevaitairara ovusia ovutarovu-ia orakasipupiepaaveira rara putepaive ora kevaitapaoro.'),\n",
       "   ('xp',\n",
       "    'Ol Sisiovara ol i save tok pilai tumas long ol yet. Tasol sampela taim ol i save koros taim pilai bilong ol i go moa yet.'),\n",
       "   ('xe',\n",
       "    'People from Sisiovara are big jokers but sometimes they anger each other going too far with the joking.')]),\n",
       " ('kevira',\n",
       "  [('ps', 'N'),\n",
       "   ('pt', 'FEM'),\n",
       "   ('ge', 'dog'),\n",
       "   ('tkp', 'dok'),\n",
       "   ('dt', '31/Oct/2005'),\n",
       "   ('cmt', 'How does this differ from kaakau?'),\n",
       "   ('ex', 'Vo Siureko-ia uva rirovira kevira kare toupaiveira.'),\n",
       "   ('xp', 'Long ples Siureko planti dok i save stap.'),\n",
       "   ('xe', 'Many dogs are in Siureko.')]),\n",
       " ('kevisi',\n",
       "  [('ps', 'N'),\n",
       "   ('pt', '???'),\n",
       "   ('dx', 'Central'),\n",
       "   ('ge', 'cabbage'),\n",
       "   ('tkp', 'kebis'),\n",
       "   ('eng', 'cabbage'),\n",
       "   ('nt', 'Tok Pisin loan'),\n",
       "   ('dt', '17/Nov/2005')]),\n",
       " ('kevoisi',\n",
       "  [('ps', 'V'),\n",
       "   ('pt', 'A'),\n",
       "   ('ge', 'persistent'),\n",
       "   ('ge', 'determined'),\n",
       "   ('tkp', '???'),\n",
       "   ('dt', '31/Oct/2005'),\n",
       "   ('vx', '1'),\n",
       "   ('cmt',\n",
       "    'Does this take a sentence complement? Is it aspectual, \"continue, keep\" (e.g. blijf in Dutch)?'),\n",
       "   ('ex', 'Kevoisiparoi va puraarapa reasipaoro.'),\n",
       "   ('xp', '???'),\n",
       "   ('xe', \"He is determined not to do what he doesn't want to do.\"),\n",
       "   ('ex',\n",
       "    'Pita upiare kevoisipaoro kepa puraparevo oisio teapi kepa viapau opesipe rara upia rera rerepieve.'),\n",
       "   ('xp',\n",
       "    'Pita i sanap strong long sik na em i wokim haus. Olsem nogut sik i daunim em na haus i no inap pinis.'),\n",
       "   ('xe', '???')]),\n",
       " ('kevoisivira',\n",
       "  [('alt', 'kevoisipavira'),\n",
       "   ('rt', 'kevoisi'),\n",
       "   ('ps', 'ADV'),\n",
       "   ('pt', 'MANNER'),\n",
       "   ('ge', 'determined-like'),\n",
       "   ('tkp', '???'),\n",
       "   ('dt', '31/Oct/2005'),\n",
       "   ('ex', 'Kevoisivira vovoupata eisi piepasa.'),\n",
       "   ('xp', '???'),\n",
       "   ('xe', 'You all desire determinedly to do it like that.'),\n",
       "   ('ex',\n",
       "    'Kevoisivira rera vurapaavo oisio rutu uvuipa ra pirutuva-ia iviroro ovaratavu iare.'),\n",
       "   ('xp',\n",
       "    'Mi lukim em olsem tru em nap strong long kalapim wara i go long hap sait.'),\n",
       "   ('xe',\n",
       "    'I saw him determined that he would cross the ??? to the other side.')]),\n",
       " ('kie',\n",
       "  [('ps', 'EXCL'),\n",
       "   ('ge', 'Watch out!'),\n",
       "   ('ge', 'Be careful!'),\n",
       "   ('tkp', 'lukaut'),\n",
       "   ('dt', '31/Oct/2005'),\n",
       "   ('ex', 'Ora vatatopou e vatatopauei avu.'),\n",
       "   ('xp', 'Yu must lukaut yu mas lukout gut.'),\n",
       "   ('xe', '???'),\n",
       "   ('ex', 'Aakova kakaeto tavipaeva oisio, Kie! Aiteto vii ragisia uriopa.'),\n",
       "   ('xp', 'Mama i tokim pikinini olsem, Lukaut! Pap bai kam stikim yu.'),\n",
       "   ('xe', \"Mama told her boy, Watch out! Dad's going to come whip you.\")]),\n",
       " ('kii',\n",
       "  [('ps', 'V'),\n",
       "   ('pt', 'A'),\n",
       "   ('ge', 'short of'),\n",
       "   ('ge', 'lacking'),\n",
       "   ('tkp', '???'),\n",
       "   ('cmt',\n",
       "    \"Meaning in example sentence is opposite of Firchow's translation!\"),\n",
       "   ('dcsv', 'true'),\n",
       "   ('vx', '1'),\n",
       "   ('dt', '31/Oct/2005'),\n",
       "   ('cmt', 'Check construction type.'),\n",
       "   ('ex', 'Kiiei oirara arova aioa.'),\n",
       "   ('xp', '???'),\n",
       "   ('xe', \"There isn't enough food for people.\"),\n",
       "   ('ex',\n",
       "    'Kepa kiiei rutu oirara iava uva viapau ragai tavukiavai ra uusira.'),\n",
       "   ('xp', 'Haus i pulap tru long ol man na mi nogat spes bilong slip.'),\n",
       "   ('xe', 'The house is full of people and I have no ??? to sleep.')]),\n",
       " ('kiikariko',\n",
       "  [('ps', 'N'),\n",
       "   ('pt', 'FEM'),\n",
       "   ('ge', 'type of bird'),\n",
       "   ('tkp', '???'),\n",
       "   ('nt', 'duck-like, webbed feet and flat bill, lives in shallow holes, ???'),\n",
       "   ('sf', 'FAUNA.BIRD'),\n",
       "   ('dt', '31/Oct/2005'),\n",
       "   ('ex',\n",
       "    'Kiikariko iriavu kokiova iria eriara-ia toupaeveira. Oisio kokotova osia pato kare.'),\n",
       "   ('xp',\n",
       "    'Kiikariko em i wanpela kain pisin i save stap insait ol hul i go insait na lek bilong em i olsem pato.'),\n",
       "   ('xe', '???')]),\n",
       " ('kiipie',\n",
       "  [('rt', 'kii'),\n",
       "   ('ps', 'V'),\n",
       "   ('pt', 'B'),\n",
       "   ('ge', 'cause to be short of'),\n",
       "   ('ge', 'cause to be lacking'),\n",
       "   ('tkp', '???'),\n",
       "   ('vx', '2'),\n",
       "   ('arg', 'O'),\n",
       "   ('dt', '08/Jun/2005'),\n",
       "   ('ex', 'Riro irara aioara kiipieivo tavete irara ragai-re.'),\n",
       "   ('xp', '???'),\n",
       "   ('xe', 'The visitors caused me to be short of food.')]),\n",
       " ('kiire',\n",
       "  [('ps', 'V'),\n",
       "   ('pt', 'A'),\n",
       "   ('ge', 'play tag'),\n",
       "   ('tkp', '???'),\n",
       "   ('vx', '1'),\n",
       "   ('ex', 'Kakaevure kiirepaaepa.'),\n",
       "   ('xp', '???'),\n",
       "   ('xe', 'The children were playing tag.'),\n",
       "   ('dt', '01/Jun/2005')]),\n",
       " ('kiire',\n",
       "  [('ps', 'N'),\n",
       "   ('pt', '???'),\n",
       "   ('ge', 'tag'),\n",
       "   ('tkp', 'wanpela kain pilai'),\n",
       "   ('dt', '31/Oct/2005'),\n",
       "   ('ex',\n",
       "    'Kiire purapaiveira kakaevure vosia iravu kakaeto iravu-ia pitureve raeraita iravu va tarioro.'),\n",
       "   ('xp',\n",
       "    'Tag em wanpela kain pilai ol mangi i save mekim. Wanpela mangi bai tasim narapela na em bai ran bihainim narapela mangi ???.'),\n",
       "   ('xe', 'Children play tag as one boy hold ??? and another chases it.')]),\n",
       " ('kiiru',\n",
       "  [('ps', 'N'),\n",
       "   ('pt', 'FEM'),\n",
       "   ('ge', 'walking stick'),\n",
       "   ('ge', 'cane'),\n",
       "   ('tkp', 'stik bilong wokabaut'),\n",
       "   ('dt', '31/Oct/2005'),\n",
       "   ('ex',\n",
       "    'Kiiru iria kukuearo-ia otuotua toupaiveira iria purapaiveira aue iava koosiva.'),\n",
       "   ('xp',\n",
       "    'Stik bilong wokabaut i gat sap long het bilong em. Ol i save mekim wanpela kain limbum.'),\n",
       "   ('xe', '??? which they make from ???.')]),\n",
       " ('kiiuto',\n",
       "  [('ps', 'N'),\n",
       "   ('pt', '???'),\n",
       "   ('ge', 'type of ant'),\n",
       "   ('tkp', 'anis'),\n",
       "   ('dt', '01/Sep/2005'),\n",
       "   ('ex',\n",
       "    'Rupavira toupare kiiuto, vegoaro toupai vasito sovaraia, vigei aiopaiveira.'),\n",
       "   ('xp', 'Em i bikpela anis i save kaikai yumi.'),\n",
       "   ('xe',\n",
       "    'This type of ant stays ???, lives in the jungle on the ground. They bite us.')]),\n",
       " ('kiki',\n",
       "  [('ps', 'V'),\n",
       "   ('pt', 'B'),\n",
       "   ('dx', 'Central'),\n",
       "   ('ge', 'kick'),\n",
       "   ('tkp', 'kikim'),\n",
       "   ('nt', 'Tok Pisin loan'),\n",
       "   ('vx', '2'),\n",
       "   ('arg', 'O'),\n",
       "   ('dt', '31/Oct/2005'),\n",
       "   ('ex', 'Pita peripa isi-va avaroi va isi kikisia kakae vure iare.'),\n",
       "   ('xp', 'Pita i kisim bol i go na em i kikim i go long ol pikinini.'),\n",
       "   ('xe', 'Peter is going with the ball to kick it to the boys.')]),\n",
       " ('kiki',\n",
       "  [('cl', 'isi'),\n",
       "   ('ps', 'N'),\n",
       "   ('pt', 'CL'),\n",
       "   ('ge', 'ball'),\n",
       "   ('tkp', 'bal'),\n",
       "   ('dt', '28/Jul/2005')]),\n",
       " ('kikipi',\n",
       "  [('ps', 'N'),\n",
       "   ('pt', 'MASC'),\n",
       "   ('dx', 'Pipipaia'),\n",
       "   ('ge', 'sago.midrib'),\n",
       "   ('eng', 'sticks within sago stalk'),\n",
       "   ('eng', 'arrow made of sago midrib'),\n",
       "   ('tkp', 'rap bilong saksak'),\n",
       "   ('tkp', 'supsup bilong saksak'),\n",
       "   ('cmt', 'Check vowel length of final vowel: kikipi or kikipii?'),\n",
       "   ('dt', '31/Oct/2005'),\n",
       "   ('ex',\n",
       "    'Kikipi ira toupareveira tetevu guruvaro vuruvuru-ia roia. Ira verapaiveira ravo guruvaro turapaive.'),\n",
       "   ('xp',\n",
       "    'Stik i save stap namel long ol lip saksak ol i save rausim dispela stik na samapim ol lip saksak.'),\n",
       "   ('xe', '???')]),\n",
       " ('kikipisi',\n",
       "  [('rt', 'kikipi'),\n",
       "   ('ps', 'N'),\n",
       "   ('pt', 'NT'),\n",
       "   ('ge', 'iron spear'),\n",
       "   ('ge', 'iron rod'),\n",
       "   ('tkp', 'spia'),\n",
       "   ('dt', '31/Oct/2005'),\n",
       "   ('ex', 'Kikipisi aearisi riro kaekae isi oara purapaiveira popotepairara.'),\n",
       "   ('xp', 'Hap haeian i longpela ol waitman i save wokim.'),\n",
       "   ('xe', '???')]),\n",
       " ('kikira',\n",
       "  [('ps', 'V'),\n",
       "   ('pt', 'B'),\n",
       "   ('ge', 'mix meat and greens'),\n",
       "   ('tkp', 'abusim abus na savor'),\n",
       "   ('arg', 'O'),\n",
       "   ('vx', '2'),\n",
       "   ('dt', '08/Jun/2005'),\n",
       "   ('ex', 'Oirato koorato kikirarevoi arua tai tapo rera orisia.'),\n",
       "   ('xp', '???'),\n",
       "   ('xe',\n",
       "    'The man is mixing the possum with green vegetables in order to cook it.')]),\n",
       " ('kikiraeko',\n",
       "  [('ps', 'N'),\n",
       "   ('pt', 'FEM'),\n",
       "   ('ge', 'spider'),\n",
       "   ('tkp', 'spaida'),\n",
       "   ('nt',\n",
       "    'Has green to yellow body, black legs and head, makes very large ???. It is much like the akave spider but larger.'),\n",
       "   ('dt', '31/Oct/2005'),\n",
       "   ('ex',\n",
       "    'Kikiraeko iriavu vaisiaro akave iria vararo-ia kokovara ora vurivuria toupaiveira. Rupara tapo kokotoara, oara kukue riropiepaiveira.'),\n",
       "   ('xp',\n",
       "    'Kikiraeko i nem bilong spaida i gat grinpela na yelo bodi na i gat ol blakpela lek i save mekim het i bikpela.'),\n",
       "   ('xe', '???')]),\n",
       " ('kikisi',\n",
       "  [('ps', 'N'),\n",
       "   ('pt', 'MASC'),\n",
       "   ('ge', 'midrib of sago frond'),\n",
       "   ('tkp', 'nok'),\n",
       "   ('dt', '31/Oct/2005'),\n",
       "   ('ex',\n",
       "    'Kikisi ira tetevu guruvaro isivaroia toupareveira ira verapaiveira vara turapasia ra vara-ia kepara purapaive.'),\n",
       "   ('xp',\n",
       "    'Bun i save stap beksait long lip saksak. Ol i save rausim na somapim saksak na mekim haus long em.'),\n",
       "   ('xe', '???')]),\n",
       " ('kikisikae',\n",
       "  [('ps', 'N'),\n",
       "   ('pt', 'NT'),\n",
       "   ('ge', 'broom'),\n",
       "   ('tkp', 'brum'),\n",
       "   ('dt', '31/Oct/2005'),\n",
       "   ('ex', 'Kikisikae oa purapaiveira aue iava tetevu ora aue opita.'),\n",
       "   ('xp', 'Brum ol i save mekim long stik bilong saksak na long kokonas.'),\n",
       "   ('xe', 'Brooms are made from sago and coconut.')]),\n",
       " ('kikisiova',\n",
       "  [('ps', 'N'),\n",
       "   ('pt', 'NT'),\n",
       "   ('ge', 'bow made for children'),\n",
       "   ('tkp', 'banara bilong pikinini'),\n",
       "   ('dt', '31/Oct/2005'),\n",
       "   ('ex',\n",
       "    'Kikisiova koetava iria purapaiveira oira kakaero-pa aue iava veeta pariero.'),\n",
       "   ('xp',\n",
       "    'Liklik bunara ol i save mekim bilong liklik mangi man. Ol i save mekim long ol hap mambu.'),\n",
       "   ('xe', '???')]),\n",
       " ('kikitausi',\n",
       "  [('ps', 'V'),\n",
       "   ('pt', 'B'),\n",
       "   ('ge', 'tear off with teeth'),\n",
       "   ('tkp', 'brukim'),\n",
       "   ('nt', 'There is humor associated with the use of this word in this way.'),\n",
       "   ('arg', 'O'),\n",
       "   ('vx', '2'),\n",
       "   ('dt', '31/Oct/2005'),\n",
       "   ('ex', 'Oirato koue sope kikitausipare va aiopaoro.'),\n",
       "   ('xp', '???'),\n",
       "   ('xe', 'The man is tearing the flesh of the pig off as he is eating it.'),\n",
       "   ('ex', 'Kakau kokai kikitausirevoi kurivira rutu rera aiooro.'),\n",
       "   ('xp', 'Dok i bagarapim tru kakaruk taim em kaikaim.'),\n",
       "   ('xe', 'The dog ripped flesh from the rooster while eating him.')]),\n",
       " ('kikoo',\n",
       "  [('ps', 'N'),\n",
       "   ('pt', 'HUM'),\n",
       "   ('ge', 'second-born'),\n",
       "   ('tkp', 'numba tu pikinini'),\n",
       "   ('eng', 'second-born (but not last) child'),\n",
       "   ('cmt', 'What if someone is both second-born and last-born?'),\n",
       "   ('dt', '31/Oct/2005'),\n",
       "   ('ex',\n",
       "    'Sira kikoova Vaeako sirovapava aue iava uvare Vaeako irapavira kavauopa uva Sira oira sirova kavauopa.'),\n",
       "   ('xp',\n",
       "    'Sira em i namba tu bikos Vaeako i bin bon pas na Sira i bon bihain long em.'),\n",
       "   ('xe',\n",
       "    'Sira is number two and Vaeako is ??? because Vaeako was born first and Sira was born ???.')]),\n",
       " ('kilia',\n",
       "  [('ps', 'V'),\n",
       "   ('pt', 'B'),\n",
       "   ('ge', 'clarify'),\n",
       "   ('tkp', 'kiliaim'),\n",
       "   ('nt', 'Tok Pisin loan'),\n",
       "   ('arg', '???'),\n",
       "   ('vx', '???'),\n",
       "   ('cmt', 'Example needed'),\n",
       "   ('dt', '08/Jun/2005')]),\n",
       " ('kio',\n",
       "  [('ps', 'V'),\n",
       "   ('pt', 'B'),\n",
       "   ('ge', 'nudge'),\n",
       "   ('tkp', 'tasim'),\n",
       "   ('eng', 'attract attention by touching, tapping, or scratching'),\n",
       "   ('arg', 'O'),\n",
       "   ('vx', '2'),\n",
       "   ('dt', '31/Oct/2005'),\n",
       "   ('ex', 'Ragai kiorevoi.'),\n",
       "   ('xp', '???'),\n",
       "   ('xe', 'He nudged me gaining my attention (discreetly).'),\n",
       "   ('ex', 'Oirato riakova kiorevoi sipareo-ia oira uvuru sovaraia.'),\n",
       "   ('xp', 'Man i tasim meri long pinga name long planti man.'),\n",
       "   ('xe', 'He man touched the woman with his finger ???.')]),\n",
       " ('kipa',\n",
       "  [('ps', 'V'),\n",
       "   ('pt', 'B'),\n",
       "   ('dx', 'Central'),\n",
       "   ('ge', 'wan samting tru'),\n",
       "   ('tkp', '???'),\n",
       "   ('vx', '???'),\n",
       "   ('dt', '08/Dec/2005'),\n",
       "   ('ex', 'Sikuruapa kipaavora laibri vukuro vateoro.'),\n",
       "   ('xp',\n",
       "    'Wanpela samting tru ia ol i bin mekim long givim ol laibri buk long skul.'),\n",
       "   ('xe', '???')]),\n",
       " ('kipapie',\n",
       "  [('rt', 'kipa'),\n",
       "   ('ps', 'V'),\n",
       "   ('pt', 'B'),\n",
       "   ('dx', 'Central'),\n",
       "   ('ge', 'wan samting tru'),\n",
       "   ('tkp', '???'),\n",
       "   ('vx', '???'),\n",
       "   ('dt', '22/Nov/2005'),\n",
       "   ('ex',\n",
       "    'Oirato riakova-pa kipapieiraoreva uvare oira vateieva sigoa uva va raga vokapaeveira viapau rava kavupaeve uvare viapau oira oisi oai.'),\n",
       "   ('xp',\n",
       "    'Man i bin mekim wanpela samting tru long taim em givim meri long wanpela naip. Na em i save wokabaut wantaim dispela naip tasol bikos em i nogat wanpela naip olsem.'),\n",
       "   ('xe', '???')]),\n",
       " ('kipe',\n",
       "  [('ps', 'V'),\n",
       "   ('pt', 'B'),\n",
       "   ('ge', 'cut grass with a sickle'),\n",
       "   ('tkp', 'saripim'),\n",
       "   ('vx', '2'),\n",
       "   ('arg', 'O'),\n",
       "   ('dt', '31/Oct/2005'),\n",
       "   ('cmt', 'What does varao mean in example?'),\n",
       "   ('ex', 'Kokapa kou kipe varao.'),\n",
       "   ('xp', 'Yu katim grass.'),\n",
       "   ('xe', 'Cut the grass.'),\n",
       "   ('ex', 'Pita isisio kou kipere uvare kepa ruvaraia toupaivoi.'),\n",
       "   ('xp', 'Pita em i katim gras bikos i stap klostu long haus.'),\n",
       "   ('xe', 'Peter is cutting the grass because it is close to the house.')]),\n",
       " ('kipekipe',\n",
       "  [('rt', 'kipe'),\n",
       "   ('ps', 'N'),\n",
       "   ('pt', '???'),\n",
       "   ('ge', 'point of land in water point at base of fridge'),\n",
       "   ('tkp', 'poin'),\n",
       "   ('dt', '31/Oct/2005'),\n",
       "   ('cmt', 'Double check original'),\n",
       "   ('ex', 'Uruvaovi ora Ivitu vo kipekipeo puraeve vo oraaivaropieovo.'),\n",
       "   ('xp', 'Uruvaori riva na Ivitu riva bung na mekim dispela point yia.'),\n",
       "   ('xe', 'Uruvaori and Ivitu meet to make a point here.'),\n",
       "   ('ex',\n",
       "    'Uruvaovi vaio ora Kikiovi airea Vurairiva-ia kipekipea puraereva oisio osia kariava.'),\n",
       "   ('xp',\n",
       "    'Uruvaovi wantaim Kikiovi tupela i bin mekim Vurairiva poin olsem palai.'),\n",
       "   ('xe',\n",
       "    'Uruvaovi and Kikiovi, the two of them made Vurairiva Point like a lizard.')]),\n",
       " ('kipekipea',\n",
       "  [('rt', 'kipekipe'),\n",
       "   ('ps', 'N'),\n",
       "   ('pt', 'NT'),\n",
       "   ('ge', 'point of land in water'),\n",
       "   ('ge', 'point at base of ridge'),\n",
       "   ('ge', 'spine of lizard'),\n",
       "   ('tkp', '???'),\n",
       "   ('dt', '18/Feb/2004')]),\n",
       " ('kipeto',\n",
       "  [('rt', 'kipe'),\n",
       "   ('ps', 'N'),\n",
       "   ('pt', 'MASC'),\n",
       "   ('ge', 'sickle'),\n",
       "   ('ge', 'scythe'),\n",
       "   ('tkp', 'scrip'),\n",
       "   ('dt', '31/Oct/2005'),\n",
       "   ('ex',\n",
       "    'Oavu varao iava kovoparaiva oa porokovira toupaiveira oisio osia siarepe isisio kipeto.'),\n",
       "   ('xp',\n",
       "    'Wanpela hap samting bilong ol samting bilong wok olsem gras naip bilong katim gras.'),\n",
       "   ('xe', '???')]),\n",
       " ('kipu',\n",
       "  [('ps', 'V'),\n",
       "   ('pt', 'B'),\n",
       "   ('ge', 'paint'),\n",
       "   ('tkp', 'penim'),\n",
       "   ('eng', 'paint'),\n",
       "   ('eng', 'smear on surface'),\n",
       "   ('arg', 'O'),\n",
       "   ('vx', '2'),\n",
       "   ('dt', '31/Oct/2005'),\n",
       "   ('ex', 'Voea kipupaive vo taritaro-ia varao opita taritaro.'),\n",
       "   ('xp', '???'),\n",
       "   ('xe', 'They would smear them with the mashed coconut meat.'),\n",
       "   ('ex',\n",
       "    'Ragai varaaro kipuivo varasiri-ia uvare kasikasi ragai-ia orapuraroe.'),\n",
       "   ('xp',\n",
       "    'Ol i penim bodi bilong mi long marasign bikos kaskas i kamap long bodi bilong mi.'),\n",
       "   ('xe',\n",
       "    'They painted my body with medicine because scabies appeared on me.')]),\n",
       " ('kipukipu',\n",
       "  [('rt', 'kipu'),\n",
       "   ('ps', 'V'),\n",
       "   ('pt', 'B'),\n",
       "   ('ge', 'rub.on'),\n",
       "   ('tkp', 'rabim'),\n",
       "   ('eng', 'rub on'),\n",
       "   ('eng', 'smear on'),\n",
       "   ('eng', 'massage'),\n",
       "   ('vx', '2'),\n",
       "   ('arg', 'O'),\n",
       "   ('dt', '08/Dec/2005'),\n",
       "   ('ex',\n",
       "    'Pita ira opita gatao-ia orakipukipu uvare poupouare toupaivoi rera kagavearo-ia.'),\n",
       "   ('xp',\n",
       "    'Pita em i rabim rabim meme bilong kokonat bikos ol das i stap long pes bilong em.'),\n",
       "   ('xe', 'Peter painted himself with coconut ??? because ??? on his face.'),\n",
       "   ('ex', 'Orakipukipuae aue-ia kukupira pupisia.'),\n",
       "   ('xp', 'Ol i rabim kle long skin bilong singsing kaul.'),\n",
       "   ('xe', 'They rubbed ??? on themselves for the singsing.')]),\n",
       " ('kipupaa',\n",
       "  [('rt', 'kipu'),\n",
       "   ('ps', 'N'),\n",
       "   ('pt', 'NT'),\n",
       "   ('ge', 'paint brush'),\n",
       "   ('tkp', 'bros bilong pen'),\n",
       "   ('dt', '31/Oct/2005'),\n",
       "   ('ex', 'Uriou kipupaa-va eva ragai vaaro.'),\n",
       "   ('xp', 'Kam wantaim bras bilong mi.'),\n",
       "   ('xe', 'Come with that brush of mine.')]),\n",
       " ('kipupato',\n",
       "  [('rt', 'kipu'),\n",
       "   ('ps', 'N'),\n",
       "   ('pt', 'HUM'),\n",
       "   ('ge', 'painter'),\n",
       "   ('tkp', 'pen man'),\n",
       "   ('avm', 'pa_required'),\n",
       "   ('dt', '31/Oct/2005'),\n",
       "   ('ex', 'Kipupato ro ira kepa kipupa.'),\n",
       "   ('xp', 'Man blong paintim ol house.'),\n",
       "   ('xe', 'A painter is one who paints houses.'),\n",
       "   ('ex', 'Vokipavira kipupato urioparoi kepa kipusia.'),\n",
       "   ('xp', 'Tumoro bai man bilong penim haus bai kam napenim haus.'),\n",
       "   ('xe', 'Tomorrow the painter is coming to paint the house.')]),\n",
       " ('kipuvira',\n",
       "  [('alt', 'kipupavira'),\n",
       "   ('rt', 'kipu'),\n",
       "   ('ps', 'ADV'),\n",
       "   ('pt', 'MANNER'),\n",
       "   ('ge', 'smeared'),\n",
       "   ('tkp', 'bagarap long pen'),\n",
       "   ('dt', '28/Aug/2005'),\n",
       "   ('ex', 'Vao varoa kipuvira toupai aue iava peri.'),\n",
       "   ('xp', 'Dispela laplap em i gat paint long em.'),\n",
       "   ('xe', 'This clothing is smeared with paint.')]),\n",
       " ('kira',\n",
       "  [('ps', 'N'),\n",
       "   ('pt', 'NT'),\n",
       "   ('ge', 'kina'),\n",
       "   ('tkp', 'kina'),\n",
       "   ('nt', 'Tok Pisin loan'),\n",
       "   ('dt', '31/Oct/2005'),\n",
       "   ('ex', 'Kira oa-ia Papua Niugini siovaraia.'),\n",
       "   ('xp', 'Kina ol i yusim insait long Papua Niugini.'),\n",
       "   ('xe', 'The kina is (used) inside of Papua New Guinea.')]),\n",
       " ('kirava',\n",
       "  [('ps', 'V'),\n",
       "   ('pt', 'A'),\n",
       "   ('ge', '???'),\n",
       "   ('tkp', 'no pilim gut'),\n",
       "   ('vx', '1'),\n",
       "   ('cmt',\n",
       "    'Need to investigate meaning--Firchow\\'s translation (\"oblivious\") seems wrong!'),\n",
       "   ('dt', '31/Oct/2005'),\n",
       "   ('ex',\n",
       "    'Kakaeto kiravaroi uvare viapau aakova ikauvira rera sisiuevo oa iava rirovira gauparevoi.'),\n",
       "   ('xp',\n",
       "    'Pikinini i no pilim gut bikos mama i no wasim em haraiap olsem na em i krai.'),\n",
       "   ('xe', '???')]),\n",
       " ('kire',\n",
       "  [('ps', 'V'),\n",
       "   ('pt', 'A'),\n",
       "   ('ge', 'play tag'),\n",
       "   ('tkp', 'wanpela kain pilai'),\n",
       "   ('vx', '???'),\n",
       "   ('dt', '22/Nov/2005'),\n",
       "   ('ex', 'Kire kakaevure visikopareira kirepaoro.'),\n",
       "   ('xp', 'Em wanpela kain pilai bilong ol pikinini.'),\n",
       "   ('xe', '???'),\n",
       "   ('ex',\n",
       "    'Kire iria purpaiveira oratariopaoro rairavu vatereve raera ita iravuva tarioro.'),\n",
       "   ('xp',\n",
       "    'Em wanpela pilai ol i save ron bai narapela i givim narapel bai givim gen ran bihainim narapela.'),\n",
       "   ('xe', '???'),\n",
       "   ('ex',\n",
       "    'Pita kirepa Tomas tapo ora rera araokoirararo. Tomas Pita vaterevoi rera-ia pituoro uva viapau uvuipa ra vorevira oira vatereve uvare viapau uvuiparoi ra ikaupareve.'),\n",
       "   ('xp',\n",
       "    'Pita i pilai tas wantaim Tomas na ol brata bilong em. Tomas em i givim Pita taim e i holim em na em i no inap givim bek gen bikos em i no inap ran.'),\n",
       "   ('xe', '???')]),\n",
       " ('kiri',\n",
       "  [('ps', 'V'),\n",
       "   ('pt', 'B'),\n",
       "   ('ge', 'rip open'),\n",
       "   ('ge', 'tear open'),\n",
       "   ('tkp', 'bruk'),\n",
       "   ('vx', '2'),\n",
       "   ('arg', 'O'),\n",
       "   ('dt', '31/Oct/2005'),\n",
       "   ('ex', 'Araisi ruu kirikirirevoi.'),\n",
       "   ('xp', '???'),\n",
       "   ('xe', 'He rips open the rice bag.'),\n",
       "   ('ex', 'Eapu kepa kiripaa eva ra avaave evaova kavuoro.'),\n",
       "   ('xp', 'Bai mi brukim haus bilong kurakun na bai ol lusim diwai na go.'),\n",
       "   ('xe', 'I will break open the ant house and they will leave the tree.')]),\n",
       " ('kirikaokao',\n",
       "  [('ps', 'N'),\n",
       "   ('pt', 'FEM'),\n",
       "   ('ge', 'bird'),\n",
       "   ('tkp', '???'),\n",
       "   ('eng', 'Dollarbird (Eurystomus orientalis)'),\n",
       "   ('sf', 'FAUNA.BIRD'),\n",
       "   ('dt', '31/Oct/2005'),\n",
       "   ('ex',\n",
       "    'Kirikaokao iria kokovaravira avuaua toupaivera ari putaearei reroaro avaka toupaiveira ora popoteara. Evaraiava vearopie kekepaoveira.'),\n",
       "   ('xp',\n",
       "    'Kirikaokao em wanpela dola pisin beksait bilong em i gat grinpela gras. Na handanit long tupela wing bilong em i gat brupela gras na long bel i gat ol liklik waitpela gras. Long ol dispela kala em i save luk nais tru.'),\n",
       "   ('xe', '???')]),\n",
       " ('kirioto',\n",
       "  [('ps', 'N'),\n",
       "   ('pt', 'MASC'),\n",
       "   ('ge', 'vulva and all parts inside'),\n",
       "   ('tkp', 'kan'),\n",
       "   ('dt', '31/Oct/2005'),\n",
       "   ('ex', 'Kirioto riakora iava osia sovaraia oaravu toupaivoi.'),\n",
       "   ('xp', 'The vulva of a woman is ???.'),\n",
       "   ('xe', '???')]),\n",
       " ('kiro',\n",
       "  [('ps', 'V'),\n",
       "   ('pt', 'B'),\n",
       "   ('ge', 'write'),\n",
       "   ('tkp', 'rait'),\n",
       "   ('tkp', 'raitim'),\n",
       "   ('arg', 'O'),\n",
       "   ('vx', '2'),\n",
       "   ('dt', '31/Oct/2005'),\n",
       "   ('ex', 'Vii vaisiaro kirori.'),\n",
       "   ('xp', 'Raitim nem bilong yu.'),\n",
       "   ('xe', 'Write your name.'),\n",
       "   ('ex', 'Ragai rovoparai kiropaoro vukua-ia.'),\n",
       "   ('xp', 'Mi wok long stat long rait long buk.'),\n",
       "   ('xe', 'I am starting to write in the book.')]),\n",
       " ('kirokiro',\n",
       "  [('ps', 'N'),\n",
       "   ('pt', 'FEM'),\n",
       "   ('ge', 'bush used for sorcery'),\n",
       "   ('tkp', 'tanget raft'),\n",
       "   ('nt', '???'),\n",
       "   ('cmt',\n",
       "    'Kirokiro em wanpela kain tanget ol i save yusim long mekim ol kainkain marasin tumbuna'),\n",
       "   ('dt', '31/Oct/2005')]),\n",
       " ('kirokiro',\n",
       "  [('rt', 'kiro'),\n",
       "   ('ps', 'V'),\n",
       "   ('pt', 'B'),\n",
       "   ('rdp', 'full'),\n",
       "   ('ge', 'write'),\n",
       "   ('tkp', '???'),\n",
       "   ('arg', 'O'),\n",
       "   ('vx', '2'),\n",
       "   ('dt', '31/Oct/2005'),\n",
       "   ('ex', 'Ragai kirokiropaa pepa ivaraia.'),\n",
       "   ('xp', 'Mi wok antap long teibol.'),\n",
       "   ('xe', 'I am writing on paper.')]),\n",
       " ('kirokiropato',\n",
       "  [('rt', 'kirokiro'),\n",
       "   ('ps', 'N'),\n",
       "   ('pt', 'MASC'),\n",
       "   ('ge', 'pencil'),\n",
       "   ('ge', 'pen'),\n",
       "   ('ge', 'typewriter'),\n",
       "   ('tkp', 'pensil'),\n",
       "   ('avm', 'pa_required'),\n",
       "   ('sc', 'INSTRUMENT'),\n",
       "   ('dt', '31/Oct/2005'),\n",
       "   ('ex',\n",
       "    'Vosia viapau kirokiropatoavai toupareve ra viapau uvuipauei oavuavuvai karekepe pepa-ia.'),\n",
       "   ('xp', 'Sapos pensol i no stap bai yu no gat samting bai kamap long pepa.'),\n",
       "   ('xe', \"If there isn't a pencil, ???.\")]),\n",
       " ('kiroko',\n",
       "  [('ps', 'N'),\n",
       "   ('pt', '???'),\n",
       "   ('ge', 'clock'),\n",
       "   ('tkp', 'kilok'),\n",
       "   ('nt', 'Tok Pisin loan'),\n",
       "   ('ig', 'yes'),\n",
       "   ('dt', '04/Oct/2004')]),\n",
       " ('kiru',\n",
       "  [('ps', 'V'),\n",
       "   ('pt', 'A'),\n",
       "   ('ge', 'have sore near mouth'),\n",
       "   ('tkp', 'i gat soa long maus'),\n",
       "   ('vx', '1'),\n",
       "   ('cmt', 'Is there a transitive version?'),\n",
       "   ('dt', '08/Dec/2005'),\n",
       "   ('ex', 'Orakiruroe rao aveke-ia eisi Ivitu sisiupaoro.'),\n",
       "   ('xp', 'Em bin mekim soa long ston long Ivitu.'),\n",
       "   ('xe', '???')]),\n",
       " ('kirukiru',\n",
       "  [('rt', 'kiru'),\n",
       "   ('ps', 'V'),\n",
       "   ('pt', 'A'),\n",
       "   ('ge', 'crisp'),\n",
       "   ('tkp', 'drai pinis'),\n",
       "   ('vx', '1'),\n",
       "   ('dt', '01/Nov/2005'),\n",
       "   ('cmt', \"What's the -a doing in kirukiru?\"),\n",
       "   ('ex', 'Korasiope koue sope vao kirukirua.'),\n",
       "   ('xp', 'Mit blong kapur na meat blong pig em stongpela mit tru.'),\n",
       "   ('xe', '???'),\n",
       "   ('ex',\n",
       "    'Vao kirukiruiraopai koie sope uva viapau uvuipai reuriara-ia va taritasia.'),\n",
       "   ('xp',\n",
       "    'Dispela mit bilong pik i strong tumas olsem na mi no inap memeim long ol tit.'),\n",
       "   ('xe', \"The pig meat is ??? and I can't chew it with my teeth.\")]),\n",
       " ('kirukirua',\n",
       "  [('rt', 'kiru'),\n",
       "   ('ps', 'N'),\n",
       "   ('pt', 'NT'),\n",
       "   ('ge', 'biscuit'),\n",
       "   ('ge', 'ground food parched on fire'),\n",
       "   ('tkp', 'bisket'),\n",
       "   ('dt', '01/Nov/2005'),\n",
       "   ('cmt', 'Check original--example seems messed up.'),\n",
       "   ('ex', 'Kirukirua vao oa viapau ukovira aipavi.'),\n",
       "   ('xp', 'Oiso osa biscuit kaikai i no gat wara instap insat long em.'),\n",
       "   ('xe', '???'),\n",
       "   ('ex',\n",
       "    'Aioa oisio osia aue visikete kirukirua oa-ia viapau aue uukoavai va-ia.'),\n",
       "   ('xp', 'Kaikai olsem biskit i drai i nogat wara long em.'),\n",
       "   ('xe', '???')]),\n",
       " ('kirupato',\n",
       "  [('rt', 'kiru'),\n",
       "   ('ps', 'N'),\n",
       "   ('pt', 'HUM'),\n",
       "   ('ge', 'person with sores around the mouth'),\n",
       "   ('tkp', 'man i gat soa long maus'),\n",
       "   ('dt', '01/Nov/2005'),\n",
       "   ('ex', 'Oivato/riarova kirupato-vii vigoa-ia kapuara taupai.'),\n",
       "   ('xp', 'Nom on meri isat sore long em.'),\n",
       "   ('xe', '???'),\n",
       "   ('ex',\n",
       "    'Oirato ira gisipoaro-ia tarivira toupaive aue kapua. Oire reraera kirupato.'),\n",
       "   ('xp', 'Man sua i raonim maus bilong em. Orait em dispela em mas sua man.'),\n",
       "   ('xe', '???')]),\n",
       " ('kitoiva',\n",
       "  [('ps', 'N'),\n",
       "   ('pt', 'FEM'),\n",
       "   ('ge', 'crayfish'),\n",
       "   ('ge', 'shrimp'),\n",
       "   ('tkp', '???'),\n",
       "   ('nt', 'Very small shrimp, comes in with whitebait on surface of ocean.'),\n",
       "   ('dt', '01/Nov/2005'),\n",
       "   ('ex', 'Kitoiva votoupaeveira avakava-ia garepavi kavoriva.'),\n",
       "   ('xp', 'Em liklik kindam em i save i stap long solwara.'),\n",
       "   ('xe', '???'),\n",
       "   ('ex',\n",
       "    'Kitoiva iria avakava iava uriopaoveira. Ra uukovi sirova ipapao. Ra voa oira oupaive oira oiripasia. Oire oira aioive.'),\n",
       "   ('xp',\n",
       "    'Liklik kain kindam i save kam long sol wara. Na bihainim wara i go antap. Na ol i save kisim na kukim kaikai.'),\n",
       "   ('xe', '???')]),\n",
       " ('kitu',\n",
       "  [('ps', 'V'),\n",
       "   ('pt', 'A'),\n",
       "   ('ge', 'store'),\n",
       "   ('ge', 'save'),\n",
       "   ('tkp', 'hipim'),\n",
       "   ('tkp', 'lusim hap bilong bihain'),\n",
       "   ('vx', '???'),\n",
       "   ('arg', '???'),\n",
       "   ('cmt',\n",
       "    'Need to double-check classification--old example (deleted) looked like class B'),\n",
       "   ('cmt', 'Need a better example'),\n",
       "   ('dt', '01/Nov/2005'),\n",
       "   ('ex', 'Ragai vao-ia kiturai aioa vore osia ogoera ra va aioa.'),\n",
       "   ('xp',\n",
       "    'Mi lusim dispela hap kaikai bilong bihain. Na sapos mi hangere bai mi kaikaim bihain.'),\n",
       "   ('xe', '???')]),\n",
       " ('kitukitu',\n",
       "  [('rt', 'kitu'),\n",
       "   ('ps', 'V'),\n",
       "   ('pt', 'B'),\n",
       "   ('ge', 'scrub clothes'),\n",
       "   ('tkp', 'sikirapim'),\n",
       "   ('arg', 'O'),\n",
       "   ('vx', '2'),\n",
       "   ('cmt', \"Doesn't seem related to kitu--may not be a reduplication of kitu\"),\n",
       "   ('dt', '01/Nov/2005'),\n",
       "   ('ex', 'Vearovira varoara kitukituerevora.'),\n",
       "   ('xp', 'Tupela meri i wasim gut laplap.'),\n",
       "   ('xe', 'The two of them washed the clothes well.'),\n",
       "   ('ex',\n",
       "    'Vosia varoa kitukituragari osia viapau aue siopu ra viapau vearo kekepape.'),\n",
       "   ('xp',\n",
       "    'Sapos yu wasim nating laplap taim i nogat sop, laplap bai i no nap luk gut.'),\n",
       "   ('xe', \"If you scrub clothing without soap it won't look good.\")]),\n",
       " ('kiu',\n",
       "  [('ps', 'V'),\n",
       "   ('pt', 'B'),\n",
       "   ('ge', 'insert'),\n",
       "   ('eng', 'put in'),\n",
       "   ('eng', 'insert'),\n",
       "   ('tkp', 'go insait'),\n",
       "   ('tkp', 'putim insait'),\n",
       "   ('dcsv', 'true'),\n",
       "   ('arg', 'O'),\n",
       "   ('vx', '2'),\n",
       "   ('dt', '18/Nov/2005'),\n",
       "   ('ex', 'Vao kiupe evoa kepa.'),\n",
       "   ('xp', 'Yu putim pik insait long house.'),\n",
       "   ('xe', '???'),\n",
       "   ('ex', 'Voea rutu kukueara kiuivere koatapaoro.'),\n",
       "   ('xp', '???'),\n",
       "   ('xe', 'They all will go head first, entering in.'),\n",
       "   ('ex',\n",
       "    'Pita koie kiurevoi kasiura sovaraia. Teapi aio kovo aioeve vosia ratau toupaeve.'),\n",
       "   ('xp',\n",
       "    'Pita i putim pik insait long banis. Nogut i kaikaim gaden sapos em i stap autsait.'),\n",
       "   ('xe',\n",
       "    'Peter put the pig inside of the fence. Unfortunately he woud eat the garden if he were outside.')]),\n",
       " ('kiupie',\n",
       "  [('rt', 'kiu'),\n",
       "   ('ps', 'V'),\n",
       "   ('pt', 'B'),\n",
       "   ('ge', 'insert'),\n",
       "   ('eng', 'put in first'),\n",
       "   ('eng', 'insert first'),\n",
       "   ('tkp', 'go insait'),\n",
       "   ('arg', 'O'),\n",
       "   ('vx', '2'),\n",
       "   ('dt', '30/Apr/2006'),\n",
       "   ('ex', 'Vavaea kiupieri rikui sovara iare.'),\n",
       "   ('xp', '???'),\n",
       "   ('xe', 'Thrust your hand into the hole.'),\n",
       "   ('ex', 'Vavaea kiupie tarausisi iava oapa-ia.'),\n",
       "   ('xp', 'Yu putim han i go insait long poket bilong trauses.'),\n",
       "   ('xe', 'Put your hands inside the pockets of your trousers.'),\n",
       "   ('ex', 'Evo turu kiupie rogori vavo-re.'),\n",
       "   ('xp', 'Yu putim pastaim hap paia wut ya i go long hap.'),\n",
       "   ('xe', '???')]),\n",
       " ('kiuto',\n",
       "  [('ps', 'N'),\n",
       "   ('pt', 'MASC'),\n",
       "   ('ge', 'type of ant'),\n",
       "   ('tkp', 'anis'),\n",
       "   ('nt', 'has stinging bite'),\n",
       "   ('sf', 'FAUNA.INSECT'),\n",
       "   ('dt', '01/Nov/2005'),\n",
       "   ('ex', 'Kiuto rupato iro avupurato kasikasipievive.'),\n",
       "   ('xp', 'Em anis em i save kaikai yumi.'),\n",
       "   ('xe', '???'),\n",
       "   ('ex',\n",
       "    'Kiuto rupato ira vasipievira avu puraparoveira uvuipau ragauri rara viavureve.'),\n",
       "   ('xp', 'Blakpela anis em inap kaikaim yu na bai yu inap krai.'),\n",
       "   ('xe', 'The black ant ??? makes bites ???.')]),\n",
       " ('kiuve',\n",
       "  [('ps', 'N'),\n",
       "   ('pt', 'FEM'),\n",
       "   ('ge', 'tropical.ulcer'),\n",
       "   ('eng', 'tropical ulcer'),\n",
       "   ('tkp', 'bikpela sua'),\n",
       "   ('nt', 'very large in size'),\n",
       "   ('dt', '01/Nov/2005'),\n",
       "   ('ex', 'Kiuve kapua eva viia.'),\n",
       "   ('xp', 'Yu gat bikpela sore em i stap long yu.'),\n",
       "   ('xe', '???'),\n",
       "   ('ex',\n",
       "    'Kiuve kapuaro iava oisioa kopiipave voari tuariri uvare vuri kapuaro rutua.'),\n",
       "   ('xp',\n",
       "    'Bikpela sua tru ol i bin save dai long em long taim bipo bikos em ol sua nogut tru.'),\n",
       "   ('xe',\n",
       "    'From tropical ulcer sores they always died long ago because they are really bad sores.')]),\n",
       " ('kiuvu',\n",
       "  [('ps', 'N'),\n",
       "   ('pt', 'MASC'),\n",
       "   ('ge', 'wind'),\n",
       "   ('tkp', 'win'),\n",
       "   ('dt', '01/Nov/2005'),\n",
       "   ('ex', 'Riro varivarito kiuvu ira oisio-va urioparoveira Kireaka-ia.'),\n",
       "   ('xp', 'Strongpela win i save kam olsem long Kereaka.'),\n",
       "   ('xe', 'A very mighty wind always come this way ??? Kereaka.')]),\n",
       " ('koa',\n",
       "  [('ps', 'V'),\n",
       "   ('pt', 'B'),\n",
       "   ('ge', 'skin'),\n",
       "   ('eng', 'bark'),\n",
       "   ('eng', 'skin'),\n",
       "   ('eng', 'peel'),\n",
       "   ('tkp', 'raosim skin'),\n",
       "   ('arg', 'O'),\n",
       "   ('vx', '2'),\n",
       "   ('dt', '01/Nov/2005'),\n",
       "   ('ex', 'Rakariua koaivere evaova iava.'),\n",
       "   ('xp', '???'),\n",
       "   ('xe', 'They will take the bark off of the tree.'),\n",
       "   ('ex',\n",
       "    'Siriavi iria rakaria kaaevoi tegotoa iava uva vo iro-ia opita ogata tuuevoi.'),\n",
       "   ('xp',\n",
       "    'Siriavi em i pulim rop bilong wel banana na em i mekim woksak kokonat long em.'),\n",
       "   ('xe',\n",
       "    'Siriavi peeled the skin from the wild banana and sewed a coconut bag from the vine.')]),\n",
       " ('koai',\n",
       "  [('ps', 'N'),\n",
       "   ('pt', 'NT'),\n",
       "   ('ge', 'clam'),\n",
       "   ('tkp', 'sel'),\n",
       "   ('tkp', 'kina'),\n",
       "   ('nt', 'edible, found on the west coast of Bougainville'),\n",
       "   ('dt', '01/Nov/2005'),\n",
       "   ('ex',\n",
       "    'Vo toupa avaka vogara savarain aiopa kave voea kasipai aue aicoro curapasa.'),\n",
       "   ('xp',\n",
       "    'Em i stap insade lang wetsan blong sol wara ol save kaikainu na makim kanag??.'),\n",
       "   ('xe', '???'),\n",
       "   ('ex',\n",
       "    'Koai riro kaekaepato akoroto ira eisi toupareveira Kereaka-ia ira oupaiveira rera oripasia ra rera aiopaive.'),\n",
       "   ('xp',\n",
       "    'Koai em wanpela kain kina o sel i save stap long Kereaka. Ol i save kisim na kukim na kaikai.'),\n",
       "   ('xe',\n",
       "    'Koai is a kind of long clam that is found in Kereaka which they get in order to cook and they eat it.')]),\n",
       " ('koakoa',\n",
       "  [('ps', 'N'),\n",
       "   ('pt', 'NT'),\n",
       "   ('ge', 'plant'),\n",
       "   ('tkp', '???'),\n",
       "   ('sf', 'FLORA'),\n",
       "   ('nt', 'has broad leaf like wild banana, used to make temporary shelter'),\n",
       "   ('dt', '01/Nov/2005'),\n",
       "   ('ex', 'Vosia avapau arua tuesia koakoa tokouvere tapo vagiva rakusia.'),\n",
       "   ('xp', 'Taim yu go kisim kumu bai yu katim tu sampela ol wail banana lip.'),\n",
       "   ('xe', 'When you go harvest vegetables, you also cut wild banana leaf.'),\n",
       "   ('ex',\n",
       "    'Koakoa oa guruvaroia kepapaupa vego keparo aio vagirotapo puropai riroara kovoaratoupai orueia koakoa.'),\n",
       "   ('xp', 'Ol save ???iuol bush hause ?usav  isat pant work longeu.'),\n",
       "   ('xe', '???'),\n",
       "   ('ex',\n",
       "    'Pita, rakariara koakoa eva ra evaova iava oara erakoera ra vara-ia tuitui kasivio.'),\n",
       "   ('xp',\n",
       "    'Pita, yu raosim ol skin bilong dwiai i bin drai diwai yet na bai yumi mekim paia long em.'),\n",
       "   ('xe', \"Peter, bark the tree ??? and from them we'll make fire.\")]),\n",
       " ('koakoa',\n",
       "  [('rt', 'koa'),\n",
       "   ('ps', 'V'),\n",
       "   ('pt', 'B'),\n",
       "   ('rdp', 'full'),\n",
       "   ('ge', 'bark a tree'),\n",
       "   ('ge', 'remove the skin'),\n",
       "   ('tkp', 'rausim skin'),\n",
       "   ('arg', 'O'),\n",
       "   ('vx', '2'),\n",
       "   ('dt', '08/Jun/2005'),\n",
       "   ('ex', 'Rakariua koaivere evaova iava.'),\n",
       "   ('xp', 'Bai ol i rausim skin bilong diwai.'),\n",
       "   ('xe', 'They will take the bark off of the tree.')]),\n",
       " ('koara',\n",
       "  [('ps', 'V'),\n",
       "   ('pt', 'B'),\n",
       "   ('ge', 'put together'),\n",
       "   ('tkp', '???'),\n",
       "   ('vx', '2'),\n",
       "   ('arg', 'O'),\n",
       "   ('nt', 'Used when putting all of the songs on a recording tape.'),\n",
       "   ('dt', '03/Nov/2005'),\n",
       "   ('ex', 'Vara rutu koaraavoi.'),\n",
       "   ('xp', '???'),\n",
       "   ('xe', 'I am putting them all together.'),\n",
       "   ('ex',\n",
       "    'Kova koara tovoivoi teipi ovaraia oisio ravara uvupaive teipi gaupiepaoro.'),\n",
       "   ('xp',\n",
       "    'Ol i putim planti singsing insait long tepe olsem bai ol i save harim taim ol i save pleim tepe.'),\n",
       "   ('xe', '???')]),\n",
       " ('koarao',\n",
       "  [('ps', 'N'),\n",
       "   ('pt', '???'),\n",
       "   ('ge', 'bird'),\n",
       "   ('tkp', 'pisin'),\n",
       "   ('eng', 'Yellow-eyed Cuckoo-shrike (Coracina lineata)'),\n",
       "   ('sa', 'urieva'),\n",
       "   ('dt', '03/Nov/2005'),\n",
       "   ('ex',\n",
       "    'Koarao kokiova iria iava kesievira toupasiveira osireitoarei ovaisivu iava tapo oira vaisipaiveira oisio urieva.'),\n",
       "   ('xp',\n",
       "    'Koarao em nem bilong wanpela pisin tupela ae bilong em i yelo na ol i save kolim em tu long narapela nem, urieva.'),\n",
       "   ('xe', '???')]),\n",
       " ('koaraua',\n",
       "  [('rt', 'koara'),\n",
       "   ('ps', 'N'),\n",
       "   ('pt', 'NT'),\n",
       "   ('ge', 'shelf'),\n",
       "   ('tkp', '???'),\n",
       "   ('eng', 'shelf'),\n",
       "   ('eng', 'platform for keeping things up off of the ground'),\n",
       "   ('eng', 'table'),\n",
       "   ('dt', '04/Nov/2005'),\n",
       "   ('ex', 'Koaraua voa uva uvuipa aio tovipau.'),\n",
       "   ('xp', 'Long hap yu can putim ol samhing.'),\n",
       "   ('xe', 'On this table you can put food.'),\n",
       "   ('ex',\n",
       "    'Koaraua oa ivaraia oaravu tovopaiveira. Teapi rasito vara vuripiepareve.'),\n",
       "   ('xp',\n",
       "    'Tebol ol i save putim ol samting antap long em. nogut graun i bagarapim.'),\n",
       "   ('xe', '???')]),\n",
       " ('koarava',\n",
       "  [('rt', 'koara'),\n",
       "   ('ps', 'N'),\n",
       "   ('pt', 'FEM'),\n",
       "   ('ge', 'table'),\n",
       "   ('tkp', 'tebol'),\n",
       "   ('cmt', 'How do koaraua and koarava differ?'),\n",
       "   ('dt', '04/Nov/2005'),\n",
       "   ('ex',\n",
       "    'Vouva uvuipa aiopasia rera ivaraia ora kiropasia kaarava ivaraia tebol.'),\n",
       "   ('xp', 'Hap yu can kaikai long na yu kan writer antap long en.'),\n",
       "   ('xe', '???'),\n",
       "   ('ex', 'Koarava iria ivaraia aiopaiveira ora rigatopaiveira.'),\n",
       "   ('xp', 'Tebol ol i save kaikai antap long em, na rait antap long em.'),\n",
       "   ('xe', 'The table, they eat and write on top of it.')]),\n",
       " ('koasio',\n",
       "  [('ps', 'N'),\n",
       "   ('pt', 'NT'),\n",
       "   ('ge', 'clam'),\n",
       "   ('tkp', '???'),\n",
       "   ('nt',\n",
       "    'edible clam like koai only longer, found on the west coast of [MISSING]'),\n",
       "   ('dt', '26/Apr/2006'),\n",
       "   ('sa', 'koai'),\n",
       "   ('cmt', 'Are koasio and koai the same?'),\n",
       "   ('ex',\n",
       "    'Vo vaisirei koai ora koasio kataitoa raga-ia ira eisi toupareveira Kereaka-ia.'),\n",
       "   ('xp',\n",
       "    'Tupela nem i stap long wanpela kina tasol. Em koai na koasio, dispela i save stap long Kereaka.'),\n",
       "   ('xe',\n",
       "    \"The two names 'koai' and 'koasio' refer to the same thing, which is found in Kereaka.\")]),\n",
       " ('koata',\n",
       "  [('ps', 'V'),\n",
       "   ('pt', 'A'),\n",
       "   ('ge', 'enter'),\n",
       "   ('tkp', 'go insait'),\n",
       "   ('dcsv', 'true'),\n",
       "   ('vx', '1'),\n",
       "   ('sc', 'MOTION'),\n",
       "   ('dt', '04/Nov/2005'),\n",
       "   ('ex', 'Pupipaoro koatapaiera.'),\n",
       "   ('xp', '???'),\n",
       "   ('xe', 'While dancing we (exclusive) entered (the village).'),\n",
       "   ('ex',\n",
       "    'Pita koata kepa siovara iare oisio ravoa uusiro uvare viapau uvuipa ra ratau uusiro. Ari uvuipa ra koataro voa usisia kepa-ia.'),\n",
       "   ('xp',\n",
       "    'Pita em i go insait long haus olsem bai em i slip long ap. Bikos em i no inap slip autsait, tasol em i nap i go slip insait long haus.'),\n",
       "   ('xe', 'Peter went inside of the house ???.')]),\n",
       " ('koatapie',\n",
       "  [('rt', 'koata'),\n",
       "   ('ps', 'V'),\n",
       "   ('pt', 'B'),\n",
       "   ('ge', 'put in'),\n",
       "   ('ge', 'accept'),\n",
       "   ('tkp', '???'),\n",
       "   ('arg', 'O'),\n",
       "   ('vx', '2'),\n",
       "   ('dt', '04/Nov/2005'),\n",
       "   ('ex', 'Jisas koatapieri.'),\n",
       "   ('xp', '???'),\n",
       "   ('xe', 'Accept Jesus into (your life).'),\n",
       "   ('ex',\n",
       "    'Ragai kovoa koatapieava vo voisi oa-ia oa iava uvuiparai ra vearovira vokovo purapa.'),\n",
       "   ('xp',\n",
       "    'Mi bin putim tru wok long hat bilong mi olsem na mi save mekim gut wok.'),\n",
       "   ('xe', '???')]),\n",
       " ('koauve',\n",
       "  [('ps', 'N'),\n",
       "   ('pt', 'FEM'),\n",
       "   ('ge', 'snail'),\n",
       "   ('tkp', 'bosi'),\n",
       "   ('nt', 'large brown type found in the jungle'),\n",
       "   ('dt', '04/Nov/2005'),\n",
       "   ('ex', 'Vo topaiveira vegoaro vurivuri kekevavi oira koauve.'),\n",
       "   ('xp', 'Enu i save istap long bik bus em i luk braun.'),\n",
       "   ('xe', '???'),\n",
       "   ('ex', 'Koauve toupaeveira eisi tura vego.'),\n",
       "   ('xp', 'Snel i save i stap long bus.'),\n",
       "   ('xe', \"The 'koauve' snail lives in the jungle.\"),\n",
       "   ('ex',\n",
       "    'Koauve vurivuri kekeva iria tuura vegoro sovaraia toupaeveira. Viapau uvuipai ra vovokio oira kekeri vo atoia.'),\n",
       "   ('xp',\n",
       "    'Koauve em wanpela kain snel i save stap long bik bus. Em i save luk braun, na tu yu no inap lukim nao long ples tude.'),\n",
       "   ('xe', '???')]),\n",
       " ('koavaato',\n",
       "  [('ps', 'N'),\n",
       "   ('pt', 'MASC'),\n",
       "   ('ge', 'betel.vine'),\n",
       "   ('tkp', 'daka'),\n",
       "   ('eng', 'betel pepper vine fruit'),\n",
       "   ('dt', '14/Nov/2005'),\n",
       "   ('ex',\n",
       "    'Koavato ira tovopaiveira akoroa-ia, ra ita vara rutu aiopaive, ra aasiva turuepe.'),\n",
       "   ('xp', 'Ol i save kaikai daka wantaim kabang, em nau bai meme buai i red.'),\n",
       "   ('xe',\n",
       "    'They put betel vine with lime powder and they eat them, and the betel nut is red.'),\n",
       "   ('ex', 'Koavato ira tapo aasi aiopaveira voeao papua niu gini pairara.'),\n",
       "   ('xp', 'Daka ol man bilong Papua Niu Gini i save kaikai buai wantaim.'),\n",
       "   ('xe',\n",
       "    'Betel nut vine is something the people of Papua New Guina eat with betel nut.')]),\n",
       " ('koe',\n",
       "  [('ps', 'V'),\n",
       "   ('pt', 'B'),\n",
       "   ('ge', 'spoon out a solid'),\n",
       "   ('tkp', 'wawan'),\n",
       "   ('arg', 'O'),\n",
       "   ('vx', '2'),\n",
       "   ('dt', '04/Nov/2005'),\n",
       "   ('ex', 'Aio koko koepaevora aako spun-ia va aiopaoro.'),\n",
       "   ('xp', '???'),\n",
       "   ('xe', 'Mother spooned out the portion of food while eating it.'),\n",
       "   ('ex', 'Upiriko koko koepae Maria koetoa-ia aiopaoro.'),\n",
       "   ('xp', 'Maria i kaikai plet kaukau long spun.'),\n",
       "   ('xe', 'Maria is spooning ??? eating ???.'),\n",
       "   ('ex', 'Aakova sipuru-ia aio koko koepae va aiopaoro.'),\n",
       "   ('xp', 'Mama em i spunim pelet kaikai long sipun na kaikaim.'),\n",
       "   ('xe', 'Mother dishes out a plate of food with a spoon and eats it.')]),\n",
       " ('koea',\n",
       "  [('ps', 'N'),\n",
       "   ('pt', 'NT'),\n",
       "   ('ge', 'swing'),\n",
       "   ('ge', 'choir'),\n",
       "   ('tkp', 'ol i singsing'),\n",
       "   ('cmt', \"Ex. sentence doesn't contain entry.\"),\n",
       "   ('dt', '04/Nov/2005'),\n",
       "   ('ex', 'Erapa uvuru oea erapai Pauto vaisiaro kaepiepaoro.'),\n",
       "   ('xp', 'Grup i sing na litimapim nem bilong God.'),\n",
       "   ('xe', '???'),\n",
       "   ('ex', 'Ruruvupa kakaero koa-ia uiriaepa eisi Vakora-ia.'),\n",
       "   ('xp',\n",
       "    'Ol pikinini bilong Ruruvu i bin win taim ol i bin sing long Wakunai.'),\n",
       "   ('xe', 'The Ruruvu children won at singing in Wakunai.')]),\n",
       " ('koekoe',\n",
       "  [('rt', 'koe'),\n",
       "   ('ps', 'V'),\n",
       "   ('pt', 'B'),\n",
       "   ('ge', 'spoon out'),\n",
       "   ('tkp', 'spunim'),\n",
       "   ('rdp', 'full'),\n",
       "   ('arg', 'O'),\n",
       "   ('vx', '2'),\n",
       "   ('dt', '04/Nov/2005'),\n",
       "   ('cmt', 'Is gloss right?'),\n",
       "   ('ex', 'Koekoe ukoa koekoeri eira-ia kapu.'),\n",
       "   ('xp', 'Yu kisikisim wara long dispela kapu.'),\n",
       "   ('xe', '???'),\n",
       "   ('ex', 'Pita ukoa koekoereva kapu-ia.'),\n",
       "   ('xp', 'Pita i bin rausim wara long kap.'),\n",
       "   ('xe', 'Peter removed the water with a cup.'),\n",
       "   ('ex', 'Pita, araisi koekoeri eera-ia sipuru ra aiori.'),\n",
       "   ('xp', 'Pita, yu spunim rais long sipun ia na bai yu kaikaim.'),\n",
       "   ('xe', 'Peter, dish out the rice with a spoon and eat (it).')]),\n",
       " ('koekoeto',\n",
       "  [('rt', 'koekoe'),\n",
       "   ('ps', 'N'),\n",
       "   ('pt', '???'),\n",
       "   ('ge', 'type of ant'),\n",
       "   ('tkp', 'anis'),\n",
       "   ('dt', '01/Dec/2004'),\n",
       "   ('ex',\n",
       "    'Koekoeto ira oisioa kepa sioparo-ia rasito vuripiereve vosia viapau oiraravai toupaive.'),\n",
       "   ('xp',\n",
       "    'Em binatang i save bagarapim graun insait haus, taim ol man i no istap.'),\n",
       "   ('xe', '???')]),\n",
       " ('koepato',\n",
       "  [('rt', 'koe'),\n",
       "   ('ps', 'N'),\n",
       "   ('pt', 'MASC'),\n",
       "   ('ge', 'spoon'),\n",
       "   ('tkp', 'spun'),\n",
       "   ('avm', 'pa_required'),\n",
       "   ('sc', 'INSTRUMENT'),\n",
       "   ('dt', '14/Nov/2005'),\n",
       "   ('ex', 'Arua rooviro tapipato koepato.'),\n",
       "   ('xp', 'Spun bilong bringim ol sup kumu.'),\n",
       "   ('xe', '???'),\n",
       "   ('ex',\n",
       "    'Vosia viapau sipuruaravai ra viapau uvuipavio tauoara iava kasiraopa aioro kaepiepasia tauoara iava.'),\n",
       "   ('xp',\n",
       "    'Sapos i nogat sipun i stap na bai yumi no inap kisim hotpela kaikai long ol pelet.'),\n",
       "   ('xe', \"If there are no spoons, we can't ???.\")]),\n",
       " ('koeta',\n",
       "  [('ps', 'V'),\n",
       "   ('pt', 'A'),\n",
       "   ('ge', 'mature'),\n",
       "   ('ge', 'grow'),\n",
       "   ('ge', 'ripen'),\n",
       "   ('tkp', '???'),\n",
       "   ('dcsv', 'true'),\n",
       "   ('vx', '1'),\n",
       "   ('nt', 'The word vioroi is now used instead.'),\n",
       "   ('dt', '01/Jun/2005'),\n",
       "   ('ex', 'Upiriko kovo koetaei.'),\n",
       "   ('xp', '???'),\n",
       "   ('xe', 'The sweet potato garden is mature.'),\n",
       "   ('ex', 'Upiriko kovo koetai ra vo kovo eripe.'),\n",
       "   ('xp', 'Gaden kaukau i orait pinis bai yumi digim.'),\n",
       "   ('xe', 'The sweet potato garden is ripe and can it can be harvested.')]),\n",
       " ('koetaova',\n",
       "  [('ps', 'V'),\n",
       "   ('pt', 'B'),\n",
       "   ('dx', 'Central'),\n",
       "   ('ge', 'arrange'),\n",
       "   ('eng', 'arrange marital exchange'),\n",
       "   ('tkp', 'stretim marit'),\n",
       "   ('vx', '???'),\n",
       "   ('dt', '08/Dec/2006'),\n",
       "   ('ex', 'Aue koetaovapare aiteto ra oratuutuukoave riakorirei-ia.'),\n",
       "   ('xp', 'Papa i wok long stretim gut tru bai ol i senis long tupela meri.'),\n",
       "   ('xe',\n",
       "    'Father arranged things and they will make an exchange with the two women.')]),\n",
       " ('koetapie',\n",
       "  [('rt', 'koeta'),\n",
       "   ('ps', 'V'),\n",
       "   ('pt', 'B'),\n",
       "   ('ge', 'investigate'),\n",
       "   ('ge', 'satisfy curiosity'),\n",
       "   ('tkp', 'painim aut gut'),\n",
       "   ('arg', 'O'),\n",
       "   ('vx', '2'),\n",
       "   ('dt', '04/Nov/2005'),\n",
       "   ('ex',\n",
       "    'Riakova koetapiesa uturoepa ato-ia, uvare rera vo kovoaro-ia aioara.'),\n",
       "   ('xp', '???'),\n",
       "   ('xe',\n",
       "    'The man followed the woman to confirm or satisfy his suspicions that she [???].'),\n",
       "   ('ex',\n",
       "    'Rakisi koetapiesia rutu utura atoia uvare utuva erievo ragai oiraaro.'),\n",
       "   ('xp',\n",
       "    'Rakisi i bin digim yam bilong mi, na mi painim em aut gut long ples.'),\n",
       "   ('xe', 'Rakisi ??? because ???.'),\n",
       "   ('ex',\n",
       "    'Riakova koetapiesia uturoepa oirato uvare rera vo kovoaro kavirueva.'),\n",
       "   ('xp',\n",
       "    'Man i bin bihainim meri i go bilong painim aut gut bikos em i bin stilim gaden kaikai bilong em.'),\n",
       "   ('xe', 'The man trailed the woman because she stole (from) his garden.')]),\n",
       " ('koetava',\n",
       "  [('alt', 'koeta'),\n",
       "   ('ps', 'N'),\n",
       "   ('pt', 'FEM'),\n",
       "   ('ge', 'bow'),\n",
       "   ('tkp', 'banara'),\n",
       "   ('dt', '04/Nov/2005'),\n",
       "   ('ex', 'Koeta iria-ia kora ritaapaveira ora aue tapo kokio.'),\n",
       "   ('xp', 'Bonara ol i save sutim kapul na pisin.'),\n",
       "   ('xe', 'With a bow they shoot possums and birds.'),\n",
       "   ('ex', 'Koetava iria-ia orekerovu rutu ritapaiveira.'),\n",
       "   ('xp', 'Banara ol i save sutim planti samting long em.'),\n",
       "   ('xe', 'With bows they shoot many things.')]),\n",
       " ('koetavira',\n",
       "  [('alt', 'koetapavira'),\n",
       "   ('rt', 'koeta'),\n",
       "   ('ps', 'ADV'),\n",
       "   ('pt', 'MANNER'),\n",
       "   ('ge', 'absolutely'),\n",
       "   ('ge', 'satisfying'),\n",
       "   ('tkp', '???'),\n",
       "   ('dt', '28/Aug/2005'),\n",
       "   ('ex', 'Evao rao-ia koetavira pituri.'),\n",
       "   ('xp', '???'),\n",
       "   ('xe', 'Hold the branch absolutely securely.'),\n",
       "   ('ex', 'Rarairi, koetavira itara pitupaoro opita atoupau.'),\n",
       "   ('xp', 'Rarairi, yu holim strong taim yu daunim kokonas.'),\n",
       "   ('xe', 'Rarairi, ???.')]),\n",
       " ('koeto',\n",
       "  [('ps', 'N'),\n",
       "   ('pt', '???'),\n",
       "   ('ge', 'sand crab'),\n",
       "   ('tkp', 'kuka'),\n",
       "   ('dt', '08/Feb/2005'),\n",
       "   ('ex', 'Koeto ira vo toupareveira rogararo.'),\n",
       "   ('xp', 'Kuka i save i stap long wet san.'),\n",
       "   ('xe', 'The crab lives on wet sand.')]),\n",
       " ('kogo',\n",
       "  [('ps', 'V'),\n",
       "   ('pt', 'B'),\n",
       "   ('ge', 'cut'),\n",
       "   ('ge', 'chop'),\n",
       "   ('tkp', '???'),\n",
       "   ('arg', 'O'),\n",
       "   ('vx', '2'),\n",
       "   ('dt', '08/Jun/2005'),\n",
       "   ('ex', 'Tuariripa irara oisoa evaoara kogopaive vara toepaoro aue-ia.'),\n",
       "   ('xp', '???'),\n",
       "   ('xe', 'People of long ago always chopped trees cutting them with stones.'),\n",
       "   ('ex',\n",
       "    'Tuariripairara oea oisioa evaoara kogopaive aue-ia avekeva torara.'),\n",
       "   ('xp', 'Ol man bilong bipo ol i save katim diwai long ston tamiok.'),\n",
       "   ('xe', '???')]),\n",
       " ('kogova',\n",
       "  [('rt', 'kogo'),\n",
       "   ('ps', 'N'),\n",
       "   ('pt', 'FEM'),\n",
       "   ('ge', 'stone axehead'),\n",
       "   ('tkp', 'akis'),\n",
       "   ('dt', '01/Dec/2004'),\n",
       "   ('ex', 'Kogova torara avekeva tuariri pairara iriaia oiso a toepaova.'),\n",
       "   ('xp', 'NO DATA.'),\n",
       "   ('xe', '???'),\n",
       "   ('ex', 'Kogova tuariripairara oiraro torara iria-ia oisioa toepaive.'),\n",
       "   ('xp',\n",
       "    'Tamiok ston bilong ol man bilong bipo ol i save yusim long katim diwai.'),\n",
       "   ('xe', '???')]),\n",
       " ('koi',\n",
       "  [('ps', 'V'),\n",
       "   ('pt', 'A'),\n",
       "   ('ge', 'high pitched sound'),\n",
       "   ('tkp', 'noisi antap'),\n",
       "   ('sc', 'EMISSION.SOUND'),\n",
       "   ('vx', '1'),\n",
       "   ('nt', 'archaic'),\n",
       "   ('dt', '08/Dec/2005'),\n",
       "   ('ex', 'Peri koiivo aue-ia araisi ovusia uusipaoe.'),\n",
       "   ('xp', 'Ol i bin kaikai rais taim Peni i bin wok long slip.'),\n",
       "   ('xe', '???')]),\n",
       " ('koie',\n",
       "  [('ps', 'N'),\n",
       "   ('pt', 'ANIM'),\n",
       "   ('ge', 'pig'),\n",
       "   ('tkp', 'pik'),\n",
       "   ('dt', '26/Sep/2006'),\n",
       "   ('ex', 'Koie uporevo Pita uva oira aiorevo rera raga aruvea.'),\n",
       "   ('xp', 'Pita em i kilim pik na em yet i kaikaim asde.'),\n",
       "   ('xe', 'Peter killed a pig and he himself ate it yesterday.'),\n",
       "   ('ex', 'Koiea ouavoi va aiosia uvare vurivira rutu ogoeparai.'),\n",
       "   ('xp', 'Hap pik mi kisim bilong kaikai bikos mi hangere nogut tru.'),\n",
       "   ('xe',\n",
       "    'I have gotten the pig in order to eat it because I am terribly hungry.')]),\n",
       " ('koie',\n",
       "  [('ps', 'V'),\n",
       "   ('pt', 'A'),\n",
       "   ('ge', 'act like a pig'),\n",
       "   ('tkp', 'wokabaut olsem pik'),\n",
       "   ('cmt',\n",
       "    'Is there a verb meaning \"get pig to eat/kisim pik\", as Firchow\\'s dictionary suggests?'),\n",
       "   ('vx', '1'),\n",
       "   ('dt', '22/Nov/2005'),\n",
       "   ('ex',\n",
       "    'Aretei koiepaoi vavaeareia vokapaoro uvare tuukeru oirare upiapaoe vavaeareia vokapaoro.'),\n",
       "   ('xp',\n",
       "    'Aretei em i wokabaut olsem pik long tupela han bikos beksait bilong em i pen.'),\n",
       "   ('xe', '???')]),\n",
       " ('koike',\n",
       "  [('ps', '???'),\n",
       "   ('ge', 'left'),\n",
       "   ('tkp', 'kais'),\n",
       "   ('tkp', 'lephan'),\n",
       "   ('dt', '04/Nov/2005'),\n",
       "   ('cmt',\n",
       "    \"What's the POS? Third example has rutu between vearo and paveira. Is that right?\"),\n",
       "   ('ex', 'Aretua koike eisi-va rera Ruruvu.'),\n",
       "   ('xp', 'Aretu em i kaisman bilong Ruruvu.'),\n",
       "   ('xe', 'Aretua is to the left of Ruruvu.'),\n",
       "   ('ex', 'Koike viia koiketo koikevira toepari.'),\n",
       "   ('xp', 'Yu kais man yu katim long left side.'),\n",
       "   ('xe', '???'),\n",
       "   ('ex', 'Era koike ira vearo rutu paveira vo vavaere-ia tapo kovopasia.'),\n",
       "   ('xp', 'Dispela han kais man ia em gutpela tru long wok long han wantaem.'),\n",
       "   ('xe', '???'),\n",
       "   ('ex',\n",
       "    'Rapiriria koike ira eisi toupareveira Uriora. Ira koike vavae iava kovopareveira.'),\n",
       "   ('xp',\n",
       "    'Rapiriri em i kais man ne em i save stap long uriora. Em i save wok long han kais.'),\n",
       "   ('xe',\n",
       "    'Rapiriri is a left-hander who is usually in Uriora. He works using his left hand.')]),\n",
       " ('koiketo',\n",
       "  [('rt', 'koike'),\n",
       "   ('ps', 'N'),\n",
       "   ('pt', 'HUM'),\n",
       "   ('ge', 'left-handed person'),\n",
       "   ('tkp', 'kaisman'),\n",
       "   ('dt', '04/Nov/2005'),\n",
       "   ('ex', 'Pita era koiketo.'),\n",
       "   ('xp', 'Pita em i kaisman.'),\n",
       "   ('xe', 'Peter is left-handed.'),\n",
       "   ('ex',\n",
       "    'Rapiriria koiketo ira uvuipa ra koike vavae-ia vii uporeve ovusia keapau oisio ira ragai upopare toepa vavae-ia.'),\n",
       "   ('xp',\n",
       "    'Rapiriri em i han kais man, em inap paitim yu long han kais, taim yu ting bai em i paitim yu long rait han.'),\n",
       "   ('xe',\n",
       "    'Rapiriri is a left-hander and he can hit you with his left hand when you think wrongly that he will hit me with his right hand.')]),\n",
       " ('koikevira',\n",
       "  [('alt', 'koikepavira'),\n",
       "   ('rt', 'koike'),\n",
       "   ('ps', 'ADV'),\n",
       "   ('pt', 'MANNER'),\n",
       "   ('ge', 'off.course'),\n",
       "   ('eng', 'off course'),\n",
       "   ('eng', 'off base'),\n",
       "   ('eng', 'off track'),\n",
       "   ('tkp', 'olsem i no stret'),\n",
       "   ('tkp', 'abrusim rot'),\n",
       "   ('dt', '04/Nov/2005'),\n",
       "   ('ex', 'Koikevira va uvuta.'),\n",
       "   ('xp', '???'),\n",
       "   ('xe', \"You didn't hear it quite right.\"),\n",
       "   ('ex', 'Koikevira koveroe Andru.'),\n",
       "   ('xp', 'Andru i pundaun long kais sait.'),\n",
       "   ('xe', 'Andru fell on his left side.'),\n",
       "   ('ex', 'Koikevira reoreoparoe avukato vosia rasireo-ia orareopaae.'),\n",
       "   ('xp',\n",
       "    'Lapun man i toktok olsem i no stret taim ol i mekim toktok bilong graun.'),\n",
       "   ('xe', 'The old man spoke ??? when they discussed land issues.')]),\n",
       " ('koikoi',\n",
       "  [('rt', 'koi'),\n",
       "   ('ps', 'V'),\n",
       "   ('pt', 'B'),\n",
       "   ('ge', 'groan with pain'),\n",
       "   ('tkp', 'krai wantaim pein'),\n",
       "   ('vx', '1'),\n",
       "   ('dcsv', 'true'),\n",
       "   ('dt', '04/Nov/2005'),\n",
       "   ('ex', 'Eake-pa koikoipari?'),\n",
       "   ('xp', 'Long wanem yu singaut?'),\n",
       "   ('xe', 'For what reason are you groaning?'),\n",
       "   ('ex', 'Raki koikoiparevoi upiapaoro.'),\n",
       "   ('xp', 'Raki i singaut taim em i sik.'),\n",
       "   ('xe', \"Rai groans with pain when he's sick.\"),\n",
       "   ('ex', 'Oirato upiapaoro koikoipare.'),\n",
       "   ('xp', 'Man i sik na em i krai wantaim pein.'),\n",
       "   ('xe', 'The man is sick and crying out from pain.')]),\n",
       " ('koikoipato',\n",
       "  [('rt', 'koikoi'),\n",
       "   ('ps', 'N'),\n",
       "   ('pt', 'HUM'),\n",
       "   ('dx', 'Pipipaia'),\n",
       "   ('ge', 'groaner'),\n",
       "   ('ge', 'whiner'),\n",
       "   ('tkp', 'man i wok long krai wantaim pen'),\n",
       "   ('avm', 'pa_required'),\n",
       "   ('dt', '04/Nov/2005')]),\n",
       " ('koikoipie',\n",
       "  [('rt', 'koikoi'),\n",
       "   ('ps', 'V'),\n",
       "   ('pt', 'B'),\n",
       "   ('ge', 'make groan with pain'),\n",
       "   ('tkp', 'mekim krai wantaim pen'),\n",
       "   ('vx', '2'),\n",
       "   ('dt', '16/Nov/2005'),\n",
       "   ('ex', 'Jon riakova koikoipierevoi uvare oira uporevoi.'),\n",
       "   ('xp', 'Jon i mekim meri singaut taim em i paitim em.'),\n",
       "   ('xe',\n",
       "    'John is making the woman groan with pain because he is hitting her.'),\n",
       "   ('ex', 'Upia avuva koikoipieiraopaivo vokiaro.'),\n",
       "   ('xp', 'Sik i mekim bubu i gron long nait.'),\n",
       "   ('xe', 'The sickness made grandmother groan with pain during the night.')]),\n",
       " ('koikoito',\n",
       "  [('rt', 'koikoi'),\n",
       "   ('ps', 'N'),\n",
       "   ('pt', 'HUM'),\n",
       "   ('ge', 'orphan'),\n",
       "   ('tkp', 'nogat papamama'),\n",
       "   ('dt', '02/Sep/2005'),\n",
       "   ('ex', 'Koikoito kakaeto ro ira arova kopiisi akovatoarei.'),\n",
       "   ('xp', 'Pikinini em papamama i dai na lusim.'),\n",
       "   ('xe', 'An orphan boy is one who the parents died without.'),\n",
       "   ('ex', 'Koikoito ro ira arova kopisi akorivatoa-re ra retoriva.'),\n",
       "   ('xp', 'Man i no gat papamama tasol ol lukautim.'),\n",
       "   ('xe', '???')]),\n",
       " ('koisi',\n",
       "  [('ps', 'N'),\n",
       "   ('pt', '???'),\n",
       "   ('ge', 'honey'),\n",
       "   ('tkp', 'hani'),\n",
       "   ('dt', '04/Nov/2005'),\n",
       "   ('ex', 'Koisi aiopava oira ukoaro-ia ukaiopareira.'),\n",
       "   ('xp', 'Ol i save dringim wara blong em.'),\n",
       "   ('xe', '???'),\n",
       "   ('ex', 'Koisi rovu oa-ia ukaiopaaveira.'),\n",
       "   ('xp', 'Hani ol i save dringim wara bilong em.'),\n",
       "   ('xe', 'Honey water, they drink from it.')]),\n",
       " ('koisiva',\n",
       "  [('rt', 'koisi'),\n",
       "   ('ps', 'N'),\n",
       "   ('pt', 'FEM'),\n",
       "   ('ge', 'honey bee'),\n",
       "   ('tkp', 'binen'),\n",
       "   ('dt', '04/Nov/2005'),\n",
       "   ('ex', 'Koisiva koisiva ragaiia pituevoi papaei koisiva.'),\n",
       "   ('xp', 'Bee em i fly n em holim mi..'),\n",
       "   ('xe', '???'),\n",
       "   ('ex', 'Koisiva iria papapaeveira.'),\n",
       "   ('xp', 'Hani bii isave palae nabaut.'),\n",
       "   ('xe', '???'),\n",
       "   ('ex',\n",
       "    'Koisiva iria vearoa purapaeveira uukoa, oa iava uvuipauei ra sipareoara rutu veaveari.'),\n",
       "   ('xp',\n",
       "    'Hani bi i save kamapim switpela wara, dispela wara yu nap likim tru ol pinga bilong yu long em.'),\n",
       "   ('xe',\n",
       "    'The honey bee makes honey, which you can like from your fingers.')]),\n",
       " ('koivira',\n",
       "  [('alt', 'koipavira'),\n",
       "   ('rt', 'koi'),\n",
       "   ('ps', 'ADV'),\n",
       "   ('pt', 'MANNER'),\n",
       "   ('ge', 'soprano'),\n",
       "   ('ge', 'high pitch'),\n",
       "   ('tkp', 'nois antap'),\n",
       "   ('dt', '28/Aug/2005'),\n",
       "   ('ex', 'Riakora koivira kovapai erapaoro.'),\n",
       "   ('xp', 'Ol meri ol sing antap taim ol i singsing.'),\n",
       "   ('xe', 'The women sing soprano while singing.'),\n",
       "   ('ex', 'Sera koivira kovapaoi.'),\n",
       "   ('xp', 'Sera em i sing antap.'),\n",
       "   ('xe', 'Sera sings soprano.')]),\n",
       " ('koka',\n",
       "  [('ps', 'V'),\n",
       "   ('pt', 'B'),\n",
       "   ('eng', 'agree'),\n",
       "   ('ge', 'agree to meet with'),\n",
       "   ('tkp', 'tok orait long bung'),\n",
       "   ('arg', 'O'),\n",
       "   ('vx', '2'),\n",
       "   ('dt', '01/Aug/2005'),\n",
       "   ('ex', 'Oirato riakova kokarevo uva rera iare avao vokiaro.'),\n",
       "   ('xp', 'Man i pasim tok wantaim meri na meri i go long em long nait.'),\n",
       "   ('xe', '???')]),\n",
       " ('kokai',\n",
       "  [('ps', 'N'),\n",
       "   ('pt', 'ANIM'),\n",
       "   ('ge', 'rooster'),\n",
       "   ('tkp', 'kakaruk'),\n",
       "   ('dt', '12/Feb/2005'),\n",
       "   ('ex', 'Kokai ira gaupareveira avito kekepaoro.'),\n",
       "   ('xp', 'Kakaruk man i save krai taim em i lukim tulait.'),\n",
       "   ('xe', 'The rooster cries as the sun appears.'),\n",
       "   ('ex', 'kataitoarei kokai vaio'),\n",
       "   ('xp', 'tupela kakaruk tasol'),\n",
       "   ('xe', 'two chickens')]),\n",
       " ('kokara',\n",
       "  [('ps', 'V'),\n",
       "   ('pt', 'A'),\n",
       "   ('ge', 'tempt'),\n",
       "   ('ge', 'try'),\n",
       "   ('ge', 'test'),\n",
       "   ('tkp', 'traim'),\n",
       "   ('cm', '-ia'),\n",
       "   ('arg', 'OBL COMP'),\n",
       "   ('vx', '2'),\n",
       "   ('cmt', 'Follow up on control structure?'),\n",
       "   ('dt', '17/Jul/2005'),\n",
       "   ('ex', 'Urioparoepa oira-ia kokarapaoro oiso-re ra va uvupaeve.'),\n",
       "   ('xp', '???'),\n",
       "   ('xe', 'He came tempting her so that she would listen to it (do it).'),\n",
       "   ('ex',\n",
       "    'Pita Dorin-ia kokaraparoe oisio ra vearo vaisi puraeve ra vuria purasi.'),\n",
       "   ('xp',\n",
       "    'Pita i traim Dorin bai em i tok orait bai tupela i wokim pasin nogut.'),\n",
       "   ('xe', 'Peter tested Dorin, if she said okay, they would fool around.')]),\n",
       " ('kokaraa',\n",
       "  [('rt', 'kokara'),\n",
       "   ('ps', '???'),\n",
       "   ('ge', 'temptation'),\n",
       "   ('tkp', 'du'),\n",
       "   ('dt', '12/Feb/2005'),\n",
       "   ('ex', 'Wesli koveroe kokaraa-ia.'),\n",
       "   ('xp', 'Wesli i pundaun long traem.'),\n",
       "   ('xe', 'Wesley fell to temptation.'),\n",
       "   ('ex', 'Kokoraa -via kokaraa era pita -via kokaraa paoi eira sara.'),\n",
       "   ('xp', 'Pita eni taram yu/sara eni taram yu.'),\n",
       "   ('xe', '???')]),\n",
       " ('kokarapato',\n",
       "  [('rt', 'kokara'),\n",
       "   ('ps', 'N'),\n",
       "   ('pt', 'HUM'),\n",
       "   ('ge', 'Satan'),\n",
       "   ('ge', 'evil spirit'),\n",
       "   ('ge', 'tempter'),\n",
       "   ('tkp', 'seten duman'),\n",
       "   ('dt', '12/Feb/2005'),\n",
       "   ('ex', 'Tugarato kokarapato ira oirara kovepiepareveira vuria iare.'),\n",
       "   ('xp', 'Evil spirit em i save daunim ol man i go long sin.'),\n",
       "   ('xe', 'The tempter spirit always makes people fall into evil.'),\n",
       "   ('ex', 'Satan kokarapato via/tugavato kokavapato.'),\n",
       "   ('xp', 'Satan em man blong taram yu eni spirit eni taim yu.'),\n",
       "   ('xe', 'Satan is a ???.')]),\n",
       " ('koke',\n",
       "  [('ps', 'V'),\n",
       "   ('pt', 'B'),\n",
       "   ('ge', 'make rain'),\n",
       "   ('tkp', 'mekim ren'),\n",
       "   ('vx', '1'),\n",
       "   ('cmt', 'Other examples?'),\n",
       "   ('dt', '04/Nov/2005'),\n",
       "   ('ex', 'Kokerivere.'),\n",
       "   ('xp', 'Yu bai mekim ren i pundaun.'),\n",
       "   ('xe', 'You will make it rain.'),\n",
       "   ('ex', 'Voari tuariri uva oisio purapaveira Sirovisia koke purapato.'),\n",
       "   ('xp',\n",
       "    'Long taim bipo ol i save tok olsem Sirovisi em man bilong mekim ren.'),\n",
       "   ('xe', 'Long ago they said that Sirovisi was a rain maker.')]),\n",
       " ('kokee',\n",
       "  [('ps', 'V'),\n",
       "   ('pt', 'B'),\n",
       "   ('ge', 'peek through a blind or crack'),\n",
       "   ('tkp', '???'),\n",
       "   ('cm', '-re'),\n",
       "   ('arg', 'OBL'),\n",
       "   ('vx', '2'),\n",
       "   ('dt', '08/Jun/2005'),\n",
       "   ('ex', 'Kakaevure kokeepaiva kepa iava.'),\n",
       "   ('xp', '???'),\n",
       "   ('xe', 'The children peeked through the blind of the house.'),\n",
       "   ('ex', 'Jon kokeeparevoi oirara-re ovusia orareopai.'),\n",
       "   ('xp', 'Jon i lukluk long hol bilong wol long ol man taim ol i miting.'),\n",
       "   ('xe', 'John peeked at people while they talked.')]),\n",
       " ('kokepato',\n",
       "  [('rt', 'koke'),\n",
       "   ('ps', 'N'),\n",
       "   ('pt', 'MASC'),\n",
       "   ('ge', 'rainy month'),\n",
       "   ('tkp', 'mun bilong ren'),\n",
       "   ('dt', '02/Sep/2005'),\n",
       "   ('ex', 'Kokepatoa utavai aue Jun.'),\n",
       "   ('xp', 'Mun Jun em i taim bilong rein.'),\n",
       "   ('xe', '???')]),\n",
       " ('kokepato',\n",
       "  [('rt', 'koke'),\n",
       "   ('ps', 'N'),\n",
       "   ('pt', 'HUM'),\n",
       "   ('ge', 'rain-maker'),\n",
       "   ('tkp', 'man bilong mekim rein'),\n",
       "   ('ex', 'Juna kokepato ira siovaraia raivara rutu vuriera.'),\n",
       "   ('xp', 'Jun em mun bilong rein insait long em ol rot i bagarap.'),\n",
       "   ('xe', '???'),\n",
       "   ('dt', '04/Nov/2005')]),\n",
       " ('kokepie',\n",
       "  [('rt', 'koke'),\n",
       "   ('ps', 'V'),\n",
       "   ('pt', 'B'),\n",
       "   ('dx', 'Central'),\n",
       "   ('ge', 'make.rain'),\n",
       "   ('tkp', 'mekim ren'),\n",
       "   ('eng', 'make rain'),\n",
       "   ('vx', '???'),\n",
       "   ('cmt',\n",
       "    'What is <osa> doing in the ex. sentence? And where is the direct object?'),\n",
       "   ('dt', '22/Nov/2005'),\n",
       "   ('ex', 'Tuariripairara osa kokepiepaive ora voea-re.'),\n",
       "   ('xp', 'Ol man bilong bipo ol i save mekim ren long ol yet.'),\n",
       "   ('xe', 'The ancestors made it rain on themselves.')]),\n",
       " ('kokerao',\n",
       "  [('ps', 'N'),\n",
       "   ('pt', 'NT'),\n",
       "   ('ge', 'opossum with black and white hair'),\n",
       "   ('ge', 'mottled'),\n",
       "   ('ge', 'spotted'),\n",
       "   ('tkp', 'kapul i gat mak'),\n",
       "   ('dt', '12/Feb/2005'),\n",
       "   ('ex',\n",
       "    'Kokerao korato kokerao rupa kopikopi pato ara aue popote (pogara).'),\n",
       "   ('xp', 'Kapur em i gat makmak blak na waitpela garas bilong en.'),\n",
       "   ('xe', '???'),\n",
       "   ('ex', 'Koorato kokeraopato, ira-ia toupai aue rupa ora aue popote.'),\n",
       "   ('xp', 'Kapul i gat makmak bilak na waitpela garas.'),\n",
       "   ('xe', 'On the kokeraopato possum there is black and white.')]),\n",
       " ('kokeriva',\n",
       "  [('ps', 'N'),\n",
       "   ('pt', 'FEM'),\n",
       "   ('ge', 'rain'),\n",
       "   ('tkp', 'ren'),\n",
       "   ('dt', '15/Apr/2006'),\n",
       "   ('cmt', \"How does kokeriva relate to kokeva? What's the plural?\"),\n",
       "   ('ex', 'Kokeriva igei-re koveoe osia karepaie vokiaro.'),\n",
       "   ('xp', 'Ren em i pundaun long mipela long rot taim mipela kam long nait.'),\n",
       "   ('xe', 'The rain fell on us as we returned at night.')]),\n",
       " ('kokeu',\n",
       "  [('ps', 'N'),\n",
       "   ('pt', 'FEM'),\n",
       "   ('ge', 'shellfish'),\n",
       "   ('tkp', 'kina kramsei'),\n",
       "   ('nt',\n",
       "    'It has a blue shell inside and out and is found in saltwater along the coast. This name preferred to asiraue which also means blue shellfish.'),\n",
       "   ('cmt', 'Is this a sentence?'),\n",
       "   ('dt', '04/Nov/2005'),\n",
       "   ('ex',\n",
       "    'Kokeu iria toupaeveira vo ukoviro vituaro-ia avakava-ia uva veauaro toupaiveira.'),\n",
       "   ('xp',\n",
       "    'Sel i save stap long as bilong wara long solwara em i save stap long arere bilong wara.'),\n",
       "   ('xe', '???')]),\n",
       " ('kokeva',\n",
       "  [('rt', 'koke'),\n",
       "   ('ps', 'N'),\n",
       "   ('pt', 'FEM'),\n",
       "   ('ge', 'rain'),\n",
       "   ('tkp', 'ren'),\n",
       "   ('dt', '12/Jan/2006'),\n",
       "   ('ex', 'Kokeva vokiara rutu-ia kovepaoi.'),\n",
       "   ('xp', '???'),\n",
       "   ('xe', 'It rains every day.'),\n",
       "   ('ex', 'Kapi, uriou kokeva koveoi.'),\n",
       "   ('xp', 'Kapi, yu kam, ren i pundaun nau.'),\n",
       "   ('xe', 'Kapi, come, the rain is falling.'),\n",
       "   ('ex', 'Vaiterei siovaraia kekira vaioa kokeva kovepaora.'),\n",
       "   ('xp', 'Insait long tupela mun ren i bin wok long pundaon.'),\n",
       "   ('xe', 'For two months it has rained.')]),\n",
       " ('koki',\n",
       "  [('ps', 'V'),\n",
       "   ('pt', 'B'),\n",
       "   ('ge', 'chisel out'),\n",
       "   ('ge', 'chip away'),\n",
       "   ('tkp', 'boaim'),\n",
       "   ('arg', 'O'),\n",
       "   ('vx', '2'),\n",
       "   ('dt', '08/Jun/2005'),\n",
       "   ('ex', 'Rivutevira raga vo eva kokipareve.'),\n",
       "   ('xp', '???'),\n",
       "   ('xe', 'He would be chipping away at the tree just like a wood borer.'),\n",
       "   ('ex', 'Timoti ora Jon topiruu kokipasivoi.'),\n",
       "   ('xp', 'Timoti na Jon i digim hol long kaku.'),\n",
       "   ('xe', 'Timothy and John chiselled away ???.')]),\n",
       " ('kokio',\n",
       "  [('ps', 'N'),\n",
       "   ('pt', 'ANIM'),\n",
       "   ('ge', 'bird'),\n",
       "   ('tkp', 'pisin'),\n",
       "   ('nt', 'generic term'),\n",
       "   ('sf', 'FAUNA.BIRD'),\n",
       "   ('dt', '27/Sep/2006'),\n",
       "   ('ex', 'Kokiova gaupaevoi.'),\n",
       "   ('xp', 'Pisin i krai.'),\n",
       "   ('xe', 'The bird is crying.'),\n",
       "   ('ex', 'Kokioto iarevoi aue Visiai.'),\n",
       "   ('xp', 'Visai i sutim pisin.'),\n",
       "   ('xe', 'Visiai shot a bird.'),\n",
       "   ('ex', 'Ragai kokio taraparai okarei ritaravo karei orisia.'),\n",
       "   ('xp', 'Mi painim pisin na bai mi sutim sampela na kukim kaikai.'),\n",
       "   ('xe', '???')]),\n",
       " ('Kokipaia',\n",
       "  [('rt', 'kokipaia'),\n",
       "   ('ps', '???'),\n",
       "   ('ge', 'name of village'),\n",
       "   ('tkp', 'ples nem'),\n",
       "   ('dt', '18/Feb/2004')]),\n",
       " ('kokito',\n",
       "  [('ps', 'N'),\n",
       "   ('pt', 'MASC'),\n",
       "   ('ge', 'ear canal'),\n",
       "   ('tkp', 'yau'),\n",
       "   ('tkp', 'ia'),\n",
       "   ('dt', '12/Feb/2005'),\n",
       "   ('ex', 'Kokito ira iava reoara uvuupapeira.'),\n",
       "   ('xp', 'Yumi save harim tok long ia.'),\n",
       "   ('xe', 'Through the ear, words are heard.')]),\n",
       " ('kokivira',\n",
       "  [('alt', 'kokipavira'),\n",
       "   ('rt', 'koki'),\n",
       "   ('ps', 'ADV'),\n",
       "   ('pt', 'MANNER'),\n",
       "   ('ge', 'unobstructed hole'),\n",
       "   ('tkp', 'go insait stret'),\n",
       "   ('dt', '03/Nov/2005'),\n",
       "   ('ex', 'Evaova kokivira toupaivoi.'),\n",
       "   ('xp', 'Diwai i gat hol.'),\n",
       "   ('xe', 'The tree has holes.'),\n",
       "   ('ex',\n",
       "    'Vavaviri kokivira araisi koko aiorevo uva vuruvuru-ia rikua toupaivo.'),\n",
       "   ('xp',\n",
       "    'Vavaviri em i kaikaim pleit rais long namel. Na namel bilong rais i gat hul.'),\n",
       "   ('xe', 'Vavaviri ??? and there is a hole in ???.')]),\n",
       " ('koko',\n",
       "  [('ps', 'V'),\n",
       "   ('pt', 'B'),\n",
       "   ('ge', 'pour'),\n",
       "   ('eng', 'pour'),\n",
       "   ('eng', 'serve'),\n",
       "   ('eng', 'dish out'),\n",
       "   ('eng', 'portion out'),\n",
       "   ('tkp', 'kapsaitim'),\n",
       "   ('arg', 'O'),\n",
       "   ('vx', '2'),\n",
       "   ('dt', '18/Nov/2005'),\n",
       "   ('ex', 'Aio kuvuro kokopaivere oirara tauoara-ia vara.'),\n",
       "   ('xp', '???'),\n",
       "   ('xe', 'The people will dish out the bundles of food onto limbum plates.'),\n",
       "   ('ex', 'Vutevi aio kokoro purae tauoara-ia.'),\n",
       "   ('xp', 'Vutevi i wokim kaikai long ol pelet.'),\n",
       "   ('xe', 'Vutevi made a plate of food.')]),\n",
       " ('koko',\n",
       "  [('ps', 'N'),\n",
       "   ('pt', 'NT'),\n",
       "   ('ge', 'flower'),\n",
       "   ('tkp', 'plaua'),\n",
       "   ('cmt', 'Translated by Firchow as \"open flower\". Need to check.'),\n",
       "   ('dt', '10/Nov/2005'),\n",
       "   ('ex', 'Kokoa rovopai karupaoro.'),\n",
       "   ('xp', 'Palaua i stat long op.'),\n",
       "   ('xe', 'The flower is starting to open up.')]),\n",
       " ('kokoi',\n",
       "  [('ps', 'N'),\n",
       "   ('pt', 'FEM'),\n",
       "   ('ge', 'type of banana'),\n",
       "   ('tkp', 'liklik han taro'),\n",
       "   ('nt', 'eating variety, short thick type'),\n",
       "   ('pt', 'itoo'),\n",
       "   ('dt', '03/Nov/2005'),\n",
       "   ('ex', 'Kokoi vioropava.'),\n",
       "   ('xp', 'Banan i save mao.'),\n",
       "   ('xe', '???'),\n",
       "   ('ex',\n",
       "    'Kokoi itoova vaisiaro otekupava iria vioropiepaiveira oira aiopasia.'),\n",
       "   ('xp',\n",
       "    'Kokoi em nem bilong wanpela banana ol i save mekim mao na kaikaim.'),\n",
       "   ('xe', '???')]),\n",
       " ('kokoisi',\n",
       "  [('ps', 'V'),\n",
       "   ('pt', 'A'),\n",
       "   ('ge', 'sweat'),\n",
       "   ('ge', 'perspire'),\n",
       "   ('tkp', 'swet'),\n",
       "   ('vx', '1'),\n",
       "   ('sc', 'BODILY.PROCESS'),\n",
       "   ('dt', '03/Nov/2005'),\n",
       "   ('ex', 'Kokoisi aisia ruvira toupai.'),\n",
       "   ('xp', 'Palaoan karamap yet.'),\n",
       "   ('xe', '???'),\n",
       "   ('ex',\n",
       "    'Aretei ikaupaoro voreoe eisi-va sikurua. Uva rirovira rutu kokoisioe vova kagave.'),\n",
       "   ('xp',\n",
       "    'Aretei em i ran bek i kam long skul. Na tuat i kamap long pes bilong em.'),\n",
       "   ('xe', 'Aretei ran back from school. And her face was very sweaty.')]),\n",
       " ('kokokoru',\n",
       "  [('ps', 'N'),\n",
       "   ('pt', '???'),\n",
       "   ('ge', 'flower bud'),\n",
       "   ('tkp', 'plaua i pas'),\n",
       "   ('dt', '03/Nov/2005'),\n",
       "   ('ex', 'Ragai kokokoru vurapaavo orua karupaivoi rara ravireo kaeroviro.'),\n",
       "   ('xp', 'Mi lukim karamap plaua, bai open taim san i kam antap.'),\n",
       "   ('xe', 'I looked at the flower bud ???.')]),\n",
       " ('kokoo',\n",
       "  [('ps', 'CLASS'),\n",
       "   ('ge', 'plateful'),\n",
       "   ('tkp', 'kaikai long plait'),\n",
       "   ('eng', 'food on a plate'),\n",
       "   ('dt', '16/Mar/2005'),\n",
       "   ('ex', 'Ragai aio kokoo aiopaavoi tauo iava.'),\n",
       "   ('xp', 'Mi kaikaiim kaikai stap long plait.'),\n",
       "   ('xe', \"I'm eating the food from a plate.\"),\n",
       "   ('ex', 'Sera aio kokoo taepae tauo-ia.'),\n",
       "   ('xp', 'Sera em i karim kaikai long plet.'),\n",
       "   ('xe', 'Sera is ??? a plate of food.'),\n",
       "   ('ex', 'Dokas aio kokoo kaepaoro uriopaoi.'),\n",
       "   ('xp', 'Dokas i karim pelet kaikai i kam.'),\n",
       "   ('xe', 'Dokas is coming carrying a plate of food.')]),\n",
       " ('kokooko',\n",
       "  [('ps', 'N'),\n",
       "   ('pt', '???'),\n",
       "   ('ge', '???'),\n",
       "   ('tkp', '???'),\n",
       "   ('cmt',\n",
       "    'Check vowel length. Some type of plant, I think--see custom medicine story'),\n",
       "   ('dt', '03/Nov/2005'),\n",
       "   ('ex', 'Purupuru kerari ro iava kokookoto oupaiveira sisiupara purapasia.'),\n",
       "   ('xp',\n",
       "    'Ol plaua bilong ol kain kain plant ol i save kisim bilong mekim marasin bilong was was.'),\n",
       "   ('xe', '???')]),\n",
       " ('kokookoa',\n",
       "  [('ps', 'N'),\n",
       "   ('pt', 'NT'),\n",
       "   ('ge', 'open flower'),\n",
       "   ('tkp', '???'),\n",
       "   ('dt', '03/Nov/2005'),\n",
       "   ('ex', 'Vearoa rutu vavao kokookoa.'),\n",
       "   ('xp', 'Naispela palaua tru.'),\n",
       "   ('xe', '???'),\n",
       "   ('ex', 'Kokookoa vearopie kekepapeira vosia karuvira toupaive.'),\n",
       "   ('xp', 'Plaua i save luk nais tru taim i stap open.'),\n",
       "   ('xe', '???')]),\n",
       " ('kokoote',\n",
       "  [('ps', 'N'),\n",
       "   ('pt', 'FEM'),\n",
       "   ('ge', 'bird'),\n",
       "   ('tkp', '???'),\n",
       "   ('eng', \"Baillon's Crake (Porzana pusilla)\"),\n",
       "   ('nt', 'Disinctive feature is its strange night cry'),\n",
       "   ('sa', 'ekarako'),\n",
       "   ('sf', 'FAUNA.BIRD'),\n",
       "   ('dt', '03/Nov/2005'),\n",
       "   ('ex', 'Kokoote iria vokiaro gaupaeveira.'),\n",
       "   ('xp', 'Pisin i save krai long nait.'),\n",
       "   ('xe', \"The Baillon's Crake cries at night.\"),\n",
       "   ('ex',\n",
       "    'Kokoote kokiova iria rasiuaro raga vokapaeveira. Viapau uvuipaoi ra papapaeve uvare etekuvira putaearei toupaiveira.'),\n",
       "   ('xp',\n",
       "    'Kokoote i wanpela pisin i save wokabaut tasol long graun.Em i no inap plai bikos tupela wung bilong em i luk olsem sot.'),\n",
       "   ('xe', '???')]),\n",
       " ('kokootu',\n",
       "  [('ps', 'N'),\n",
       "   ('pt', 'FEM'),\n",
       "   ('ge', 'chicken'),\n",
       "   ('eng', 'chicken'),\n",
       "   ('eng', 'hen'),\n",
       "   ('tkp', 'kakaruk'),\n",
       "   ('dt', '03/Nov/2005'),\n",
       "   ('ex', 'Kokootu iria takura koupaoveira.'),\n",
       "   ('xp', 'Kakaruk meri i save bonim kiau.'),\n",
       "   ('xe', 'Chikens lay eggs.'),\n",
       "   ('ex', 'Kokootu ruipapaveira oirara rutu uvare vearopiea rutua varua.'),\n",
       "   ('xp', 'Kakaruk olgeta man i save laikim tru bikos em i gutpela abus tru.'),\n",
       "   ('xe', 'Everyone wants chicken because it is good meat.')]),\n",
       " ('kokopa',\n",
       "  [('ps', 'N'),\n",
       "   ('pt', 'MASC'),\n",
       "   ('ge', 'mudskippers'),\n",
       "   ('tkp', '???'),\n",
       "   ('nt', 'live in mangrove swamps'),\n",
       "   ('dt', '03/Nov/2005'),\n",
       "   ('ex', 'Kokopa ira tuvuuara-ia toupareveira.'),\n",
       "   ('xp', 'Em wanpela kain liklik palai i save istap long tais.'),\n",
       "   ('xe', 'The mudskipper lives in swamps.'),\n",
       "   ('ex',\n",
       "    'Kokopa ira vaguru kouro-ia tuvuara-ia toupareveira. Ira ora vikiparoveira oisio rutu putaearava toupare.'),\n",
       "   ('xp',\n",
       "    'Kokopa i wanpela kain liklik plai i save stap insait long tais bilong mangur. I save kalap olsem em i gat wing.'),\n",
       "   ('xe', '???')]),\n",
       " ('kokopakou',\n",
       "  [('ps', 'N'),\n",
       "   ('pt', '???'),\n",
       "   ('ge', 'overgrown bush area'),\n",
       "   ('tkp', 'bus'),\n",
       "   ('dt', '03/Nov/2005'),\n",
       "   ('ex', 'Kokopakou oa upiriko kovo ruuvoi.'),\n",
       "   ('xp', 'Liklik bus i karamapim gaden kaukau.'),\n",
       "   ('xe', 'Growth covers sweet potato gardens.'),\n",
       "   ('ex',\n",
       "    'Vosia kaukau kovo purari, oire kasivarivira kokopa touro toetoepari. Teapi aio kovo vuripe rara kokopakou orapurape.'),\n",
       "   ('xp',\n",
       "    'Sapos yu mekim gaden kaukau, orait yu mas klinim olgeta bus olgeta taim. nogut bus i bagarapim gaden kaikai.'),\n",
       "   ('xe', '???')]),\n",
       " ('kokopeko',\n",
       "  [('ps', 'V'),\n",
       "   ('pt', 'A'),\n",
       "   ('ge', 'unconscious'),\n",
       "   ('ge', 'in a stupor'),\n",
       "   ('tkp', 'i laik dai'),\n",
       "   ('vx', '1'),\n",
       "   ('dt', '22/Nov/2005'),\n",
       "   ('sc', '???'),\n",
       "   ('ex', 'Kokopeko ro oirato kokepekoparoi kopiragapaoro.'),\n",
       "   ('xp', '???'),\n",
       "   ('xe', '???'),\n",
       "   ('ex', 'Raki kokopekoparoi oisio ra kopiiro.'),\n",
       "   ('xp', 'Raki i wok long hap dai.'),\n",
       "   ('xe', 'Raki is unconscious as if about to die.')]),\n",
       " ('kokopekovira',\n",
       "  [('alt', 'kokopekopavira'),\n",
       "   ('rt', 'kokopeko'),\n",
       "   ('ps', 'ADV'),\n",
       "   ('pt', 'MANNER'),\n",
       "   ('ge', 'unconsciously'),\n",
       "   ('tkp', 'olsem i dai'),\n",
       "   ('dt', '28/Aug/2005'),\n",
       "   ('ex', 'Raki kokopekovira pieparevoi ra kopiiro.'),\n",
       "   ('xp', 'Raki i wok long hap dai, tasol bai em i dai yet.'),\n",
       "   ('xe', 'Raki ???.')]),\n",
       " ('kokopeoto',\n",
       "  [('rt', 'kokopeo'),\n",
       "   ('ps', 'N'),\n",
       "   ('pt', 'MASC'),\n",
       "   ('ge', 'type of plant'),\n",
       "   ('tkp', '???'),\n",
       "   ('sf', 'FLORA'),\n",
       "   ('nt', 'grass-like with green and white striped leaves'),\n",
       "   ('dt', '12/Feb/2005'),\n",
       "   ('ex', 'Kokopeoto rerapauiveira kokovara guruvato ora popote ta raivaro.'),\n",
       "   ('xp', 'Ol i save plaint?? Eni green pelaleares na eni white .'),\n",
       "   ('xe', '???'),\n",
       "   ('ex', 'Kokopeoto ira vegoaro toupareveira, ra popotevira kokookopareve.'),\n",
       "   ('xp', 'Em wanpela kain plant bilong bus na i save gat waitpela palaua.'),\n",
       "   ('xe', '???')]),\n",
       " ('kokopuoto',\n",
       "  [('rt', 'kokopuo'),\n",
       "   ('ps', 'N'),\n",
       "   ('pt', 'MASC'),\n",
       "   ('ge', 'butterfly'),\n",
       "   ('ge', 'moth'),\n",
       "   ('tkp', 'batapiai'),\n",
       "   ('nt', \"Is the 'ave' in the second ex sentence really just 'aue'?\"),\n",
       "   ('dt', '13/Nov/2005'),\n",
       "   ('ex', 'Kokopuoto ira papaparevoi.'),\n",
       "   ('xp', 'Batapalai i palai i go.'),\n",
       "   ('xe', 'The butterfly flies.'),\n",
       "   ('ex',\n",
       "    'Kokopuoto kekeavo ave vearopieto ovusia kokoa iava uukovi ivuparevo.'),\n",
       "   ('xp', 'Mi lukim naispela bataplai taim em i pulim wara bilong plaua.'),\n",
       "   ('xe',\n",
       "    'I saw a pretty butterfly while he pulled water from an open flower.'),\n",
       "   ('ex', 'Kokopuo kare uuko rupipai purupuru kokokoro-ia.'),\n",
       "   ('xp', 'Ol bata plai ol i pulim wara long ol plaua.'),\n",
       "   ('xe', '???')]),\n",
       " ('kokopuovira',\n",
       "  [('alt', 'kokopuopavira'),\n",
       "   ('rt', 'kokopuo'),\n",
       "   ('ps', 'ADV'),\n",
       "   ('pt', 'MANNER'),\n",
       "   ('ge', '???'),\n",
       "   ('tkp', 'olsem bata plai'),\n",
       "   ('cmt',\n",
       "    \"What about kokopuvira? Are we dealing with two words? Meanings don't seem related.\"),\n",
       "   ('dt', '14/Nov/2005'),\n",
       "   ('ex', 'Kokopuovira rutu Tokii vurapaavoi.'),\n",
       "   ('xp', 'Mi ken lukim Mt. Bagana longwe tru.'),\n",
       "   ('xe', 'I look at Mt. Bagana ???.'),\n",
       "   ('ex', 'Kokopuvira pukuiara vurapaavo vavoisio avakava-ia.'),\n",
       "   ('xp', 'Mi lukim ol maunten longwe tru long nambis i luk liklik tru.'),\n",
       "   ('xe', 'I looked at the mountains ???'),\n",
       "   ('ex', 'Kokopuovira rutu papapava kekepaoviroi vavoisio virauaaro.'),\n",
       "   ('xp', 'Balus i luk olsem stret bata plai taim em i wok long pilai antap.'),\n",
       "   ('xe', '???')]),\n",
       " ('Kokopuru',\n",
       "  [('ps', 'N'),\n",
       "   ('pt', 'PN'),\n",
       "   ('dx', 'Central'),\n",
       "   ('ge', 'name'),\n",
       "   ('tkp', 'nem'),\n",
       "   ('ig', 'yes'),\n",
       "   ('dt', '26/Jul/2005')]),\n",
       " ('kokopuvira',\n",
       "  [('rt', 'kokopu'),\n",
       "   ('ps', 'ADV'),\n",
       "   ('pt', 'MANNER'),\n",
       "   ('ge', 'hazy'),\n",
       "   ('ge', 'bluish in appearace at a distance'),\n",
       "   ('tkp', '???'),\n",
       "   ('nt', 'As mountains appear with a blue hazy appearace in the distance.'),\n",
       "   ('dt', '18/Feb/2004'),\n",
       "   ('ex',\n",
       "    'Vosa torepau pukuia kukuearoi ra kokopuovira vuropari tauai ruture ra kuravira kekepapiro vegoa.'),\n",
       "   ('xp',\n",
       "    'Taim yu sanap lonas antap long wanepela mauntan bai yu lukluk igo longwe tru bai bush bai lukbtue.'),\n",
       "   ('xe', '???')]),\n",
       " ('kokora',\n",
       "  [('ps', 'N'),\n",
       "   ('pt', 'MASC'),\n",
       "   ('ge', 'last-born son'),\n",
       "   ('tkp', 'las pikinini meri'),\n",
       "   ('dt', '12/Feb/2005'),\n",
       "   ('cmt', 'Is this used only for males?'),\n",
       "   ('ex', 'Rearia kokora ovoio kavauto.'),\n",
       "   ('xp', 'Reari em i lasbon boi.'),\n",
       "   ('xe', 'Reari is the youngest boy, the last-born.')]),\n",
       " ('kokorai',\n",
       "  [('rt', 'kokora'),\n",
       "   ('ps', 'N'),\n",
       "   ('pt', 'FEM'),\n",
       "   ('ge', 'last-born daughter'),\n",
       "   ('tkp', '???'),\n",
       "   ('cmt', 'Is this term gender-specific?'),\n",
       "   ('sf', 'KIN'),\n",
       "   ('dt', '13/Feb/2005'),\n",
       "   ('ex', 'Ovoio kavauva rutu riakova.'),\n",
       "   ('xp', 'Last pela pikinin meri.'),\n",
       "   ('xe', '???'),\n",
       "   ('ex', 'Betia kokorai, ovoio kavauva.'),\n",
       "   ('xp', 'Betty em i las bon meri.'),\n",
       "   ('xe', 'Betty is youngest, the last-born girl.')]),\n",
       " ('kokorato',\n",
       "  [('rt', 'kokora'),\n",
       "   ('ps', 'N'),\n",
       "   ('pt', 'NT???'),\n",
       "   ('ge', 'last born son'),\n",
       "   ('tkp', 'las pikinini man'),\n",
       "   ('cmt', 'Can the term kokorava be used?'),\n",
       "   ('dt', '13/Feb/2005'),\n",
       "   ('ex', 'Kokorato ovoi kavauto rutu.'),\n",
       "   ('xp', 'Laspela pikinin nom em born bihain tru.'),\n",
       "   ('xe', 'The youngest is truly the last-born.'),\n",
       "   ('ex', 'Rearia kokorato.'),\n",
       "   ('xp', 'Reari em i las bon man.'),\n",
       "   ('xe', 'Reari is the last-born.')]),\n",
       " ('kokori',\n",
       "  [('ps', 'V'),\n",
       "   ('pt', '???'),\n",
       "   ('ge', 'spiralled'),\n",
       "   ('tkp', 'bosi tantan'),\n",
       "   ('cmt', '???'),\n",
       "   ('vx', '???'),\n",
       "   ('dt', '22/Nov/2005'),\n",
       "   ('ex', 'Kokori purari oira kirooro.'),\n",
       "   ('xp', 'Yu raitim o.'),\n",
       "   ('xe', 'You write it in a spiral.')]),\n",
       " ('kokorivira',\n",
       "  [('rt', 'kokori'),\n",
       "   ('ps', 'ADV'),\n",
       "   ('pt', 'MANNER'),\n",
       "   ('ge', 'spiralling'),\n",
       "   ('tkp', 'tantan'),\n",
       "   ('dt', '13/Feb/2005'),\n",
       "   ('ex', 'Kokorivira va purava kirooro.'),\n",
       "   ('xp', 'Yu raitim samting i raunpela.'),\n",
       "   ('xe', 'Write something in a spiral.')]),\n",
       " ('kokoro',\n",
       "  [('ps', 'V'),\n",
       "   ('pt', 'A'),\n",
       "   ('ge', 'crazy'),\n",
       "   ('tkp', 'longlong'),\n",
       "   ('eng', 'crazy'),\n",
       "   ('eng', 'insane'),\n",
       "   ('eng', 'foolish'),\n",
       "   ('eng', 'stupid'),\n",
       "   ('am', 'true'),\n",
       "   ('vx', '1'),\n",
       "   ('dt', '01/Jun/2005'),\n",
       "   ('ex', 'Sioro ira oisioa kokoroparo vokiaro vokapaoro ora kovapaoro.'),\n",
       "   ('xp', 'Sioro em i save rongrong na raun long nait na singsing.'),\n",
       "   ('xe', 'A crazy peron is one who runs around at night singing.'),\n",
       "   ('ex', 'Kokoropaoi rirovira upiapaoro.'),\n",
       "   ('xp', '???'),\n",
       "   ('xe', 'She is out of her head being very sick.')]),\n",
       " ('kokoroki',\n",
       "  [('ps', 'N'),\n",
       "   ('pt', 'FEM'),\n",
       "   ('ge', 'earring worn in the ear lobe'),\n",
       "   ('ge', 'ring for finger or nose'),\n",
       "   ('tkp', 'ring'),\n",
       "   ('dt', '13/Feb/2005'),\n",
       "   ('ex',\n",
       "    'Kokoroki tuariri pariako vo rotokasaia oisi kokoroki tivopave vo kokiavaia ora vo iruvaoto.'),\n",
       "   ('xp',\n",
       "    'Ol meri blong Rotokas ol i save putim kokoroki long ear blong ol na long nare blong ol.'),\n",
       "   ('xe', '???'),\n",
       "   ('ex', 'Rotokasipa riako oisioa kokorokiara tovopaive vo kokiara-ia.'),\n",
       "   ('xp', 'Bipo ol meri Rotokasi ol i save putim ia rig long ia bilong ol.'),\n",
       "   ('xe', 'Rotokas woman always used to put earings on their ears.')]),\n",
       " ('kokoroku',\n",
       "  [('ps', 'V'),\n",
       "   ('pt', 'B'),\n",
       "   ('ge', 'crow'),\n",
       "   ('tkp', '???'),\n",
       "   ('dt', '03/Nov/2005'),\n",
       "   ('cmt',\n",
       "    \"Is Rarova a person's name? There seems to be disagreement over classification? Is it V.A or V.B? Also, no translation for second half of one ex sentence!\"),\n",
       "   ('vx', '1'),\n",
       "   ('dcsv', 'false'),\n",
       "   ('ex', 'Kokai kokorokupare.'),\n",
       "   ('xp', '???'),\n",
       "   ('xe', 'The rooster is crowing.'),\n",
       "   ('ex', 'Raku ira kokoropavira rutu vokapare.'),\n",
       "   ('xp', 'Raku i wokabaut olsem rongrong man.'),\n",
       "   ('xe', 'Raku is walking around crowing.'),\n",
       "   ('ex', 'Kokai kokorokupareva voisio Rarova.'),\n",
       "   ('xp', 'Kakaruk em i krai long Rarova.'),\n",
       "   ('xe', 'The chicken is crowing ???'),\n",
       "   ('ex',\n",
       "    'Riroto kokai kokorokuparoi Rarova urui-ia. Oira kare kokai kare kokorokupaveira.'),\n",
       "   ('xp', 'Bikpela kakaruk em krai long ples Rarova. ???.')]),\n",
       " ('kokorokupie',\n",
       "  [('rt', 'kokoroku'),\n",
       "   ('ps', 'V'),\n",
       "   ('pt', 'B'),\n",
       "   ('ge', 'make.crow'),\n",
       "   ('tkp', 'mekim kakaruk i krai'),\n",
       "   ('eng', 'make crow'),\n",
       "   ('vx', '2'),\n",
       "   ('arg', 'O'),\n",
       "   ('dt', '22/Nov/2005'),\n",
       "   ('ex', 'Kokai kokorokupievo aviua.'),\n",
       "   ('xp', 'Tulait i laik bruk taim kakaruk i krai.'),\n",
       "   ('xe', 'Dawn made the rooster cry.')]),\n",
       " ('kokoropato',\n",
       "  [('rt', 'kokoro'),\n",
       "   ('ps', 'N'),\n",
       "   ('pt', 'HUM'),\n",
       "   ('ge', 'crazy person'),\n",
       "   ('tkp', 'longlong man'),\n",
       "   ('eng', 'insane person'),\n",
       "   ('eng', 'fool'),\n",
       "   ('eng', 'crazy person'),\n",
       "   ('eng', 'lunatic'),\n",
       "   ('eng', 'nutcase'),\n",
       "   ('avm', 'pa_required'),\n",
       "   ('dt', '02/Sep/2005'),\n",
       "   ('ex', 'Avoeao kokoropatoa rutu ro oirato.'),\n",
       "   ('xp', 'Ol man, dispela man i rongrong man tru.'),\n",
       "   ('xe', '???, this man is truly crazy.')]),\n",
       " ('kokorosi',\n",
       "  [('ps', 'N'),\n",
       "   ('pt', 'FEM'),\n",
       "   ('ge', 'cockroach'),\n",
       "   ('tkp', 'kakalak'),\n",
       "   ('tkp', 'kokros'),\n",
       "   ('nt', 'Tok Pisin loan'),\n",
       "   ('dt', '03/Nov/2005'),\n",
       "   ('ex', 'Kokorosi iria vokapae.'),\n",
       "   ('xp', 'Kokoros em i wokabaut.'),\n",
       "   ('xe', 'Cockaroaches walk around.'),\n",
       "   ('ex',\n",
       "    'Kokorusi vuriva rutu iria-pa reasiparaveira uvare aioara vuripiepaeveira ora varoara.'),\n",
       "   ('xp',\n",
       "    'Kokros i nogut tru, mi save les tru long em bikos em i save bagarapim ol kaikai wantaim ol laplap.'),\n",
       "   ('xe',\n",
       "    \"Cockroaches, they are really bad and I don't like them because they always ruin food and clothing.\")]),\n",
       " ('kokorovira',\n",
       "  [('alt', 'kokoropavira'),\n",
       "   ('rt', 'kokoro'),\n",
       "   ('ps', 'ADV'),\n",
       "   ('pt', 'MANNER'),\n",
       "   ('ge', 'foolishly'),\n",
       "   ('tkp', 'olsem longlong'),\n",
       "   ('dt', '03/Nov/2005'),\n",
       "   ('ex',\n",
       "    'Ragai riakova vurapaavo kokoropavira ovusia vokapaevo raivaro uva keaparae oisio kokopava uvare upiapaoe.'),\n",
       "   ('xp',\n",
       "    'Mi lukim meri taim em i wokabaut olsem long long meri long rot bikos em i sik.'),\n",
       "   ('xe',\n",
       "    'I watched the woman being crazy while she walked on the road and I mistook her for a crazy person because she was sick.')]),\n",
       " ('kokoru',\n",
       "  [('ps', 'N'),\n",
       "   ('pt', '???'),\n",
       "   ('ge', 'flower bud'),\n",
       "   ('tkp', 'piaua i pas'),\n",
       "   ('cmt', 'Check vowel length. Is kokoru related to kokoruuto?'),\n",
       "   ('dt', '14/Nov/2005'),\n",
       "   ('ex', 'Kokoru vosia kokoa viapa karupaivi.'),\n",
       "   ('xp', 'Taim flower ino open iyet.'),\n",
       "   ('xe', '???'),\n",
       "   ('ex', 'Kokoru kare arua kovo vuripieivo.'),\n",
       "   ('xp', 'Ol binatang i bagarapim gaden kumu.'),\n",
       "   ('xe', 'The insects ruined the vegetable garden.'),\n",
       "   ('ex',\n",
       "    'Kararuoa-ia kokoru kekeavo oa touvira karuvere rara ravireo kaeroviro.'),\n",
       "   ('xp',\n",
       "    'Mi lukim plaua bilong aibiskus i no op yet. Bai i open taim san i lait.'),\n",
       "   ('xe',\n",
       "    'I saw the flower bud on the ??? which will open once the sun ???.')]),\n",
       " ('kokoruu',\n",
       "  [('ps', 'V'),\n",
       "   ('pt', 'A'),\n",
       "   ('ge', 'insect-infested'),\n",
       "   ('tkp', 'i gat snek o binatang'),\n",
       "   ('cmt', 'Check vowel length'),\n",
       "   ('vx', '1'),\n",
       "   ('dt', '22/Nov/2005'),\n",
       "   ('ex', 'Ruve kovo kokoruei uvare viapau vo kovo iava kovopaiveira.'),\n",
       "   ('xp', 'Gaden aibika i gat snek o binatang bikos ol i no save klimin.')]),\n",
       " ('kokoruu',\n",
       "  [('rt', 'kokoruu'),\n",
       "   ('ps', 'N'),\n",
       "   ('pt', 'MASC'),\n",
       "   ('ge', 'worm'),\n",
       "   ('tkp', 'binatang olsem snek'),\n",
       "   ('cmt', 'Check relationship between kokoruu and kokoruuto!'),\n",
       "   ('dt', '10/Nov/2005'),\n",
       "   ('ex', 'Kokoruuto ira vokaparevoi kakau rao-ia.'),\n",
       "   ('xp', 'Binatang i wokabaut long han bilong kakau.'),\n",
       "   ('xe', 'A ??? walks around on cocoa leaves.')]),\n",
       " ('kokosi',\n",
       "  [('ps', 'N'),\n",
       "   ('pt', 'NT'),\n",
       "   ('ge', 'stinging nettle'),\n",
       "   ('tkp', 'salat paitim skin'),\n",
       "   ('dt', '03/Nov/2005'),\n",
       "   ('ex', '')]),\n",
       " ('kokosi',\n",
       "  [('ps', 'V'),\n",
       "   ('pt', 'A'),\n",
       "   ('ge', 'itch'),\n",
       "   ('eng', 'itch'),\n",
       "   ('eng', 'sting'),\n",
       "   ('tkp', 'skirap'),\n",
       "   ('vx', '1'),\n",
       "   ('cmt',\n",
       "    'I take it that the -ia arg is optional and licensed by general semantics---i.e., not an argument of the verb.'),\n",
       "   ('dt', '22/Nov/2005'),\n",
       "   ('ex', 'Kokosirai opoa-ia kopupa oa viapau vearovira oripiro.'),\n",
       "   ('xp', 'Mi skirap long taro i no tan gut.'),\n",
       "   ('xe', \"I itch from the taro ??? that wasn't well cooked.\")]),\n",
       " ('Kokosiria',\n",
       "  [('ps', 'N'),\n",
       "   ('pt', 'PN'),\n",
       "   ('ge', 'name of village'),\n",
       "   ('tkp', 'ples nem'),\n",
       "   ('dt', '13/Feb/2005'),\n",
       "   ('ex', 'Kokosiria eisi Sisivi-ia ruvaraia.'),\n",
       "   ('xp', 'Kokosiria i stap klostu long Sisivi.'),\n",
       "   ('xe', 'Kokosiria is close to Sisivi.')]),\n",
       " ('kokosito',\n",
       "  [('rt', 'kokosi'),\n",
       "   ('ps', 'N'),\n",
       "   ('pt', 'HUM'),\n",
       "   ('ge', 'sore-covered.man'),\n",
       "   ('eng', 'person with sore-covered body'),\n",
       "   ('tkp', 'man i gat sua oltaim'),\n",
       "   ('dt', '03/Nov/2005'),\n",
       "   ('cmt', \"Tok Pisin translation doesn't match gloss? What's up?\"),\n",
       "   ('ex', 'Kokosito viaa kokosito kapuapato.'),\n",
       "   ('xp', 'Yu gat sare.'),\n",
       "   ('xe', '???'),\n",
       "   ('ex', 'Kokosito era oirato.'),\n",
       "   ('xp', 'Man ia lek nogut.'),\n",
       "   ('xe', 'That man is a sore-covered man.'),\n",
       "   ('ex',\n",
       "    'Kokosito ro ira-ia opesiasia kapua toupaiveira oa iava eisi voea vaisipaiveira oisio kokosito.'),\n",
       "   ('xp', 'Kokosito em man i gat soa bilong bipo, soa i no save pinis.'),\n",
       "   ('xe', '??? and that\\'s why they call them a \"kokosito\".')]),\n",
       " ('kokosiva',\n",
       "  [('rt', 'kokosi'),\n",
       "   ('ps', 'N'),\n",
       "   ('pt', 'FEM'),\n",
       "   ('ge', 'large sore'),\n",
       "   ('ge', 'infection'),\n",
       "   ('tkp', 'bikpela sua'),\n",
       "   ('cmt', \"Gloss and translation of entry in example don't dovetail!\"),\n",
       "   ('dt', '13/Feb/2005'),\n",
       "   ('ex', 'Kokosiva via kokosiva ugoaia kapua toupa.'),\n",
       "   ('xp', 'Yu save meri.'),\n",
       "   ('xe', '???'),\n",
       "   ('ex', 'Viviura kokosiva.'),\n",
       "   ('xp', 'Viviura lek nogut.'),\n",
       "   ('xe', 'Viviura is a ???.')]),\n",
       " ('kokotagoe',\n",
       "  [('ps', 'N'),\n",
       "   ('pt', 'MASC'),\n",
       "   ('ge', 'type of banana'),\n",
       "   ('tkp', '???'),\n",
       "   ('nt', 'has a strong smell when ripe'),\n",
       "   ('pt', 'itoo'),\n",
       "   ('sa', 'kovato'),\n",
       "   ('sa', 'vatauvore'),\n",
       "   ('dt', '03/Nov/2005'),\n",
       "   ('ex', 'Kokotagoe itova vioropava.'),\n",
       "   ('xp', 'Em i nem bilong bananana i save mao.'),\n",
       "   ('xe', '???'),\n",
       "   ('ex', 'Kokotagoe itoova vaisiaro iria vioropiepaiveira oira aiopasia.'),\n",
       "   ('xp', 'Kiokotagoe nem bilong banana em ol save mekim mao kaikai.'),\n",
       "   ('xe', '???')]),\n",
       " ('kokote',\n",
       "  [('ps', 'N'),\n",
       "   ('pt', 'FEM'),\n",
       "   ('ge', 'bird'),\n",
       "   ('tkp', 'wanpela kain pisin'),\n",
       "   ('nt',\n",
       "    'has small black body, lives on the ground, feathers are not nicely [MISSING???]'),\n",
       "   ('sf', 'FAUNA.BIRD'),\n",
       "   ('dt', '03/Nov/2005'),\n",
       "   ('ex',\n",
       "    'Kokote iria vo gauaro uvuoro uvuipauei ra uririu uvare osivuraga gaupaeveira aue tapo putaearei viapau osio riro kaekaeareia oa iava viapau papapaeveira.'),\n",
       "   ('xp',\n",
       "    'Kokote krai bilong em i narapela kain yu nap poret sapos yu harim krai bilong em. na tu ol wuing bilong em i sot olsem na em i no inap plai.'),\n",
       "   ('xe', \"??? and that's why it doesn't fly.\")]),\n",
       " ('kokoto',\n",
       "  [('ps', 'N'),\n",
       "   ('pt', 'NT'),\n",
       "   ('ge', 'leg'),\n",
       "   ('tkp', 'lek'),\n",
       "   ('cmt',\n",
       "    \"It looks like <kokoto> can also be M or F when it's used as a predicative noun. Not sure how to register this in the dictionary...\"),\n",
       "   ('dt', '17/Nov/2006'),\n",
       "   ('ex', 'Kokotoa raga iava upipai uvare koevrae aveke iare.'),\n",
       "   ('xp', 'Lek bilong mi i pen bikos mi pundaun antap long ston.'),\n",
       "   ('xe', '???'),\n",
       "   ('ex',\n",
       "    'Riro kaekae kokototoa Periaviri. Viapau uvuipauei rare tapo ikauri. Arivi vuripa arova ikaurevere.'),\n",
       "   ('xp',\n",
       "    'Periaviri i gat ol longpela lek. Nogat yu nap ran wantaim em tasol yu trangu bai em i ran lusim yu.'),\n",
       "   ('xe', \"Periaviri has really long legs. You can't run with him. ??.\")]),\n",
       " ('kokotu',\n",
       "  [('ps', 'N'),\n",
       "   ('pt', 'NT'),\n",
       "   ('ge', 'sucker of taro plant'),\n",
       "   ('tkp', 'stik taro'),\n",
       "   ('dt', '03/Nov/2005'),\n",
       "   ('ex', 'Ragai kokotuara pausia avaparai.'),\n",
       "   ('xp', 'Mi laik go planim ol stik taro.'),\n",
       "   ('xe', 'I am going to plant taro suckers.')]),\n",
       " ('kokotua',\n",
       "  [('ps', 'N'),\n",
       "   ('pt', '???'),\n",
       "   ('ge', 'heel of foot'),\n",
       "   ('tkp', 'as bilong lek'),\n",
       "   ('dt', '10/Jan/2007'),\n",
       "   ('cmt', 'example sentence needed')]),\n",
       " ('kokotuo',\n",
       "  [('ps', 'N'),\n",
       "   ('pt', 'FEM'),\n",
       "   ('ge', 'heel of foot'),\n",
       "   ('tkp', 'nupela stik taro'),\n",
       "   ('dt', '20/Nov/2006'),\n",
       "   ('cmt',\n",
       "    'How does this relate to kokotu or kokotua? Clean up second ex sentence.'),\n",
       "   ('ex', 'Kokotuo vii iava kokotuo vo toupae vo kokotoia.'),\n",
       "   ('xp', 'Em i stap long leg bilong yu.'),\n",
       "   ('xe', '???'),\n",
       "   ('ex',\n",
       "    'Kokotoa-iva kokotuo iria kokotoa kaepiepaeveira ra vearovira vokapape.'),\n",
       "   ('xp', 'Beksait bilong lek i save antapim lek taim yumi save wokabaut.'),\n",
       "   ('xe', '???')]),\n",
       " ('kokovae',\n",
       "  [('ps', 'V'),\n",
       "   ('pt', 'A'),\n",
       "   ('ge', 'sing'),\n",
       "   ('tkp', 'singsing'),\n",
       "   ('sc', 'EMISSION.SOUND'),\n",
       "   ('vx', '1'),\n",
       "   ('dt', '22/Nov/2005'),\n",
       "   ('ex', 'Rirovira kokovaepaave.'),\n",
       "   ('xp', '???'),\n",
       "   ('xe', 'They would be singing a lot.'),\n",
       "   ('ex', 'Kakae riako kokovaepaai.'),\n",
       "   ('xp', 'Ol liklik meri ol i singsing istap.'),\n",
       "   ('xe', 'Young women sing a lot.'),\n",
       "   ('ex', 'Ragai oisio ruipaparaveira ra vovokiro rutu-ia kokovaepara.'),\n",
       "   ('xp', 'Mi save laik singsing olgeta dei.'),\n",
       "   ('xe', 'I like to sing every day.')]),\n",
       " ('kokovaeva',\n",
       "  [('rt', 'kokovae'),\n",
       "   ('ps', 'N'),\n",
       "   ('pt', 'FEM'),\n",
       "   ('ge', 'song'),\n",
       "   ('tkp', '???'),\n",
       "   ('dt', '03/Nov/2005'),\n",
       "   ('ex', 'Kokovaeva oiakovara.'),\n",
       "   ('xp', 'Dispela eni song.'),\n",
       "   ('xe', '???'),\n",
       "   ('ex', 'Kokovaeva vaisiaro Vatevu.'),\n",
       "   ('xp', 'Nem bilong singsing em i Vatevu.'),\n",
       "   ('xe', 'The name of the song is Vatevu.'),\n",
       "   ('ex',\n",
       "    'Iriavu rutu-pa ruipaparaveira erava oisio ra oira raga-ia kokovaepara.'),\n",
       "   ('xp',\n",
       "    'Mi save laikim wanpela song tasol olsem bai mi save singim dispela song tasol olgeta dei.'),\n",
       "   ('xe', '???')]),\n",
       " ('kokovara',\n",
       "  [('ps', 'V'),\n",
       "   ('pt', 'A'),\n",
       "   ('ge', 'green'),\n",
       "   ('eng', 'green'),\n",
       "   ('eng', 'unripe'),\n",
       "   ('tkp', 'grin'),\n",
       "   ('tkp', 'no mau'),\n",
       "   ('sc', '???'),\n",
       "   ('cmt', 'Check exs.'),\n",
       "   ('vx', '???'),\n",
       "   ('dt', '03/Oct/2006'),\n",
       "   ('ex', 'Kokovara viapau vioroisi vaisi kokovaravira toupa.'),\n",
       "   ('xp', 'Em i no luk mao yet.'),\n",
       "   ('xe', '???')]),\n",
       " ('kokovara',\n",
       "  [('ps', 'N'),\n",
       "   ('pt', 'NT'),\n",
       "   ('cl', 'isi'),\n",
       "   ('ge', 'unripe coconut'),\n",
       "   ('tkp', 'kulau'),\n",
       "   ('dt', '13/Feb/2005'),\n",
       "   ('ex', 'Kokovara isi opita isi viapau erakopape.'),\n",
       "   ('xp', 'Kokonas i grin yet na i no drai.'),\n",
       "   ('xe', \"The unripe coconut is a coconut, which isn't dry.\"),\n",
       "   ('ex', 'Kokovara isi opita isi.'),\n",
       "   ('xp', 'Kokonas em i green.'),\n",
       "   ('xe', 'The unripe coconut is a coconut.')]),\n",
       " ('kokovaravira',\n",
       "  [('rt', 'kokovara'),\n",
       "   ('ps', 'ADV'),\n",
       "   ('pt', 'MANNER'),\n",
       "   ('ge', 'unripe'),\n",
       "   ('tkp', 'grin no mau'),\n",
       "   ('dt', '22/Nov/2005'),\n",
       "   ('ex', 'Itova kokovaravira raga toupae.'),\n",
       "   ('xp', 'Banana i no mao yet.'),\n",
       "   ('xe', 'The banana is just unripe.')]),\n",
       " ('kokovu',\n",
       "  [('ps', 'V'),\n",
       "   ('pt', 'B'),\n",
       "   ('dx', 'Central'),\n",
       "   ('ge', 'shave head'),\n",
       "   ('tkp', '???'),\n",
       "   ('vx', '2'),\n",
       "   ('arg', 'O'),\n",
       "   ('dt', '23/Aug/2005'),\n",
       "   ('ex', 'Oirato orui kokovurevoi uvare oira rutu siirevoi.'),\n",
       "   ('xp', 'Man em i lusim liklik hap gras tasol taim em i katim olgeta gras.'),\n",
       "   ('xe', '???')]),\n",
       " ('kokovua',\n",
       "  [('ps', 'N'),\n",
       "   ('pt', 'NT'),\n",
       "   ('sn', '1'),\n",
       "   ('ge', 'small hill'),\n",
       "   ('tkp', 'liklik maunten'),\n",
       "   ('dt', '03/Nov/2005'),\n",
       "   ('ex', 'Kokovua aareavi vaesia.'),\n",
       "   ('xp', 'Em liklik mounta.'),\n",
       "   ('xe', '???'),\n",
       "   ('ex', 'Savere kokovua purare orui-ia.'),\n",
       "   ('xp', 'Savere i katim stret garas bilong en.'),\n",
       "   ('xe', 'Savere is making ??? of his hair.'),\n",
       "   ('ex', 'Vaesi kokovu-ia ikaupaoro iparae uvare etekua.'),\n",
       "   ('xp', 'Mi ran i go antap long liklik maunten bikos i sotpela tasol.'),\n",
       "   ('xe', \"I went running up the steep hill because it's short.\")]),\n",
       " ('kokovua',\n",
       "  [('rt', 'kokovu'),\n",
       "   ('ps', 'V'),\n",
       "   ('pt', 'B'),\n",
       "   ('sn', '2'),\n",
       "   ('ge', 'shave the hair line'),\n",
       "   ('tkp', 'sepim arere bilong gras'),\n",
       "   ('arg', '???'),\n",
       "   ('vx', '???'),\n",
       "   ('cmt', 'Need another example'),\n",
       "   ('dt', '03/Nov/2005'),\n",
       "   ('ex', 'Savere kokovua purare orui-ia.'),\n",
       "   ('xp', 'Savere i katim stret garas bilong en.'),\n",
       "   ('xe', 'Savere shaved the hair on his head.'),\n",
       "   ('ex', 'Savere oui rutu siirevoi uva gareavi kavure kokovua kukue-ia.'),\n",
       "   ('xp',\n",
       "    'Savere em i katim olgeta gras ne em i lusim liklik ap garas long het bilong em.'),\n",
       "   ('xe', 'Savere cut all of his hair and a little ??? on his head.')]),\n",
       " ('kokovua',\n",
       "  [('rt', 'kokovu'),\n",
       "   ('ps', 'N'),\n",
       "   ('pt', 'NT'),\n",
       "   ('dx', 'Central'),\n",
       "   ('ge', 'head-shaving'),\n",
       "   ('tkp', 'kat antap long gras bilong het'),\n",
       "   ('dt', '23/Aug/2005'),\n",
       "   ('ex', 'Oirato orui-ia kokovua purarevoi orasiioro.'),\n",
       "   ('xp', 'Man em i wokim kat antap long gras bilong het bilong em.'),\n",
       "   ('xe', '???')]),\n",
       " ('kokovupaparie',\n",
       "  [('rt', 'kokovupa'),\n",
       "   ('ps', '???'),\n",
       "   ('ge', 'bamboo razor blade'),\n",
       "   ('tkp', 'hap mambu bilong sepim resa'),\n",
       "   ('dt', '03/Nov/2005'),\n",
       "   ('ex',\n",
       "    'Voari tuariri uva oirara oisioa givgivu kouro kokovuive aue-ia kokovupaparie.'),\n",
       "   ('xp',\n",
       "    'Long taim bipo ol man i save sevim maus garas bilong ol long ol liklik hap mambu.'),\n",
       "   ('xe', '???')]),\n",
       " ('kokovurito',\n",
       "  [('ps', 'N'),\n",
       "   ('pt', 'MASC'),\n",
       "   ('ge', 'inside'),\n",
       "   ('tkp', 'insait bilong kaikai'),\n",
       "   ('eng', 'inside of anything edible'),\n",
       "   ('cmt', 'What\\'s going on with \"orioripaiavaiava\"?'),\n",
       "   ('dt', '03/Nov/2005'),\n",
       "   ('ex',\n",
       "    'Seva oisio ruipapaoi ra orioripaiavaiava upoa kokovurito aioeve uvare riro gorupai rakaria.'),\n",
       "   ('xp',\n",
       "    'Seva em i laik olsem bai em i kaikaim insait bilong taro ol i skirapim bikos skin i strong.'),\n",
       "   ('xe', 'Seva wants ??? because the skin is really strong.')]),\n",
       " ('koku',\n",
       "  [('ps', 'V'),\n",
       "   ('pt', 'B'),\n",
       "   ('ge', 'break off at base'),\n",
       "   ('ge', 'snap off at base'),\n",
       "   ('tkp', 'brukim skru bilong het'),\n",
       "   ('arg', 'O'),\n",
       "   ('vx', '2'),\n",
       "   ('nt',\n",
       "    'Refers to breaking off anything standing, and doing it without a knife'),\n",
       "   ('dt', '14/Nov/2005'),\n",
       "   ('ex', 'Pita sipoiua tuu kokureva kovoa-ia.'),\n",
       "   ('xp', '???'),\n",
       "   ('xe',\n",
       "    'Peter broke off the standing sugar cane at the base in the garden.'),\n",
       "   ('ex', 'Itova kokuoviroi.'),\n",
       "   ('xp', 'Banana i bruk namel.'),\n",
       "   ('xe', 'The banana is broken at the base.')]),\n",
       " ('kokuoku',\n",
       "  [('ps', 'N'),\n",
       "   ('pt', 'FEM'),\n",
       "   ('ge', 'plant'),\n",
       "   ('tkp', 'plant olsem wail taro'),\n",
       "   ('nt',\n",
       "    'like wild taro but with edible young leaves. It has a distinct [MISSING???]'),\n",
       "   ('sf', 'FLORA'),\n",
       "   ('dt', '13/Jan/2006'),\n",
       "   ('ex',\n",
       "    'Oiso toupaiveira osa aue uriko uva vegoa rutu toupaiveira kouoko oiso toupa osa aue arua.'),\n",
       "   ('xp', 'Em i save i stap long bus no oisave kaikaim olsem kumu tasol.'),\n",
       "   ('xe', '???'),\n",
       "   ('ex', 'Kokuokua arua oa ukoviro vatuaro-ia toupaiveira.'),\n",
       "   ('xp', 'Wanpela kain kumu taro i sae istap arere long wara.'),\n",
       "   ('xe', '???'),\n",
       "   ('ex',\n",
       "    'Kokuokua vo siarao iava urikova iava airepa guru vaaro aiopaiveira.'),\n",
       "   ('xp',\n",
       "    'Kokuoku i kam long ol lain bilong wail taro. Ol i save kaikaim yangpela lip bilong em.'),\n",
       "   ('xe', '???')]),\n",
       " ('kokureko',\n",
       "  [('ps', 'N'),\n",
       "   ('pt', 'FEM'),\n",
       "   ('ge', 'umbrella'),\n",
       "   ('ge', 'taro leaf'),\n",
       "   ('tkp', 'ambrela'),\n",
       "   ('tkp', 'lip bilong bikpela taro'),\n",
       "   ('sf', 'FLORA'),\n",
       "   ('dt', '13/Jan/2006'),\n",
       "   ('ex',\n",
       "    'Kokurekoara rirovira toupaiveira vegoaro, oara-ia oraraipipaveira kokeva-ia.'),\n",
       "   ('xp',\n",
       "    'Em i wanpela bikpela wail taro, na ol i yusim olsem amberela long taim bilong ren.'),\n",
       "   ('xe',\n",
       "    'Taro leaves are big in the jungloe, and you can cover yourself with it in the rain.'),\n",
       "   ('ex',\n",
       "    'Koevare vataupas or ora rakurakupas. Tuaripairava airaio??umballa. Koureko veagoaro toupai rirovi. Koureko oiso toupai osa umballa. Ora vigei vovokioiavo.'),\n",
       "   ('xp',\n",
       "    'Em i stap long bik bush of isave usim tam rain?? I podaw bai yum karamp long em em umbrell blong yum no ol man blong before.'),\n",
       "   ('xe', '???')]),\n",
       " ('kokuuto',\n",
       "  [('rt', 'kokuu'),\n",
       "   ('ps', 'N'),\n",
       "   ('pt', 'HUM'),\n",
       "   ('ge', 'cheeky person'),\n",
       "   ('tkp', '???'),\n",
       "   ('dt', '13/Feb/2005'),\n",
       "   ('ex', 'Pita, vii riro kokuuto kuvuto.'),\n",
       "   ('xp', 'Pita, yu man bilong giaman.'),\n",
       "   ('xe', \"Peter, you're a big ???.\"),\n",
       "   ('ex', 'Rereki-ia riro kokuuto.'),\n",
       "   ('xp', 'Rereki em i man bilong giaman.'),\n",
       "   ('xe', 'Rereki is a big ???.')]),\n",
       " ('kooe',\n",
       "  [('ps', 'V'),\n",
       "   ('pt', 'A'),\n",
       "   ('ge', 'swing'),\n",
       "   ('eng', 'swing on something'),\n",
       "   ('tkp', '???'),\n",
       "   ('vx', '1'),\n",
       "   ('dt', '01/Jun/2005'),\n",
       "   ('ex', 'Kakaevure kooepaai.'),\n",
       "   ('xp', '???'),\n",
       "   ('xe', 'The children are swinging on something.'),\n",
       "   ('ex', 'Peraisi kooeparoi garoava-ia.'),\n",
       "   ('xp', 'Peraisi em i sisoo long kanda.'),\n",
       "   ('xe', 'Peraisi is swinging on a vine.')]),\n",
       " ('kookaa',\n",
       "  [('ps', 'N'),\n",
       "   ('pt', 'MASC'),\n",
       "   ('ge', 'grasshopper'),\n",
       "   ('tkp', '???'),\n",
       "   ('sf', 'FAUNA'),\n",
       "   ('nt',\n",
       "    'Has small brown body. Alternate name of siikoto. Also referred to as the female of the siikoto'),\n",
       "   ('dt', '29/Jul/2005'),\n",
       "   ('ex', 'Koka sikoto ira aiopaiveira avuka riako.'),\n",
       "   ('xp', 'Ol lapun meri ol i save kaikai dispela kain grasopa.'),\n",
       "   ('xe', '???'),\n",
       "   ('ex', 'Kooka sikoto votoupa veriva vegoaro aropato koora.'),\n",
       "   ('xp', 'Grasshopper i save i stap long bush ol i save kaikaim.'),\n",
       "   ('xe', '???'),\n",
       "   ('ex', 'Kookaa sikoto votoupareveira egoaro aiopato.'),\n",
       "   ('xp', 'Lokas i save i stap long bus na ol i save kaikai.'),\n",
       "   ('xe', '???')]),\n",
       " ('kookai',\n",
       "  [('ps', 'N'),\n",
       "   ('pt', 'MASC'),\n",
       "   ('ge', 'rooster'),\n",
       "   ('tkp', '???'),\n",
       "   ('dt', '13/Feb/2005'),\n",
       "   ('ex',\n",
       "    'Kookai ira gaupare avi kekepaoro ora kookai aiopai sispea meat visei varo.'),\n",
       "   ('xp',\n",
       "    'Rooster em i save lukim tonight na yumi save kaikam roosten em meat.'),\n",
       "   ('xe', '???')]),\n",
       " ('kookoo',\n",
       "  [('ps', 'N'),\n",
       "   ('pt', 'MASC'),\n",
       "   ('ge', 'doll'),\n",
       "   ('ge', 'toy'),\n",
       "   ('ge', 'infant'),\n",
       "   ('tkp', '???'),\n",
       "   ('nt', 'baby talk'),\n",
       "   ('dt', '02/Dec/2004'),\n",
       "   ('ex', 'Kookoo u kakaeto aakovo kakaeto kookoo piap reva rovopiepaoro.'),\n",
       "   ('xp', 'Mamo em givem susu long lilik baby.'),\n",
       "   ('xe', '???'),\n",
       "   ('ex', 'Kookoo kakaevure voreoaro, ora vosia akova kakaeto roropaeve.'),\n",
       "   ('xp',\n",
       "    'Tokto bilong ol pikinini, na tu sapos mama i givim susu long liklik pikinini.'),\n",
       "   ('xe', '???')]),\n",
       " ('kookooia',\n",
       "  [('ps', 'V'),\n",
       "   ('pt', 'A'),\n",
       "   ('ge', 'mourn'),\n",
       "   ('ge', 'singsing-cry'),\n",
       "   ('tkp', '???'),\n",
       "   ('vx', '1'),\n",
       "   ('sc', 'EMISSION.SOUND'),\n",
       "   ('dt', '01/Jun/2005'),\n",
       "   ('ex', 'Kookooiaaepa koovapaoro.'),\n",
       "   ('xp', '???'),\n",
       "   ('xe', 'They sang mournfully.'),\n",
       "   ('ex', 'Oirara ora riakora kookooiapai gau kova roia kopiitoa-pa oirato.'),\n",
       "   ('xp', 'Ol manmeri ol i singsing krai long man i dai.'),\n",
       "   ('xe', 'Men and women ???.')]),\n",
       " ('kookoopeko',\n",
       "  [('ps', 'V'),\n",
       "   ('pt', 'A'),\n",
       "   ('ge', 'faint'),\n",
       "   ('tkp', '???'),\n",
       "   ('sc', '???'),\n",
       "   ('vx', '1'),\n",
       "   ('dt', '01/Jun/2005'),\n",
       "   ('ex', 'Kookoopekoroi.'),\n",
       "   ('xp', '???'),\n",
       "   ('xe', 'He fainted.'),\n",
       "   ('ex', 'Raki kookoopekoparoi oisio ra kopiiro.'),\n",
       "   ('xp', 'Raki i wok long hap dai.'),\n",
       "   ('xe', 'Raki is faint and about to die.')]),\n",
       " ('kookoopi',\n",
       "  [('ps', 'N'),\n",
       "   ('pt', 'FEM'),\n",
       "   ('ge', 'tail'),\n",
       "   ('tkp', '???'),\n",
       "   ('nt', 'of e.g. lizard, dog, pig'),\n",
       "   ('dt', '02/Dec/2004'),\n",
       "   ('ex',\n",
       "    'Kookoopi kaakau kookoopiaro kookoopi va toupare vo ira voresuraia vokapare aue kokoti.'),\n",
       "   ('xp',\n",
       "    'Tail blong dog wanem?? Kain animol igat fourpela legs em igat tail.'),\n",
       "   ('xe', '???')]),\n",
       " ('kooku',\n",
       "  [('ps', 'V'),\n",
       "   ('pt', 'A'),\n",
       "   ('ge', 'lie'),\n",
       "   ('tkp', 'giaman'),\n",
       "   ('vx', '1'),\n",
       "   ('arg', '???'),\n",
       "   ('cmt', 'Is the person lied to really marked by iava?'),\n",
       "   ('cm', 'iava'),\n",
       "   ('dt', '19/Mar/2006'),\n",
       "   ('ex', 'Koiku kookupaue, vii kuvupauei.'),\n",
       "   ('xp', 'Yu giaman, yu no tok tru.'),\n",
       "   ('xe', \"You're lying. You're not telling the truth.\"),\n",
       "   ('ex', 'Meri, kookupauei ragai iava.'),\n",
       "   ('xp', 'Meri, yu giaman long mi.'),\n",
       "   ('xe', \"Mary, you're lying to me.\")]),\n",
       " ('kookuto',\n",
       "  [('rt', 'kooku'),\n",
       "   ('ps', 'N'),\n",
       "   ('pt', 'HUM'),\n",
       "   ('ge', 'liar'),\n",
       "   ('tkp', 'giaman'),\n",
       "   ('avm', 'pa_barred'),\n",
       "   ('dt', '02/Sep/2005'),\n",
       "   ('ex', 'Pita, viia kookuto.'),\n",
       "   ('xp', 'Pita, yu man bilong giaman.'),\n",
       "   ('xe', \"Peter, you're a liar.\")]),\n",
       " ('kookuvira',\n",
       "  [('rt', 'kooku'),\n",
       "   ('ps', 'ADV'),\n",
       "   ('pt', 'MANNER'),\n",
       "   ('ge', 'lying'),\n",
       "   ('tkp', 'olsem giaman'),\n",
       "   ('dt', '13/Feb/2005'),\n",
       "   ('ex',\n",
       "    'Sera iava osireitorei vuri Sera uva kookuvira raga vurapaevo osa oirato varaoa kavirurevo.'),\n",
       "   ('xp',\n",
       "    'Tupela ai bilong Sera i bagarap na em i lukluk giaman tasol taim man i stilim laplap.'),\n",
       "   ('xe', \"Sera's eyes ??? and ???.\")]),\n",
       " ('koopi',\n",
       "  [('ps', 'N'),\n",
       "   ('pt', '???'),\n",
       "   ('ge', 'coffee'),\n",
       "   ('tkp', 'kopi'),\n",
       "   ('nt', 'Tok Pisin loan'),\n",
       "   ('dt', '14/Feb/2005'),\n",
       "   ('ex', 'Koopi paupaiveira turueirara oira-ia moni oupasia.'),\n",
       "   ('xp', 'Ol retskin ol i save palanim kopii bilong kisim moni.'),\n",
       "   ('xe',\n",
       "    'The redskins (people from mainland PNG) plant coffee in order to make money from it.')]),\n",
       " ('koopipi',\n",
       "  [('ps', 'N'),\n",
       "   ('pt', '???'),\n",
       "   ('ge', 'red-leafed plant'),\n",
       "   ('tkp', 'retpela purpur'),\n",
       "   ('nt', 'grows low to ground'),\n",
       "   ('sf', 'FLORA'),\n",
       "   ('dt', '15/Feb/2005'),\n",
       "   ('ex', 'Koopipi vo toupai vegaaro koopipi.'),\n",
       "   ('xp', '???'),\n",
       "   ('xe', '???'),\n",
       "   ('ex', 'Revasipavira guru vapaivera ora vatapo vararo.'),\n",
       "   ('xp', '???'),\n",
       "   ('xe', '???'),\n",
       "   ('ex', 'Koopipi kouro votoupaiveira vegoaro.'),\n",
       "   ('xp', 'Em i wanpela kain plant i save istap long bus.'),\n",
       "   ('xe', '???')]),\n",
       " ('koora',\n",
       "  [('ps', 'N'),\n",
       "   ('pt', '???'),\n",
       "   ('ge', 'opossum'),\n",
       "   ('tkp', 'kapul'),\n",
       "   ('nt', 'generic term'),\n",
       "   ('dt', '02/Dec/2004'),\n",
       "   ('ex', 'Koorato siopea oaive rotokasipairara.'),\n",
       "   ('xp', 'Kapul em i mit bilong ol Rotokasi.'),\n",
       "   ('xe', '???')]),\n",
       " ('kooroo',\n",
       "  [('ps', 'V'),\n",
       "   ('pt', 'A'),\n",
       "   ('ge', 'have hampered speech'),\n",
       "   ('ge', 'be hoarse'),\n",
       "   ('tkp', '???'),\n",
       "   ('vx', '1'),\n",
       "   ('cmt', 'Check vowel length'),\n",
       "   ('dt', '01/Jun/2005'),\n",
       "   ('ex', 'Kooroopape.'),\n",
       "   ('xp', '???'),\n",
       "   ('xe',\n",
       "    'It is hoarse (said, for example, when a radio speaker works poorly).'),\n",
       "   ('ex', 'Koorooiraorai koovapaoro.'),\n",
       "   ('xp', 'Nek bilong mi bagarap taim mi singsing.'),\n",
       "   ('xe', 'I was really hoarse while singing.')]),\n",
       " ('koorooto',\n",
       "  [('ps', 'N'),\n",
       "   ('pt', 'MASC'),\n",
       "   ('sn', '1'),\n",
       "   ('ge', 'type of lizard'),\n",
       "   ('tkp', '???'),\n",
       "   ('nt',\n",
       "    \"Makes a sound like a hoarse throat. Hold it in your hand and you will also become hoarse: sirie `lizard'.\"),\n",
       "   ('sf', 'FAUNA'),\n",
       "   ('dt', '02/Dec/2004'),\n",
       "   ('ex', 'Koorooto ira vegoaro toupareveira tatagara.'),\n",
       "   ('xp',\n",
       "    'Em i wanpela liklik palai i save istap aninit long ol sting diwai.'),\n",
       "   ('xe', '???')]),\n",
       " ('koorooto',\n",
       "  [('rt', 'kooroo'),\n",
       "   ('ps', 'N'),\n",
       "   ('pt', 'MASC'),\n",
       "   ('sn', '2'),\n",
       "   ('ge', 'speechless man because of handicap'),\n",
       "   ('tkp', 'man i gat nek i pas'),\n",
       "   ('cmt', 'Check vowel length'),\n",
       "   ('dt', '01/Mar/2005'),\n",
       "   ('ex', 'Ivatoa korooto ira viapau vearovira reoreoparo.'),\n",
       "   ('xp', 'Ivato em i nek nogut em i no save toktok gut.'),\n",
       "   ('xe', \"The mute Ivato can't talk right.\"),\n",
       "   ('ex', 'Viia korooto koroovira reopauei.'),\n",
       "   ('xp', '???'),\n",
       "   ('xe', '???')]),\n",
       " ('kooroovira',\n",
       "  [('rt', 'kooroo'),\n",
       "   ('ps', 'ADV'),\n",
       "   ('pt', 'MANNER'),\n",
       "   ('ge', 'hoarsely'),\n",
       "   ('ge', '???'),\n",
       "   ('tkp', 'olsem ???'),\n",
       "   ('dt', '01/Mar/2005'),\n",
       "   ('ex', 'Ruke koroovira reoparoveira.'),\n",
       "   ('xp', 'Luk i no save toktok klia.'),\n",
       "   ('xe', 'Luke always speaks with an impediment.'),\n",
       "   ('ex', 'Koroovira toupaavoi viapau uvuipara reopasia roroiovira.'),\n",
       "   ('xp', 'Mi no i nap toktok gut bikos nek blong i pas.'),\n",
       "   ('xe', \"I can't speak well because my neck is ???.\")]),\n",
       " ('kooru',\n",
       "  [('ps', 'N'),\n",
       "   ('pt', 'NT'),\n",
       "   ('ge', 'unripe.coconut'),\n",
       "   ('eng', 'unripe coconut'),\n",
       "   ('tkp', 'kulau'),\n",
       "   ('nt', 'Full form is opita kooru.'),\n",
       "   ('dt', '01/Oct/2006'),\n",
       "   ('ex', 'Kooru ukaio ruipaparai.'),\n",
       "   ('xp', 'Mi laik dring kulau.'),\n",
       "   ('xe', 'I want to drink unripe coconut.')]),\n",
       " ('koota',\n",
       "  [('ps', 'CLASS'),\n",
       "   ('ge', 'rope-like'),\n",
       "   ('tkp', '???'),\n",
       "   ('eng', 'group of rope-like objects'),\n",
       "   ('dt', '04/Sep/2005'),\n",
       "   ('ex', 'Riro koota rutu aue iro evaova-ia.'),\n",
       "   ('xp', 'Plenti rop tru long diwai.'),\n",
       "   ('xe', '???'),\n",
       "   ('ex', 'Iro kootaro kekeavo evaova-ia.'),\n",
       "   ('xp', 'Mi lukim pinis plenti rop i stap long diwai.'),\n",
       "   ('xe', '???')]),\n",
       " ('kootopa',\n",
       "  [('ps', 'N'),\n",
       "   ('pt', '???'),\n",
       "   ('ge', 'corn'),\n",
       "   ('tkp', 'mais'),\n",
       "   ('dt', '01/Mar/2005'),\n",
       "   ('ex', 'Kootopa kukara ovaisiuvu kukara.'),\n",
       "   ('xp', 'Rotokas igat twopela long corn .'),\n",
       "   ('xe', '???'),\n",
       "   ('ex', 'Kootopa aioparai oara ouavo eisi uua.'),\n",
       "   ('xp', 'Mi kaikai kon. Mi kisim long bung.'),\n",
       "   ('xe', 'I am eating corn that I go at the meeting.')]),\n",
       " ('kootutu',\n",
       "  [('ps', 'N'),\n",
       "   ('pt', 'FEM'),\n",
       "   ('ge', 'stocky fat woman'),\n",
       "   ('tkp', '???'),\n",
       "   ('dt', '28/Aug/2005'),\n",
       "   ('ex', 'Kootutu oo riako iri kovaevira riropao/toupaeve.'),\n",
       "   ('xp', 'Dispela meri em I fatpela meri.'),\n",
       "   ('xe', '???'),\n",
       "   ('ex', 'Ivia kootutu, viapau uvuipaoi ikauvira vokasia.'),\n",
       "   ('xp', 'Ivi em i patpela meri, na em i no inap wokabaut kuik.'),\n",
       "   ('xe', \"Ivi is fat, she can't walk quickly.\")]),\n",
       " ('koou',\n",
       "  [('ps', 'N'),\n",
       "   ('pt', '???'),\n",
       "   ('ge', 'incest between parent and child or siblings'),\n",
       "   ('tkp', 'slip wantaim bisnis'),\n",
       "   ('dt', '14/Feb/2005'),\n",
       "   ('ex', 'Kuvapea koou ira papari-va oureva.'),\n",
       "   ('xp', 'Kuvape i bin kisim kandere bilong en o wanpisin bilong en.'),\n",
       "   ('xe', 'Kuvape is a committer of incest who married a ???.')]),\n",
       " ('kooupato',\n",
       "  [('rt', 'koou'),\n",
       "   ('ps', 'N'),\n",
       "   ('pt', 'HUM'),\n",
       "   ('ge', 'incestuous person'),\n",
       "   ('tkp', '???'),\n",
       "   ('dt', '14/Feb/2005'),\n",
       "   ('ex', 'Kooupato oirato ira siara riakova ootoparoveira.'),\n",
       "   ('xp', 'Man i save pamukim ol wanpisin meri.'),\n",
       "   ('xe',\n",
       "    'An incestuous person is one who has sex with woman of the same clan.')]),\n",
       " ('koova',\n",
       "  [('ps', 'V'),\n",
       "   ('pt', 'A'),\n",
       "   ('ge', 'sing'),\n",
       "   ('tkp', 'singsing'),\n",
       "   ('sc', '???'),\n",
       "   ('nt', 'involves dancing while singing'),\n",
       "   ('vx', '1'),\n",
       "   ('dt', '08/Sep/2006'),\n",
       "   ('ex', 'Voea rutu koova rovopaavere pupipaoro.'),\n",
       "   ('xp', '???'),\n",
       "   ('xe', 'All of them will start dancing, blowing the pipes and singsing.'),\n",
       "   ('ex', 'Uriora vata koovapai pupipaoro.'),\n",
       "   ('xp', 'Ol uriora ol i singsing long kaul.'),\n",
       "   ('xe', 'The people of Uriora are having a singsing blowing pipes.')]),\n",
       " ('koova',\n",
       "  [('ps', 'N'),\n",
       "   ('pt', 'FEM'),\n",
       "   ('ge', 'song'),\n",
       "   ('tkp', 'singsing'),\n",
       "   ('vx', '1'),\n",
       "   ('dt', '28/Sep/2006'),\n",
       "   ('ex', 'Voea rutu koova rovopaavere pupipaoro.'),\n",
       "   ('xp', '???'),\n",
       "   ('xe', 'All of them will start dancing, blowing the pipes and singsing.'),\n",
       "   ('ex', 'Uriora vata koovapai pupipaoro.'),\n",
       "   ('xp', 'Ol uriora ol i singsing long kaul.'),\n",
       "   ('xe', 'The people of Uriora are having a singsing.')]),\n",
       " ('koovoto',\n",
       "  [('rt', 'koovo'),\n",
       "   ('ps', 'N'),\n",
       "   ('pt', 'HUM'),\n",
       "   ('ge', 'cheeky person'),\n",
       "   ('ge', 'joker'),\n",
       "   ('tkp', 'siki man'),\n",
       "   ('tkp', 'giaman'),\n",
       "   ('dt', '14/Feb/2005'),\n",
       "   ('ex', 'Reviria riro koovoto vo riako-re varo verapaoro.'),\n",
       "   ('xp',\n",
       "    'Reviri i man bilong pilai na em i save rausim laplap long ol meri.'),\n",
       "   ('xe', \"Reviri is a big joker who removes the women's clothes.\"),\n",
       "   ('ex',\n",
       "    'Ro oirato ri koovoto viapau osio oiropa reorovaia respa rovere. Oira oiraparoia reoparovere.'),\n",
       "   ('xp', 'Man i tok pilai tasol sampela taim bai mekim ol trupela stori.'),\n",
       "   ('xe', '???')]),\n",
       " ('koovotova',\n",
       "  [('ps', 'N'),\n",
       "   ('pt', 'FEM'),\n",
       "   ('ge', 'posts used to hold up rafters'),\n",
       "   ('tkp', '???'),\n",
       "   ('dt', '02/Dec/2004'),\n",
       "   ('ex', 'Koovotova iri kepaa pitupaeva gorupiepaoro.'),\n",
       "   ('xp', 'Post em save holim house long stongim.'),\n",
       "   ('xe', '???'),\n",
       "   ('ex', 'Koovotova iria ivaraia kaaroara tovotovopaiveira kepa-ia.'),\n",
       "   ('xp', 'Longpela diwa i ol i save putim antap long pos na putim ol rapta.'),\n",
       "   ('xe', '???')]),\n",
       " ('kopa',\n",
       "  [('ps', 'V'),\n",
       "   ('pt', 'B'),\n",
       "   ('ge', 'swallow'),\n",
       "   ('eng', 'swallow'),\n",
       "   ('eng', 'gulp down'),\n",
       "   ('eng', 'ingest'),\n",
       "   ('tkp', 'daunim'),\n",
       "   ('arg', 'O'),\n",
       "   ('vx', '2'),\n",
       "   ('dt', '28/Sep/2006'),\n",
       "   ('ex', 'Kakau aioa kopaevoi ikauvira rutu.'),\n",
       "   ('xp', 'Dok i daunim kwik hap kaukau.'),\n",
       "   ('xe', 'The dog quickly swallowed the food.'),\n",
       "   ('ex', 'Kopa aioa kopa va aiovo.'),\n",
       "   ('xp', 'Yu kaikai na dawnim.'),\n",
       "   ('xe', '???')]),\n",
       " ('kopakai',\n",
       "  [('ps', 'N'),\n",
       "   ('pt', 'FEM'),\n",
       "   ('ge', 'sugar cane'),\n",
       "   ('tkp', '???'),\n",
       "   ('sf', 'FLORA'),\n",
       "   ('nt',\n",
       "    'Striped with brown inside. It was formerly taboo for children to eat it since it stunted their ???'),\n",
       "   ('dt', '14/Feb/2005'),\n",
       "   ('ex',\n",
       "    'Sipoiva kopakai, iria-ia oisioa kakaevure-re korukorupave voari tuariri.'),\n",
       "   ('xp',\n",
       "    'Suka ken i baraun insait, na ol man bilong bipo i save tambuim ol pikinini.'),\n",
       "   ('xe', '???')]),\n",
       " ('kopakava',\n",
       "  [('ps', 'N'),\n",
       "   ('pt', 'FEM'),\n",
       "   ('ge', 'baby'),\n",
       "   ('ge', 'black female'),\n",
       "   ('tkp', '???'),\n",
       "   ('dt', '02/Dec/2004'),\n",
       "   ('ex', 'Riakova kopakave rupa varava.'),\n",
       "   ('xp', 'Black meri.'),\n",
       "   ('xe', '???'),\n",
       "   ('ex', 'Riakova kopakava eisi-va oira Buin.'),\n",
       "   ('xp', 'Buin meri i skin bilak.'),\n",
       "   ('xe', '???')]),\n",
       " ('kopakopa',\n",
       "  [('rt', 'kopa'),\n",
       "   ('ps', 'V'),\n",
       "   ('pt', 'B'),\n",
       "   ('rdp', 'full'),\n",
       "   ('ge', 'gulp.down'),\n",
       "   ('tkp', '???'),\n",
       "   ('eng', 'swallow quickly'),\n",
       "   ('eng', 'qulp down'),\n",
       "   ('am', 'false'),\n",
       "   ('arg', 'O'),\n",
       "   ('vx', '2'),\n",
       "   ('dt', '30/Aug/2005'),\n",
       "   ('ex', 'Aioara kopakopapari.'),\n",
       "   ('xp', '???'),\n",
       "   ('xe', 'You are gulping down the food.'),\n",
       "   ('ex', 'Kaakau iria kaukau kopakopapaoi ikaupavira rutu.'),\n",
       "   ('xp', 'Dok i wok long daunim kwik tru ol kaukau.'),\n",
       "   ('xe', 'The dog is quickly devouring the sweet potatos.')]),\n",
       " ('kopakovira',\n",
       "  [('alt', 'kopakopavira'),\n",
       "   ('rt', 'kopakopa'),\n",
       "   ('ps', 'ADV'),\n",
       "   ('pt', 'MANNER'),\n",
       "   ('ge', 'gulping-like'),\n",
       "   ('tkp', '???'),\n",
       "   ('dt', '30/Aug/2005'),\n",
       "   ('ex', 'Kopakopavira aiopare.'),\n",
       "   ('xp', '???'),\n",
       "   ('xe', 'He is eating quickly gulping down his food.'),\n",
       "   ('ex', 'Kopakopavira aiopaevoi koie.'),\n",
       "   ('xp', 'Pik i wok long kaikai hariap tru.'),\n",
       "   ('xe', 'The pig is eating ???.')]),\n",
       " ('kopato',\n",
       "  [('rt', 'kopa'),\n",
       "   ('ps', 'N'),\n",
       "   ('pt', 'HUM'),\n",
       "   ('ge', 'big eater'),\n",
       "   ('ge', 'voracious eater'),\n",
       "   ('tkp', '???'),\n",
       "   ('cmt', 'Make sure that form kopato, kopava, kopairara all exist.'),\n",
       "   ('dt', '14/Feb/2005'),\n",
       "   ('ex', 'Riro aio kopava koie.'),\n",
       "   ('xp', 'Pik i save kaikai tumas.'),\n",
       "   ('xe', 'Pigs are big eaters.'),\n",
       "   ('ex', 'Riro aio kopava koie kovoara-ia.'),\n",
       "   ('xp', '???'),\n",
       "   ('xe', 'The pig is a big eater in the gardens (destructive pest).')]),\n",
       " ('kopii',\n",
       "  [('ps', 'V'),\n",
       "   ('pt', 'A'),\n",
       "   ('ge', 'die'),\n",
       "   ('eng', 'die'),\n",
       "   ('eng', 'very ill'),\n",
       "   ('tkp', 'dai'),\n",
       "   ('vx', '1'),\n",
       "   ('cmt', 'Check aspectual difference, dying/very ill vs. dead.'),\n",
       "   ('dcsv', 'true'),\n",
       "   ('dt', '01/Jun/2005'),\n",
       "   ('ex', 'Viapau oiso taraipasi oiso osa kopiipavioveira.'),\n",
       "   ('xp', '???'),\n",
       "   ('xe', \"They both didn't know how we always die.\"),\n",
       "   ('ex', 'Kopi apesia kopipauei eke?'),\n",
       "   ('xp', '???'),\n",
       "   ('xe', '???')]),\n",
       " ('kopiia',\n",
       "  [('rt', 'kopii'),\n",
       "   ('ps', 'N'),\n",
       "   ('pt', 'NT'),\n",
       "   ('ge', 'death'),\n",
       "   ('ge', 'sickness'),\n",
       "   ('tkp', '???'),\n",
       "   ('dt', '14/Feb/2005'),\n",
       "   ('ex', 'Riroa kopiia toupaivoi vovokio-ia.'),\n",
       "   ('xp', 'Tudei i gat bikpela sik istap.'),\n",
       "   ('xe', 'Serious illness exists today.'),\n",
       "   ('ex', 'Kopia kopia-ia viei vouokio.'),\n",
       "   ('xp', 'Bai dai nam tassol.'),\n",
       "   ('xe', '???'),\n",
       "   ('ex', 'Kopiia viepao.'),\n",
       "   ('xp', 'Yo istap long dai.'),\n",
       "   ('xe', '???')]),\n",
       " ('kopiipato',\n",
       "  [('rt', 'kopii'),\n",
       "   ('ps', 'N'),\n",
       "   ('pt', 'HUM'),\n",
       "   ('ge', 'sick person'),\n",
       "   ('tkp', 'man i gat sik'),\n",
       "   ('dt', '02/Sep/2005'),\n",
       "   ('ex', 'Riroirara kopiipairara toupaivoi eisi ruvarupa kepa-ia.'),\n",
       "   ('xp', 'Plenti sik manmeri ol i stap long haus marasin.'),\n",
       "   ('xe', 'Many sick people are in the medical station.')]),\n",
       " ('kopiipie',\n",
       "  [('rt', 'kopii'),\n",
       "   ('ps', 'V'),\n",
       "   ('pt', 'B'),\n",
       "   ('ge', 'kill'),\n",
       "   ('eng', 'murder'),\n",
       "   ('eng', 'kill'),\n",
       "   ('tkp', 'mekim dai'),\n",
       "   ('arg', 'O'),\n",
       "   ('vx', '2'),\n",
       "   ('cmt',\n",
       "    \"Last example is a bit weird. If they killed him, he's dead, no? How could he be weak?\"),\n",
       "   ('dt', '18/Nov/2005'),\n",
       "   ('ex', 'Tomas Jon kopiipierevo rera upooro.'),\n",
       "   ('xp', 'Tomas i kilim dai Jon, taim em i paitim em.'),\n",
       "   ('xe', 'Tomas killed John by hitting him.'),\n",
       "   ('ex', 'Kopipie oirato upari uva kopiovoira.'),\n",
       "   ('xp', 'Yo kilim man man i dai olgeta.'),\n",
       "   ('xe', '???'),\n",
       "   ('ex', 'Rera kopiipieiva. Oire raveraveroepa.'),\n",
       "   ('xp', '???'),\n",
       "   ('xe', 'They were killing him. And he became very weak.')]),\n",
       " ('kopiito',\n",
       "  [('rt', 'kopii'),\n",
       "   ('ps', 'N'),\n",
       "   ('pt', 'HUM'),\n",
       "   ('ge', 'dead person'),\n",
       "   ('ge', 'corpse'),\n",
       "   ('ge', 'seriously sick man'),\n",
       "   ('ge', 'spirit of dead man'),\n",
       "   ('tkp', '???'),\n",
       "   ('dt', '02/Dec/2004'),\n",
       "   ('ex', 'Kopiito roia oirato kopiito urauraroia.'),\n",
       "   ('xp', 'Dead man/spirit of dead man.'),\n",
       "   ('xe', '???'),\n",
       "   ('ex', 'Kopiitoava avai rera rovasia eisi tova urui.'),\n",
       "   ('xp', 'Diaman ol i go palanim long matmat.'),\n",
       "   ('xe', '???')]),\n",
       " ('kopikao',\n",
       "  [('ps', 'N'),\n",
       "   ('pt', 'FEM'),\n",
       "   ('ge', 'bird'),\n",
       "   ('tkp', 'pisin'),\n",
       "   ('eng', 'Yellow Bittern (Ixobryuchus sinensis)'),\n",
       "   ('sa', 'vaakira'),\n",
       "   ('sf', 'FAUNA.BIRD'),\n",
       "   ('dt', '14/Feb/2005'),\n",
       "   ('ex', 'Kopikao riro kaekae kokotova.'),\n",
       "   ('xp', 'Em pisin i gat longpela lek.'),\n",
       "   ('xe', 'The Yellow Bittern has long legs.'),\n",
       "   ('ex', 'Vokiaro gaupaevaira koikas kokiova.'),\n",
       "   ('xp', 'Long night i save singautim narapela pisin.'),\n",
       "   ('xe', '???')]),\n",
       " ('kopikopi',\n",
       "  [('rt', 'kopi'),\n",
       "   ('ps', 'V'),\n",
       "   ('pt', 'B'),\n",
       "   ('rdp', 'full'),\n",
       "   ('ge', 'baptize'),\n",
       "   ('ge', 'sprinkle'),\n",
       "   ('tkp', 'i gat planti mak'),\n",
       "   ('nt', 'Used mainly in the United Church.'),\n",
       "   ('arg', 'O'),\n",
       "   ('vx', '2'),\n",
       "   ('dt', '08/Jun/2005'),\n",
       "   ('ex', 'Minista kakaevure kopikopiparevoi toupa vokia.'),\n",
       "   ('xp', 'Long sande minista bai baptaisim ol pikinini.'),\n",
       "   ('xe', 'The minister will baptize the children on sunday.'),\n",
       "   ('ex', 'Oirara kopikopipaivora pastairara vo lotua iare voea.'),\n",
       "   ('xp', '???'),\n",
       "   ('xe', 'The pastors baptized the people, marking them into the church.')]),\n",
       " ('kopikopiara',\n",
       "  [('rt', 'kopikopi'),\n",
       "   ('ps', 'N'),\n",
       "   ('pt', 'NT'),\n",
       "   ('rdp', 'full'),\n",
       "   ('ge', 'spotted'),\n",
       "   ('ge', 'dots'),\n",
       "   ('ge', 'blotches'),\n",
       "   ('tkp', 'ol makmak'),\n",
       "   ('dt', '07/Sep/2005'),\n",
       "   ('ex', 'Varoa-ia kopikopiara toupaivoi.'),\n",
       "   ('xp', 'Laplap i gat ol makmak.'),\n",
       "   ('xe', 'There are stains on the clothing.')]),\n",
       " ('kopipi',\n",
       "  [('ps', 'N'),\n",
       "   ('pt', 'MASC'),\n",
       "   ('ge', 'type of plant'),\n",
       "   ('tkp', 'raunpela haus'),\n",
       "   ('nt', 'Has read leaves and is used as a tall border plant.'),\n",
       "   ('sf', 'FLORA'),\n",
       "   ('dt', '02/Dec/2004')]),\n",
       " ('kopirovu',\n",
       "  [('ps', 'N'),\n",
       "   ('pt', 'MASC'),\n",
       "   ('ge', 'rope'),\n",
       "   ('ge', 'hawswer'),\n",
       "   ('tkp', 'paklain'),\n",
       "   ('dt', '14/Feb/2005'),\n",
       "   ('ex', 'Virera kopirovu aue tukepato.'),\n",
       "   ('xp', 'Em rop blong yu blong pasim samting.'),\n",
       "   ('xe', '???'),\n",
       "   ('ex', 'Reka kopirovu-ia kotokotoara tukerevoi.'),\n",
       "   ('xp', 'Reka i pasim ol kago long rop.'),\n",
       "   ('xe', 'Reka tied up the cargo with rope.')]),\n",
       " ('kopu',\n",
       "  [('ps', '???'),\n",
       "   ('dx', 'Central'),\n",
       "   ('ge', '???'),\n",
       "   ('tkp', 'i no tan'),\n",
       "   ('eng', '???'),\n",
       "   ('dt', '13/Nov/2005'),\n",
       "   ('ex', 'Sira kopu pitoka veraevoi upiriko pitoka ovusia viapau oripiro.'),\n",
       "   ('xp', 'Sira em i rausim sospen kaukau taim em i no tan.'),\n",
       "   ('xe', '???')]),\n",
       " ('kopua',\n",
       "  [('ps', '???'),\n",
       "   ('ge', 'green'),\n",
       "   ('ge', 'unripe'),\n",
       "   ('ge', 'uncooked'),\n",
       "   ('tkp', 'i no mau'),\n",
       "   ('cmt', \"Example doesn't look like a verb.\"),\n",
       "   ('dt', '22/Nov/2005'),\n",
       "   ('ex', 'Kopua raga eva koie kuvu.'),\n",
       "   ('xp', 'Mambu pik i no tan gut.'),\n",
       "   ('xe', '???')]),\n",
       " ('kopuasi',\n",
       "  [('ps', 'V'),\n",
       "   ('pt', 'A'),\n",
       "   ('vx', '1'),\n",
       "   ('dx', 'Central'),\n",
       "   ('ge', 'restored'),\n",
       "   ('eng', 'restored'),\n",
       "   ('eng', 'rejuvenated'),\n",
       "   ('tkp', 'pilim gut gen'),\n",
       "   ('dt', '24/Aug/2005'),\n",
       "   ('ex', 'Ragai kopuasirai uvare sisiurai.'),\n",
       "   ('xp', 'Mi pilim gut gen bikos mi waswas.'),\n",
       "   ('xe', '???')]),\n",
       " ('kopuasipie',\n",
       "  [('rt', 'kopuasi'),\n",
       "   ('ps', 'V'),\n",
       "   ('pt', 'B'),\n",
       "   ('ge', 'restore'),\n",
       "   ('ge', 'rejuvenate'),\n",
       "   ('tkp', '???'),\n",
       "   ('vx', '2'),\n",
       "   ('arg', 'O'),\n",
       "   ('dt', '08/Jun/2005'),\n",
       "   ('ex', 'Leo kepa kopuasipierevo va kipuoro, uva vearo kekepai.'),\n",
       "   ('xp', 'Leo i penim haus na em i luk nais tru.'),\n",
       "   ('xe', 'Leo restored his house by painting it, and it looks good.'),\n",
       "   ('ex', 'Va kopuasi pierivo va kipuoro vorerivira.'),\n",
       "   ('xp', '???'),\n",
       "   ('xe', 'You restored it while painting it again.')]),\n",
       " ('kopuasito',\n",
       "  [('rt', 'kopuasi'),\n",
       "   ('ps', 'N'),\n",
       "   ('pt', 'MASC'),\n",
       "   ('ge', 'young'),\n",
       "   ('tkp', 'yangpela'),\n",
       "   ('cmt',\n",
       "    'Double-check translation. It says young but seems to get translated as smart.'),\n",
       "   ('dt', '01/Jun/2005'),\n",
       "   ('ex', 'Kopuasito viapau upiavai revaia riro goruto.'),\n",
       "   ('xp', 'I no gat sik em stong pela man.'),\n",
       "   ('xe', '???'),\n",
       "   ('ex', 'Kopuasito ro kakaeto, viapau upiavai rera-ia.'),\n",
       "   ('xp', 'Smatpela boi tru nogat sik long em.'),\n",
       "   ('xe', '???'),\n",
       "   ('ex', 'Vii kopuasitoa rutu viovokoto.'),\n",
       "   ('xp', 'Yu smatpela yangpela boi.'),\n",
       "   ('xe', \"You're a smart boy.\")]),\n",
       " ('kopuasitovira',\n",
       "  [('rt', 'kopuasi'),\n",
       "   ('ps', 'ADV'),\n",
       "   ('pt', 'MANNER'),\n",
       "   ('ge', 'youthful'),\n",
       "   ('tkp', 'olsem yangpela'),\n",
       "   ('dt', '14/Feb/2005'),\n",
       "   ('ex', 'Latu kopuasivira raga touparevoi, uva viapau ikauvira uusiparoi.'),\n",
       "   ('xp', 'Latu i skin kirap yet na em i no slip kwik.'),\n",
       "   ('xe', \"Latu is ???, and he can't fall asleep quickly.\"),\n",
       "   ('ex', 'Vii kopuasitovira touparivo viovokovira.'),\n",
       "   ('xp', 'Yu luk yangpela man.'),\n",
       "   ('xe', '???')]),\n",
       " ('kopuasivira',\n",
       "  [('rt', 'kopuasi'),\n",
       "   ('ps', 'ADV'),\n",
       "   ('pt', 'MANNER'),\n",
       "   ('ge', 'young and fresh'),\n",
       "   ('ge', 'powerful'),\n",
       "   ('ge', 'tirelessly'),\n",
       "   ('tkp', '???'),\n",
       "   ('dt', '19/Feb/2004'),\n",
       "   ('ex', 'Kopuasivira kovopare.'),\n",
       "   ('xp', '???'),\n",
       "   ('xe', 'He works tirelessly.')]),\n",
       " ('Kopuisi',\n",
       "  [('ps', 'N'),\n",
       "   ('pt', 'PN'),\n",
       "   ('ge', 'Kopuisi'),\n",
       "   ('eng', 'Kopuisi'),\n",
       "   ('nt', 'proper name'),\n",
       "   ('dt', '26/Jan/2005')]),\n",
       " ('kopukopu',\n",
       "  [('rt', 'kopu'),\n",
       "   ('ps', 'V'),\n",
       "   ('pt', 'A'),\n",
       "   ('rdp', 'full'),\n",
       "   ('ge', 'frontside'),\n",
       "   ('tkp', 'poret bilong haus'),\n",
       "   ('nt', 'front of anything (e.g., shirt, blouse, body, house)'),\n",
       "   ('dt', '22/Nov/2005'),\n",
       "   ('cmt', 'How can this be a verb? Something is confused here.'),\n",
       "   ('ex', 'Kepa oiso ragavira kopukopupai.'),\n",
       "   ('xp', '???'),\n",
       "   ('xe', '???')]),\n",
       " ('kopukopua',\n",
       "  [('rt', 'kopukopu'),\n",
       "   ('ps', 'N'),\n",
       "   ('pt', 'NT'),\n",
       "   ('ge', 'front side of house'),\n",
       "   ('tkp', '???'),\n",
       "   ('dt', '22/Nov/2005'),\n",
       "   ('ex', 'Kepa iava kopukopua oisio ragavira toupaivoi.'),\n",
       "   ('xp', 'Pran bilong haus istap olsem.'),\n",
       "   ('xe', 'The front of the house is just like this.'),\n",
       "   ('ex', 'Kuvupato tovori ra kopukopua-ia avaka isiro pitupitupieri.'),\n",
       "   ('xp', 'Yu putim siot, na bai yu pasim ol baton.'),\n",
       "   ('xe', '???')]),\n",
       " ('kopupa',\n",
       "  [('ps', 'N'),\n",
       "   ('pt', '???'),\n",
       "   ('ge', 'unripe'),\n",
       "   ('ge', 'green yet'),\n",
       "   ('tkp', '???'),\n",
       "   ('dt', '01/Jun/2005'),\n",
       "   ('am', 'false'),\n",
       "   ('ex', 'Kopupa vao vaviokoa viapau viorio/melon.'),\n",
       "   ('xp', 'Pawpaw is bao yet water melon i no bao yet.'),\n",
       "   ('xe', '???'),\n",
       "   ('ex', 'Kopupa isi raga eva isi aue vavioko.'),\n",
       "   ('xp', 'Popo i grin yet na i no mau.'),\n",
       "   ('xe', 'The pawpaw is unripe.')]),\n",
       " ('kopupira',\n",
       "  [('ps', 'N'),\n",
       "   ('pt', 'NT'),\n",
       "   ('ge', 'red clay-like ground'),\n",
       "   ('tkp', '???'),\n",
       "   ('dt', '02/Dec/2004'),\n",
       "   ('ex', 'Rasiva revasi kekevira dupae rasiva rasiaiwa.'),\n",
       "   ('xp', 'NO DATA.'),\n",
       "   ('xe', '???')]),\n",
       " ('kopuro',\n",
       "  [('ps', 'N'),\n",
       "   ('pt', 'FEM'),\n",
       "   ('ge', 'fly'),\n",
       "   ('tkp', '???'),\n",
       "   ('nt', 'Small type that lives in jungle.'),\n",
       "   ('dt', '20/Feb/2005'),\n",
       "   ('ex', 'Kopuro korikoripa va vegotoupaeveira oisi kekevavi.'),\n",
       "   ('xp', 'Tausito em luk olsem fly nn lizard.'),\n",
       "   ('xe', '???'),\n",
       "   ('ex', 'Kopuro korikoripava.'),\n",
       "   ('xp', 'Liklik palai i gat ol makmak.'),\n",
       "   ('xe', 'The ??? is ???.')]),\n",
       " ('Kopuru',\n",
       "  [('ps', 'N'),\n",
       "   ('pt', 'PN'),\n",
       "   ('ge', 'name'),\n",
       "   ('tkp', 'nem'),\n",
       "   ('dt', '14/Feb/2005'),\n",
       "   ('ex', 'Kopurua ro vurapato oirato.'),\n",
       "   ('xp', 'Em i masol na strongpela man.'),\n",
       "   ('xe', 'Kopuru is a strong man.')]),\n",
       " ('kopuvioro',\n",
       "  [('rt', 'kopu'),\n",
       "   ('ps', 'N'),\n",
       "   ('pt', '???'),\n",
       "   ('cl', 'isi'),\n",
       "   ('ge', 'unripe banana'),\n",
       "   ('tkp', '???'),\n",
       "   ('pt', 'itoo'),\n",
       "   ('dt', '12/Aug/2005'),\n",
       "   ('ex', 'Kopu isi raga vaisio ito isi.'),\n",
       "   ('xp', 'Banana i no mau.'),\n",
       "   ('xe', '???')]),\n",
       " ('kopuvira',\n",
       "  [('alt', 'kopupavira'),\n",
       "   ('rt', 'kopu'),\n",
       "   ('ps', 'ADV'),\n",
       "   ('pt', 'MANNER'),\n",
       "   ('ge', 'uncooked'),\n",
       "   ('ge', 'unripe'),\n",
       "   ('tkp', '???'),\n",
       "   ('dt', '13/Nov/2005'),\n",
       "   ('ex', 'Kopupavira toupaivoi upiriko pitoka.'),\n",
       "   ('xp', 'Sospen kaukau i no tan.'),\n",
       "   ('xe', 'The saucepan of sweet potatos is uncooked.'),\n",
       "   ('ex', 'Viapau vearovira vao opoa oripiro o kopupavira toupaevoi.'),\n",
       "   ('xp', '???'),\n",
       "   ('xe', \"The taro isn't well cooked, it is still uncooked.\"),\n",
       "   ('ex',\n",
       "    'Kopuvira raga araisi orievo rara igei-pa uva oisi raga oira aioiovo.'),\n",
       "   ('xp', 'Rara em i kukim rais i no tan gut na mipela kaikaim olsem tasol.'),\n",
       "   ('xe', '???')]),\n",
       " ('kora',\n",
       "  [('ps', 'V'),\n",
       "   ('pt', 'A'),\n",
       "   ('ge', 'vent'),\n",
       "   ('eng', 'vent anger or frustration on an object'),\n",
       "   ('tkp', '???'),\n",
       "   ('vx', '1'),\n",
       "   ('cmt', 'Is there casemarking? Is there a second argument?'),\n",
       "   ('dt', '26/Jun/2005'),\n",
       "   ('ex', 'Terita koveroi uva totoroe. Oire koraai oirara, evaova ritapaoro.'),\n",
       "   ('xp',\n",
       "    'Terita i pundaun long diwai na liklik taim em i dai na ol man i sutim diwai.'),\n",
       "   ('xe', 'Terita fell down and ???.'),\n",
       "   ('ex', 'Oiratoa-ia koraaepa oirara, uvare koveroepa opita atopaoro.'),\n",
       "   ('xp', '???'),\n",
       "   ('xe',\n",
       "    'The people vented their frustration and sorrow for the man because ???.')]),\n",
       " ('korapato',\n",
       "  [('rt', 'kora'),\n",
       "   ('ps', 'N'),\n",
       "   ('pt', 'MASC'),\n",
       "   ('ge', 'punishment tree'),\n",
       "   ('tkp', '???'),\n",
       "   ('nt', 'tree designated to receive punishment otherwise vented on a ???'),\n",
       "   ('sa', 'kasiava'),\n",
       "   ('dt', '14/Feb/2005'),\n",
       "   ('ex', 'Eva oa-ia korapato purai oisio ra va ritaive oirara.'),\n",
       "   ('xp', 'Diwai ol i sanapim bai ol man i kam sutim.'),\n",
       "   ('xe', '???')]),\n",
       " ('korara',\n",
       "  [('ps', 'V'),\n",
       "   ('pt', 'A'),\n",
       "   ('ge', 'spin top in play'),\n",
       "   ('tkp', '???'),\n",
       "   ('sc', '???'),\n",
       "   ('vx', '1'),\n",
       "   ('dt', '01/Jun/2005'),\n",
       "   ('ex', 'Viovokopairara oea korarapai aue-ia atope visikopaoro.'),\n",
       "   ('xp', 'Ol boi i pilai long het bilong sel kokonas.'),\n",
       "   ('xe', '???'),\n",
       "   ('ex', 'Korarapaai viovokopairara atopeara-ia.'),\n",
       "   ('xp', '???'),\n",
       "   ('xe', 'The boys are playing a spinning game with coconut shell tops.')]),\n",
       " ('koraraoko',\n",
       "  [('ps', 'N'),\n",
       "   ('pt', 'FEM'),\n",
       "   ('ge', 'type of frog'),\n",
       "   ('tkp', '???'),\n",
       "   ('nt',\n",
       "    \"Small yellow to brown body, large feet. It was pictured on Papua New Guinea's 20 toea postage stamp.\"),\n",
       "   ('dt', '14/Feb/2005'),\n",
       "   ('ex', 'Koraraoko iria tatagaara reroara toupaeveira.'),\n",
       "   ('xp', 'Em wanpela kain rokrok i save istap aninit long ol diwai.'),\n",
       "   ('xe', 'The ??? frog lives underneath ??? trees.')]),\n",
       " ('korau',\n",
       "  [('ps', 'V'),\n",
       "   ('pt', 'A'),\n",
       "   ('ge', 'clear'),\n",
       "   ('ge', 'unobstructed'),\n",
       "   ('eng', 'clear or unobstructed'),\n",
       "   ('tkp', 'klia'),\n",
       "   ('vx', '1'),\n",
       "   ('cmt', 'example needed'),\n",
       "   ('dt', '28/Apr/2007')]),\n",
       " ('koraua',\n",
       "  [('rt', 'korau'),\n",
       "   ('ps', 'N'),\n",
       "   ('pt', 'NT'),\n",
       "   ('ge', 'clearing'),\n",
       "   ('tkp', 'hap i klia'),\n",
       "   ('dt', '26/Jan/2005'),\n",
       "   ('ex', 'Vavo toreu koraua ra vavoiso vurari avakava.'),\n",
       "   ('xp', 'Yu sanap long peles kilia na yu lukluk i go long solwava.'),\n",
       "   ('xe', 'You stand up at a clear spot and you can see the ocean.'),\n",
       "   ('ex', 'Vavo vurari koraua-ia.'),\n",
       "   ('xp', 'Yu sanap long klia peles.'),\n",
       "   ('xe', 'You stand up on a cleared spot.'),\n",
       "   ('ex', 'Jon koraua-ia vokapare rogaraua-ia, avakava sirova.'),\n",
       "   ('xp', 'Jon i wokabaut ples klia long wetsan arere long solwara.'),\n",
       "   ('xe', '???')]),\n",
       " ('korauru',\n",
       "  [('ps', 'N'),\n",
       "   ('pt', 'MASC'),\n",
       "   ('ge', 'type of lizard'),\n",
       "   ('tkp', '???'),\n",
       "   ('nt', 'has small brown body and lives in the treetops'),\n",
       "   ('dt', '14/Feb/2005'),\n",
       "   ('ex', 'Korauru ira vavo isio toupareveira vegoaro.'),\n",
       "   ('xp', 'Palai i save istap long bus.'),\n",
       "   ('xe', 'The ??? lizard lives in the bush.')]),\n",
       " ('korauvira',\n",
       "  [('rt', 'korau'),\n",
       "   ('ps', 'ADV'),\n",
       "   ('pt', 'MANNER'),\n",
       "   ('ge', 'unobstructed'),\n",
       "   ('tkp', 'olsem klia'),\n",
       "   ('dt', '29/May/2005'),\n",
       "   ('cmt', 'What is aue doing in the first example?'),\n",
       "   ('ex', 'Kovauvira vurapi vavoiso uva viaei riapu rukutavai.'),\n",
       "   ('xp', 'Em luk klia lang nogat kaut.'),\n",
       "   ('xe', 'It looks clear and ???.'),\n",
       "   ('ex', 'Toki korauvira rutu kareke.'),\n",
       "   ('xp', 'Bagana i klia tru.'),\n",
       "   ('xe', 'Mt. Balbi can be clearly seen.'),\n",
       "   ('ex', 'Korauvira toupai aue evaoa.'),\n",
       "   ('xp', 'Diwais em i stap long ples klia.'),\n",
       "   ('xe', 'The trees are in the clearing.'),\n",
       "   ('ex', 'Ezra korauvira rutu toreparoi.'),\n",
       "   ('xp', 'Ezra i sanap long ples klia.'),\n",
       "   ('xe', 'Ezra is standing up in the clearing.')]),\n",
       " ('korea',\n",
       "  [('ps', 'N'),\n",
       "   ('pt', 'NT'),\n",
       "   ('ge', 'waddle of rooster or hen'),\n",
       "   ('tkp', '???'),\n",
       "   ('dt', '29/May/2005'),\n",
       "   ('ex', 'Korea oa kokai-ia toupaiveira.'),\n",
       "   ('xp', 'Buk we ol kaikai i save istap long kakaruk.'),\n",
       "   ('xe', '???')]),\n",
       " ('korekare',\n",
       "  [('ps', 'N'),\n",
       "   ('pt', '???'),\n",
       "   ('ge', 'animals'),\n",
       "   ('tkp', 'ol animal'),\n",
       "   ('cmt',\n",
       "    'Does <kore> appear by itself, without the free pluralizer <kare>? This appears to be the generic term for all fauna. Double-check what is applies to.'),\n",
       "   ('dt', '22/Jan/2007')]),\n",
       " ('Korere',\n",
       "  [('ps', 'N'),\n",
       "   ('pt', 'PN'),\n",
       "   ('ge', 'Korean'),\n",
       "   ('tkp', 'bilong Korea'),\n",
       "   ('dt', '02/Dec/2004'),\n",
       "   ('ex', 'korerepairara'),\n",
       "   ('xp', 'pipol bilong Korea'),\n",
       "   ('xe', 'Koreans')]),\n",
       " ('korereto',\n",
       "  [('ps', 'N'),\n",
       "   ('pt', 'MASC'),\n",
       "   ('ge', 'type of lizard'),\n",
       "   ('tkp', '???'),\n",
       "   ('nt', 'small with ridge down the back, lives in sago palms and coconut'),\n",
       "   ('sf', 'FAUNA'),\n",
       "   ('dt', '02/Dec/2004'),\n",
       "   ('ex',\n",
       "    'Korereto koriava rera vararoia vo tou pareveira tetevu guruvaro ova vo opita raoroia.'),\n",
       "   ('xp',\n",
       "    'Korereto em i got ol makmak long body blong en em i save i stap long han blong sago na coconut lip.'),\n",
       "   ('xe',\n",
       "    'The koreto lizard has got a mark on his body and he is usually on sago palms or coconut leaves.'),\n",
       "   ('ex',\n",
       "    'Korereto koripato ira vo toupareveira tetevu guruva roia, tavaravira kou koupaoro.'),\n",
       "   ('xp',\n",
       "    'Palai i gat makmak na i save istap long ol lip saksak, na i save karim kiau dabol.'),\n",
       "   ('xe', '???')]),\n",
       " ('kori',\n",
       "  [('ps', 'V'),\n",
       "   ('pt', 'B'),\n",
       "   ('ge', 'mark'),\n",
       "   ('eng', 'mark'),\n",
       "   ('eng', 'weave with design'),\n",
       "   ('eng', 'write'),\n",
       "   ('tkp', 'rait makim'),\n",
       "   ('arg', '???'),\n",
       "   ('vx', '???'),\n",
       "   ('cmt',\n",
       "    \"Need more examples, probably can be found in corpus. What's with last example? Can <kori> also mean `cut'?\"),\n",
       "   ('dt', '10/Jan/2007'),\n",
       "   ('ex', 'Takekoriiva.'),\n",
       "   ('xp', '???'),\n",
       "   ('xe', 'They wove the bamboo with a design.'),\n",
       "   ('ex', 'Avaisisi koripava tururevoi takei kepa-ia.'),\n",
       "   ('xp', '???'),\n",
       "   ('xe', 'Avaisisi sews a patterned design on the house walls.'),\n",
       "   ('ex', 'Koue korivo oira siarearo verasia uva oira orivo.'),\n",
       "   ('xp',\n",
       "    'Ol i bin katim pik na ol i rausim bel bilong em na bihain ol i kukim pik.'),\n",
       "   ('xe', 'They ??? the pig, removing its guts, and they cooked it.')]),\n",
       " ('koria',\n",
       "  [('rt', 'kori'),\n",
       "   ('ps', 'N'),\n",
       "   ('pt', 'NT'),\n",
       "   ('ge', 'writing'),\n",
       "   ('ge', 'markings'),\n",
       "   ('ge', 'design'),\n",
       "   ('tkp', 'makmak raft'),\n",
       "   ('dt', '14/Feb/2005'),\n",
       "   ('ex', 'Avaisisi koria purarevoi kepa-ia.'),\n",
       "   ('xp', 'Avaisisi i wokim ol makmak long haus.'),\n",
       "   ('xe', 'Avaisisi is putting markings on the house.')]),\n",
       " ('Koribori',\n",
       "  [('ps', 'N'),\n",
       "   ('pt', 'PN'),\n",
       "   ('ge', 'village name'),\n",
       "   ('tkp', 'ples nem'),\n",
       "   ('dx', 'Aita'),\n",
       "   ('dt', '14/Feb/2005'),\n",
       "   ('ex', 'Uruia vaisiaro vao Korvore eisi Siteamasi-ia ruvaraia.'),\n",
       "   ('xp', 'Nem bilong ples korobore klostu long siteamasi.'),\n",
       "   ('xe', 'The village named Koribori is close to Siteamasi.')]),\n",
       " ('korikori',\n",
       "  [('rt', 'kori'),\n",
       "   ('ps', '???'),\n",
       "   ('ge', 'marking'),\n",
       "   ('tkp', 'makmak'),\n",
       "   ('eng', 'writing'),\n",
       "   ('eng', 'markings'),\n",
       "   ('eng', 'design'),\n",
       "   ('dt', '14/May/2005')]),\n",
       " ('korikoripava',\n",
       "  [('rt', 'korikori'),\n",
       "   ('ps', 'N'),\n",
       "   ('pt', 'FEM'),\n",
       "   ('ge', 'snake with marks on its back'),\n",
       "   ('ge', 'Upe hat with designs'),\n",
       "   ('tkp', 'snek i gat makmak'),\n",
       "   ('tkp', 'upe hat'),\n",
       "   ('cmt', 'Double-check translation'),\n",
       "   ('dt', '14/Feb/2005'),\n",
       "   ('ex', 'Upeva korikoripava.'),\n",
       "   ('xp', 'Upe i gat ol makmak.'),\n",
       "   ('xe', 'The Upe is patterned.')]),\n",
       " ('korita',\n",
       "  [('ps', 'V'),\n",
       "   ('pt', 'B'),\n",
       "   ('ge', 'carve'),\n",
       "   ('tkp', '???'),\n",
       "   ('ge', 'carve'),\n",
       "   ('ge', 'dissect'),\n",
       "   ('ge', 'cut up'),\n",
       "   ('nt', 'applies to meat'),\n",
       "   ('arg', 'O'),\n",
       "   ('vx', '2'),\n",
       "   ('dt', '03/Jul/2005'),\n",
       "   ('ex', 'Oire voava rera koritaive rera aiosia.'),\n",
       "   ('xp', '???'),\n",
       "   ('xe', 'Then they would cut him up to eat him.')]),\n",
       " ('korita',\n",
       "  [('ps', 'N'),\n",
       "   ('pt', '???'),\n",
       "   ('ge', 'cutlet?'),\n",
       "   ('tkp', '???'),\n",
       "   ('dt', '13/Feb/2005'),\n",
       "   ('ex', 'Jonatan koie korita kuvupare aue-ia veeta.'),\n",
       "   ('xp', 'Jonatan i pulamapim pik ol i katim pinis long ol mambu.'),\n",
       "   ('xe', 'Jonathan filled the bamboo with pig cutlets.')]),\n",
       " ('koriteira',\n",
       "  [('ps', 'N'),\n",
       "   ('pt', '???'),\n",
       "   ('ge', 'container'),\n",
       "   ('tkp', 'kontaina'),\n",
       "   ('nt', 'Tok Pisin loan'),\n",
       "   ('dt', '23/Jul/2004')]),\n",
       " ('koro',\n",
       "  [('ps', 'V'),\n",
       "   ('pt', 'A'),\n",
       "   ('ge', 'blinded'),\n",
       "   ('ge', 'go inside the eye'),\n",
       "   ('tkp', 'sut i go long ai rop'),\n",
       "   ('cmt',\n",
       "    'Check semantics. How do you specify what went in the eye? Can you say I was blinded by an insect in my eye.'),\n",
       "   ('dt', '22/Nov/2005'),\n",
       "   ('vx', '???'),\n",
       "   ('cmt', 'Check original -- koroai or kororai?'),\n",
       "   ('ex', 'Viapau vearoviva vurapaa uvare korotoae ragai.'),\n",
       "   ('xp', 'Mi no lukluk gut bikos mi gat samting i stap long ei.'),\n",
       "   ('xe', \"I can't see well because I've got something in my eye.\"),\n",
       "   ('ex', 'Viapau vearovira vurapaa uvare koroai ragai osireiaro-ia.'),\n",
       "   ('xp', 'Mi no lukluk gut bikos i gat samting long ai bilong mi.'),\n",
       "   ('xe', \"I can't see well because I'm blind.\")]),\n",
       " ('kororo',\n",
       "  [('ps', 'N'),\n",
       "   ('pt', '???'),\n",
       "   ('ge', 'bird'),\n",
       "   ('tkp', 'pisin'),\n",
       "   ('eng', 'Papuan Frogmouth (Podargus papuensis)'),\n",
       "   ('dt', '12/Jul/2004')]),\n",
       " ('kororo',\n",
       "  [('ps', 'N'),\n",
       "   ('pt', 'NT'),\n",
       "   ('cl', 'isi'),\n",
       "   ('ge', 'ball'),\n",
       "   ('ge', 'round'),\n",
       "   ('ge', 'sphere'),\n",
       "   ('tkp', 'bol'),\n",
       "   ('tkp', 'raunpela ston'),\n",
       "   ('dt', '13/Nov/2005'),\n",
       "   ('ex', 'Ipura kororoisi rutu-ia avekeisi kokioto ritarevoi porokoa-ia.'),\n",
       "   ('xp', 'Ipura em i sutim pisin long raunpela ston stret long katapila.'),\n",
       "   ('xe', '???')]),\n",
       " ('kororoisivira',\n",
       "  [('rt', 'kororoisi'),\n",
       "   ('ps', 'ADV'),\n",
       "   ('pt', 'MANNER'),\n",
       "   ('ge', 'round'),\n",
       "   ('ge', 'spherical'),\n",
       "   ('ge', 'ball-like'),\n",
       "   ('tkp', 'bol'),\n",
       "   ('tkp', 'raunpela'),\n",
       "   ('dt', '07/Feb/2005'),\n",
       "   ('ex', 'Opo kuio kororoisivira toupaivo.'),\n",
       "   ('xp', 'Taro em i raunpela.'),\n",
       "   ('xe', 'Taro is round.')]),\n",
       " ('kororovi',\n",
       "  [('rt', 'kororo'),\n",
       "   ('ps', 'N'),\n",
       "   ('pt', 'NT'),\n",
       "   ('ge', 'circle'),\n",
       "   ('tkp', 'raunpela lain'),\n",
       "   ('dt', '13/Feb/2005')]),\n",
       " ('kororovivira',\n",
       "  [('rt', 'kororovi'),\n",
       "   ('ps', 'ADV'),\n",
       "   ('pt', 'MANNER'),\n",
       "   ('ge', 'circular'),\n",
       "   ('tkp', 'olsem raunpela'),\n",
       "   ('dt', '13/Feb/2005'),\n",
       "   ('ex', 'Kororovivira raga opo purapae riakora.'),\n",
       "   ('xp', 'Ol meri i wok long wokim ol raunpela sikon.'),\n",
       "   ('xe', 'The women make only scones (literally, round taro/bread).'),\n",
       "   ('ex', 'Kororovivira opo isiro puraevo Vitera.'),\n",
       "   ('xp', 'Vitera i wokim ol raunpela sikon.'),\n",
       "   ('xe', 'Vitera made a scone (literally, round taro/bread) .')]),\n",
       " ('kororu',\n",
       "  [('ps', 'V'),\n",
       "   ('pt', 'A'),\n",
       "   ('ge', 'endangered'),\n",
       "   ('ge', 'near death'),\n",
       "   ('tkp', 'i laik dai'),\n",
       "   ('dcsv', 'true'),\n",
       "   ('vx', '???'),\n",
       "   ('cmt', 'Does this mean close or close to death? Huh?'),\n",
       "   ('dt', '22/Nov/2005'),\n",
       "   ('ex', 'Kororu Sera ei kororu avia ra kopia.'),\n",
       "   ('xp', 'Liklik taim tasol na Sera bai dai.'),\n",
       "   ('xe', 'Sera will die soon.'),\n",
       "   ('ex', 'Kororu pita ei kororu avia ra kopiro.'),\n",
       "   ('xp', 'Liklik taim tasol na Pita bai dai.'),\n",
       "   ('xe', 'Peter will die soon.'),\n",
       "   ('ex', 'Pita epao kororua via ra kopiiro.'),\n",
       "   ('xp', 'Pita i stap long liklik hap tasol na bai em i dai.'),\n",
       "   ('xe', '???')]),\n",
       " ('kororupie',\n",
       "  [('rt', 'kororu'),\n",
       "   ('ps', 'V'),\n",
       "   ('pt', 'B'),\n",
       "   ('ge', 'stranded by flood'),\n",
       "   ('tkp', 'wara i pasim em'),\n",
       "   ('arg', 'O'),\n",
       "   ('vx', '2'),\n",
       "   ('dt', '08/Jun/2005'),\n",
       "   ('ex', 'Sera kororupievo pirutuva uva viapau kareoe.'),\n",
       "   ('xp', 'Wara i tait na i pasim Sera long sait na em i no kam.'),\n",
       "   ('xe', \"The flood stranded Sera and she didn't come.\"),\n",
       "   ('ex', 'Kororupie pirutuva igei/ragai/visii/vei kororupie.'),\n",
       "   ('xp', 'Yu mi napa go long peles because taiet em pasim yu.'),\n",
       "   ('xe', '???'),\n",
       "   ('ex', 'Voi kareapa eisi wakunai voea kororupie pirutuva.'),\n",
       "   ('xp', '???'),\n",
       "   ('xe', '???')]),\n",
       " ('koroto',\n",
       "  [('ps', 'V'),\n",
       "   ('pt', 'B'),\n",
       "   ('ge', 'meet together'),\n",
       "   ('tkp', 'bung'),\n",
       "   ('cm', '-re'),\n",
       "   ('arg', 'OBL'),\n",
       "   ('vx', '2'),\n",
       "   ('dt', '08/Jun/2005'),\n",
       "   ('ex', 'John, Pita-re korotosia ira karepa eisi-va Wakunai.'),\n",
       "   ('xp', 'John yu go na bungim Pita em i kam long Wakunai.'),\n",
       "   ('xe', \"John, you go meet Peter, he's coming from Wakunai.\"),\n",
       "   ('ex', 'Vii korotopari Sera-re.'),\n",
       "   ('xp', 'Yu laik bungim Sera.'),\n",
       "   ('xe', \"You're going to meet with Sera.\"),\n",
       "   ('ex', 'Ragai avaparai Mak-re korotosia eisi raivaro.'),\n",
       "   ('xp', 'Mi go bungim Mak long rot.'),\n",
       "   ('xe', \"I'm going to meet Mark on the road.\")]),\n",
       " ('koroviri',\n",
       "  [('ps', 'V'),\n",
       "   ('pt', 'B'),\n",
       "   ('ge', 'braid'),\n",
       "   ('ge', 'plait'),\n",
       "   ('ge', 'twist together'),\n",
       "   ('tkp', 'pas wantaim'),\n",
       "   ('arg', 'O'),\n",
       "   ('vx', '2'),\n",
       "   ('dt', '08/Jun/2005'),\n",
       "   ('cmt', 'Double-check second sentence.'),\n",
       "   ('ex', 'Irorio koroviripasivoi.'),\n",
       "   ('xp', '???'),\n",
       "   ('xe', 'The two men are braiding rope.'),\n",
       "   ('ex', 'Mata koroviri purapae kuvera ua purasia.'),\n",
       "   ('xp', 'Mata i pasim tupela rop bilong wokim ubian.'),\n",
       "   ('xe', 'Mata ???.')]),\n",
       " ('korovo',\n",
       "  [('ps', 'N'),\n",
       "   ('pt', '???'),\n",
       "   ('ge', 'oil'),\n",
       "   ('ge', 'lubricate'),\n",
       "   ('tkp', 'welim'),\n",
       "   ('cmt', \"What's the gender?\"),\n",
       "   ('dt', '07/Sep/2006'),\n",
       "   ('ex', 'Korovo opita korovo isipava varaua isipasia.'),\n",
       "   ('xp', 'Oil blong kokonas blong napim long body.'),\n",
       "   ('xe', 'Coconut oil ???.'),\n",
       "   ('ex', 'Korovo varaua isipava aue iava opita.'),\n",
       "   ('xp', 'Oil bilong rapim long skin, na ol i ave wokim long kokonas.'),\n",
       "   ('xe', '???')]),\n",
       " ('koru',\n",
       "  [('ps', 'V'),\n",
       "   ('pt', 'B'),\n",
       "   ('ge', 'make return'),\n",
       "   ('tkp', 'bekim'),\n",
       "   ('dcsv', 'true'),\n",
       "   ('cmt', 'Not clear on meaning--double check vowel length'),\n",
       "   ('dt', '19/Mar/2006'),\n",
       "   ('ex',\n",
       "    'Jon-re korusia opeita eva oupare/pitare korusa opeita avaparo skulsa.'),\n",
       "   ('xp', 'Tokim John no kan go/tokim pita em/noken go long skul.'),\n",
       "   ('xe', '???'),\n",
       "   ('ex',\n",
       "    'Kokusia kokoto rekuo kokusa uriou vorio avivikepaoro kokusia uriou.'),\n",
       "   ('xp', 'Bukim sikul na yu bowim head blong yu.'),\n",
       "   ('xe', '???'),\n",
       "   ('ex', 'Sipito igei-re koru kovoarapa.'),\n",
       "   ('xp', 'Chief i tokim mipela long noken go wok.'),\n",
       "   ('xe', '???'),\n",
       "   ('ex', 'Fidelis korupare Ata teapi avaro eisi-re uukova uvare pirutuoe.'),\n",
       "   ('xp', 'Fidelis Aata i stopim nogut em i go long wara i tait.'),\n",
       "   ('xe',\n",
       "    'Aata stopped Fidelis from going to the water because it was high tide.')]),\n",
       " ('Koruko',\n",
       "  [('ps', 'N'),\n",
       "   ('pt', 'PN'),\n",
       "   ('ge', 'village name'),\n",
       "   ('tkp', 'ples nem'),\n",
       "   ('sa', 'Sirioripaia'),\n",
       "   ('dx', 'Pipipaia'),\n",
       "   ('dt', '13/Feb/2005'),\n",
       "   ('ex', 'Oropeara eisi-va urioroi Koruko.'),\n",
       "   ('xp', 'Oropeara kam long Koruko.'),\n",
       "   ('xe', 'Oropeara comes from Koruko.')]),\n",
       " ('korukoru',\n",
       "  [('rt', 'koru'),\n",
       "   ('rdp', 'full'),\n",
       "   ('ps', 'V'),\n",
       "   ('pt', 'A'),\n",
       "   ('ge', 'block'),\n",
       "   ('ge', 'obstruct'),\n",
       "   ('eng', 'block'),\n",
       "   ('eng', 'obstruct'),\n",
       "   ('eng', 'hinder'),\n",
       "   ('eng', 'deter'),\n",
       "   ('tkp', '???'),\n",
       "   ('vx', '2'),\n",
       "   ('arg', 'OBL'),\n",
       "   ('cm', '-re'),\n",
       "   ('dt', '17/Jul/2005'),\n",
       "   ('ex', 'Uva ragai-re korukoruragaparoepa.'),\n",
       "   ('xp', '???'),\n",
       "   ('xe', 'He tried to hinder me, but in vain.'),\n",
       "   ('ex', 'Jemis-re korukoruparoe aiteto, ovusia uturoe.'),\n",
       "   ('xp', 'Papa i rausim Jemis, tasol em i go bihain.'),\n",
       "   ('xe', 'Dad blocked Jemis but he followed.')]),\n",
       " ('korukorupato',\n",
       "  [('rt', 'korukoru'),\n",
       "   ('ps', 'N'),\n",
       "   ('pt', 'HUM'),\n",
       "   ('ge', 'interloper'),\n",
       "   ('eng', 'interloper'),\n",
       "   ('eng', 'intermediary'),\n",
       "   ('tkp', 'man bilong stopim'),\n",
       "   ('avm', 'pa_required'),\n",
       "   ('dt', '02/Sep/2005')]),\n",
       " ('koruo',\n",
       "  [('ps', '???'),\n",
       "   ('ge', 'young'),\n",
       "   ('tkp', 'yangpela'),\n",
       "   ('cmt', 'No examples'),\n",
       "   ('dt', '01/Jun/2005')]),\n",
       " ('koruoto',\n",
       "  [('rt', 'koruo'),\n",
       "   ('ps', 'N'),\n",
       "   ('pt', 'HUM'),\n",
       "   ('ge', 'young person'),\n",
       "   ('tkp', 'yangpela man'),\n",
       "   ('dt', '13/Feb/2005'),\n",
       "   ('ex', 'Koueto koruoto.'),\n",
       "   ('xp', 'Yangpela pig.'),\n",
       "   ('xe', '???'),\n",
       "   ('ex', 'Viia koruoto viovokoto.'),\n",
       "   ('xp', 'Yu yangpela man.'),\n",
       "   ('xe', \"You're a young man.\"),\n",
       "   ('ex', 'Koruoto roia viovokoto oirato.'),\n",
       "   ('xp', 'Boi em i yangpela tasol.'),\n",
       "   ('xe', '???')]),\n",
       " ('koruou',\n",
       "  [('ps', 'V'),\n",
       "   ('pt', 'A'),\n",
       "   ('ge', 'sacrifice'),\n",
       "   ('tkp', 'ofa'),\n",
       "   ('cm', '-pa'),\n",
       "   ('vx', '???'),\n",
       "   ('arg', 'OBL'),\n",
       "   ('cmt', 'Unclear whether the non-sub args are subcategorized...'),\n",
       "   ('dt', '04/Dec/2006'),\n",
       "   ('ex', 'Tuariripa irara oisoa tugara kare-pa koruoupaave aue-ia koie.'),\n",
       "   ('xp', '???'),\n",
       "   ('xe',\n",
       "    'People of long ago would always sacrifice to the bush spirits using.'),\n",
       "   ('ex', 'Tuariripairara oisioa koruoupave aue-ia koie tugara kare-pa.'),\n",
       "   ('xp',\n",
       "    'Ol man bilong bipo ol i save givim pik long ol masalai bilong bus.'),\n",
       "   ('xe', 'The ancestors always sacrified pigs to the spirits.')]),\n",
       " ('koruoua',\n",
       "  [('rt', 'koruou'),\n",
       "   ('ps', 'N'),\n",
       "   ('pt', 'NT'),\n",
       "   ('ge', 'sacrifice'),\n",
       "   ('tkp', 'ofa'),\n",
       "   ('dt', '13/Feb/2005'),\n",
       "   ('ex', 'Koruoua purasia avapaviei vavo tugaratoa-pa.'),\n",
       "   ('xp', 'Bai yumi go givim kaikai long masalai.'),\n",
       "   ('xe', \"We're going to make a sacrifice to the spirits.\"),\n",
       "   ('ex', 'Koruoua purapai vavo pugara.'),\n",
       "   ('xp', 'Sacrifice long ol bush spirit.'),\n",
       "   ('xe', '???')]),\n",
       " ('koruovira',\n",
       "  [('rt', 'koruo'),\n",
       "   ('ps', 'ADV'),\n",
       "   ('pt', 'MANNER'),\n",
       "   ('ge', 'young'),\n",
       "   ('tkp', 'yangpela'),\n",
       "   ('dt', '13/Feb/2005'),\n",
       "   ('ex', 'Koruovira toupai koie kare.'),\n",
       "   ('xp', 'Ol pik ol i stap yangpela.'),\n",
       "   ('xe', 'The pigs are young.')]),\n",
       " ('korupie',\n",
       "  [('rt', 'koru'),\n",
       "   ('ps', 'V'),\n",
       "   ('pt', 'B'),\n",
       "   ('ge', 'take outside'),\n",
       "   ('tkp', 'i kam ausait'),\n",
       "   ('arg', 'O'),\n",
       "   ('vx', '2'),\n",
       "   ('dt', '08/Jun/2005'),\n",
       "   ('ex', 'Sigoa korupie kepa siovara iava.'),\n",
       "   ('xp', 'Yu kisim naip kam arasait long haus.'),\n",
       "   ('xe', 'Take the knife outside from the house.')]),\n",
       " ('korupievira',\n",
       "  [('rt', 'koru'),\n",
       "   ('ps', 'ADV'),\n",
       "   ('pt', 'MANNER'),\n",
       "   ('ge', 'whispered-like'),\n",
       "   ('tkp', '???'),\n",
       "   ('cmt', \"Check vowel length. Gloss and example don't match.\"),\n",
       "   ('dt', '13/Feb/2005'),\n",
       "   ('ex', 'Pitokava korupievira toupae.'),\n",
       "   ('xp', 'Sospen i stap arasait.'),\n",
       "   ('xe', 'The saucepan is ???.')]),\n",
       " ('kosi',\n",
       "  [('ps', 'V'),\n",
       "   ('pt', 'A'),\n",
       "   ('ge', 'exit'),\n",
       "   ('eng', 'go out'),\n",
       "   ('eng', 'exit'),\n",
       "   ('eng', 'come out'),\n",
       "   ('tkp', 'go autsait'),\n",
       "   ('tkp', 'kamaut'),\n",
       "   ('dcsv', 'true'),\n",
       "   ('sc', 'MOTION'),\n",
       "   ('vx', '1'),\n",
       "   ('cmt', 'Sentence fragment?'),\n",
       "   ('dt', '20/Nov/2005'),\n",
       "   ('ex', 'Kakau kosia vao vii vaaro.'),\n",
       "   ('xp', 'Hap bek kakau bilong yu.'),\n",
       "   ('xe', '???')]),\n",
       " ('kosikosi',\n",
       "  [('rt', 'kosi'),\n",
       "   ('ps', 'V'),\n",
       "   ('pt', 'B'),\n",
       "   ('ge', 'cut off sago palm leaves'),\n",
       "   ('tkp', 'katkatim lip bilong saksak'),\n",
       "   ('arg', 'O'),\n",
       "   ('vx', '2'),\n",
       "   ('dt', '10/Aug/2005'),\n",
       "   ('ex', 'Sipoia kosikosi.'),\n",
       "   ('xp', 'Katimkatim suger cane.'),\n",
       "   ('xe', 'Kat the sugarcane.'),\n",
       "   ('ex', 'Kokora, tetevu rao kosikosi.'),\n",
       "   ('xp', 'Kokora, yu kakatim han bilong saksak.'),\n",
       "   ('xe', 'Kokora, cut the sago branch.'),\n",
       "   ('ex',\n",
       "    'Ragai uviara rava opoara kosikosipavoi oisio ra vara kukuearo paua.'),\n",
       "   ('xp',\n",
       "    'Mi wok long katikatim ol taro long het bilong ol olsem bai mi pranim ol het bilong taro.'),\n",
       "   ('xe', '???')]),\n",
       " ('kosikosi',\n",
       "  [('rt', 'kosi'),\n",
       "   ('rdp', 'full'),\n",
       "   ('ps', 'V'),\n",
       "   ('pt', 'A'),\n",
       "   ('ge', 'exit'),\n",
       "   ('tkp', 'go autsait'),\n",
       "   ('tkp', 'kamaut'),\n",
       "   ('eng', 'come out'),\n",
       "   ('eng', 'exit'),\n",
       "   ('ge', 'gush out'),\n",
       "   ('tkp', 'kamkamaut strong'),\n",
       "   ('dcpv', 'true'),\n",
       "   ('vx', '1'),\n",
       "   ('sc', 'MOTION'),\n",
       "   ('cmt', 'Is this a full word or really a stem?'),\n",
       "   ('dt', '14/Nov/2005'),\n",
       "   ('ex', 'Kosikosipapiro ukoa vo tage tou.'),\n",
       "   ('xp', 'Kamkam out long dispela tager wara.'),\n",
       "   ('xe', '???'),\n",
       "   ('ex', 'Vukoa kosikosipapiro vavova pukuia.'),\n",
       "   ('xp', 'Wara em i kamkam out long dispela mauntem.'),\n",
       "   ('xe', 'Water is gushing out of this mountain.'),\n",
       "   ('ex', 'Ukovi vavo-va kosikosipapiroveira pukuia vituaro.'),\n",
       "   ('xp', 'Wara i save kam aut long as bilong dispela maunten.'),\n",
       "   ('xe', 'The river gushes out from the base of the mountain.'),\n",
       "   ('ex', 'Kakae vure kosikosipaviroi kepa sovara iava.'),\n",
       "   ('xp', 'Ol pikinini i kam autsait long haus na i go.'),\n",
       "   ('xe', 'The children have come outside of the house.')]),\n",
       " ('kosipa',\n",
       "  [('ps', 'V'),\n",
       "   ('pt', 'B'),\n",
       "   ('ge', '???'),\n",
       "   ('tkp', 'katim het bilong taro'),\n",
       "   ('vx', '2'),\n",
       "   ('arg', 'O'),\n",
       "   ('cmt',\n",
       "    'The meaning of \"earn money/painim moni\" is not recognized by informants. Can you have kosipapaavoi?'),\n",
       "   ('dt', '22/Nov/2005'),\n",
       "   ('ex', 'Varao rutu kosipaa vo raga.'),\n",
       "   ('xp', 'Bai mi hipim olgeta samting long hia.'),\n",
       "   ('xe', '???'),\n",
       "   ('ex', 'Ragai opo kosiparai opo kosipa-ia.'),\n",
       "   ('xp',\n",
       "    'Mi katim het bilong taro long samtin gbilong katim het bilong taro.'),\n",
       "   ('xe', '???')]),\n",
       " ('kosipato',\n",
       "  [('ps', 'N'),\n",
       "   ('pt', '???'),\n",
       "   ('ge', '???'),\n",
       "   ('tkp', '???'),\n",
       "   ('dt', '23/Nov/2004'),\n",
       "   ('ex', 'Opo kosipatoa akavi avakava iava rera akoroto.'),\n",
       "   ('xp', 'Sel bilong sol wara em bilong katim taro.'),\n",
       "   ('xe', '???')]),\n",
       " ('kosipie',\n",
       "  [('rt', 'kosi'),\n",
       "   ('ps', 'V'),\n",
       "   ('pt', 'B'),\n",
       "   ('ge', 'make exit'),\n",
       "   ('tkp', '???'),\n",
       "   ('arg', 'O'),\n",
       "   ('vx', '2'),\n",
       "   ('dt', '08/Jun/2005'),\n",
       "   ('ex', 'Oire avipe ra voava voea kosipieive ita aia voeava pupisia.'),\n",
       "   ('xp', '???'),\n",
       "   ('xe',\n",
       "    'Then when it was light they would bring them out again to singsing with.'),\n",
       "   ('ex', 'Aviipai ra voea kosipiepe voea-va pupisia.'),\n",
       "   ('xp',\n",
       "    'Taim i tulait bai yumi bringim ol i kam arasait, bai yumi singsing wantaim ol.'),\n",
       "   ('xe', \"When it's ??? we'll bring you ??? in order to sing with them.\")]),\n",
       " ('kosivago',\n",
       "  [('ps', 'N'),\n",
       "   ('pt', 'NT'),\n",
       "   ('ge', 'decorative shell'),\n",
       "   ('tkp', 'sel bilong bilas'),\n",
       "   ('nt', 'large flat type worn on neck as decoration'),\n",
       "   ('dt', '26/Jan/2005'),\n",
       "   ('ex',\n",
       "    'Kosivago asipava tuariripaira oisoa asipave kosivagoi avakavaio oiso kosiva puropaive oira kuripaori asipasa.'),\n",
       "   ('xp',\n",
       "    'Shel ol man blong bipo ol save putim long nek blong ol na biras long em ol i save kisim long sol wara.'),\n",
       "   ('xe',\n",
       "    'A shell that in the past people put on their neck and which ??? usually find in the ocean.'),\n",
       "   ('ex', 'Kosivaio pekeri oa oisioa kuripaive va-ia asiipasia.'),\n",
       "   ('xp', 'Sel ol i save skirapim bilong hangamapim long nek.'),\n",
       "   ('xe', '???')]),\n",
       " ('kosiviro',\n",
       "  [('ps', 'V'),\n",
       "   ('pt', 'A'),\n",
       "   ('ge', 'go out'),\n",
       "   ('ge', 'exit'),\n",
       "   ('tkp', 'aut'),\n",
       "   ('vx', '1'),\n",
       "   ('sc', 'MOTION'),\n",
       "   ('cmt', 'Is the viro necessary?'),\n",
       "   ('dt', '14/Nov/2005'),\n",
       "   ('ex', 'Vokiaro kosivirorae uva ovato kekeavo osa vokaparevo.'),\n",
       "   ('xp',\n",
       "    'Long nait mi kam ausait na mi lukim sotpela wailman taim em wokabaut.'),\n",
       "   ('xe', 'At night I went out and I saw a dwarf man as he walked around.'),\n",
       "   ('ex', 'Josep kosiviro kepa iava.'),\n",
       "   ('xp', 'Joseph em i go arasait long haus.'),\n",
       "   ('xe', '???')]),\n",
       " ('koto',\n",
       "  [('ps', 'V'),\n",
       "   ('pt', 'A'),\n",
       "   ('ge', 'hang'),\n",
       "   ('tkp', 'hangamap'),\n",
       "   ('vx', '1'),\n",
       "   ('dt', '01/Jun/2005'),\n",
       "   ('ex', 'Aatu kotivira kotopaoi uusipaoro.'),\n",
       "   ('xp', '???'),\n",
       "   ('xe', 'The flying fox hangs in a hanging position while sleeping.'),\n",
       "   ('ex', 'Aatu iria kotovira uusipaoveira.'),\n",
       "   ('xp', 'Bilak bokis i sae hangamap na slip.'),\n",
       "   ('xe', '???')]),\n",
       " ('kotokoto',\n",
       "  [('rt', 'koto'),\n",
       "   ('ps', 'N'),\n",
       "   ('pt', 'NT'),\n",
       "   ('ge', 'cargo'),\n",
       "   ('ge', 'supplies'),\n",
       "   ('tkp', 'kago'),\n",
       "   ('dt', '02/Dec/2004'),\n",
       "   ('ex', 'Varao voriri kotokotoara.'),\n",
       "   ('xp', 'Yu buy ol dispela cargo.'),\n",
       "   ('xe', 'You buy these supplies.'),\n",
       "   ('ex', 'Rari kotokoto ousia avaroe eisi Buka, aio kitupa kepa iare.'),\n",
       "   ('xp', 'Rari em i go kisim kago long Buka i kam long sitoa.'),\n",
       "   ('xe', '???')]),\n",
       " ('kotokotoara',\n",
       "  [('rt', 'kotokoto'),\n",
       "   ('ps', 'N'),\n",
       "   ('pt', 'NT'),\n",
       "   ('ge', 'cargo'),\n",
       "   ('ge', 'supplies'),\n",
       "   ('tkp', 'kago'),\n",
       "   ('dt', '03/Dec/2004'),\n",
       "   ('ex', 'Varao voriri kotokotoara.'),\n",
       "   ('xp', 'Yu baiim ol dispela cago.'),\n",
       "   ('xe', 'You buy these supplies.'),\n",
       "   ('ex', 'Kotokotoara uriopai uvuoa-ia.'),\n",
       "   ('xp', 'Ol kago bai i kam long sip.'),\n",
       "   ('xe', '???')]),\n",
       " ('kotopa',\n",
       "  [('rt', 'koto'),\n",
       "   ('ps', 'N'),\n",
       "   ('pt', 'NT'),\n",
       "   ('ge', 'fishhook'),\n",
       "   ('ge', 'hook'),\n",
       "   ('ge', 'hanger'),\n",
       "   ('tkp', 'huk'),\n",
       "   ('cmt', 'Sentence fragment?'),\n",
       "   ('dt', '02/Dec/2004'),\n",
       "   ('ex', 'Pokokoa eva pitoka kotopa.'),\n",
       "   ('xp', 'Huk bilong hangamapim sospen.'),\n",
       "   ('xe', '???')]),\n",
       " ('kotopa',\n",
       "  [('rt', 'koto'),\n",
       "   ('ps', 'N'),\n",
       "   ('pt', 'LOC'),\n",
       "   ('ge', 'hanging from'),\n",
       "   ('tkp', '???'),\n",
       "   ('dt', '07/Feb/2005')]),\n",
       " ('kotovira',\n",
       "  [('rt', 'koto'),\n",
       "   ('ps', 'ADV'),\n",
       "   ('pt', 'MANNER'),\n",
       "   ('ge', 'hanging'),\n",
       "   ('tkp', '???'),\n",
       "   ('dt', '03/Dec/2004'),\n",
       "   ('ex', 'Atuu kotovira uusipaoi.'),\n",
       "   ('xp', 'Fly bokis em i slip hangamap.'),\n",
       "   ('xe', 'The flying fox sleeps hanging.'),\n",
       "   ('ex', 'Kotovira uusiu.'),\n",
       "   ('xp', 'Yu slip hangamap.'),\n",
       "   ('xe', 'You sleep hanging up.'),\n",
       "   ('ex', 'Kotovira uusipaoi aatu.'),\n",
       "   ('xp', 'Bilak bokis i hangamap na slip.'),\n",
       "   ('xe', '???')]),\n",
       " ('kotu',\n",
       "  [('ps', 'V'),\n",
       "   ('pt', 'B'),\n",
       "   ('ge', 'bite'),\n",
       "   ('tkp', 'kaikai'),\n",
       "   ('arg', 'O'),\n",
       "   ('vx', '2'),\n",
       "   ('dt', '08/Jun/2005'),\n",
       "   ('ex', 'Aakova aioa kotupaevoi.'),\n",
       "   ('xp', 'Mama em i baitim kaikai.'),\n",
       "   ('xe', 'The mother is biting the food.'),\n",
       "   ('ex', 'Sera opoa kotupaevoi kakaetoa-pa.'),\n",
       "   ('xp', 'Sera i wok long kaikai na givim ol liklik hap long pikinini.'),\n",
       "   ('xe', 'Sera is biting the food for the child.')]),\n",
       " ('kotukotu',\n",
       "  [('rt', 'kotu'),\n",
       "   ('ps', 'V'),\n",
       "   ('pt', 'B'),\n",
       "   ('ge', 'gnash teeth'),\n",
       "   ('ge', 'grind teeth together'),\n",
       "   ('tkp', '???'),\n",
       "   ('arg', 'O'),\n",
       "   ('vx', '2'),\n",
       "   ('dt', '08/Jun/2005'),\n",
       "   ('rdp', 'full'),\n",
       "   ('ex', 'Reuriara kuripare va kotukotu para???.'),\n",
       "   ('xp', 'Em mekim ol tit bilong em.'),\n",
       "   ('xe', '???'),\n",
       "   ('ex', 'Rupeiri ora reuriaro kotukotuparevoi.'),\n",
       "   ('xp', 'Rupeiri i wok long kaikaim ol titi bilong en.'),\n",
       "   ('xe', '???')]),\n",
       " ('kotupiua',\n",
       "  [('ps', 'N'),\n",
       "   ('pt', 'NT'),\n",
       "   ('ge', 'knee'),\n",
       "   ('tkp', 'skru bilong lek'),\n",
       "   ('dt', '03/Dec/2004'),\n",
       "   ('ex', 'Sara iava kotupiua upiapae.'),\n",
       "   ('xp', 'Skuru bilong Sara i wok long pen.'),\n",
       "   ('xe', \"Sera's knee hurts.\")]),\n",
       " ('koturu',\n",
       "  [('wf', 'koturua'),\n",
       "   ('rt', 'koturu'),\n",
       "   ('ps', 'N'),\n",
       "   ('pt', 'NT'),\n",
       "   ('ge', 'bark'),\n",
       "   ('tkp', '???'),\n",
       "   ('eng', 'tree bark'),\n",
       "   ('dt', '21/May/2005'),\n",
       "   ('ex', 'Evao koturu v??? oupaiveira kepa kovovopasia.'),\n",
       "   ('xp', 'Skili blong diwai ol i save kisim blong banisim house.'),\n",
       "   ('xe', '???'),\n",
       "   ('ex', 'Koturua siovaraia Kauasi tovareva Raupeto.'),\n",
       "   ('xp', 'Raupeto i bin palanim Kauasi long skin bilong diwai.'),\n",
       "   ('xe', 'Raupeto buried Kauasi inside tree bark.')]),\n",
       " ('kou',\n",
       "  [('ps', 'CLASS'),\n",
       "   ('ge', 'heap'),\n",
       "   ('tkp', 'hip'),\n",
       "   ('dt', '04/Sep/2005'),\n",
       "   ('ex', 'Tesi kokopa kouro tosievoi kepa iava.'),\n",
       "   ('xp', 'Tesi em i katim plenti bus long haus.'),\n",
       "   ('xe', '???')]),\n",
       " ('kou',\n",
       "  [('ps', 'V'),\n",
       "   ('pt', 'B'),\n",
       "   ('ge', 'lay egg'),\n",
       "   ('ge', 'defecate'),\n",
       "   ('tkp', '???'),\n",
       "   ('dcsv', '???'),\n",
       "   ('am', '???'),\n",
       "   ('arg', 'O'),\n",
       "   ('sc', 'EXCRETION'),\n",
       "   ('vx', '2'),\n",
       "   ('nt', 'defecate reading considered vulgar'),\n",
       "   ('dt', '08/Jun/2005'),\n",
       "   ('ex', 'Kokotu takura koupaoi.'),\n",
       "   ('xp', 'Kakaruk meri em i mekim ol kiau.'),\n",
       "   ('xe', 'Hens produce eggs.'),\n",
       "   ('ex', 'Ragai oiraro kokotu takura kou oi pekuri-ia.'),\n",
       "   ('xp', 'Kakaruk bilong mi i putim kiau long basket.'),\n",
       "   ('xe', '???')]),\n",
       " ('koue',\n",
       "  [('ps', 'N'),\n",
       "   ('pt', 'ANIM'),\n",
       "   ('ge', 'pig'),\n",
       "   ('tkp', 'pik'),\n",
       "   ('dt', '08/Dec/2005'),\n",
       "   ('ex', 'Ben oiraaro koue karuvera kovo aioevo.'),\n",
       "   ('xp', 'Pik bilong Ben i kaikaim gaden singapo.'),\n",
       "   ('xe', \"Ben's pig ate the ??? garden.\"),\n",
       "   ('ex', 'Koue tarasia avaae eisi vegoaro aiosia.'),\n",
       "   ('xp', 'Ol i go painim pik long bilong kaikai.'),\n",
       "   ('xe', '???')]),\n",
       " ('koue',\n",
       "  [('ps', 'V'),\n",
       "   ('pt', 'B'),\n",
       "   ('ge', 'collect pig to eat'),\n",
       "   ('tkp', 'kisim pik'),\n",
       "   ('vx', '???'),\n",
       "   ('arg', '???'),\n",
       "   ('cmt', 'Examples needed'),\n",
       "   ('dt', '08/Jun/2005')]),\n",
       " ('koui',\n",
       "  [('ps', '???'),\n",
       "   ('ge', 'selfish with food'),\n",
       "   ('tkp', 'no laik givim kaikai'),\n",
       "   ('dt', '08/Jun/2005'),\n",
       "   ('ex', 'Rakea koui aue-ia aio.'),\n",
       "   ('xp', 'Rake em i makau man long kaikai.'),\n",
       "   ('xe', '???')]),\n",
       " ('koukou',\n",
       "  [('ps', '???'),\n",
       "   ('ge', 'Chinese'),\n",
       "   ('tkp', 'saina'),\n",
       "   ('tkp', 'hongkong'),\n",
       "   ('dt', '26/Jan/2005'),\n",
       "   ('ex', 'Koukou oea katai pua-ia toupaiveira.'),\n",
       "   ('xp', 'Ol saina ol i save luk wankain.'),\n",
       "   ('xe', 'All Chinese look alike.')]),\n",
       " ('koukouo',\n",
       "  [('ps', 'V'),\n",
       "   ('pt', 'B'),\n",
       "   ('ge', 'laugh heartily at'),\n",
       "   ('tkp', 'lap long'),\n",
       "   ('nt', 'not the generic term'),\n",
       "   ('cmt', 'Check spelling.'),\n",
       "   ('sa', 'agesi'),\n",
       "   ('sc', '???'),\n",
       "   ('vx', '2'),\n",
       "   ('arg', 'O'),\n",
       "   ('dt', '08/Jun/2005'),\n",
       "   ('ex', 'Rapi, e ragai koukooparivoi?'),\n",
       "   ('xp', 'Rapi, yu lap long mi?'),\n",
       "   ('xe', 'Rapi, are you laughing at me?')]),\n",
       " ('koukouo',\n",
       "  [('ps', 'V'),\n",
       "   ('pt', 'A'),\n",
       "   ('ge', 'laugh heartily'),\n",
       "   ('tkp', 'lap'),\n",
       "   ('nt', 'not the generic term'),\n",
       "   ('cmt', 'Check spelling.'),\n",
       "   ('sa', 'agesi'),\n",
       "   ('sc', '???'),\n",
       "   ('vx', '1'),\n",
       "   ('dt', '01/Jun/2005'),\n",
       "   ('ex', 'Viovokoto koukouoparoi.'),\n",
       "   ('xp', '???'),\n",
       "   ('xe', 'The boy is laughing heartily.')]),\n",
       " ('kova',\n",
       "  [('ps', 'V'),\n",
       "   ('pt', 'A'),\n",
       "   ('ge', 'grow'),\n",
       "   ('eng', 'grow'),\n",
       "   ('eng', 'mature'),\n",
       "   ('tkp', 'kamap bikpela'),\n",
       "   ('vx', '1'),\n",
       "   ('sc', '???'),\n",
       "   ('dt', '10/Nov/2005'),\n",
       "   ('ex', 'Evaova kovae uuko ovi ruvara-ia.'),\n",
       "   ('xp', 'Diwai i bin kamap bikpela klostu long wara.'),\n",
       "   ('xe', 'The tree grew near the stream.'),\n",
       "   ('ex', 'Evaova kovae uukovi ruvaraia.'),\n",
       "   ('xp', 'Diwai i kru klostu long wara.'),\n",
       "   ('xe', '???'),\n",
       "   ('ex', 'Kasivari kovova rutu oia Ovoteivi.'),\n",
       "   ('xp', 'Ovoteivi em i meri bilong wok hat tru.'),\n",
       "   ('xe', 'Ovoteivi is a hard worker.')]),\n",
       " ('kovaaro',\n",
       "  [('rt', 'kova'),\n",
       "   ('ps', 'N'),\n",
       "   ('pt', 'NT'),\n",
       "   ('ge', 'growth of something'),\n",
       "   ('tkp', '???'),\n",
       "   ('dt', '03/Dec/2004'),\n",
       "   ('ex', 'Kakau isiro iava kovaara kaepiroi.'),\n",
       "   ('xp', 'Ol kru bilong kaukau i kamap.'),\n",
       "   ('xe', '???')]),\n",
       " ('kovaeto',\n",
       "  [('rt', 'kovae'),\n",
       "   ('ps', 'N'),\n",
       "   ('pt', 'MASC'),\n",
       "   ('ge', 'stocky fat man'),\n",
       "   ('tkp', '???'),\n",
       "   ('dt', '05/Feb/2005'),\n",
       "   ('ex', 'Kovaeto oirato ira viapau uvuipa ra kovopareve.'),\n",
       "   ('xp', 'Bikpela na patpela man i no inap long wok.'),\n",
       "   ('xe', \"A fat man, he can't work.\")]),\n",
       " ('kovaii',\n",
       "  [('ps', 'N'),\n",
       "   ('pt', 'NT'),\n",
       "   ('ge', 'taro with long root'),\n",
       "   ('tkp', 'longpela taro'),\n",
       "   ('pt', 'opo'),\n",
       "   ('cmt', 'Sentence fragment for ex.'),\n",
       "   ('dt', '12/Aug/2005'),\n",
       "   ('ex', 'Kovaii kuio aue opo.'),\n",
       "   ('xp', 'Longpela taro.'),\n",
       "   ('xe', '???')]),\n",
       " ('kovakovara',\n",
       "  [('rt', 'kova'),\n",
       "   ('ps', 'N'),\n",
       "   ('pt', 'NT'),\n",
       "   ('ge', 'shoots of plant'),\n",
       "   ('tkp', '???'),\n",
       "   ('cmt', 'Why is it plural with singular agreement?'),\n",
       "   ('dt', '03/Dec/2004'),\n",
       "   ('ex', 'Uutu kovo iava kovakovaara kaepiroi.'),\n",
       "   ('xp', 'Ol kru bilong gaden yam i sut i kam antap.'),\n",
       "   ('xe', '???')]),\n",
       " ('kovapato',\n",
       "  [('rt', 'kova'),\n",
       "   ('ps', 'N'),\n",
       "   ('pt', 'MASC'),\n",
       "   ('ge', 'stomach'),\n",
       "   ('tkp', 'bek bilong bel'),\n",
       "   ('dt', '03/Dec/2004'),\n",
       "   ('ex', 'Koue iava kovapato, uva aioara toupaiveira.'),\n",
       "   ('xp', 'Bel bilong pik we ol kaikai i save istap.'),\n",
       "   ('xe', '???')]),\n",
       " ('kovarato',\n",
       "  [('rt', 'kova'),\n",
       "   ('ps', 'N'),\n",
       "   ('pt', 'MASC'),\n",
       "   ('ge', 'shoots of plant or tree coming from where cut was made'),\n",
       "   ('ge', 'sprouts from cut'),\n",
       "   ('tkp', '???'),\n",
       "   ('nt', 'Plural is kovakovara.'),\n",
       "   ('dt', '03/Dec/2004'),\n",
       "   ('ex', 'Kasiava iava kovarato putepare eisi Ruruu.'),\n",
       "   ('xp', 'Han bilong diwai kanu i antap tru long Ruruu.'),\n",
       "   ('xe', '???')]),\n",
       " ('kovarua',\n",
       "  [('ps', 'N'),\n",
       "   ('pt', 'NT'),\n",
       "   ('ge', 'bushes'),\n",
       "   ('ge', 'foliage'),\n",
       "   ('tkp', 'hap bus'),\n",
       "   ('dt', '03/Dec/2004'),\n",
       "   ('ex', 'Kovaruara upiriko kovo ruuvo.'),\n",
       "   ('xp', 'Bus i karamapim gaden kaukau.'),\n",
       "   ('xe', '???')]),\n",
       " ('kovasi',\n",
       "  [('ps', 'V'),\n",
       "   ('pt', 'A'),\n",
       "   ('ge', 'pregnant'),\n",
       "   ('tkp', '???'),\n",
       "   ('nt', 'dog or pig only'),\n",
       "   ('sc', '???'),\n",
       "   ('vx', '1'),\n",
       "   ('dt', '01/Jun/2005'),\n",
       "   ('ex', 'Koie kovasioi iria kakae kavaupaoi rara.'),\n",
       "   ('xp', '???'),\n",
       "   ('xe', 'The pig is pregnant and she will farrow later.'),\n",
       "   ('ex', 'Koue kovasioi ra kakaekarevai kavaueve rara.'),\n",
       "   ('xp', 'Pik i gat bel nau, na bai em i bonim sampela pikinini pik.'),\n",
       "   ('xe',\n",
       "    'The pig is pregnant and will eventually give birth to some piglets.')]),\n",
       " ('kovata',\n",
       "  [('ps', 'V'),\n",
       "   ('pt', 'A'),\n",
       "   ('ge', 'thrilled'),\n",
       "   ('ge', 'happy'),\n",
       "   ('tkp', 'lap hepi'),\n",
       "   ('dt', '01/Jun/2005'),\n",
       "   ('cmt', 'Can you specify what one is happy about?'),\n",
       "   ('sc', 'EMOTION'),\n",
       "   ('vx', '1'),\n",
       "   ('ex', 'Kovatapau.'),\n",
       "   ('xp', 'Yu amamas tru.'),\n",
       "   ('xe', 'You are smiling.'),\n",
       "   ('ex', 'Pita kovatairaoparoi agesipaoro.'),\n",
       "   ('xp', 'Pita i amamas tru na em i lap.'),\n",
       "   ('xe', 'Pita is very happy and is laughing.'),\n",
       "   ('ex', 'Oirara kovatae rutu ovusia voea agesipieavo.'),\n",
       "   ('xp', 'Ol man i amamas tru taim mi mekim ol i lap.'),\n",
       "   ('xe', 'Everyone was thrilled because I made them laugh.')]),\n",
       " ('kovatavira',\n",
       "  [('rt', 'kovata'),\n",
       "   ('ps', 'ADV'),\n",
       "   ('pt', 'MANNER'),\n",
       "   ('ge', 'thrilled'),\n",
       "   ('ge', 'happy'),\n",
       "   ('tkp', 'amamas'),\n",
       "   ('dt', '03/Dec/2004'),\n",
       "   ('ex', 'Riakova kovatavira vurapae.'),\n",
       "   ('xp', '???'),\n",
       "   ('xe', 'The woman is looking on with a smile.'),\n",
       "   ('ex', 'Jois kovatavira rutu vurapae ragai-va.'),\n",
       "   ('xp', 'Jois i amamas tru na em i lukluk long mi.'),\n",
       "   ('xe', '???')]),\n",
       " ('kovato',\n",
       "  [('ps', 'N'),\n",
       "   ('pt', 'MASC'),\n",
       "   ('ge', 'type of banana'),\n",
       "   ('tkp', '???'),\n",
       "   ('nt', 'strong-smelling when ripe'),\n",
       "   ('pt', 'itoo'),\n",
       "   ('dt', '12/Aug/2005'),\n",
       "   ('ex', 'Kovato itoto ira vioroparoveira ra rera aiopaive.'),\n",
       "   ('xp', 'Banana i save mao na ol i sae kaikai.'),\n",
       "   ('xe', '???')]),\n",
       " ('kovauke',\n",
       "  [('ps', 'N'),\n",
       "   ('pt', 'FEM'),\n",
       "   ('ge', 'type of banana'),\n",
       "   ('tkp', '???'),\n",
       "   ('nt', 'short stubby eating type'),\n",
       "   ('pt', 'itoo'),\n",
       "   ('dt', '12/Aug/2005'),\n",
       "   ('ex', 'Kovauke iria vioropaoveira ra oira aiopaive.'),\n",
       "   ('xp', 'Banana i save mao na ol i save kaikai.'),\n",
       "   ('xe', '???')]),\n",
       " ('Kovava',\n",
       "  [('ps', 'N'),\n",
       "   ('pt', 'PN'),\n",
       "   ('ge', 'cave near Ibu'),\n",
       "   ('tkp', 'wanpela hol ston'),\n",
       "   ('dt', '03/Dec/2004'),\n",
       "   ('ex', 'Kovava kepa oa eisi toupaiveira Ibu-ia ruvaraia.'),\n",
       "   ('xp', 'Hol Kovava istap klostu long Ibu.'),\n",
       "   ('xe', '???')]),\n",
       " ('kove',\n",
       "  [('ps', 'V'),\n",
       "   ('pt', 'A'),\n",
       "   ('ge', 'fall'),\n",
       "   ('ge', 'drop'),\n",
       "   ('tkp', 'pundaun'),\n",
       "   ('vx', '1'),\n",
       "   ('sc', '???'),\n",
       "   ('nt', 'also used to describe laying eggs'),\n",
       "   ('dt', '08/Dec/2005'),\n",
       "   ('ex', 'Teapi ipau ra ora kepioro ita koveuvere vorevira.'),\n",
       "   ('xp', '???'),\n",
       "   ('xe', \"It wouldn't be good if you climbed up and fell down again.\"),\n",
       "   ('ex', 'Avaisisi koveroe rikui-ia vokiaro ravapaoro.'),\n",
       "   ('xp', 'Avaisisi em i pundaun long hul long nait taim em lukaut kapul.'),\n",
       "   ('xe', 'Avaisisi fell into the hole at night while searching for possums.'),\n",
       "   ('ex', 'Tavuteua viorooro kove.'),\n",
       "   ('xp', 'Mango i mau na em i pundaun.'),\n",
       "   ('xe', 'Fell down, being mature. (???)'),\n",
       "   ('ex', 'Erik aitearo koveroe kepa iava.'),\n",
       "   ('xp', 'Papa bilong Erik em i pundaun long haus.'),\n",
       "   ('xe', \"Eric's father fell down off the house.\")]),\n",
       " ('kove',\n",
       "  [('ps', 'V'),\n",
       "   ('pt', 'B'),\n",
       "   ('ge', 'fell'),\n",
       "   ('tkp', 'pundaunim'),\n",
       "   ('vx', '2'),\n",
       "   ('arg', 'O'),\n",
       "   ('cmt', \"What's the difference between transitive kove and kovepie?\"),\n",
       "   ('dt', '17/Oct/2005')]),\n",
       " ('kovea',\n",
       "  [('rt', 'kove'),\n",
       "   ('ps', 'N'),\n",
       "   ('pt', 'NT'),\n",
       "   ('ge', 'pocket'),\n",
       "   ('tkp', 'bak'),\n",
       "   ('dt', '03/Dec/2004'),\n",
       "   ('ex', 'Kovea-ia toupaivoi monia.'),\n",
       "   ('xp', 'Moni istap long poket.'),\n",
       "   ('xe', '???')]),\n",
       " ('kovekove',\n",
       "  [('rt', 'kove'),\n",
       "   ('ps', 'V'),\n",
       "   ('pt', 'A'),\n",
       "   ('ge', 'drip repeatedly'),\n",
       "   ('tkp', 'pundaun planti'),\n",
       "   ('vx', '1'),\n",
       "   ('sc', '???'),\n",
       "   ('dt', '07/Sep/2005'),\n",
       "   ('rdp', 'full'),\n",
       "   ('ex', 'Uva gauoviro oisiri kovekovepaepa kakate sovara-ia.'),\n",
       "   ('xp', '???'),\n",
       "   ('xe', 'The tears dripped into the bamboo tube.')]),\n",
       " ('koveoapa',\n",
       "  [('rt', 'kove'),\n",
       "   ('ps', '???'),\n",
       "   ('ge', 'kit bag'),\n",
       "   ('tkp', 'kikbek'),\n",
       "   ('cmt', 'Sentence fragment for ex. sentence.d'),\n",
       "   ('dt', '03/Dec/2004'),\n",
       "   ('ex', 'Koeoapa Susan varo.'),\n",
       "   ('xp', 'Bilum bilong Susan.'),\n",
       "   ('xe', '???')]),\n",
       " ('koveva',\n",
       "  [('rt', 'kove'),\n",
       "   ('ps', 'N'),\n",
       "   ('pt', 'NT'),\n",
       "   ('ge', 'sack'),\n",
       "   ('ge', 'string bag'),\n",
       "   ('tkp', 'bilum'),\n",
       "   ('tkp', 'bek'),\n",
       "   ('dt', '03/Dec/2004')]),\n",
       " ('Kovia',\n",
       "  [('ps', 'N'),\n",
       "   ('pt', 'PN'),\n",
       "   ('ge', 'Kovia'),\n",
       "   ('tkp', 'Kovia'),\n",
       "   ('dt', '26/Jan/2005'),\n",
       "   ('ex', 'Oirato vaisiaro Kovia.'),\n",
       "   ('xp', 'Nem bilong man em long Kovia.'),\n",
       "   ('xe', \"The man's name is Kovia.\")]),\n",
       " ('kovikoro',\n",
       "  [('ps', 'N'),\n",
       "   ('pt', 'FEM'),\n",
       "   ('ge', 'type of bush frog'),\n",
       "   ('tkp', '???'),\n",
       "   ('dt', '03/Dec/2004'),\n",
       "   ('ex', 'Kovikoro iria gaupaeveira ovusia vokipape.'),\n",
       "   ('xp', 'Em i wanpela kain rokrok i save krai taim i laik tudak.'),\n",
       "   ('xe', '???')]),\n",
       " ('kovire',\n",
       "  [('ps', '???'),\n",
       "   ('ge', 'whitewash'),\n",
       "   ('tkp', 'kambang'),\n",
       "   ('dt', '03/Dec/2004'),\n",
       "   ('ex', 'Kovirea rasia oa popotevira toupaiveira.'),\n",
       "   ('xp', 'Dispela em i waitpela giraun.'),\n",
       "   ('xe', '???')]),\n",
       " ('kovirea',\n",
       "  [('rt', 'kovire'),\n",
       "   ('ps', 'N'),\n",
       "   ('pt', 'NT'),\n",
       "   ('ge', 'whitewash'),\n",
       "   ('ge', 'white-colored earth'),\n",
       "   ('tkp', '???'),\n",
       "   ('nt',\n",
       "    \"White colored earth found near old Togarao one half hour's walk from ???\"),\n",
       "   ('dt', '26/Jan/2005')]),\n",
       " ('kovo',\n",
       "  [('ps', 'N'),\n",
       "   ('pt', 'NT'),\n",
       "   ('ge', 'garden'),\n",
       "   ('ge', 'work'),\n",
       "   ('tkp', 'gaden'),\n",
       "   ('tkp', 'wok'),\n",
       "   ('eng', 'garden'),\n",
       "   ('eng', 'work'),\n",
       "   ('dt', '19/May/2005'),\n",
       "   ('ex', 'Ragai kovopaavoi vo araisi kovo-ia.'),\n",
       "   ('xp', 'Mi wok long gaden rais.'),\n",
       "   ('xe', '???')]),\n",
       " ('kovo',\n",
       "  [('ps', 'V'),\n",
       "   ('pt', 'B'),\n",
       "   ('ge', 'work'),\n",
       "   ('tkp', 'wok'),\n",
       "   ('dcsv', 'true'),\n",
       "   ('vx', '1'),\n",
       "   ('cmt', 'Can this take an object? Need to check.'),\n",
       "   ('dt', '10/Nov/2005'),\n",
       "   ('ex', 'Ragai vo reoaro uvupaoro kovopareve.'),\n",
       "   ('xp', '???'),\n",
       "   ('xe', 'Hearing my talk (being obedient), he would be working.')]),\n",
       " ('kovo',\n",
       "  [('ps', 'CLASS'),\n",
       "   ('ge', 'garden'),\n",
       "   ('tkp', 'gaden'),\n",
       "   ('dt', '04/Sep/2005'),\n",
       "   ('ex', 'Aio kovoro tapo oisoa tekiive vosia kopiiro oirato.'),\n",
       "   ('xp', 'Taim man em i dai, ol i save bagarapim ol gaden kaikai bilong em.'),\n",
       "   ('xe',\n",
       "    'If a man would died, they would always destroy his gardens also.')]),\n",
       " ('kovoa',\n",
       "  [('rt', 'kovo'),\n",
       "   ('ps', 'N'),\n",
       "   ('pt', 'NT'),\n",
       "   ('ge', 'garden'),\n",
       "   ('ge', 'work'),\n",
       "   ('ge', 'week'),\n",
       "   ('ge', 'day'),\n",
       "   ('tkp', 'gaden'),\n",
       "   ('tkp', 'wok'),\n",
       "   ('tkp', 'wik'),\n",
       "   ('tkp', 'de'),\n",
       "   ('dt', '04/Sep/2005'),\n",
       "   ('ex', 'Kovoa eva Justin vo kovoaaro.'),\n",
       "   ('xp', 'Em gaden o wok bilong Justin.'),\n",
       "   ('xe', \"That's Justin's garden.\")]),\n",
       " ('kovokovo',\n",
       "  [('rt', 'kovo'),\n",
       "   ('ps', 'V'),\n",
       "   ('pt', 'B'),\n",
       "   ('ge', 'fence off'),\n",
       "   ('ge', 'surround'),\n",
       "   ('tkp', 'banisim'),\n",
       "   ('tkp', 'susap'),\n",
       "   ('arg', 'O'),\n",
       "   ('vx', '2'),\n",
       "   ('dt', '08/Jun/2005'),\n",
       "   ('ex', 'Oirato kepa kovokovoreva kasura-ia koie kare asavira.'),\n",
       "   ('xp', '???'),\n",
       "   ('xe', 'The man surrounded his house with a fence against (to keep out).'),\n",
       "   ('ex', 'Kokaipa icepa kovokovosia ra voa toupaive.'),\n",
       "   ('xp', 'Banisim house kakaruk bai ol i stap insait.'),\n",
       "   ('xe', '???'),\n",
       "   ('ex', 'Vao kepa kovokovosia uriou ari uteoparai.'),\n",
       "   ('xp', 'Yo kam banis haus em i kolor tumas.'),\n",
       "   ('xe', '???'),\n",
       "   ('ex', 'Oirara rutu kepa kovokovopaivoi sipito vo kepaaro.'),\n",
       "   ('xp', 'Olgeta man bai banisim haus bilong chief.'),\n",
       "   ('xe', 'Everyone is going to fence the house of the chief.')]),\n",
       " ('kovokovo',\n",
       "  [('rt', 'kovo'),\n",
       "   ('ps', 'V'),\n",
       "   ('pt', 'A'),\n",
       "   ('ge', 'play'),\n",
       "   ('eng', \"play Jew's Harp\"),\n",
       "   ('tkp', 'pilai chusap'),\n",
       "   ('vx', '1'),\n",
       "   ('dt', '22/Feb/2006'),\n",
       "   ('ex', 'Kovokovo-ia puraiparoe avukato.'),\n",
       "   ('xp', 'Lapun man i bin wok long pilai long mambu paip.'),\n",
       "   ('xe', '???')]),\n",
       " ('kovokovo',\n",
       "  [('rt', 'kovo'),\n",
       "   ('ps', 'N'),\n",
       "   ('pt', 'NT'),\n",
       "   ('ge', \"Jew's.harp\"),\n",
       "   ('eng', \"Jew's Harp\"),\n",
       "   ('tkp', 'chusap'),\n",
       "   ('dt', '08/Dec/2005'),\n",
       "   ('ex', 'Kovokovo-ia piraiparoe avukato.'),\n",
       "   ('xp', 'Lapun man i bin wok long pilai long mambu paip.'),\n",
       "   ('xe', \"The old man played the Jew's harp.\")]),\n",
       " ('kovokovoa',\n",
       "  [('rt', 'kovokovo'),\n",
       "   ('ps', 'N'),\n",
       "   ('pt', 'NT'),\n",
       "   ('ge', 'fence'),\n",
       "   ('tkp', 'banis'),\n",
       "   ('cmt', 'Check original for subject of 3rd sentence.'),\n",
       "   ('dt', '08/Dec/2005'),\n",
       "   ('ex', 'Kepaia kovovao tovori va kakeoro.'),\n",
       "   ('xp', 'Yu putim banis long house.'),\n",
       "   ('xe', 'You are putting up a fence around the house.'),\n",
       "   ('ex', 'Kovovoa kepa iava kovovoa.'),\n",
       "   ('xp', 'Dispela em banis blong house.'),\n",
       "   ('xe', 'This is a house fence.'),\n",
       "   ('ex', 'Kovokovoa purapai ??? koue kare-re.'),\n",
       "   ('xp', 'Ol youth ol i wokim banis bilong ol pik.'),\n",
       "   ('xe', '???')]),\n",
       " ('kovopaa',\n",
       "  [('rt', 'kovo'),\n",
       "   ('ps', 'N'),\n",
       "   ('pt', 'NT'),\n",
       "   ('ge', 'tool'),\n",
       "   ('tkp', 'tul'),\n",
       "   ('dt', '02/Sep/2005'),\n",
       "   ('ex', 'Oaravu rutu kovopaara kepa siovaraia toupai.'),\n",
       "   ('xp', 'Ol tuls bilong wok istap insait long haus.'),\n",
       "   ('xe', 'All of the tools are in the house.')]),\n",
       " ('kovopato',\n",
       "  [('rt', 'kovo'),\n",
       "   ('ps', 'N'),\n",
       "   ('pt', 'HUM'),\n",
       "   ('ge', 'laborer'),\n",
       "   ('ge', 'worker'),\n",
       "   ('tkp', 'wokman'),\n",
       "   ('avm', 'pa_required'),\n",
       "   ('dt', '02/Sep/2005'),\n",
       "   ('ex', 'Pita kovopato vo kepaio.'),\n",
       "   ('xp', 'Pita man blong work long house.'),\n",
       "   ('xe', 'Peter is a house-builder.'),\n",
       "   ('ex', 'Pol a ragai reraro kovopato.'),\n",
       "   ('xp', 'Pol em i wokman bilong mi.'),\n",
       "   ('xe', 'Paul is my workman.')]),\n",
       " ('kovopie',\n",
       "  [('rt', 'kovo'),\n",
       "   ('ps', 'V'),\n",
       "   ('pt', 'B'),\n",
       "   ('ge', 'make work'),\n",
       "   ('eng', 'make work'),\n",
       "   ('eng', 'use to make work'),\n",
       "   ('tkp', 'yusim'),\n",
       "   ('arg', 'O'),\n",
       "   ('vx', '2'),\n",
       "   ('dt', '16/Nov/2005'),\n",
       "   ('cmt', \"What's the locative noun doing in the 2nd sentence?\"),\n",
       "   ('ex', 'Monia kovopie kakau vorioro.'),\n",
       "   ('xp', 'Yu mekim wok dispela moni long baiim kokoa.'),\n",
       "   ('xe', 'You make money by buying cocoa.'),\n",
       "   ('ex', 'Pol monia kovopiepare kakau voripaoro va-ia.'),\n",
       "   ('xp', 'Pol i mekim wok moni taim em i baim kakau.'),\n",
       "   ('xe', 'Paul is making money buying cocoa with it.'),\n",
       "   ('ex', 'Sera vaio ora Rarasori ragai kovopiesivo.'),\n",
       "   ('xp', 'Sera wantaim Rarason i givim wok long mi.'),\n",
       "   ('xe', 'Sera and Robinson gave me work.')]),\n",
       " ('kovoruko',\n",
       "  [('ps', 'N'),\n",
       "   ('pt', 'MASC'),\n",
       "   ('ge', 'white-bark tree'),\n",
       "   ('tkp', '???'),\n",
       "   ('dt', '30/Aug/2005'),\n",
       "   ('ex', 'Evaova popotevira rakaripapeira kovurukoua.'),\n",
       "   ('xp', 'Em wampela diwai skin blong em i save white.'),\n",
       "   ('xe', 'That is a tree whose skin is white.')]),\n",
       " ('kovoto',\n",
       "  [('rt', 'kovo'),\n",
       "   ('ps', 'N'),\n",
       "   ('pt', 'MASC'),\n",
       "   ('dx', 'Central'),\n",
       "   ('ge', 'big.garden'),\n",
       "   ('ge', 'big garden'),\n",
       "   ('tkp', 'bikpela gaden'),\n",
       "   ('avm', 'pa_barred'),\n",
       "   ('dt', '02/Sep/2005')]),\n",
       " ('kovovo',\n",
       "  [('rt', 'kovo'),\n",
       "   ('ps', 'V'),\n",
       "   ('pt', 'B'),\n",
       "   ('ge', 'fence'),\n",
       "   ('ge', 'protect'),\n",
       "   ('tkp', 'banisim'),\n",
       "   ('arg', 'O'),\n",
       "   ('vx', '2'),\n",
       "   ('dt', '08/Jun/2005'),\n",
       "   ('ex', 'Kepa kovovo va utoro.'),\n",
       "   ('xp', 'Yo banisim house bikol?? Em kolor tumas.'),\n",
       "   ('xe', '???'),\n",
       "   ('ex', 'Koue karen kovovo sapi kovoa aioive.'),\n",
       "   ('xp', 'You mekim fence long gut of ikaikaim garden.'),\n",
       "   ('xe', '???'),\n",
       "   ('ex', 'Koue kare kovovori ikauvira teapi kosiaviro kovoara aiosia.'),\n",
       "   ('xp',\n",
       "    'Yu banisim kwik ol pik, nogut ol i kam arasait na kaikaim ol gaden.'),\n",
       "   ('xe', 'Fence the pigs quickly lest they escape and eat the gardens.')]),\n",
       " ('kovuaka',\n",
       "  [('alt', 'kovoaka'),\n",
       "   ('ps', 'N'),\n",
       "   ('pt', 'NT'),\n",
       "   ('ge', 'roof'),\n",
       "   ('tkp', 'rup'),\n",
       "   ('dt', '05/Feb/2005'),\n",
       "   ('ex',\n",
       "    'Kepa-ia konoaka avo kovuako puropai aue iava tetevu guruvaro kepa iare.'),\n",
       "   ('xp', 'Roof blong house/ol I woekim blong house long ol sago levevis?? .'),\n",
       "   ('xe', '???')]),\n",
       " ('kovuaro',\n",
       "  [('rt', 'kovu'),\n",
       "   ('ps', 'N'),\n",
       "   ('pt', 'NT'),\n",
       "   ('eng', 'middle section'),\n",
       "   ('eng', 'center section'),\n",
       "   ('ge', 'middle'),\n",
       "   ('tkp', 'namel'),\n",
       "   ('dt', '10/May/2005'),\n",
       "   ('ex', 'Pita rakoru tokorevo kovuaro-va.'),\n",
       "   ('xp', 'Pita i katim snek namel.'),\n",
       "   ('xe', 'Pita cut the snake from the middle.')]),\n",
       " ('kovukovu',\n",
       "  [('rt', 'kovu'),\n",
       "   ('ps', '???'),\n",
       "   ('ge', 'false'),\n",
       "   ('ge', 'fake'),\n",
       "   ('ge', 'untrue'),\n",
       "   ('tkp', 'giaman'),\n",
       "   ('dt', '01/Jun/2005'),\n",
       "   ('ex', 'Riro kovukovu reotoa rutu vii.'),\n",
       "   ('xp', 'Yu man bilong toktok nating.'),\n",
       "   ('xe', '???')]),\n",
       " ('kovukovuto',\n",
       "  [('rt', 'kovukovu'),\n",
       "   ('ps', 'N'),\n",
       "   ('pt', 'MASC'),\n",
       "   ('ge', 'tree'),\n",
       "   ('tkp', 'wanpela rain diwai'),\n",
       "   ('sf', 'FLORA'),\n",
       "   ('nt', 'tall fast-growing type with pithy center'),\n",
       "   ('dt', '14/Nov/2005'),\n",
       "   ('ex',\n",
       "    'Kovukovuto riro kaekaepavira riparoveira. Vosia evakoro ra rivivuroviro sovara iava.'),\n",
       "   ('xp',\n",
       "    'I em wanpela kan diwai em i save gro hariap. Taim em i dai nau bai i gat hol insait.'),\n",
       "   ('xe', 'The ??? grows very long. When it ???, it is ??? inside.'),\n",
       "   ('ex', 'Kovukovuto riro ikaupa riroto.'),\n",
       "   ('xp', 'Plant i save gro kwik tru.'),\n",
       "   ('xe', 'The ??? plant is a really fast grower.')]),\n",
       " ('kovukovuvira',\n",
       "  [('rt', 'kovukovu'),\n",
       "   ('ps', 'ADV'),\n",
       "   ('pt', 'MANNER'),\n",
       "   ('ge', 'falsely'),\n",
       "   ('tkp', 'olsem giaman'),\n",
       "   ('dt', '03/Dec/2004'),\n",
       "   ('ex', 'Kovukovuvira reoreopau, Leo.'),\n",
       "   ('xp', 'Leo, toktok bilong yu i no tru.'),\n",
       "   ('xe', '???')]),\n",
       " ('kovuru',\n",
       "  [('ps', '???'),\n",
       "   ('ge', '???'),\n",
       "   ('eng', '???'),\n",
       "   ('tkp', '???'),\n",
       "   ('dt', '13/Nov/2005'),\n",
       "   ('ex',\n",
       "    'Veeta tou kovururi eva evoa uva vo raga urio vasipae kovoa tasiasipaoro.'),\n",
       "   ('xp',\n",
       "    'Yu putim akros mambu ia bikos ol i wok long kam olsem nabaut na kurukutim gaden.'),\n",
       "   ('xe', '???')]),\n",
       " ('kovurui',\n",
       "  [('alt', 'kovuru'),\n",
       "   ('alt', 'kovuruva'),\n",
       "   ('ps', 'N'),\n",
       "   ('pt', 'FEM'),\n",
       "   ('ge', 'rafter'),\n",
       "   ('eng', 'rafter'),\n",
       "   ('eng', 'eave of roof'),\n",
       "   ('tkp', 'sparen'),\n",
       "   ('dt', '25/Jul/2005'),\n",
       "   ('ex', 'Kovurup kepai kovurui tovori kovuakare.'),\n",
       "   ('xp', '???'),\n",
       "   ('xe', '???'),\n",
       "   ('ex', 'Kovurui ivaraia kovuakaua tovota.'),\n",
       "   ('xp', 'Putim ridge kap antap long rapta.'),\n",
       "   ('xe', '???')]),\n",
       " ('kovuruko',\n",
       "  [('alt', 'kuvuruko'),\n",
       "   ('ps', 'N'),\n",
       "   ('pt', 'NT'),\n",
       "   ('ge', 'carved decorative marks on arrows'),\n",
       "   ('ge', 'decoration on arrow shaft'),\n",
       "   ('tkp', '???'),\n",
       "   ('am', 'true'),\n",
       "   ('dt', '13/May/2005'),\n",
       "   ('cmt', 'Are kovuruko and kuvuruko both acceptable pronunciations?'),\n",
       "   ('ex', 'Kovurukopava rakoru kekeavo.'),\n",
       "   ('xp', 'Mi lukim sinek i gat makmak.'),\n",
       "   ('xe', 'I am looking at the decorated snake.'),\n",
       "   ('ex', 'Vao kovuruko evaoa va vearo kekepe.'),\n",
       "   ('xp', '???'),\n",
       "   ('xe', '???'),\n",
       "   ('ex', 'Kearitou kovuruko eva vauruvare.'),\n",
       "   ('xp', 'Yu decoraturem dispela blong wokim spear.'),\n",
       "   ('xe', '???'),\n",
       "   ('ex', 'Kovuruko ova evaova popote rakari ova.'),\n",
       "   ('xp', 'Diwai em sking bilong en i wait.'),\n",
       "   ('xe', '???'),\n",
       "   ('ex', 'Kuvuruko-pa tou keari tou.'),\n",
       "   ('xp', 'Pitpit i gat makmak long en.'),\n",
       "   ('xe', '???')]),\n",
       " ('kovurukovira',\n",
       "  [('alt', 'kovurukopavira'),\n",
       "   ('rt', 'kovuruko'),\n",
       "   ('ps', 'ADV'),\n",
       "   ('pt', 'MANNER'),\n",
       "   ('ge', 'striped'),\n",
       "   ('tkp', '???'),\n",
       "   ('nt', 'The meaning, many stripes, is marked by the reduplicated form'),\n",
       "   ('dt', '30/Aug/2005'),\n",
       "   ('ex', 'Auero rutu kovurukopavira toupaivo.'),\n",
       "   ('xp', 'Olgeta samting i gat makmak istap.'),\n",
       "   ('xe', '???')]),\n",
       " ('kovuruvira',\n",
       "  [('rt', 'kovuru'),\n",
       "   ('ps', 'ADV'),\n",
       "   ('pt', 'MANNER'),\n",
       "   ('ge', 'at a right angle'),\n",
       "   ('ge', 'cross-wise'),\n",
       "   ('ge', 'horizontal'),\n",
       "   ('tkp', '???'),\n",
       "   ('dt', '13/Nov/2005'),\n",
       "   ('ex', 'Kovuruvira kaeu.'),\n",
       "   ('xp', 'Karim dispela a cross.'),\n",
       "   ('xe', '???'),\n",
       "   ('ex', 'Kovuruvira vao tovo.'),\n",
       "   ('xp', 'Putim dispela across.'),\n",
       "   ('xe', '???'),\n",
       "   ('ex', 'Jon kovuruvira vokaparevoi raiva-ia.'),\n",
       "   ('xp', 'Jon wokabaut krosim rot i go.'),\n",
       "   ('xe', 'John walked crossing the road.')]),\n",
       " ('kovuto',\n",
       "  [('ps', 'N'),\n",
       "   ('pt', 'HUM'),\n",
       "   ('ge', 'abdomen'),\n",
       "   ('ge', 'stomach'),\n",
       "   ('ge', 'diarrhea'),\n",
       "   ('tkp', 'bel'),\n",
       "   ('tkp', 'pekpek wara'),\n",
       "   ('dt', '26/Jan/2005'),\n",
       "   ('ex', 'Oirato iava kovuto.'),\n",
       "   ('xp', 'Bel blong man.'),\n",
       "   ('xe', '???'),\n",
       "   ('ex', 'Rakova iava kovuto.'),\n",
       "   ('xp', 'Bel blong meri.'),\n",
       "   ('xe', '???'),\n",
       "   ('ex', 'Vii iava kovuto.'),\n",
       "   ('xp', 'Bel blong yu.'),\n",
       "   ('xe', '???'),\n",
       "   ('ex', 'Varesia riro kovuto.'),\n",
       "   ('xp', 'Varsia em i bikbel.'),\n",
       "   ('xe', '???')]),\n",
       " ('kuara',\n",
       "  [('ps', 'V'),\n",
       "   ('pt', 'B'),\n",
       "   ('ge', 'yell at'),\n",
       "   ('tkp', '???'),\n",
       "   ('cm', '-va'),\n",
       "   ('arg', 'OBL'),\n",
       "   ('vx', '2'),\n",
       "   ('dt', '08/Jun/2005'),\n",
       "   ('ex', 'Rera-va kuarapaeva.'),\n",
       "   ('xp', '???'),\n",
       "   ('xe', 'She yelled at him.'),\n",
       "   ('ex', 'Potaki-va kuarapaivo ovusia taviparoe.'),\n",
       "   ('xp', 'Ol i wok long singaut bikmaus long Potaki taim em i toksave.'),\n",
       "   ('xe', 'They are yelling at Potaki while he talks.')]),\n",
       " ('kue',\n",
       "  [('ps', 'V'),\n",
       "   ('pt', 'A'),\n",
       "   ('ge', 'bear.fruit'),\n",
       "   ('tkp', 'karim pikinini bilong diwai'),\n",
       "   ('eng', 'reproduce'),\n",
       "   ('eng', 'bear fruit'),\n",
       "   ('cmt', 'In the second example, is it vo or va?'),\n",
       "   ('vx', '1'),\n",
       "   ('dt', '07/Jun/2005'),\n",
       "   ('ex', 'Opitato kueroi.'),\n",
       "   ('xp', 'Kokonas i karim nau.'),\n",
       "   ('xe', 'The coconut tree is bearing fruit.'),\n",
       "   ('ex', 'Vosa kakao kueo, ra apeisi vo kuepiea.'),\n",
       "   ('xp', '???'),\n",
       "   ('xe', 'When the cocoa bears fruit, then what do I do with the fruit?')]),\n",
       " ('kuea',\n",
       "  [('alt', 'kue'),\n",
       "   ('rt', 'kue'),\n",
       "   ('ps', 'N'),\n",
       "   ('pt', 'NT'),\n",
       "   ('ge', 'fruit'),\n",
       "   ('tkp', 'prut pikinini'),\n",
       "   ('dt', '10/May/2005'),\n",
       "   ('ex', 'Opita kuea vaoi vosa evaova kuepe.'),\n",
       "   ('xp', 'Sapos diwai em isat pa fruit.'),\n",
       "   ('xe', '???'),\n",
       "   ('ex', 'Opitatoa-ia kuea vavo.'),\n",
       "   ('xp', 'Kokonas i karim pinis nau.'),\n",
       "   ('xe', '???')]),\n",
       " ('kuga',\n",
       "  [('ps', 'V'),\n",
       "   ('pt', 'B'),\n",
       "   ('ge', 'bump into'),\n",
       "   ('ge', 'nudge'),\n",
       "   ('tkp', '???'),\n",
       "   ('cm', '-ia'),\n",
       "   ('arg', 'OBL'),\n",
       "   ('vx', '2'),\n",
       "   ('dt', '08/Jun/2005'),\n",
       "   ('ex', 'Vii-ia kugapaavoi.'),\n",
       "   ('xp', '???'),\n",
       "   ('xe', 'I am bumping into you.'),\n",
       "   ('ex', 'Siraovira vii-ia kugaavoi.'),\n",
       "   ('xp', 'Sori tru, mi bam long yu.'),\n",
       "   ('xe', '???')]),\n",
       " ('kui',\n",
       "  [('ps', 'N'),\n",
       "   ('pt', '???'),\n",
       "   ('ge', 'semen'),\n",
       "   ('tkp', 'melek'),\n",
       "   ('dt', '04/Dec/2004'),\n",
       "   ('ex', 'Kui oiratoa-ia toupai ora riakova.'),\n",
       "   ('xp', 'Semen em istap long man na meri.'),\n",
       "   ('xe', '???')]),\n",
       " ('kuio',\n",
       "  [('ps', 'CLASS'),\n",
       "   ('ge', 'round'),\n",
       "   ('tkp', '???'),\n",
       "   ('eng', 'group of round objects'),\n",
       "   ('dt', '02/Jun/2005'),\n",
       "   ('ex', 'Kuiorei.'),\n",
       "   ('xp', '???'),\n",
       "   ('xe', 'Two round objects.'),\n",
       "   ('ex', 'Riro kuio rutu vao opo kuio.'),\n",
       "   ('xp', 'Triapela raunpela taro.'),\n",
       "   ('xe', '???')]),\n",
       " ('kuioi',\n",
       "  [('ps', 'N'),\n",
       "   ('pt', 'NT'),\n",
       "   ('ge', 'taro with round root'),\n",
       "   ('tkp', 'raunpela taro'),\n",
       "   ('pt', 'opo'),\n",
       "   ('dt', '12/Aug/2005'),\n",
       "   ('ex', 'Opo kuioi ragaipa oo kuioi aue opo.'),\n",
       "   ('xp', 'Yu givim taro.'),\n",
       "   ('xe', '???'),\n",
       "   ('ex', 'Ragai-pa okuioi opo.'),\n",
       "   ('xp', 'Yu givim mi wanpela taro.'),\n",
       "   ('xe', '???')]),\n",
       " ('kuiopesi',\n",
       "  [('ps', 'N'),\n",
       "   ('pt', 'MASC'),\n",
       "   ('ge', 'frog'),\n",
       "   ('tkp', '???'),\n",
       "   ('nt', 'small yellow body, pictured on PNG postage stamp, lives on leaves'),\n",
       "   ('dt', '04/Dec/2004'),\n",
       "   ('ex', 'Kuiopesi iria toupaeveira eisi vegoaro.'),\n",
       "   ('xp', 'Liklik rokrok i save istap long bus.'),\n",
       "   ('xe', '???')]),\n",
       " ('kuiopetu',\n",
       "  [('ps', 'N'),\n",
       "   ('pt', 'MASC'),\n",
       "   ('ge', 'type of frog'),\n",
       "   ('tkp', '???'),\n",
       "   ('nt', 'Small variety. This was pictured on the 10t PNG postage stamp.'),\n",
       "   ('dt', '04/Dec/2004'),\n",
       "   ('ex', 'Kuiopetu iria toupae 10 toia stamp-ia vao PNG.'),\n",
       "   ('xp', 'Rokrok poto bilong en istap long 10 toia PNG stamp.'),\n",
       "   ('xe', '???')]),\n",
       " ('kuito',\n",
       "  [('ps', 'N'),\n",
       "   ('pt', 'MASC'),\n",
       "   ('ge', 'type of ant'),\n",
       "   ('tkp', '???'),\n",
       "   ('nt', 'body is blue-black, like army ant'),\n",
       "   ('dt', '04/Dec/2004'),\n",
       "   ('ex', 'Iravivu ita avarato rera vaisiaro kuito.'),\n",
       "   ('xp', 'Wanpela kain anis kolim long kuito.'),\n",
       "   ('xe', '???')]),\n",
       " ('kuka',\n",
       "  [('ps', 'N'),\n",
       "   ('pt', 'FEM'),\n",
       "   ('ge', 'shackle'),\n",
       "   ('ge', 'handcuffs'),\n",
       "   ('tkp', 'hankap sagoi'),\n",
       "   ('dt', '04/Dec/2004'),\n",
       "   ('ex',\n",
       "    'Polis kuka tovoiva ira vavaearoi vosia vuria purareve kuka tovoivo John vare rivo kaureotoa.'),\n",
       "   ('xp', 'Polis i putim hankuf long han bilong man sapos em i bikhet.'),\n",
       "   ('xe', '???'),\n",
       "   ('ex', 'Kuka tovopaiveira oirara-ia kaureoirara.'),\n",
       "   ('xp', 'Polis i save putim ankap long ol bikhet man.'),\n",
       "   ('xe', '???')]),\n",
       " ('kukara',\n",
       "  [('ps', 'N'),\n",
       "   ('pt', 'FEM'),\n",
       "   ('ge', 'corn'),\n",
       "   ('ge', 'cane'),\n",
       "   ('tkp', 'maispitpit'),\n",
       "   ('nt', 'wilde type'),\n",
       "   ('dt', '04/Dec/2004'),\n",
       "   ('ex', 'Saimon riro kukara aioto.'),\n",
       "   ('xp', 'Saimon man bilong kaikai kon.'),\n",
       "   ('xe', '???')]),\n",
       " ('kukauviro',\n",
       "  [('rt', '--'),\n",
       "   ('ps', 'V'),\n",
       "   ('pt', 'A'),\n",
       "   ('ge', 'deteriorate'),\n",
       "   ('tkp', 'i laik bruk'),\n",
       "   ('tkp', 'pundaun nating'),\n",
       "   ('vx', '1'),\n",
       "   ('cmt', \"Is viro really part of the stem? If so, it's been lexicalized.\"),\n",
       "   ('dt', '22/Nov/2005'),\n",
       "   ('ex',\n",
       "    'Kukauviro opeita evoa torepau vlaraim sapi kukauviro vo-re etokasi.'),\n",
       "   ('xp', 'Nogut yu pundaun i go long paia.'),\n",
       "   ('xe', '???'),\n",
       "   ('ex', 'Teapi kukauviro eisi-re vagapa.'),\n",
       "   ('xp', 'Nogut yu pundaun i go long watpal.'),\n",
       "   ('xe', \"Don't fall down the waterfall.\"),\n",
       "   ('ex', 'Raka teapi kukauviro evoa-re rikui.'),\n",
       "   ('xp', 'Raka, nogut yu pundaun i go long hol.'),\n",
       "   ('xe', \"Raka, don't fall down into the hole.\"),\n",
       "   ('ex',\n",
       "    'Avukato kukauviroragaparoi kopiioro uvare rera viapau goruavai oa iava kukarovi vovokio.'),\n",
       "   ('xp',\n",
       "    'Lapun man bai pundaun nating na bai em dai bikos em nogat strong olsem na em i pundaun nating tude.'),\n",
       "   ('xe',\n",
       "    \"The old man is ??? dying because he has no strength and that's why he ??? today.\")]),\n",
       " ('kukiuki',\n",
       "  [('ps', 'V'),\n",
       "   ('pt', 'B'),\n",
       "   ('ge', 'shake something'),\n",
       "   ('ge', 'rattle something'),\n",
       "   ('tkp', 'meknoisim'),\n",
       "   ('arg', 'O'),\n",
       "   ('vx', '2'),\n",
       "   ('dt', '08/Jun/2005'),\n",
       "   ('ex', 'Moniara kukiukiri bokis sovara-ia.'),\n",
       "   ('xp', '???'),\n",
       "   ('xe', 'Shake the money inside the box.'),\n",
       "   ('ex', 'Moniara kukiukiri raka-pa tou siovaraia.'),\n",
       "   ('xp', 'Yu sekim ol moni insait long tin.'),\n",
       "   ('xe', '???')]),\n",
       " ('kukiukia',\n",
       "  [('rt', 'kukiuki'),\n",
       "   ('ps', 'N'),\n",
       "   ('pt', 'NT'),\n",
       "   ('ge', 'rattles for play'),\n",
       "   ('tkp', 'salamon bilong pilai'),\n",
       "   ('dt', '04/Dec/2004'),\n",
       "   ('ex', 'Pita kukiukia vo evaova-ia, osia voa touparevo.'),\n",
       "   ('xp', 'Pita istap long diwai na mi sekim em.'),\n",
       "   ('xe', '???')]),\n",
       " ('kuku',\n",
       "  [('ps', 'V'),\n",
       "   ('pt', 'B'),\n",
       "   ('ge', 'spoonfeed'),\n",
       "   ('tkp', '???'),\n",
       "   ('arg', 'O'),\n",
       "   ('vx', '2'),\n",
       "   ('nt',\n",
       "    'To feed a person incapable of feeding himself. Used describing a pastor who feeds the people from the Word of God.'),\n",
       "   ('dt', '08/Jun/2005'),\n",
       "   ('ex', 'Rusa kakaeto kukupaevo gisipo-ia.'),\n",
       "   ('xp', 'Rusa i givim kaikai long pikinini long maus.'),\n",
       "   ('xe', '???')]),\n",
       " ('kukua',\n",
       "  [('ps', 'N'),\n",
       "   ('pt', 'NT'),\n",
       "   ('ge', 'galip nut'),\n",
       "   ('tkp', 'galip'),\n",
       "   ('tkp', 'kasang'),\n",
       "   ('eng', 'Java nut'),\n",
       "   ('eng', 'galip nut'),\n",
       "   ('eng', 'ngali nut (Canarium indicum)'),\n",
       "   ('dt', '04/Dec/2004'),\n",
       "   ('ex', 'Vutara-ia kuepapeira aue kukua vo ivaraia.'),\n",
       "   ('xp', 'Garip i save karim wanpela taim insait long yia.'),\n",
       "   ('xe', '???')]),\n",
       " ('kukuaua',\n",
       "  [('rt', 'kukua'),\n",
       "   ('ps', 'N'),\n",
       "   ('pt', 'NT'),\n",
       "   ('ge', 'candle'),\n",
       "   ('ge', 'light made from sap of Tahitian chestnut'),\n",
       "   ('tkp', 'kandel bilong wara bilong galip'),\n",
       "   ('dt', '04/Dec/2004'),\n",
       "   ('ex', 'Kukuaua oa aviavipaiveira rara va rukuepaive.'),\n",
       "   ('xp', 'Kendol i save lait, sapos ol i laitim.'),\n",
       "   ('xe', '???')]),\n",
       " ('kukue',\n",
       "  [('ps', 'N'),\n",
       "   ('pt', 'FEM'),\n",
       "   ('ge', 'head'),\n",
       "   ('eng', 'head'),\n",
       "   ('eng', 'skull'),\n",
       "   ('tkp', 'het'),\n",
       "   ('dt', '17/Nov/2005'),\n",
       "   ('ex',\n",
       "    'Riko siopaipaavo ovusia Rarasiori tapo pauparoe uvare kukuvaipaa tovoparevo vo kukue.'),\n",
       "   ('xp',\n",
       "    'Mi no wok long luksave long Riko taim em i wok long sindaun wantaim Rarason bikos em iputim kep long het bilong em.'),\n",
       "   ('xe',\n",
       "    \"I didn't recognize Riko when he was seated with Robinson because he put a hat on his head.\")]),\n",
       " ('kukue pute',\n",
       "  [('rt', 'akotei'),\n",
       "   ('ps', 'N'),\n",
       "   ('pt', '???'),\n",
       "   ('ge', 'type of ant'),\n",
       "   ('tkp', 'anis'),\n",
       "   ('nt', 'nickname'),\n",
       "   ('sa', 'akotei'),\n",
       "   ('dt', '04/Feb/2004')]),\n",
       " ('kukuepaa',\n",
       "  [('rt', 'kukue'),\n",
       "   ('ps', 'N'),\n",
       "   ('pt', 'NT'),\n",
       "   ('ge', 'hat'),\n",
       "   ('tkp', 'hat'),\n",
       "   ('dt', '04/Dec/2004'),\n",
       "   ('ex', 'Kukuepa/rageipa kukuepa vate ataria.'),\n",
       "   ('xp', 'Yu givim hap hat blong fish.'),\n",
       "   ('xe', '???'),\n",
       "   ('ex', 'Ragai-pa kukuepaa vateri sipoia.'),\n",
       "   ('xp', 'Yu givim mi het bilong suka.'),\n",
       "   ('xe', '???')]),\n",
       " ('kukuku',\n",
       "  [('ps', 'N'),\n",
       "   ('pt', 'NT'),\n",
       "   ('ge', 'headwater of river'),\n",
       "   ('tkp', 'het bilong wara'),\n",
       "   ('dt', '04/Dec/2004'),\n",
       "   ('ex', 'Uko kukuku.'),\n",
       "   ('xp', 'Head blong wara.'),\n",
       "   ('xe', '???'),\n",
       "   ('ex', 'Vouva ukovi parupaivo kukuku.'),\n",
       "   ('xp', 'Long hap wara em stoter?? igi.'),\n",
       "   ('xe', '???'),\n",
       "   ('ex', 'Ivitu kukuku iava parupae eisi pukuia.'),\n",
       "   ('xp', 'Het bilong Ivitu istap long maunten.'),\n",
       "   ('xe', '???')]),\n",
       " ('kukupira',\n",
       "  [('ps', 'N'),\n",
       "   ('pt', 'NT'),\n",
       "   ('ge', 'type of ground'),\n",
       "   ('tkp', '???'),\n",
       "   ('nt', 'Loamy clay ground that is hard when dry but very ???'),\n",
       "   ('dt', '04/Dec/2004'),\n",
       "   ('ex', 'Kukupira rasi vearopai, atari-pa rovu purasia.'),\n",
       "   ('xp', 'Hap retpela giraun i gutpela long wokim pis pon.'),\n",
       "   ('xe', '???')]),\n",
       " ('kukuriko',\n",
       "  [('ps', '???'),\n",
       "   ('ge', 'head'),\n",
       "   ('ge', 'most important part'),\n",
       "   ('tkp', '???'),\n",
       "   ('vx', '???'),\n",
       "   ('dt', '19/Mar/2006'),\n",
       "   ('ex', 'Oara rutu-pa kukurikopai.'),\n",
       "   ('xp', '???'),\n",
       "   ('xe', 'It is the most important part of all.'),\n",
       "   ('ex', 'Kokioto era evoa kukuriko-ia.'),\n",
       "   ('xp', 'Pisin i stap long het bilong diwai.'),\n",
       "   ('xe', '???')]),\n",
       " ('kukurikoto',\n",
       "  [('rt', 'kukuriko'),\n",
       "   ('ps', 'N'),\n",
       "   ('pt', 'MASC'),\n",
       "   ('ge', 'head of tree, talk, or thought'),\n",
       "   ('ge', 'crown of tree'),\n",
       "   ('tkp', '???'),\n",
       "   ('dt', '04/Dec/2004'),\n",
       "   ('ex', 'Kukurikoto evaovaiava.'),\n",
       "   ('xp', 'Head blong diwai.'),\n",
       "   ('xe', '???'),\n",
       "   ('ex', 'Korato varo, eisi kukurikoto.'),\n",
       "   ('xp', 'Kapul istap long het bilong diwai.'),\n",
       "   ('xe', '???')]),\n",
       " ('kukusiri',\n",
       "  [('ps', 'N'),\n",
       "   ('pt', 'MASC'),\n",
       "   ('ge', 'midrib of sago frond'),\n",
       "   ('tkp', 'nok'),\n",
       "   ('dt', '04/Dec/2004'),\n",
       "   ('ex', 'Te?? tevu guruvaiava kukusiri.'),\n",
       "   ('xp', 'Brum blong saksak.'),\n",
       "   ('xe', '???'),\n",
       "   ('ex', 'Kukusiri tetevu guruva iava.'),\n",
       "   ('xp', 'Bun bilong lip saksak.'),\n",
       "   ('xe', '???')]),\n",
       " ('kukutauvu',\n",
       "  [('ps', 'N'),\n",
       "   ('pt', 'FEM'),\n",
       "   ('ge', 'parrot'),\n",
       "   ('tkp', '???'),\n",
       "   ('eng', 'Superb Fruit Dove (Ptilinopus superbus)'),\n",
       "   ('eng', 'Claret-breasted Fruit Dove (Ptilinopus viridis)'),\n",
       "   ('nt', 'female of visooto'),\n",
       "   ('cmt', 'Check spelling'),\n",
       "   ('sa', 'uvuutu'),\n",
       "   ('sf', 'FAUNA.BIRD'),\n",
       "   ('dt', '04/Dec/2004'),\n",
       "   ('ex', 'Kukutavu oisio raga oira osia uruvau.'),\n",
       "   ('xp', 'Pisin i olsem tasol barus.'),\n",
       "   ('xe', '???')]),\n",
       " ('kukutu',\n",
       "  [('ps', 'N'),\n",
       "   ('pt', 'NT'),\n",
       "   ('ge', 'coconut'),\n",
       "   ('tkp', 'drip'),\n",
       "   ('nt', 'immature green without juice'),\n",
       "   ('dt', '04/Dec/2004'),\n",
       "   ('ex', 'Opita kukutu ukoara viapau opitatai aiosa.'),\n",
       "   ('xp', '?? Kokos em nara tasol no gat meat blong kaikai.'),\n",
       "   ('xe', '???'),\n",
       "   ('ex', 'Kura kopukupuva osa kokovaraviratoupaevo oira oruparo.'),\n",
       "   ('xp', 'Grass blong em em blue na em istap green.'),\n",
       "   ('xe', '???'),\n",
       "   ('ex', 'Kukutuisi vaisio aisia viapau aue uuko.'),\n",
       "   ('xp', 'Liklik kokonas i nogat wara istap.'),\n",
       "   ('xe', '???')]),\n",
       " ('kukuuku',\n",
       "  [('ps', 'V'),\n",
       "   ('pt', 'B'),\n",
       "   ('ge', 'make footfall'),\n",
       "   ('tkp', 'krungutim'),\n",
       "   ('cmt', 'Rethink translation'),\n",
       "   ('dt', '16/Nov/2005'),\n",
       "   ('vx', '1'),\n",
       "   ('ex', 'Oirato kukuukupaoro torirevo oa iava kaakaukare rera-va tarioae.'),\n",
       "   ('xp', 'Man i mekim nois olsem na ol dok ronim em.'),\n",
       "   ('xe', '???'),\n",
       "   ('ex', 'Kikisi kukuukupavoi.'),\n",
       "   ('xp', 'Bal em i bam long graun.'),\n",
       "   ('xe', '???'),\n",
       "   ('ex', 'Oirato era ira kukuukupare ira uvupavoi.'),\n",
       "   ('xp', 'Mi harim man i wokabaut i kam.'),\n",
       "   ('xe', '???'),\n",
       "   ('ex', 'Pita kukuukupieoro puterevo kepa-ia.'),\n",
       "   ('xp', 'Pita i mekim nois taim em i wokabaut klostu long haus.'),\n",
       "   ('xe', '???')]),\n",
       " ('kukuukua',\n",
       "  [('rt', 'kukuuku'),\n",
       "   ('ps', '???'),\n",
       "   ('ge', 'sound of footsteps'),\n",
       "   ('tkp', 'nois bilong iek'),\n",
       "   ('dt', '04/Dec/2004'),\n",
       "   ('ex',\n",
       "    'Vosa vokapareve rairavu vuri osa kukuukua piepare vokapaoro oirato kukuu piepare.'),\n",
       "   ('xp', 'Taim yu harim mom em woik baut.'),\n",
       "   ('xe', '???')]),\n",
       " ('kukuukupie',\n",
       "  [('rt', 'kukuuku'),\n",
       "   ('ps', 'V'),\n",
       "   ('pt', 'B'),\n",
       "   ('ge', 'make footfall'),\n",
       "   ('tkp', 'krungutim'),\n",
       "   ('vx', '???'),\n",
       "   ('cmt', 'Can it take an object?'),\n",
       "   ('dt', '22/Nov/2005'),\n",
       "   ('ex', 'Pita kukuukupieoro puterevo kepa-ia.'),\n",
       "   ('xp', 'Pita i mekim nois taim em i wokabaut klostu long haus.'),\n",
       "   ('xe', '???')]),\n",
       " ('kukuuvua',\n",
       "  [('ps', 'N'),\n",
       "   ('pt', 'NT'),\n",
       "   ('ge', 'roof'),\n",
       "   ('tkp', '???'),\n",
       "   ('dt', '04/Dec/2004'),\n",
       "   ('ex', 'Kepa kukuuvua-ro.'),\n",
       "   ('xp', 'Roof blong hause.'),\n",
       "   ('xe', '???'),\n",
       "   ('ex', 'Kepa-ia kukuuvua tovota.'),\n",
       "   ('xp', 'Yupela putim rup antap long haus.'),\n",
       "   ('xe', '???')]),\n",
       " ('kukuvai',\n",
       "  [('ps', 'V'),\n",
       "   ('pt', 'B'),\n",
       "   ('ge', 'shelter head'),\n",
       "   ('ge', 'cover the head from rain or sun'),\n",
       "   ('tkp', 'karamapim het'),\n",
       "   ('cmt', 'Check classification? Class A or B? Is it labile?'),\n",
       "   ('vx', '???'),\n",
       "   ('arg', '???'),\n",
       "   ('dt', '08/Jun/2005'),\n",
       "   ('ex', 'Kukue kukuvairi ambrela-ia.'),\n",
       "   ('xp', '???'),\n",
       "   ('xe', 'Shelter you head with the umbrella.'),\n",
       "   ('ex', 'Pita, kukuvaiu ari kokeva koveoi.'),\n",
       "   ('xp', 'Pita, yu karamap nau ren i pundaun.'),\n",
       "   ('xe', \"Pita, cover up because it's raining.\")]),\n",
       " ('kukuvaipaa',\n",
       "  [('rt', 'kukuvai'),\n",
       "   ('ps', 'N'),\n",
       "   ('pt', 'NT'),\n",
       "   ('ge', 'hat'),\n",
       "   ('tkp', 'hat'),\n",
       "   ('cmt', 'Sentence fragment'),\n",
       "   ('dt', '04/Dec/2004'),\n",
       "   ('ex', 'Porisito vaaro kukuvaipa.'),\n",
       "   ('xp', 'Hat bilong polis.'),\n",
       "   ('xe', 'Police hat.')]),\n",
       " ('kukuvita',\n",
       "  [('ps', 'N'),\n",
       "   ('pt', 'NT'),\n",
       "   ('cl', 'isi'),\n",
       "   ('ge', 'tree fern'),\n",
       "   ('tkp', '???'),\n",
       "   ('nt', 'small with edible new shoots'),\n",
       "   ('sa', 'kepikepiisi'),\n",
       "   ('sf', 'FAUNA'),\n",
       "   ('dt', '12/Feb/2005'),\n",
       "   ('cmt', 'Is vegaropa isi really a word? Come on, really?'),\n",
       "   ('ex', 'Kukuvita isi vegoaropa isi aisia-ia kupeiara toupaiveira.'),\n",
       "   ('xp', 'Em wanpela kain plant i save gat ol miupela sut.'),\n",
       "   ('xe', '???')]),\n",
       " ('kukuvua',\n",
       "  [('rt', 'kukuvu'),\n",
       "   ('ps', 'N'),\n",
       "   ('pt', '???'),\n",
       "   ('ge', 'roof cap'),\n",
       "   ('tkp', 'rup rabun'),\n",
       "   ('dt', '04/Dec/2004'),\n",
       "   ('ex', 'Kepa iava kukuvua.'),\n",
       "   ('xp', 'Rup bilong haus.'),\n",
       "   ('xe', '???')]),\n",
       " ('Kuokuo',\n",
       "  [('ps', 'N'),\n",
       "   ('pt', 'PN'),\n",
       "   ('ge', 'name'),\n",
       "   ('tkp', 'nem'),\n",
       "   ('cmt', 'Sentence fragment'),\n",
       "   ('dt', '26/Jan/2005'),\n",
       "   ('ex', 'Kuokuo riakova tugarava vegoaropava.'),\n",
       "   ('xp', 'Masalai meri bilong bus.'),\n",
       "   ('xe', '???')]),\n",
       " ('kupare',\n",
       "  [('ps', 'V'),\n",
       "   ('pt', 'B'),\n",
       "   ('ge', 'smoke'),\n",
       "   ('eng', 'smoke'),\n",
       "   ('eng', 'produce smoke'),\n",
       "   ('tkp', 'mekim smok'),\n",
       "   ('vx', '1'),\n",
       "   ('sc', '???'),\n",
       "   ('dt', '27/Sep/2006'),\n",
       "   ('ex', 'Etokasi kupareepa.'),\n",
       "   ('xp', '???'),\n",
       "   ('xe', 'The fire smoked.'),\n",
       "   ('ex', 'Toki kupareparoveira vokiara rutu-ia.'),\n",
       "   ('xp', 'Bagana i save smuk olgeta dei.'),\n",
       "   ('xe', '???')]),\n",
       " ('kupareto',\n",
       "  [('rt', 'kupare'),\n",
       "   ('ps', 'N'),\n",
       "   ('pt', 'MASC'),\n",
       "   ('ge', 'smoke'),\n",
       "   ('tkp', 'smok'),\n",
       "   ('dt', '04/Dec/2004'),\n",
       "   ('ex', 'Kupareto ira vusivusipareveira etokasi iava.'),\n",
       "   ('xp', 'Simuk i save kam aut long paia.'),\n",
       "   ('xe', '???')]),\n",
       " ('kupekupe',\n",
       "  [('ps', 'V'),\n",
       "   ('pt', 'B'),\n",
       "   ('ge', 'fan'),\n",
       "   ('tkp', 'givim win'),\n",
       "   ('arg', 'O'),\n",
       "   ('vx', '2'),\n",
       "   ('dt', '08/Jun/2005'),\n",
       "   ('ex', 'Ragai kakaeto kupekupepavoi uvare kasiraoparoi.'),\n",
       "   ('xp', 'Mi givim win long pikinini bikos em i hot.'),\n",
       "   ('xe', \"I'm fanning the child because it's hot.\")]),\n",
       " ('kupekupepa',\n",
       "  [('rt', 'kupekupe'),\n",
       "   ('ps', 'N'),\n",
       "   ('pt', '???'),\n",
       "   ('ge', 'fan'),\n",
       "   ('tkp', 'samting bilong givim win'),\n",
       "   ('dt', '13/Jul/2004'),\n",
       "   ('ex', 'Ragai orakupekupeparai kupekupepaia.'),\n",
       "   ('xp', 'Mi givim win long mi yet long fan.'),\n",
       "   ('xe', \"I'm fanning myself with the fan.\")]),\n",
       " ('kupero',\n",
       "  [('ps', 'N'),\n",
       "   ('pt', 'FEM'),\n",
       "   ('ge', 'shoulder joint'),\n",
       "   ('tkp', 'sol'),\n",
       "   ('dt', '04/Dec/2004'),\n",
       "   ('ex', 'Kupero koue iava.'),\n",
       "   ('xp', 'Bun skuru bilong pik.'),\n",
       "   ('xe', '???')]),\n",
       " ('kuperoo',\n",
       "  [('ps', 'N'),\n",
       "   ('pt', '???'),\n",
       "   ('ge', 'arrow with bone tip'),\n",
       "   ('tkp', 'supsup i gat bun'),\n",
       "   ('dt', '04/Dec/2004'),\n",
       "   ('ex', 'Siova kuperoo paurevora keari tou-ia.'),\n",
       "   ('xp', 'Siova i bin putim bun bilong pik long pitpit.'),\n",
       "   ('xe', '???')]),\n",
       " ('kuperovira',\n",
       "  [('rt', 'kupero'),\n",
       "   ('ps', 'ADV'),\n",
       "   ('pt', 'MANNER'),\n",
       "   ('ge', 'dull flat-like'),\n",
       "   ('tkp', '???'),\n",
       "   ('dt', '04/Dec/2004'),\n",
       "   ('ex', 'Kuperovira raga vokapavoi.'),\n",
       "   ('xp', 'Mi wokabaut nating na mi no save.'),\n",
       "   ('xe', '???')]),\n",
       " ('kupii',\n",
       "  [('ps', 'N'),\n",
       "   ('pt', '???'),\n",
       "   ('ge', 'pupa of beetle'),\n",
       "   ('tkp', 'pikinini bilong binatang'),\n",
       "   ('dt', '07/Mar/2005'),\n",
       "   ('ex', 'Kupito era kokopuoto.'),\n",
       "   ('xp', 'Batapalai i kamap pupa.'),\n",
       "   ('xe', '???')]),\n",
       " ('kupukupu',\n",
       "  [('rt', 'kupu'),\n",
       "   ('ps', 'V'),\n",
       "   ('pt', 'A'),\n",
       "   ('rdp', 'full'),\n",
       "   ('ge', 'excited'),\n",
       "   ('ge', 'anxious'),\n",
       "   ('tkp', 'kirapim bel'),\n",
       "   ('vx', '1'),\n",
       "   ('sc', '???'),\n",
       "   ('dt', '07/Sep/2005'),\n",
       "   ('rdp', 'full'),\n",
       "   ('ex', 'Ragai iava vovou isi kupukupuiraopaivo rorupaoro.'),\n",
       "   ('xp', 'Bel bilong mi seksek tru taim mi amamas.'),\n",
       "   ('xe', 'My heart shakes when I am truly happy.')]),\n",
       " ('kurae',\n",
       "  [('ps', 'N'),\n",
       "   ('pt', 'FEM'),\n",
       "   ('ge', 'frog'),\n",
       "   ('tkp', '???'),\n",
       "   ('nt',\n",
       "    'green, rubbery appearance, cries just before the rain to get the ???. Pictured on the 15t PNG postage stamp.'),\n",
       "   ('sf', 'FAUNA'),\n",
       "   ('dt', '04/Dec/2004'),\n",
       "   ('ex', 'Kurae iria gaupaeveira vosia kokeva koveo.'),\n",
       "   ('xp', 'Rokrok bilong bus i save krai long taim bilong ren.'),\n",
       "   ('xe', '???')]),\n",
       " ('kurasia',\n",
       "  [('ps', '???'),\n",
       "   ('ge', 'wrist'),\n",
       "   ('tkp', 'skru bilong han'),\n",
       "   ('dt', '26/Jan/2005')]),\n",
       " ('kurasia',\n",
       "  [('ps', 'N'),\n",
       "   ('pt', 'NT'),\n",
       "   ('ge', 'lower bones of limbs'),\n",
       "   ('tkp', '???'),\n",
       "   ('sf', 'BP'),\n",
       "   ('dt', '04/Dec/2004'),\n",
       "   ('ex', 'Kurasia keru upiapai ragai-re.'),\n",
       "   ('xp', 'Bun bilong mi i pen.'),\n",
       "   ('xe', 'My wrist bone hurts.')]),\n",
       " ('kurei',\n",
       "  [('ps', 'N'),\n",
       "   ('pt', 'FEM'),\n",
       "   ('ge', 'lizard'),\n",
       "   ('tkp', '???'),\n",
       "   ('nt', 'black smooth skin, small, lives near the beach'),\n",
       "   ('sf', 'FAUNA'),\n",
       "   ('dt', '04/Dec/2004'),\n",
       "   ('ex', 'Kurei iria tetevu guruvaro-ia toupaeveira.'),\n",
       "   ('xp', 'Geko i save istap long ol lip saksak.'),\n",
       "   ('xe', '???')]),\n",
       " ('kuri',\n",
       "  [('ps', 'V'),\n",
       "   ('pt', 'B'),\n",
       "   ('ge', 'scrape'),\n",
       "   ('tkp', 'skrapim'),\n",
       "   ('eng', 'scrape'),\n",
       "   ('eng', 'scratch'),\n",
       "   ('eng', 'gnashing'),\n",
       "   ('eng', 'gritting'),\n",
       "   ('arg', 'O'),\n",
       "   ('vx', '2'),\n",
       "   ('dt', '08/Jun/2005'),\n",
       "   ('ex', 'Visii iava reuri oauisii kuripaoro siraovira toupataua voa.'),\n",
       "   ('xp', '???'),\n",
       "   ('xe', 'You were sorrowfully there gritting/grashing your teeth.'),\n",
       "   ('ex', 'Robin, opita kuriu.'),\n",
       "   ('xp', 'Robin, yu skirapim kokonas.'),\n",
       "   ('xe', 'Robin, scrape some coconut.')]),\n",
       " ('kuriato',\n",
       "  [('ps', 'N'),\n",
       "   ('pt', 'FEM'),\n",
       "   ('ge', 'frog'),\n",
       "   ('tkp', '???'),\n",
       "   ('nt', 'very small black body'),\n",
       "   ('dt', '04/Dec/2004'),\n",
       "   ('ex', 'Kuriatoa garepavavi, iria gaupaeveira.'),\n",
       "   ('xp', 'Em wanpela liklik rokrok i save krai ol taim long bus.'),\n",
       "   ('xe', '???')]),\n",
       " ('kurikaakaakuto',\n",
       "  [('ps', 'N'),\n",
       "   ('pt', 'MASC'),\n",
       "   ('ge', 'weevil'),\n",
       "   ('tkp', '???'),\n",
       "   ('nt', 'insect with long proboscis, looks like boll-weevil'),\n",
       "   ('sf', 'FAUNA'),\n",
       "   ('dt', '04/Dec/2004'),\n",
       "   ('ex', 'Kurkaakaakuto kokoruto riropa oruto.'),\n",
       "   ('xp', 'Binatang i gat bikpela garas.'),\n",
       "   ('xe', '???')]),\n",
       " ('kurikasi',\n",
       "  [('ps', 'V'),\n",
       "   ('pt', 'B'),\n",
       "   ('ge', 'urge along'),\n",
       "   ('ge', 'prod along'),\n",
       "   ('tkp', 'hariapim'),\n",
       "   ('arg', 'O'),\n",
       "   ('vx', '2'),\n",
       "   ('dt', '08/Jun/2005'),\n",
       "   ('ex', 'Koie kurikasireva oirato.'),\n",
       "   ('xp', '???'),\n",
       "   ('xe', 'The man urged the pig along.'),\n",
       "   ('ex', 'Pita koue kurikasirevoi kasiura iare.'),\n",
       "   ('xp', 'Pita i hariapaim tru pik i go long banis.'),\n",
       "   ('xe', 'Peter urged the pigs into the fence.')]),\n",
       " ('kurikasivira',\n",
       "  [('rt', 'kurikasi'),\n",
       "   ('ps', 'ADV'),\n",
       "   ('pt', 'MANNER'),\n",
       "   ('ge', 'urgently'),\n",
       "   ('tkp', 'olsem hariap'),\n",
       "   ('dt', '04/Dec/2004'),\n",
       "   ('ex', 'Kurikasivira rutu kareai riakora eisi uupa tapi.'),\n",
       "   ('xp', 'Ol meri i kam bek kwik tru long bung.'),\n",
       "   ('xe', '???')]),\n",
       " ('kurikoko',\n",
       "  [('ps', 'N'),\n",
       "   ('pt', 'NT'),\n",
       "   ('ge', 'orchid'),\n",
       "   ('tkp', 'wanpela kain piaua'),\n",
       "   ('dt', '04/Dec/2004'),\n",
       "   ('ex', 'Kurikoko oa vo toupaiveira evaoara-ia.'),\n",
       "   ('xp', 'Em palaua i save istap long ol diwai.'),\n",
       "   ('xe', '???')]),\n",
       " ('kurikuri',\n",
       "  [('rt', 'kuri'),\n",
       "   ('ps', 'V'),\n",
       "   ('pt', 'B'),\n",
       "   ('ge', 'scratch repeatedly'),\n",
       "   ('tkp', 'skrapim'),\n",
       "   ('arg', 'O'),\n",
       "   ('vx', '2'),\n",
       "   ('dt', '08/Jun/2005'),\n",
       "   ('rdp', 'full'),\n",
       "   ('ex', 'David kavorava kurikruipare.'),\n",
       "   ('xp', 'David i skirapim girire.'),\n",
       "   ('xe', 'David is scratching his grille.'),\n",
       "   ('ex', 'Kurikuripavoi varaua iava.'),\n",
       "   ('xp', 'Skin bilong mi skirap.'),\n",
       "   ('xe', '???')]),\n",
       " ('kuripaa',\n",
       "  [('rt', 'kuri'),\n",
       "   ('ps', 'N'),\n",
       "   ('pt', 'NT'),\n",
       "   ('ge', 'drawknife'),\n",
       "   ('ge', 'scraper'),\n",
       "   ('tkp', 'naip samting'),\n",
       "   ('dt', '07/Mar/2005'),\n",
       "   ('ex', 'Raki, uriou sigo kuripaa-va.'),\n",
       "   ('xp', 'Raki, yu kam wantaim pail.'),\n",
       "   ('xe', 'Raki, come here with the scraper.')]),\n",
       " ('kuritava',\n",
       "  [('ps', 'N'),\n",
       "   ('pt', 'FEM'),\n",
       "   ('ge', 'octopus'),\n",
       "   ('ge', 'squid'),\n",
       "   ('tkp', 'tauka'),\n",
       "   ('dt', '26/Jan/2005'),\n",
       "   ('ex',\n",
       "    'Kuritava iria avakava siovaraia toupaeveira, uvui ra uvuoavai rokopieve.'),\n",
       "   ('xp',\n",
       "    'Urita i save istap insait long solwara, em inap daunim sip i go insait long solwara.'),\n",
       "   ('xe', '???')]),\n",
       " ('kuroa',\n",
       "  [('rt', 'kuro'),\n",
       "   ('ps', 'N'),\n",
       "   ('pt', 'NT'),\n",
       "   ('ge', 'half'),\n",
       "   ('tkp', 'hap'),\n",
       "   ('dt', '07/Dec/2004'),\n",
       "   ('ex', 'Kuroa raga vao-ia kepa, viapau opesiera.'),\n",
       "   ('xp', 'Haus em i hap tasol i no pinis iet.'),\n",
       "   ('xe', \"The haus is half-done, it wasn't finished.\")]),\n",
       " ('kuroea',\n",
       "  [('ps', 'N'),\n",
       "   ('pt', 'NT'),\n",
       "   ('ge', 'vine with leathery appearance'),\n",
       "   ('ge', 'shoe'),\n",
       "   ('tkp', 'wanpela kain rop'),\n",
       "   ('tkp', 'su'),\n",
       "   ('dt', '04/Dec/2004'),\n",
       "   ('ex', 'Iroiro oa vaisipai oisio kuroea, ora tasipara.'),\n",
       "   ('xp', 'Em i rop, tu ol Rotoaksi i save kolim su long dispela frut.'),\n",
       "   ('xe', '???')]),\n",
       " ('kurokuro',\n",
       "  [('rt', 'kuro'),\n",
       "   ('ps', 'V'),\n",
       "   ('pt', 'A'),\n",
       "   ('ge', 'arthritic'),\n",
       "   ('ge', 'paralyzed'),\n",
       "   ('tkp', 'haphapim'),\n",
       "   ('vx', '1'),\n",
       "   ('sc', '???'),\n",
       "   ('dt', '01/Jun/2005'),\n",
       "   ('rdp', 'full'),\n",
       "   ('ex', 'Vavaea korukorupai ragaire.'),\n",
       "   ('xp', '???'),\n",
       "   ('xe', 'My hand is paralyzed.'),\n",
       "   ('ex', 'Ragai-re vavaea kurokuroepa.'),\n",
       "   ('xp', 'Han bilong mi i bin nogut.'),\n",
       "   ('xe', 'My hand is paralyzed.')]),\n",
       " ('kurokuroto',\n",
       "  [('alt', 'kurokuropato'),\n",
       "   ('rt', 'kurokuro'),\n",
       "   ('ps', 'N'),\n",
       "   ('pt', 'HUM'),\n",
       "   ('ge', 'arthritic person'),\n",
       "   ('tkp', '???'),\n",
       "   ('dt', '15/Nov/2005'),\n",
       "   ('ex',\n",
       "    'Ro oirato ira viapau vearovira vokaparevo uva kokotoa ei vuruvira kurukuroto.'),\n",
       "   ('xp', 'Man i no wokabaut gut bikos ol lek bilong em mo em nogut.'),\n",
       "   ('xe', '???')]),\n",
       " ('kuroo',\n",
       "  [('ps', 'N'),\n",
       "   ('pt', '???'),\n",
       "   ('ge', \"child's penis\"),\n",
       "   ('tkp', 'kok bilong pikinini'),\n",
       "   ('nt', 'acceptable in mixed company'),\n",
       "   ('cmt', 'Check spelling: kuro or kuroo? Sentence fragment.'),\n",
       "   ('dt', '04/Dec/2004'),\n",
       "   ('ex', 'Kakaetoa iava kuro.'),\n",
       "   ('xp', 'Bol bilong liklik boi.'),\n",
       "   ('xe', '???')]),\n",
       " ('kurooro',\n",
       "  [('ps', 'N'),\n",
       "   ('pt', 'NT'),\n",
       "   ('ge', 'crumbs'),\n",
       "   ('ge', 'small particles'),\n",
       "   ('tkp', 'ol hap kaikai'),\n",
       "   ('cmt', 'Check spelling kuroro or kurooro?'),\n",
       "   ('dt', '04/Dec/2004'),\n",
       "   ('ex', 'Pita vaio ora Jon aio kurooro aiosivoi.'),\n",
       "   ('xp', 'Pita na Jon i kaikaim ol hap kaikai.'),\n",
       "   ('xe', '???'),\n",
       "   ('ex', 'Aio kuroro tovori evara vearovira.'),\n",
       "   ('xp', 'Yu putim gut ol hap kaikai.'),\n",
       "   ('xe', '???')]),\n",
       " ('kurovira',\n",
       "  [('rt', 'kuro'),\n",
       "   ('ps', 'ADV'),\n",
       "   ('pt', 'MANNER'),\n",
       "   ('ge', 'incompletely'),\n",
       "   ('tkp', 'hapim'),\n",
       "   ('dt', '13/Nov/2005'),\n",
       "   ('ex', 'Kurovira toupaivo rari vuku.'),\n",
       "   ('xp', '???'),\n",
       "   ('xe', 'The trust is incomplete.'),\n",
       "   ('ex', 'Kurovira kepa purarivo.'),\n",
       "   ('xp', 'Yu hapim haus.'),\n",
       "   ('xe', '???'),\n",
       "   ('ex', 'Kurovira aio koko kekeavo ragai vaaro oa aioivo.'),\n",
       "   ('xp',\n",
       "    'Mi lukim pelet kaikai bilong mi olsem ol i kaikai long em na ol i hapim.'),\n",
       "   ('xe', '???')]),\n",
       " ('kuru',\n",
       "  [('ps', 'V'),\n",
       "   ('pt', 'B'),\n",
       "   ('ge', 'strip off branches'),\n",
       "   ('tkp', '???'),\n",
       "   ('dt', '08/Jun/2005'),\n",
       "   ('arg', 'O'),\n",
       "   ('vx', '2'),\n",
       "   ('ex', 'Evaova kururi.'),\n",
       "   ('xp', '???'),\n",
       "   ('xe', 'Strip the tree of all the branches.'),\n",
       "   ('ex', 'Kasiva kuru kekepari vavoisio Ruru.'),\n",
       "   ('xp', 'Yu lukim wanpela han het bilong diwai kanu long Ruru.'),\n",
       "   ('xe', '???')]),\n",
       " ('kurue',\n",
       "  [('ps', 'N'),\n",
       "   ('pt', 'MASC'),\n",
       "   ('ge', 'pigeon'),\n",
       "   ('tkp', 'balus'),\n",
       "   ('eng', 'Spice Imperial Pigeon (Ducula myristicivora)'),\n",
       "   ('eng', 'Pacific Imperial Pigeon (Ducula pacifica)'),\n",
       "   ('dt', '31/Aug/2005'),\n",
       "   ('ex', 'Kurue ira kukua aiopaoro ora toupieparoveira.'),\n",
       "   ('xp', 'Pisin barus i save kaikai garip na istap isi.'),\n",
       "   ('xe', '???')]),\n",
       " ('kurupi',\n",
       "  [('ps', 'N'),\n",
       "   ('pt', '???'),\n",
       "   ('ge', 'starling'),\n",
       "   ('tkp', 'pisin'),\n",
       "   ('eng', 'Singing Starling (Aploni cantoroides)'),\n",
       "   ('nt', 'clan totem'),\n",
       "   ('sa', 'orokui'),\n",
       "   ('sf', 'FAUNA.BIRD'),\n",
       "   ('dt', '12/Jul/2004')]),\n",
       " ('kururai',\n",
       "  [('ps', 'N'),\n",
       "   ('pt', 'FEM'),\n",
       "   ('ge', 'bamboo water carrier'),\n",
       "   ('tkp', '???'),\n",
       "   ('eng', 'two joined sections of bamboo used for carrying water'),\n",
       "   ('dt', '04/Dec/2004'),\n",
       "   ('ex', 'veta kururai ukaepava.'),\n",
       "   ('xp', 'mambu bilong karim wara'),\n",
       "   ('xe', '???'),\n",
       "   ('ex', 'Salome kururae-ia ukovi kaepae.'),\n",
       "   ('xp', 'Salome i karim wara long mambu.'),\n",
       "   ('xe', '???')]),\n",
       " ('kururu',\n",
       "  [('ps', 'V'),\n",
       "   ('pt', 'B'),\n",
       "   ('ge', 'crumble something'),\n",
       "   ('tkp', '???'),\n",
       "   ('arg', 'O'),\n",
       "   ('vx', '2'),\n",
       "   ('dt', '08/Jun/2005'),\n",
       "   ('ex', 'Va kurururi.'),\n",
       "   ('xp', '???'),\n",
       "   ('xe', 'You crumble it.'),\n",
       "   ('ex', 'Bisketea aiopaoro va kururuavoi.'),\n",
       "   ('xp', 'Mi kaikaim bisket na i bruk liklik tru.'),\n",
       "   ('xe', '???')]),\n",
       " ('kurutu',\n",
       "  [('ps', 'N'),\n",
       "   ('pt', 'NT'),\n",
       "   ('ge', 'portion'),\n",
       "   ('ge', 'part of'),\n",
       "   ('tkp', '???'),\n",
       "   ('dt', '04/Dec/2004'),\n",
       "   ('ex', 'Uuko kurutu vateri eva.'),\n",
       "   ('xp', '???'),\n",
       "   ('xe', 'Give that half full cup of water (to him).'),\n",
       "   ('ex', 'Uko kurutu vateri eva ragai-pa.'),\n",
       "   ('xp', 'Yu givim hap wara long mi.'),\n",
       "   ('xe', '???')]),\n",
       " ('Kusi',\n",
       "  [('ps', 'N'),\n",
       "   ('pt', 'PN'),\n",
       "   ('ge', 'village name'),\n",
       "   ('tkp', 'ples nem'),\n",
       "   ('dx', 'Aita'),\n",
       "   ('dt', '04/Dec/2004'),\n",
       "   ('ex', 'Uruia vaisiaro aue kusi oa toupai eisi Aita.'),\n",
       "   ('xp', 'Nem bilong ples Kusi istap long Aita.'),\n",
       "   ('xe', '???')]),\n",
       " ('kusii',\n",
       "  [('ps', 'V'),\n",
       "   ('pt', 'A'),\n",
       "   ('ge', 'cool off'),\n",
       "   ('tkp', '???'),\n",
       "   ('dt', '01/Jun/2005'),\n",
       "   ('vx', '1'),\n",
       "   ('sc', '???'),\n",
       "   ('ex', 'Varaua rera-re kusiipe.'),\n",
       "   ('xp', '???'),\n",
       "   ('xe', 'His body would cool off.'),\n",
       "   ('ex', 'Ukoara kusiipapeira eisi Tutue.'),\n",
       "   ('xp', 'Ol wara i save kol long Balbi.'),\n",
       "   ('xe', 'The waters are always cold on Mt. Balbi.')]),\n",
       " ('kusike',\n",
       "  [('ps', 'N'),\n",
       "   ('pt', 'FEM'),\n",
       "   ('ge', 'rat'),\n",
       "   ('tkp', 'rat'),\n",
       "   ('nt', 'archaic'),\n",
       "   ('sa', 'isike'),\n",
       "   ('dt', '04/Dec/2004'),\n",
       "   ('ex', 'Kusike votoupai vegoaro ora vo kepara sovaraia.'),\n",
       "   ('xp', 'Rat em i stap long bus na em i stap tu long ples.'),\n",
       "   ('xe', 'Rats are in the bush and also in houses.'),\n",
       "   ('ex', 'Kusike upoevo epusi.'),\n",
       "   ('xp', 'Pusi i kilim rat.'),\n",
       "   ('xe', 'The cat killed the rat.')]),\n",
       " ('kusito',\n",
       "  [('ps', 'N'),\n",
       "   ('pt', 'MASC'),\n",
       "   ('ge', 'shellfish'),\n",
       "   ('ge', 'scallop'),\n",
       "   ('tkp', '???'),\n",
       "   ('nt',\n",
       "    'So called because in the past the shell was attached to a piece of wood ???'),\n",
       "   ('dt', '04/Dec/2004'),\n",
       "   ('ex', 'Kusito opita kuripato.'),\n",
       "   ('xp', 'Skarap bilong skarapim kokonas.'),\n",
       "   ('xe', '???')]),\n",
       " ('kuu',\n",
       "  [('ps', '???'),\n",
       "   ('ge', 'talk.from.the.grave'),\n",
       "   ('eng', 'talk to dead man'),\n",
       "   ('eng', \"dead person's talk\"),\n",
       "   ('tkp', '???'),\n",
       "   ('dcsv', 'true'),\n",
       "   ('vx', '???'),\n",
       "   ('cmt',\n",
       "    \"Is this archaic? Isn't recognized by informants, who only can think of ku (short vowel). It may be that kuupie is rootless?\"),\n",
       "   ('dt', '27/Sep/2006')]),\n",
       " ('kuu',\n",
       "  [('ps', 'V'),\n",
       "   ('pt', 'B'),\n",
       "   ('ge', 'satisfied with'),\n",
       "   ('ge', 'finished with'),\n",
       "   ('tkp', 'hepi long en'),\n",
       "   ('tkp', 'pinisim'),\n",
       "   ('cmt',\n",
       "    \"Check vowel length. Don't really understand this... Need more examples and some follow-up.\"),\n",
       "   ('vx', '???'),\n",
       "   ('arg', '???'),\n",
       "   ('dt', '27/Sep/2006'),\n",
       "   ('ex', 'Vii kupaavoi eva opesirivo.'),\n",
       "   ('xp', 'Mi lak save yu pisism dispela.'),\n",
       "   ('xe', '???'),\n",
       "   ('ex', 'Vii kupavoi oisio e kovoa opesirivo.'),\n",
       "   ('xp', 'Mi laik save, yu pinisim wok bilong yu.'),\n",
       "   ('xe', '???'),\n",
       "   ('ex', 'Rarasori kovoara rutu kupare ra karero verevira eisi-re Amerika.'),\n",
       "   ('xp', 'Rarason bai pinim tru ol wok bihain bai em i go bek long Amerika.'),\n",
       "   ('xe', 'Robinson is going to finish all of the work ???.')]),\n",
       " ('kuukuuvu',\n",
       "  [('rt', 'kuuvu'),\n",
       "   ('ps', 'V'),\n",
       "   ('pt', 'A'),\n",
       "   ('ge', 'lie'),\n",
       "   ('ge', 'deceive'),\n",
       "   ('tkp', 'giamanim'),\n",
       "   ('vx', '1'),\n",
       "   ('sc', '???'),\n",
       "   ('dt', '07/Sep/2005'),\n",
       "   ('cmt', 'Follow up on second example.'),\n",
       "   ('rdp', 'partial'),\n",
       "   ('ex', 'Kuukuuvupaue vii.'),\n",
       "   ('xp', 'Yu giaman man.'),\n",
       "   ('xe', 'You lie.'),\n",
       "   ('ex', 'Vori areae riro kuukuuva-va ruvaraia riakova.'),\n",
       "   ('xp', 'Ol i askim moni long meri bilong giaman.'),\n",
       "   ('xe', 'They ask for money for the lying woman.')]),\n",
       " ('kuukuuvuto',\n",
       "  [('alt', 'kuukuuvupato'),\n",
       "   ('rt', 'kuukuuvu'),\n",
       "   ('ps', 'N'),\n",
       "   ('pt', 'HUM'),\n",
       "   ('ge', 'liar'),\n",
       "   ('ge', 'deceiver'),\n",
       "   ('tkp', '???'),\n",
       "   ('dt', '02/Sep/2005'),\n",
       "   ('ex', 'Pita riro kuukuuvuto.'),\n",
       "   ('xp', 'Pita em i man bilong giaman man.'),\n",
       "   ('xe', 'Peter is a big liar.'),\n",
       "   ('ex', 'Riro kuukuuvuva vii.'),\n",
       "   ('xp', 'Yu man bilong giaman.'),\n",
       "   ('xe', \"You're a liar.\"),\n",
       "   ('ex', 'Tugarato riro kuukuuvuto ira oirara keakeapareveira.'),\n",
       "   ('xp', 'Setan i man bilong giaman em i save giamanim ol man.'),\n",
       "   ('xe', 'Satan is a big liar who deceives people.')]),\n",
       " ('kuuoa',\n",
       "  [('ps', 'N'),\n",
       "   ('pt', 'NT'),\n",
       "   ('ge', 'owl'),\n",
       "   ('tkp', 'korol'),\n",
       "   ('nt', 'small brown body, large yellow eyes, wire tufts around the'),\n",
       "   ('cmt',\n",
       "    \"According to Wakunai informants, it's kuo (short 'o' and no final 'a'), and is used for all owls. Need to double-check.\"),\n",
       "   ('sf', 'FAUNA.BIRD'),\n",
       "   ('dt', '08/Mar/2005'),\n",
       "   ('ex',\n",
       "    'Kuuoa viro osireiva vokiaro vokapaeveira papapaoro ora ava-ia uusipaoveira.'),\n",
       "   ('xp',\n",
       "    'I gat bikpela ei na em i save fly long nait i slip long ol hol bilong diwai.'),\n",
       "   ('xe', '???'),\n",
       "   ('ex', 'Kuuo iria gaupaeveira vokiaro.'),\n",
       "   ('xp', 'Korol i save karai long nait.'),\n",
       "   ('xe', 'The owl cries at night.')]),\n",
       " ('kuupie',\n",
       "  [('rt', 'kuu'),\n",
       "   ('ps', 'V'),\n",
       "   ('pt', 'B'),\n",
       "   ('ge', 'talk.to.the.dead'),\n",
       "   ('tkp', 'tokim dai man'),\n",
       "   ('eng', 'speak to the dead'),\n",
       "   ('eng', 'communicate with the spirit of a dead person'),\n",
       "   ('arg', 'O'),\n",
       "   ('vx', '2'),\n",
       "   ('cmt', \"Does 'rera' with 'ukaiopiesia' refer to a drinker or drinkee?\"),\n",
       "   ('dt', '08/Dec/2005'),\n",
       "   ('ex', 'Kuupiereva.'),\n",
       "   ('xp', '???'),\n",
       "   ('xe', 'He caused the spirit of the dead person to speak.'),\n",
       "   ('ex', 'Siorairara oisioa kopiiirara kuupiepaive.'),\n",
       "   ('xp', 'Ol poisin man i save singautim spirit bilong ol dai man.'),\n",
       "   ('xe', 'Poison men always talk to the spirits of the dead.'),\n",
       "   ('ex', 'Kuu oirato kuupiepaveira vosa ruva tovarovoive.'),\n",
       "   ('xp', '???'),\n",
       "   ('xe', '???'),\n",
       "   ('ex', 'Uva Kokota Tovisia kuupiepareva.'),\n",
       "   ('xp', 'Kokota i singautim spirit bilong Tovisia.'),\n",
       "   ('xe', 'And Kokota spoke to the spirit of Tovisia.'),\n",
       "   ('ex', 'Kopito kuupieivo eisi tova urui rera ukaiopiesia.'),\n",
       "   ('xp', 'Ol i kolim dai man long matmat long mekim em dring.'),\n",
       "   ('xe', '???')]),\n",
       " ('kuurea',\n",
       "  [('ps', 'N'),\n",
       "   ('pt', 'FEM'),\n",
       "   ('ge', 'gecko'),\n",
       "   ('tkp', 'geko'),\n",
       "   ('nt', 'large with white skin'),\n",
       "   ('sf', 'FAUNA'),\n",
       "   ('dt', '10/Feb/2005'),\n",
       "   ('ex', 'Korikoripato vavauiavo oiso vera osa.'),\n",
       "   ('xp', 'Em i gat ol makmak ol luk okam geko.'),\n",
       "   ('xe', '???'),\n",
       "   ('ex', 'Kuurea ira toupareveira tetevu guruvaro siovaraia.'),\n",
       "   ('xp', 'Geko i save istap insait long ol lip saksak.'),\n",
       "   ('xe', 'The kuurea gecko lives on the leaves of sago.')]),\n",
       " ('kuuri',\n",
       "  [('ps', 'V'),\n",
       "   ('pt', 'A'),\n",
       "   ('ge', 'grunt'),\n",
       "   ('ge', 'huff and puff'),\n",
       "   ('tkp', 'pulim win strong'),\n",
       "   ('vx', '1'),\n",
       "   ('sc', 'BODILY.PROCESS'),\n",
       "   ('cmt', 'Need ex to illustrate subj agreement'),\n",
       "   ('dt', '01/Jun/2005'),\n",
       "   ('cmt', 'Check original--first verb is dependent verb, no?'),\n",
       "   ('ex', 'Pita kuuripaoro iiparoei vaisia-ia.'),\n",
       "   ('xp', 'Pita em i pulim strongpela win taim i go antap long maunten.'),\n",
       "   ('xe', 'Peter is going up the mountain huffing and puffing.')]),\n",
       " ('kuuva',\n",
       "  [('ps', '???'),\n",
       "   ('ge', 'blue'),\n",
       "   ('ge', 'purple'),\n",
       "   ('tkp', 'blupela'),\n",
       "   ('tkp', 'pepol'),\n",
       "   ('dt', '14/Nov/2005'),\n",
       "   ('ex',\n",
       "    'Siroiri kuuvapa isi karuvera isi erievo ragai-pa uva vo ogatava karerai va orisia.'),\n",
       "   ('xp',\n",
       "    'Siroiri em i digim pepolpela singapo bilong mi na mi woksakim i kam long peles long kukim.'),\n",
       "   ('xe', '???')]),\n",
       " ('kuuvaki',\n",
       "  [('ps', 'V'),\n",
       "   ('pt', 'A'),\n",
       "   ('ge', 'quiet'),\n",
       "   ('tkp', '???'),\n",
       "   ('vx', '1'),\n",
       "   ('sc', '???'),\n",
       "   ('dt', '01/Jun/2005'),\n",
       "   ('ex',\n",
       "    'Oirato kuuvakito roira viapau reoparoveira ova veva vovouaro ragai toupareve.'),\n",
       "   ('xp', 'Mau i no nap toktok tumas em bai i stap ig tasol.'),\n",
       "   ('xe', '???'),\n",
       "   ('ex', 'Kuvakivira toupareveira.'),\n",
       "   ('xp', 'Em i save istap isi na em i no save toktok.'),\n",
       "   ('xe', 'He is usually quiet.')]),\n",
       " ('kuuvakito',\n",
       "  [('rt', 'kuuvaki'),\n",
       "   ('ps', 'N'),\n",
       "   ('pt', 'HUM'),\n",
       "   ('ge', \"quiet person who doesn't talk much\"),\n",
       "   ('ge', 'docile person'),\n",
       "   ('tkp', '???'),\n",
       "   ('avm', 'pa_barred'),\n",
       "   ('dt', '02/Sep/2005'),\n",
       "   ('ex', 'Roo ira viapau ririvira reo puraparo.'),\n",
       "   ('xp', 'Man ino save toktok tuma.'),\n",
       "   ('xe', \"One who doesn't ???.\"),\n",
       "   ('ex', 'Kuvakitoa ro oirato ira viapau rirovira reoreoparo.'),\n",
       "   ('xp', 'Man bilong istap isi na em i no save toktok tumas.'),\n",
       "   ('xe', \"A quiet man is a man who doesn't talk much.\")]),\n",
       " ('kuuvato',\n",
       "  [('ps', 'N'),\n",
       "   ('pt', 'MASC'),\n",
       "   ('ge', 'parrot'),\n",
       "   ('tkp', '???'),\n",
       "   ('eng', 'Eclectus Parrot (Eclectus roratus)'),\n",
       "   ('sa', 'sikarato'),\n",
       "   ('sf', 'FAUNA.BIRD'),\n",
       "   ('dt', '10/Feb/2005'),\n",
       "   ('ex', 'Sikavoto kuuvato kokovavavira toupare.'),\n",
       "   ('xp', 'Parrot em blue va em green pinis.'),\n",
       "   ('xe', '???'),\n",
       "   ('ex', 'Kuuvato kokovarato kokioto.'),\n",
       "   ('xp', 'Parot em i grinpela pisin.'),\n",
       "   ('xe', 'The kuuvato is a green pidgin.')]),\n",
       " ('kuuvavira',\n",
       "  [('rt', 'kuuva'),\n",
       "   ('ps', 'ADV'),\n",
       "   ('pt', 'MANNER'),\n",
       "   ('ge', 'blue'),\n",
       "   ('tkp', 'blupela'),\n",
       "   ('cmt', 'Also translated as pepol/purple'),\n",
       "   ('dt', '14/Nov/2005'),\n",
       "   ('cmt',\n",
       "    'Again, the adv kuuvavira is used to modify A in 2nd example. Check Tok Pisin on 1st example.'),\n",
       "   ('ex', 'Kuuvavira kekepapiroi vavoisi.'),\n",
       "   ('xp', 'Em i luk blu long hap i noway tru.'),\n",
       "   ('xe', 'It looks blue there.'),\n",
       "   ('ex', 'Avakava kuuvavira kekeavoi uva siraorai.'),\n",
       "   ('xp', 'Mi lukim solwara i blu turu, na mi sori.'),\n",
       "   ('xe', 'I saw the ocean looking blue and I felt sad.'),\n",
       "   ('ex', 'Kuuvavira kekepapiroi eva purpurua ovusia va kaepari.'),\n",
       "   ('xp', '???'),\n",
       "   ('xe', '???'),\n",
       "   ('ex',\n",
       "    'Kuuvapavira rutu paruvo uukovi vo va tegoto ovusia rera toerevo Sipei.'),\n",
       "   ('xp',\n",
       "    'Wara bilong wail banana i ron na i luk pepol stret taim Sipei i katim daun nail banana.'),\n",
       "   ('xe', 'The water from the wild banana flowed purple as Sipei cut it.')]),\n",
       " ('kuuvu',\n",
       "  [('ps', 'V'),\n",
       "   ('pt', 'A'),\n",
       "   ('ge', 'lie'),\n",
       "   ('ge', 'deceive'),\n",
       "   ('tkp', 'tok giaman'),\n",
       "   ('vx', '1'),\n",
       "   ('sc', '???'),\n",
       "   ('dt', '01/Jun/2005'),\n",
       "   ('ex', 'Asi vii vai kuuvupauei vo vokio.'),\n",
       "   ('xp', 'Ating yu tok giaman tude!'),\n",
       "   ('xe', 'Why you are lying today, I think!'),\n",
       "   ('ex', 'Apoka, kuuvupauei, riro kuuvuto vii.'),\n",
       "   ('xp', 'Apoka, yu giaman, man bilong giaman.'),\n",
       "   ('xe', \"Apoka, you're lying, you big liar.\")]),\n",
       " ('kuuvuvira',\n",
       "  [('rt', 'kuuvu'),\n",
       "   ('ps', 'ADV'),\n",
       "   ('pt', 'MANNER'),\n",
       "   ('ge', 'deceptively'),\n",
       "   ('ge', 'untruthfully'),\n",
       "   ('ge', 'illusive'),\n",
       "   ('tkp', '???'),\n",
       "   ('dt', '10/Feb/2005'),\n",
       "   ('ex', 'Kuuvuvira ita toupare evoa ra avaro Buka iare.'),\n",
       "   ('xp', 'Em i stap giaman gen bai i go long Buka.'),\n",
       "   ('xe', '???.'),\n",
       "   ('ex', 'Kuuvuvira reo purapa ra kaviruro.'),\n",
       "   ('xp', 'Em i toktok giaman gen bai em stil.'),\n",
       "   ('xe', '???.'),\n",
       "   ('ex', 'Jeri kuuvuvira uusiparoi ra vokiaro vokapasia avaro.'),\n",
       "   ('xp', 'Jerry i slip giaman, bai em i go raun long nait.'),\n",
       "   ('xe', 'Jerry pretends to sleep and goes out and about at night.')]),\n",
       " ('kuva',\n",
       "  [('ps', 'V'),\n",
       "   ('pt', 'B'),\n",
       "   ('ge', 'work sorcery'),\n",
       "   ('tkp', 'gip papait'),\n",
       "   ('eng', 'work sorcery'),\n",
       "   ('eng', 'do black magic'),\n",
       "   ('arg', 'O'),\n",
       "   ('vx', '2'),\n",
       "   ('dt', '08/Jun/2005'),\n",
       "   ('ex', 'Uririparaepa oiso teapi ragai kuvaive.'),\n",
       "   ('xp', '???'),\n",
       "   ('xe', 'I was afraid lest they would work sorcery on me.'),\n",
       "   ('ex', 'Latu uririparoera oisio teapi rera kuvaive.'),\n",
       "   ('xp', 'Lati i poret olsem nogut ol i poisinim em.'),\n",
       "   ('xe', 'Latu is afraid that they will poisin him.')]),\n",
       " ('kuvaku',\n",
       "  [('ps', 'N'),\n",
       "   ('pt', 'FEM'),\n",
       "   ('ge', 'plant'),\n",
       "   ('tkp', '???'),\n",
       "   ('sf', 'FLORA'),\n",
       "   ('nt',\n",
       "    'After the smashed branch was in place, the area of the break was warmed ??? , branches were smashed and used as splints for holding ???'),\n",
       "   ('dt', '12/Feb/2005'),\n",
       "   ('ex', 'Voari tuariri oisioa oirato kuvakupaive, rara kovero orakepisia.'),\n",
       "   ('xp',\n",
       "    'Bipo ol man i save putim kuvaku long man sapos em i pundaun na brukim lek.'),\n",
       "   ('xe', '???')]),\n",
       " ('kuvato',\n",
       "  [('ps', '???'),\n",
       "   ('ge', 'name of clan'),\n",
       "   ('tkp', '???'),\n",
       "   ('dt', '04/Dec/2004'),\n",
       "   ('ex', 'Siara oa vaisipaiveira oisio kuvato eisi Aita.'),\n",
       "   ('xp', 'Nem bilong wanpela bisnis ol Aita i save kolim long kuvato.'),\n",
       "   ('xe', '???')]),\n",
       " ('kuvau',\n",
       "  [('ps', 'V'),\n",
       "   ('pt', 'A'),\n",
       "   ('ge', 'alone'),\n",
       "   ('tkp', 'ples i nogat man'),\n",
       "   ('dcsv', 'true'),\n",
       "   ('vx', '1'),\n",
       "   ('sc', '???'),\n",
       "   ('dt', '02/Jun/2005'),\n",
       "   ('ex', 'Kuvauuei.'),\n",
       "   ('xp', '???'),\n",
       "   ('xe', 'You are all alone.'),\n",
       "   ('ex', 'Togarao-ia kuvauei rutu, viapau oirara ora riakoravai.'),\n",
       "   ('xp', 'Ples Togarao i nogat  manmeri tru.'),\n",
       "   ('xe', '???')]),\n",
       " ('kuvaupie',\n",
       "  [('rt', 'kuvau'),\n",
       "   ('ps', 'V'),\n",
       "   ('pt', 'B'),\n",
       "   ('ge', 'desert'),\n",
       "   ('ge', 'leave alone'),\n",
       "   ('tkp', '???'),\n",
       "   ('cm', '-re'),\n",
       "   ('arg', 'OBL'),\n",
       "   ('vx', '2'),\n",
       "   ('dt', '08/Jun/2005'),\n",
       "   ('ex', 'Ragai-re kuvaupieri kopioro.'),\n",
       "   ('xp', 'Yu dai bai mi tasol istap wan pis.'),\n",
       "   ('xe', 'You will die, leaving me behind.'),\n",
       "   ('ex', 'Ragai-re kuvaupietavoi kareoro eisi-re atoia.'),\n",
       "   ('xp', 'Yupela lusim mi na go long ples, na mi i stap wanpis.'),\n",
       "   ('xe', 'You return to the village, leaving me behind.'),\n",
       "   ('ex', 'Ovokivu-ia kuvaupieiva vikuoro vo-re opopasia.'),\n",
       "   ('xp', '???'),\n",
       "   ('xe',\n",
       "    'One time they deserted (the village) going to the garden to get taro.'),\n",
       "   ('ex', 'Avai kovosia kuvaupieoro vova.'),\n",
       "   ('xp', 'Nogat man long hia olgeta i go work.'),\n",
       "   ('xe', '???')]),\n",
       " ('kuvauvira',\n",
       "  [('rt', 'kuvau'),\n",
       "   ('ps', 'ADV'),\n",
       "   ('pt', 'MANNER'),\n",
       "   ('ge', 'alone'),\n",
       "   ('ge', 'isolated'),\n",
       "   ('tkp', '???'),\n",
       "   ('dt', '04/Dec/2004'),\n",
       "   ('ex', 'Kuvauvira toupari.'),\n",
       "   ('xp', '???'),\n",
       "   ('xe', 'You are all alone.'),\n",
       "   ('ex', 'Kovatoa-ia toupaiveira kuvauvira.'),\n",
       "   ('xp', 'Mi save istap wanpis long kovatoa.'),\n",
       "   ('xe', '???')]),\n",
       " ('kuvera',\n",
       "  [('ps', 'V'),\n",
       "   ('pt', 'B'),\n",
       "   ('ge', 'net fish or animals'),\n",
       "   ('tkp', 'wokim umben'),\n",
       "   ('cmt',\n",
       "    'Example looks like incorporation. Double-check verb classification (A or B).'),\n",
       "   ('vx', '???'),\n",
       "   ('dt', '22/Nov/2005'),\n",
       "   ('ex',\n",
       "    'Kuverapare ovusia rera-pa atari kare sigupavoi ra ora kiukiuave kuveraua sovarai ravo kare oureve vokare orisia.'),\n",
       "   ('xp',\n",
       "    'Em i wok long net taim mi raun ol pis na bai ol i go sinait umben na bai em i kisim ol na kukim ol.'),\n",
       "   ('xe', '???'),\n",
       "   ('ex', 'Rokoe atari-kuveraroepa avakava-ia.'),\n",
       "   ('xp', '???'),\n",
       "   ('xe', 'Rokoe netted fish in the sea.')]),\n",
       " ('kuverava',\n",
       "  [('ps', 'N'),\n",
       "   ('pt', 'FEM'),\n",
       "   ('ge', 'net'),\n",
       "   ('ge', 'spider web'),\n",
       "   ('ge', 'strainer'),\n",
       "   ('tkp', 'umben haus bilong spaida'),\n",
       "   ('dt', '08/Mar/2005'),\n",
       "   ('ex', 'Kuverava kokio kuverapava vo vegoaro.'),\n",
       "   ('xp', 'Ubian bilong kisim pisin long bus.'),\n",
       "   ('xe', '???'),\n",
       "   ('ex', 'Kuverava atari kuverapava ora aue kavari kokio.'),\n",
       "   ('xp', 'Net blong netim fish.'),\n",
       "   ('xe', '???'),\n",
       "   ('ex', 'Pita oiraaro kuverava atari kuverapava avakava-ia.'),\n",
       "   ('xp', 'Ubian bilong Pita, em i save kisim pis long solwara.'),\n",
       "   ('xe', '???')]),\n",
       " ('kuvere',\n",
       "  [('ps', 'V'),\n",
       "   ('pt', 'B'),\n",
       "   ('ge', 'make an echo'),\n",
       "   ('tkp', 'krai i kam bek'),\n",
       "   ('cmt', 'Need simple example'),\n",
       "   ('arg', '???'),\n",
       "   ('vx', '???'),\n",
       "   ('dt', '08/Jun/2005'),\n",
       "   ('ex',\n",
       "    'Vosa pukuia kukueavo torepay ra kakupiepari ora oiveta ra ova vioepaurere viraga. Keapauvere oiso oravu vi atopare.'),\n",
       "   ('xp',\n",
       "    'Taim yu stap antap name long tupela maunten na yu singaut bikpela bai singaut blong yu bai go. Na yu ting olsen wanpela man i mekim??sigaut blong yu.'),\n",
       "   ('xe', '???'),\n",
       "   ('ex', 'Ora vii raga reraro kuvereto vii aatoparevoi.'),\n",
       "   ('xp', 'Singaut bilong yu tasol i pairap na i bekim yu.'),\n",
       "   ('xe', '???')]),\n",
       " ('kuverea',\n",
       "  [('rt', 'kuvere'),\n",
       "   ('ps', '???'),\n",
       "   ('ge', 'incomplete'),\n",
       "   ('ge', 'unready'),\n",
       "   ('ge', 'not all right'),\n",
       "   ('tkp', 'i no redi'),\n",
       "   ('dt', '02/Jun/2005'),\n",
       "   ('ex', 'Kuverea vao-ia opoa. Kuverea vao-ia opeitarai ovoipa.'),\n",
       "   ('xp', 'Tam ino ready yet. Dispela kaikai ino ready yet.'),\n",
       "   ('xe', '???'),\n",
       "   ('ex', 'Kuverea raga vao-ia opoa.'),\n",
       "   ('xp', 'Em taro i no orait.'),\n",
       "   ('xe', '???')]),\n",
       " ('kuvereto',\n",
       "  [('rt', 'kuvere'),\n",
       "   ('ps', 'N'),\n",
       "   ('pt', 'MASC'),\n",
       "   ('ge', 'echo'),\n",
       "   ('tkp', 'krai i kam bek'),\n",
       "   ('dt', '15/Nov/2005'),\n",
       "   ('ex', 'Vii raga oravioepaue.'),\n",
       "   ('xp', 'Yu tasol yu bihanim toktok bla??.'),\n",
       "   ('xe', '???'),\n",
       "   ('ex', 'Andru kakuupiepare ovusia kuvereto pokoparovi vavoisio.'),\n",
       "   ('xp', 'Andru i singaut na singaut bilong em yet i pairap long hap.'),\n",
       "   ('xe', '???')]),\n",
       " ('kuverevira',\n",
       "  [('rt', 'kuvere'),\n",
       "   ('ps', 'ADV'),\n",
       "   ('pt', 'MANNER'),\n",
       "   ('ge', 'incompletely'),\n",
       "   ('tkp', 'i no redi'),\n",
       "   ('dt', '04/Dec/2004'),\n",
       "   ('ex', 'Kuverevira kovoa toupaivo opeitai ovoipai.'),\n",
       "   ('xp', 'Gaden i no ready yet tru.'),\n",
       "   ('xe', \"The garden isn't ready yet.\"),\n",
       "   ('ex', 'Kuverevira raga toupai upiriko kovo.'),\n",
       "   ('xp', 'Gaden kaukau i no orait iet.'),\n",
       "   ('xe', '???')]),\n",
       " ('kuvoro',\n",
       "  [('ps', 'V'),\n",
       "   ('pt', 'A'),\n",
       "   ('ge', 'burnt out'),\n",
       "   ('ge', 'extinguished'),\n",
       "   ('tkp', 'i no gat paia'),\n",
       "   ('eng', 'burned out'),\n",
       "   ('eng', 'extinguished'),\n",
       "   ('cmt',\n",
       "    'Seems to have extended meaning. Get examples of the literal and figurative meanings.'),\n",
       "   ('dt', '02/Jun/2005'),\n",
       "   ('vx', '1'),\n",
       "   ('sc', '???'),\n",
       "   ('ex', \"Uva oiso puraaepa, ``Eavoeao, e kuvorotae?''.\"),\n",
       "   ('xp', '???'),\n",
       "   ('xe', \"They said this, ``Why, are you all burned out?''.\"),\n",
       "   ('ex', 'Jekop kuvororoe eisi vegoaro ravapaoro.'),\n",
       "   ('xp', 'Jekop i slip nogat long nait taim em i lukaut kapul long bus.'),\n",
       "   ('xe', 'Jekop burnt out in the jungle looking for possum. (???)')]),\n",
       " ('kuvu',\n",
       "  [('ps', 'V'),\n",
       "   ('pt', 'B'),\n",
       "   ('ge', 'fill.up'),\n",
       "   ('tkp', 'pulamapim'),\n",
       "   ('tkp', 'putim kaikai insait long mambu'),\n",
       "   ('eng', 'fill up'),\n",
       "   ('eng', 'put inside bamboo'),\n",
       "   ('eng', 'clothe'),\n",
       "   ('arg', 'O'),\n",
       "   ('vx', '2'),\n",
       "   ('dt', '08/Jun/2005'),\n",
       "   ('cmt',\n",
       "    \"Is John filling the pig with bamboo or vice-versa in the 2nd ex sentence? What's the arg structure?\"),\n",
       "   ('ex', 'Vosia koieavai upoa oisoa iriai kuvua aue-ia veeta.'),\n",
       "   ('xp', '???'),\n",
       "   ('xe',\n",
       "    'When I would kill a pig, I would always put it inside bamboo tubes.'),\n",
       "   ('ex', 'Jon koie kori kuvupare aue-ia veeta.'),\n",
       "   ('xp', 'Jon i wok long pulamapim pik long mambu.'),\n",
       "   ('xe', 'John is filling the bamboo with pig. (Or vice-versa?)')]),\n",
       " ('kuvuara',\n",
       "  [('ps', 'N'),\n",
       "   ('pt', 'NT'),\n",
       "   ('ge', 'clothing'),\n",
       "   ('tkp', 'klos'),\n",
       "   ('eng', 'clothes'),\n",
       "   ('eng', 'clothing'),\n",
       "   ('eng', 'apparel'),\n",
       "   ('dt', '07/Feb/2005'),\n",
       "   ('ex',\n",
       "    'Vievara kuvuara ragai varao veavopava kuvuara ora vorioro karerai esis sitoa??.'),\n",
       "   ('xp', 'Em ol colhing blong yu. Yu buy ikam long store.'),\n",
       "   ('xe', '???'),\n",
       "   ('ex', 'Ragai vaararoa varao kuvuara, oara voriavo.'),\n",
       "   ('xp', 'Em ol dispela siot bilong mi, mi bin baim.'),\n",
       "   ('xe', 'This clothing of mine, I bought it.')]),\n",
       " ('kuvukuvu',\n",
       "  [('rt', 'kuvu'),\n",
       "   ('ps', 'V'),\n",
       "   ('pt', 'B'),\n",
       "   ('rdp', 'full'),\n",
       "   ('ge', 'fill up'),\n",
       "   ('ge', 'stamp the ground'),\n",
       "   ('tkp', 'pulapim krungutim graun'),\n",
       "   ('vx', '2'),\n",
       "   ('arg', 'O'),\n",
       "   ('cmt', 'Need good example; this example'),\n",
       "   ('dt', '08/Dec/2005'),\n",
       "   ('ex', 'Koue kuvukuvuivo aue-ia veeta vara tutupaoro rasitoa-ia.'),\n",
       "   ('xp', 'Ol i pulumapim ol mambu pik long mambu.'),\n",
       "   ('xe', 'They filled the pig with bamboo and buried it in the ground.')]),\n",
       " ('kuvukuvua',\n",
       "  [('rt', 'kuvukuvu'),\n",
       "   ('ps', 'N'),\n",
       "   ('pt', 'NT'),\n",
       "   ('ge', 'pole planted in the ground as sounding board'),\n",
       "   ('tkp', 'diwai bilong autim nois'),\n",
       "   ('dt', '07/Feb/2005'),\n",
       "   ('ex', 'Totoueua-ia kuvkuvua purarevo Pauro, rasitoa-ia va tovaoro.'),\n",
       "   ('xp',\n",
       "    'Pauro i palanim hap diwai long graun. Taim ol man i wok long kruktim na i wok long pairap.'),\n",
       "   ('xe', 'Paul planted ???.')]),\n",
       " ('kuvupato',\n",
       "  [('alt', 'kuvuto'),\n",
       "   ('rt', 'kuvu'),\n",
       "   ('ps', 'N'),\n",
       "   ('pt', 'MASC'),\n",
       "   ('ge', 'shirt'),\n",
       "   ('eng', 'shirt'),\n",
       "   ('eng', 'jacket'),\n",
       "   ('eng', 'coat'),\n",
       "   ('tkp', 'klos'),\n",
       "   ('tkp', 'saket'),\n",
       "   ('sc', '???'),\n",
       "   ('dt', '02/Sep/2005'),\n",
       "   ('ex', 'Ragai reraaro kuvupato kavirurevo Pita.'),\n",
       "   ('xp', 'Pita em i stilim siot bilong mi.'),\n",
       "   ('xe', 'Peter stole my shirt.')]),\n",
       " ('kuvuto',\n",
       "  [('ps', 'N'),\n",
       "   ('pt', '???'),\n",
       "   ('ge', 'clothes'),\n",
       "   ('ge', 'clothing'),\n",
       "   ('tkp', 'laplap'),\n",
       "   ('dt', '28/Jul/2004')])]"
      ]
     },
     "execution_count": 119,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# https://software.sil.org/toolbox/\n",
    "from nltk.corpus import toolbox\n",
    "toolbox.entries('rotokas.dic')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5   WordNet\n",
    "\n",
    "WordNet is a semantically-oriented dictionary of English, similar to a traditional thesaurus but with a richer structure. \n",
    "\n",
    "NLTK includes the English WordNet, with **155,287 words** and **117,659 synonym sets**. \n",
    "\n",
    "### 5.1   Senses and Synonyms"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[Synset('car.n.01')]"
      ]
     },
     "execution_count": 120,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from nltk.corpus import wordnet as wn\n",
    "wn.synsets('motorcar')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['car', 'auto', 'automobile', 'machine', 'motorcar']"
      ]
     },
     "execution_count": 121,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "wn.synset('car.n.01').lemma_names()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'a motor vehicle with four wheels; usually propelled by an internal combustion engine'"
      ]
     },
     "execution_count": 122,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "wn.synset('car.n.01').definition()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['he needs a car to get to work']"
      ]
     },
     "execution_count": 123,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "wn.synset('car.n.01').examples()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[Lemma('car.n.01.car'),\n",
       " Lemma('car.n.01.auto'),\n",
       " Lemma('car.n.01.automobile'),\n",
       " Lemma('car.n.01.machine'),\n",
       " Lemma('car.n.01.motorcar')]"
      ]
     },
     "execution_count": 124,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# the pairing of a synset with a word is called a lemma\n",
    "wn.synset('car.n.01').lemmas()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Lemma('car.n.01.automobile')"
      ]
     },
     "execution_count": 125,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "wn.lemma('car.n.01.automobile')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Synset('car.n.01')"
      ]
     },
     "execution_count": 126,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "wn.lemma('car.n.01.automobile').synset()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'automobile'"
      ]
     },
     "execution_count": 127,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "wn.lemma('car.n.01.automobile').name()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[Synset('car.n.01'),\n",
       " Synset('car.n.02'),\n",
       " Synset('car.n.03'),\n",
       " Synset('car.n.04'),\n",
       " Synset('cable_car.n.01')]"
      ]
     },
     "execution_count": 128,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "wn.synsets('car')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 130,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['car', 'auto', 'automobile', 'machine', 'motorcar']\n",
      "['car', 'railcar', 'railway_car', 'railroad_car']\n",
      "['car', 'gondola']\n",
      "['car', 'elevator_car']\n",
      "['cable_car', 'car']\n"
     ]
    }
   ],
   "source": [
    "for synset in wn.synsets('car'):\n",
    "    print(synset.lemma_names())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 131,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[Lemma('car.n.01.car'),\n",
       " Lemma('car.n.02.car'),\n",
       " Lemma('car.n.03.car'),\n",
       " Lemma('car.n.04.car'),\n",
       " Lemma('cable_car.n.01.car')]"
      ]
     },
     "execution_count": 131,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "wn.lemmas('car')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 132,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[Lemma('dish.n.01.dish')]"
      ]
     },
     "execution_count": 132,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "wn.synset('dish.n.01').lemmas()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 133,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Lemma('dish.n.01.dish')"
      ]
     },
     "execution_count": 133,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "wn.lemma('dish.n.01.dish')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 134,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Synset('dish.n.01')"
      ]
     },
     "execution_count": 134,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "wn.lemma('dish.n.01.dish').synset()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 135,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<bound method Lemma.name of Lemma('dish.n.01.dish')>"
      ]
     },
     "execution_count": 135,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "wn.lemma('dish.n.01.dish').name"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 5.2   The WordNet Hierarchy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 136,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Synset('ambulance.n.01')"
      ]
     },
     "execution_count": 136,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "motorcar = wn.synset('car.n.01')\n",
    "types_of_motorcar = motorcar.hyponyms()\n",
    "types_of_motorcar[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 137,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Model_T',\n",
       " 'S.U.V.',\n",
       " 'SUV',\n",
       " 'Stanley_Steamer',\n",
       " 'ambulance',\n",
       " 'beach_waggon',\n",
       " 'beach_wagon',\n",
       " 'bus',\n",
       " 'cab',\n",
       " 'compact',\n",
       " 'compact_car',\n",
       " 'convertible',\n",
       " 'coupe',\n",
       " 'cruiser',\n",
       " 'electric',\n",
       " 'electric_automobile',\n",
       " 'electric_car',\n",
       " 'estate_car',\n",
       " 'gas_guzzler',\n",
       " 'hack',\n",
       " 'hardtop',\n",
       " 'hatchback',\n",
       " 'heap',\n",
       " 'horseless_carriage',\n",
       " 'hot-rod',\n",
       " 'hot_rod',\n",
       " 'jalopy',\n",
       " 'jeep',\n",
       " 'landrover',\n",
       " 'limo',\n",
       " 'limousine',\n",
       " 'loaner',\n",
       " 'minicar',\n",
       " 'minivan',\n",
       " 'pace_car',\n",
       " 'patrol_car',\n",
       " 'phaeton',\n",
       " 'police_car',\n",
       " 'police_cruiser',\n",
       " 'prowl_car',\n",
       " 'race_car',\n",
       " 'racer',\n",
       " 'racing_car',\n",
       " 'roadster',\n",
       " 'runabout',\n",
       " 'saloon',\n",
       " 'secondhand_car',\n",
       " 'sedan',\n",
       " 'sport_car',\n",
       " 'sport_utility',\n",
       " 'sport_utility_vehicle',\n",
       " 'sports_car',\n",
       " 'squad_car',\n",
       " 'station_waggon',\n",
       " 'station_wagon',\n",
       " 'stock_car',\n",
       " 'subcompact',\n",
       " 'subcompact_car',\n",
       " 'taxi',\n",
       " 'taxicab',\n",
       " 'tourer',\n",
       " 'touring_car',\n",
       " 'two-seater',\n",
       " 'used-car',\n",
       " 'waggon',\n",
       " 'wagon']"
      ]
     },
     "execution_count": 137,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sorted(lemma.name() for synset in types_of_motorcar for lemma in synset.lemmas())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 138,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[Synset('motor_vehicle.n.01')]"
      ]
     },
     "execution_count": 138,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "motorcar.hypernyms()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 139,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2"
      ]
     },
     "execution_count": 139,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "paths = motorcar.hypernym_paths()\n",
    "len(paths)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 140,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['entity.n.01',\n",
       " 'physical_entity.n.01',\n",
       " 'object.n.01',\n",
       " 'whole.n.02',\n",
       " 'artifact.n.01',\n",
       " 'instrumentality.n.03',\n",
       " 'container.n.01',\n",
       " 'wheeled_vehicle.n.01',\n",
       " 'self-propelled_vehicle.n.01',\n",
       " 'motor_vehicle.n.01',\n",
       " 'car.n.01']"
      ]
     },
     "execution_count": 140,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "[synset.name() for synset in paths[0]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 141,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['entity.n.01',\n",
       " 'physical_entity.n.01',\n",
       " 'object.n.01',\n",
       " 'whole.n.02',\n",
       " 'artifact.n.01',\n",
       " 'instrumentality.n.03',\n",
       " 'conveyance.n.03',\n",
       " 'vehicle.n.01',\n",
       " 'wheeled_vehicle.n.01',\n",
       " 'self-propelled_vehicle.n.01',\n",
       " 'motor_vehicle.n.01',\n",
       " 'car.n.01']"
      ]
     },
     "execution_count": 141,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "[synset.name() for synset in paths[1]]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 5.3   More Lexical Relations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 142,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[Synset('burl.n.02'),\n",
       " Synset('crown.n.07'),\n",
       " Synset('limb.n.02'),\n",
       " Synset('stump.n.01'),\n",
       " Synset('trunk.n.01')]"
      ]
     },
     "execution_count": 142,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "wn.synset('tree.n.01').part_meronyms()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 143,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[Synset('heartwood.n.01'), Synset('sapwood.n.01')]"
      ]
     },
     "execution_count": 143,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "wn.synset('tree.n.01').substance_meronyms()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 144,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[Synset('forest.n.01')]"
      ]
     },
     "execution_count": 144,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "wn.synset('tree.n.01').member_holonyms()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 145,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "batch.n.02: (often followed by `of') a large number or amount or extent\n",
      "mint.n.02: any north temperate plant of the genus Mentha with aromatic leaves and small mauve flowers\n",
      "mint.n.03: any member of the mint family of plants\n",
      "mint.n.04: the leaves of a mint plant used fresh or candied\n",
      "mint.n.05: a candy that is flavored with a mint oil\n",
      "mint.n.06: a plant where money is coined by authority of the government\n"
     ]
    }
   ],
   "source": [
    "for synset in wn.synsets('mint', wn.NOUN):\n",
    "    print(synset.name() + ':', synset.definition())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 146,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[Synset('mint.n.02')]"
      ]
     },
     "execution_count": 146,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "wn.synset('mint.n.04').part_holonyms()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 147,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[Synset('mint.n.05')]"
      ]
     },
     "execution_count": 147,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "wn.synset('mint.n.04').substance_holonyms()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 148,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[Synset('step.v.01')]"
      ]
     },
     "execution_count": 148,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "wn.synset('walk.v.01').entailments()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 149,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[Synset('chew.v.01'), Synset('swallow.v.01')]"
      ]
     },
     "execution_count": 149,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "wn.synset('eat.v.01').entailments()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 150,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[Synset('arouse.v.07'), Synset('disappoint.v.01')]"
      ]
     },
     "execution_count": 150,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "wn.synset('tease.v.03').entailments()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 151,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[Lemma('demand.n.02.demand')]"
      ]
     },
     "execution_count": 151,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "wn.lemma('supply.n.02.supply').antonyms()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 152,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[Lemma('linger.v.04.linger')]"
      ]
     },
     "execution_count": 152,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "wn.lemma('rush.v.01.rush').antonyms()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 153,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[Lemma('vertical.a.01.vertical'), Lemma('inclined.a.02.inclined')]"
      ]
     },
     "execution_count": 153,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "wn.lemma('horizontal.a.01.horizontal').antonyms()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 154,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[Lemma('legato.r.01.legato')]"
      ]
     },
     "execution_count": 154,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "wn.lemma('staccato.r.01.staccato').antonyms()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 5.4   Semantic Similarity"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 155,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[Synset('baleen_whale.n.01')]"
      ]
     },
     "execution_count": 155,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "right = wn.synset('right_whale.n.01')\n",
    "orca = wn.synset('orca.n.01')\n",
    "minke = wn.synset('minke_whale.n.01')\n",
    "tortoise = wn.synset('tortoise.n.01')\n",
    "novel = wn.synset('novel.n.01')\n",
    "right.lowest_common_hypernyms(minke)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 156,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[Synset('whale.n.02')]"
      ]
     },
     "execution_count": 156,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "right.lowest_common_hypernyms (orca)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 159,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[Synset('vertebrate.n.01')]"
      ]
     },
     "execution_count": 159,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "right.lowest_common_hypernyms (tortoise)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 160,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[Synset('entity.n.01')]"
      ]
     },
     "execution_count": 160,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "right.lowest_common_hypernyms(novel)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 161,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "14"
      ]
     },
     "execution_count": 161,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "wn.synset('baleen_whale.n.01').min_depth()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 162,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "13"
      ]
     },
     "execution_count": 162,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "wn.synset('whale.n.02').min_depth()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 163,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "8"
      ]
     },
     "execution_count": 163,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "wn.synset('vertebrate.n.01').min_depth()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 164,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 164,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "wn.synset('entity.n.01').min_depth()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 165,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.25"
      ]
     },
     "execution_count": 165,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "right.path_similarity(minke)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 166,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.16666666666666666"
      ]
     },
     "execution_count": 166,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "right.path_similarity(orca)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 167,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.07692307692307693"
      ]
     },
     "execution_count": 167,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "right.path_similarity(tortoise)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 168,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.043478260869565216"
      ]
     },
     "execution_count": 168,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "right.path_similarity(novel)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6   Summary\n",
    "\n",
    "* A text corpus is a large, structured collection of texts. NLTK comes with many corpora, e.g., the Brown Corpus, nltk.corpus.brown.\n",
    "\n",
    "* Some text corpora are categorized, e.g., by genre or topic; sometimes the categories of a corpus overlap each other.\n",
    "\n",
    "* A conditional frequency distribution is a collection of frequency distributions, each one for a different condition. They can be used for counting word frequencies, given a context or a genre.\n",
    "\n",
    "* Python programs more than a few lines long should be entered using a text editor, saved to a file with a .py extension, and accessed using an import statement.\n",
    "\n",
    "* Python functions permit you to associate a name with a particular block of code, and re-use that code as often as necessary.\n",
    "\n",
    "* Some functions, known as \"methods\", are associated with an object and we give the object name followed by a period followed by the function, like this: x.funct(y), e.g., word.isalpha().\n",
    "\n",
    "* To find out about some variable v, type help(v) in the Python interactive interpreter to read the help entry for this kind of object.\n",
    "\n",
    "* WordNet is a semantically-oriented dictionary of English, consisting of synonym sets — or synsets — and organized into a network.\n",
    "\n",
    "* Some functions are not available by default, but must be accessed using Python's import statement."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
