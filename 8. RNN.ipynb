{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Recurrent Neural Network\n",
    "\n",
    "A **Neural Network** is defined as a pattern matching through the connection of many very simple functions to create one very powerful function, very loosely based on connectec neurons in the brain.\n",
    "\n",
    "As per Jeff Dean, Google Senior Fellow in the Systems and Infrastructure Group: *when you hear the term deep learning, just think of a large deep neural net. Deep refers to the number of layers typically and so this is kind of the popular term that's been adopted in the press.* \n",
    "\n",
    "A **Recurrent Neural Network** is defined as a pattern matching through the connection of many very simple functions to create one very powerful function; this function has an understanding of the data's sequential nature (using feedback loops that form a sense of memory).\n",
    "\n",
    "**Notice:** \n",
    " * TF-IDF takes words independently, that is one spot in the vector per word\n",
    " * word2vec and doc2vec capature context with a window around the given word\n",
    " * RNN ingests the text in the same way that we actually read: evaluating each word within the context of the words that came before it."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Read in data and split into training and test set\n",
    "# NOTE: we are NOT cleaning the data\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "pd.set_option('display.max_colwidth', 1000)\n",
    "\n",
    "messages = pd.read_csv('spam.csv', encoding='latin-1')\n",
    "messages = messages.drop(labels = [\"Unnamed: 2\", \"Unnamed: 3\", \"Unnamed: 4\"], axis = 1)\n",
    "messages.columns = [\"label\", \"text\"]\n",
    "labels = np.where(messages['label']=='spam', 1, 0)\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(messages['text'],\n",
    "                                                    labels, test_size=0.2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import the tools we will need from keras\n",
    "from keras.preprocessing.text import Tokenizer\n",
    "from keras.preprocessing.sequence import pad_sequences"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize and fit the tokenizer\n",
    "tokenizer = Tokenizer()\n",
    "tokenizer.fit_on_texts(X_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Use that tokenizer to transform the text messages in the training and test sets\n",
    "X_train_seq = tokenizer.texts_to_sequences(X_train)\n",
    "X_test_seq = tokenizer.texts_to_sequences(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# What do these sequences look like?\n",
    "X_train_seq[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Pad the sequences so each sequence is the same length\n",
    "X_train_seq_padded = pad_sequences(X_train_seq, 50)\n",
    "X_test_seq_padded = pad_sequences(X_test_seq, 50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# What do these padded sequences look like?\n",
    "X_train_seq_padded[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Build Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import the tools needed from keras and define functions to calculate recall and precision\n",
    "import keras.backend as K\n",
    "from keras.layers import Dense, Embedding, LSTM\n",
    "from keras.models import Sequential\n",
    "\n",
    "def recall_m(y_true, y_pred):\n",
    "        true_positives = K.sum(K.round(K.clip(y_true * y_pred, 0, 1)))\n",
    "        possible_positives = K.sum(K.round(K.clip(y_true, 0, 1)))\n",
    "        recall = true_positives / (possible_positives + K.epsilon())\n",
    "        return recall\n",
    "\n",
    "def precision_m(y_true, y_pred):\n",
    "        true_positives = K.sum(K.round(K.clip(y_true * y_pred, 0, 1)))\n",
    "        predicted_positives = K.sum(K.round(K.clip(y_pred, 0, 1)))\n",
    "        precision = true_positives / (predicted_positives + K.epsilon())\n",
    "        return precision"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Construct a simple RNN model\n",
    "model = Sequential()\n",
    "\n",
    "model.add(Embedding(len(tokenizer.index_word)+1, 32))\n",
    "model.add(LSTM(32, dropout=0, recurrent_dropout=0))\n",
    "model.add(Dense(32, activation='relu'))\n",
    "model.add(Dense(1, activation='sigmoid'))\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compile the model\n",
    "model.compile(optimizer='adam',\n",
    "              loss='binary_crossentropy',\n",
    "              metrics=['accuracy', precision_m, recall_m])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Fit the RNN model\n",
    "history = model.fit(X_train_seq_padded, y_train, \n",
    "                    batch_size=32, epochs=10,\n",
    "                    validation_data=(X_test_seq_padded, y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot the evaluation metrics by each epoch for the model to see if we are over or underfitting\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "for i in ['accuracy', 'precision_m', 'recall_m']:\n",
    "    acc = history.history[i]\n",
    "    val_acc = history.history['val_{}'.format(i)]\n",
    "    epochs = range(1, len(acc) + 1)\n",
    "\n",
    "    plt.figure()\n",
    "    plt.plot(epochs, acc, label='Training Accuracy')\n",
    "    plt.plot(epochs, val_acc, label='Validation Accuracy')\n",
    "    plt.title('Results for {}'.format(i))\n",
    "    plt.legend()\n",
    "    plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
